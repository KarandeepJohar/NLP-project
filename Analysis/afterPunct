============================= test session starts ==============================
platform darwin -- Python 2.7.8, pytest-2.9.1, py-1.4.31, pluggy-0.3.1
rootdir: /Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests, inifile: 
collected 341 items

test_compute.py ...FF.............................F..........F.F............F.F....FFFF..FF......F.FF.F.....FFF.................................FF........FF..FF..F.F..........FFFF..FF...................F....FFF......F.F..................F..........F.F..F.............FFFFF..F..FFFF....FFFF.......F..FF....F..................FF........FFF.....FF..........FFE

==================================== ERRORS ====================================
________________________ ERROR at setup of test_factoid ________________________
file /Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py, line 45
  def test_factoid(param_factoid):
        fixture 'param_factoid' not found
        available fixtures: tmpdir_factory, pytestconfig, cache, recwarn, monkeypatch, record_xml_property, capfd, capsys, tmpdir
        use 'py.test --fixtures [testpath]' for help on them.

/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py:45
=================================== FAILURES ===================================
______________________________ test_yesno[param3] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114c4128>, (<src.tfidf.TF_IDF object at 0x10a445d10>, set(['alessandro', 'alessandro_volta', 'volta'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114c4128>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.47220176458358765, {u'tokens': [u'*', u'-LRB-', u'An', u'additional', u'invention', u'pioneered', u'by', u'Volta', u',', u'was', u'the', u'remotely', u'operated', u'pistol', u'.'], u'lemmas': [u'*', u'-lrb-', u'a', u'additional', u'invention', u'pioneer', u'by', u'Volta', u',', u'be', u'the', u'remotely', u'operate', u'pistol', u'.'], u'pos': [u'SYM', u'-LRB-', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'NNP', u',', u'VBD', u'DT', u'RB', u'VBN', u'NN', u'.'], u'char_offsets': [[3333, 3334], [3336, 3337], [3338, 3340], [3341, 3351], [3352, 3361], [3362, 3371], [3372, 3374], [3375, 3380], [3380, 3381], [3382, 3385], [3386, 3389], [3390, 3398], [3399, 3407], [3408, 3414], [3414, 3415]]}) 
answer: set([u'invent'])
candidate Sentence: (0.10924229025840759, {u'tokens': [u'In', u'1800', u',', u'as', u'the', u'result', u'of', u'a', u'professional', u'disagreement', u'over', u'the', u'galvanic', u'response', u'advocated', u'by', u'Galvani', u',', u'he', u'invented', u'the', u'voltaic', u'pile', u',', u'an', u'early', u'electric', u'battery', u',', u'which', u'produced', u'a', u'steady', u'electric', u'current', u'.'], u'lemmas': [u'in', u'1800', u',', u'as', u'the', u'result', u'of', u'a', u'professional', u'disagreement', u'over', u'the', u'galvanic', u'response', u'advocate', u'by', u'Galvani', u',', u'he', u'invent', u'the', u'voltaic', u'pile', u',', u'a', u'early', u'electric', u'battery', u',', u'which', u'produce', u'a', u'steady', u'electric', u'current', u'.'], u'pos': [u'IN', u'CD', u',', u'IN', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'NNP', u',', u'PRP', u'VBD', u'DT', u'JJ', u'NN', u',', u'DT', u'JJ', u'JJ', u'NN', u',', u'WDT', u'VBD', u'DT', u'JJ', u'JJ', u'JJ', u'.'], u'char_offsets': [[2451, 2453], [2454, 2458], [2458, 2459], [2460, 2462], [2463, 2466], [2467, 2473], [2474, 2476], [2477, 2478], [2479, 2491], [2492, 2504], [2505, 2509], [2510, 2513], [2514, 2522], [2523, 2531], [2532, 2541], [2542, 2544], [2545, 2552], [2552, 2553], [2554, 2556], [2557, 2565], [2566, 2569], [2570, 2577], [2578, 2582], [2582, 2583], [2584, 2586], [2587, 2592], [2593, 2601], [2602, 2609], [2609, 2610], [2611, 2616], [2617, 2625], [2626, 2627], [2628, 2634], [2635, 2643], [2644, 2651], [2651, 2652]]}) 
answer: set([u'operate', u'pistol', u'remotely'])
candidate Sentence: (0.072616934776306152, {u'tokens': [u'Count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u'-LRB-', u'February', u'18', u',', u'1745', u'--', u'March', u'5', u',', u'1827', u'-RRB-', u'was', u'an', u'Italian', u'Giuliano', u'Pancaldi', u',', u'``', u'Volta', u':', u'Science', u'and', u'culture', u'in', u'the', u'age', u'of', u'enlightenment', u"''", u',', u'Princeton', u'University', u'Press', u',', u'2003', u'.'], u'lemmas': [u'count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u'-lrb-', u'February', u'18', u',', u'1745', u'--', u'March', u'5', u',', u'1827', u'-rrb-', u'be', u'a', u'italian', u'Giuliano', u'Pancaldi', u',', u'``', u'Volta', u':', u'Science', u'and', u'culture', u'in', u'the', u'age', u'of', u'enlightenment', u"''", u',', u'Princeton', u'University', u'Press', u',', u'2003', u'.'], u'pos': [u'VB', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'CD', u',', u'CD', u':', u'NNP', u'CD', u',', u'CD', u'-RRB-', u'VBD', u'DT', u'JJ', u'NNP', u'NNP', u',', u'``', u'NNP', u':', u'NNP', u'CC', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u"''", u',', u'NNP', u'NNP', u'NNP', u',', u'CD', u'.'], u'char_offsets': [[0, 5], [6, 16], [17, 25], [26, 33], [34, 43], [44, 49], [50, 51], [51, 59], [60, 62], [62, 63], [64, 68], [69, 70], [71, 76], [77, 78], [78, 79], [80, 84], [84, 85], [86, 89], [90, 92], [93, 100], [101, 109], [110, 118], [118, 119], [120, 121], [121, 126], [126, 127], [128, 135], [136, 139], [140, 147], [148, 150], [151, 154], [155, 158], [159, 161], [162, 175], [175, 176], [176, 177], [178, 187], [188, 198], [199, 204], [204, 205], [206, 210], [210, 211]]}) 
answer: set([u'remotely', u'pistol', u'invent', u'operate'])
candidate Sentence: (0.066992253065109253, {u'tokens': [u'*', u'History', u'of', u'the', u'battery', u'*', u'History', u'of', u'the', u'internal', u'combustion', u'engine', u'*', u'Volta', u'and', u'the', u'``', u'Pile', u"''", u'*', u'Count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u':', u'A', u'Pioneer', u'in', u'Electrochemistry'], u'lemmas': [u'*', u'history', u'of', u'the', u'battery', u'*', u'history', u'of', u'the', u'internal', u'combustion', u'engine', u'*', u'Volta', u'and', u'the', u'``', u'pile', u"''", u'*', u'count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u':', u'A', u'Pioneer', u'in', u'Electrochemistry'], u'pos': [u'SYM', u'NN', u'IN', u'DT', u'NN', u'SYM', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u'SYM', u'NNP', u'CC', u'DT', u'``', u'VB', u"''", u'SYM', u'VB', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u':', u'NNP', u'NNP', u'IN', u'NNP'], u'char_offsets': [[5833, 5834], [5835, 5842], [5843, 5845], [5846, 5849], [5850, 5857], [5858, 5859], [5860, 5867], [5868, 5870], [5871, 5874], [5875, 5883], [5884, 5894], [5895, 5901], [5902, 5903], [5905, 5910], [5911, 5914], [5915, 5918], [5919, 5920], [5920, 5924], [5924, 5925], [5926, 5927], [5929, 5934], [5935, 5945], [5946, 5954], [5955, 5962], [5963, 5972], [5973, 5978], [5978, 5979], [5980, 5981], [5982, 5989], [5990, 5992], [5993, 6009]]}) 
answer: set([u'remotely', u'pistol', u'invent', u'operate'])
candidate Sentence: (0.066288046538829803, {u'tokens': [u'The', u'reactions', u'in', u'this', u'cell', u'are', u'as', u'follows', u':', u':', u'Zn', u'\u2192', u'Zn', u'2', u'+', u'+', u'2e', u'-', u':', u'2H', u'+', u'+', u'2e', u'-', u'\u2192', u'H', u'2', u'The', u'copper', u'does', u'not', u'react', u',', u'functioning', u'as', u'an', u'electrode', u'for', u'the', u'reaction', u'.'], u'lemmas': [u'the', u'reaction', u'in', u'this', u'cell', u'be', u'as', u'follow', u':', u':', u'zn', u'\u2192', u'zn', u'2', u'+', u'+', u'2e', u'-', u':', u'2h', u'+', u'+', u'2e', u'-', u'\u2192', u'h', u'2', u'the', u'copper', u'do', u'not', u'react', u',', u'function', u'as', u'a', u'electrode', u'for', u'the', u'reaction', u'.'], u'pos': [u'DT', u'NNS', u'IN', u'DT', u'NN', u'VBP', u'IN', u'VBZ', u':', u':', u'NN', u'CD', u'NN', u'CD', u'CC', u'CC', u'SYM', u':', u':', u'NN', u'CC', u'CC', u'SYM', u':', u'NN', u'NN', u'CD', u'DT', u'NN', u'VBZ', u'RB', u'VB', u',', u'VBG', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[4459, 4462], [4463, 4472], [4473, 4475], [4476, 4480], [4481, 4485], [4486, 4489], [4490, 4492], [4493, 4500], [4500, 4501], [4502, 4503], [4504, 4506], [4509, 4510], [4513, 4515], [4516, 4517], [4517, 4518], [4520, 4521], [4522, 4524], [4525, 4526], [4527, 4528], [4529, 4531], [4532, 4533], [4535, 4536], [4538, 4540], [4541, 4542], [4546, 4547], [4550, 4551], [4552, 4553], [4554, 4557], [4558, 4564], [4565, 4569], [4570, 4573], [4574, 4579], [4579, 4580], [4581, 4592], [4593, 4595], [4596, 4598], [4599, 4608], [4609, 4612], [4613, 4616], [4617, 4625], [4625, 4626]]}) 
answer: set([u'operate', u'pistol', u'invent', u'remotely'])
candidate Sentence: (0.065874144434928894, {u'tokens': [u'He', u'made', u'use', u'of', u'a', u'Leyden', u'jar', u'to', u'send', u'an', u'electric', u'current', u'from', u'Como', u'to', u'Milan', u'-LRB-', u'~', u'50', u'km', u'or', u'~', u'30', u'miles', u'-RRB-', u',', u'which', u'in', u'turn', u',', u'set', u'off', u'the', u'pistol', u'.'], u'lemmas': [u'he', u'make', u'use', u'of', u'a', u'Leyden', u'jar', u'to', u'send', u'a', u'electric', u'current', u'from', u'Como', u'to', u'Milan', u'-lrb-', u'~', u'50', u'km', u'or', u'~', u'30', u'mile', u'-rrb-', u',', u'which', u'in', u'turn', u',', u'set', u'off', u'the', u'pistol', u'.'], u'pos': [u'PRP', u'VBD', u'NN', u'IN', u'DT', u'NNP', u'NN', u'TO', u'VB', u'DT', u'JJ', u'JJ', u'IN', u'NNP', u'TO', u'NNP', u'-LRB-', u'CD', u'CD', u'NN', u'CC', u'NN', u'CD', u'NNS', u'-RRB-', u',', u'WDT', u'IN', u'NN', u',', u'VBN', u'RP', u'DT', u'NN', u'.'], u'char_offsets': [[3416, 3418], [3419, 3423], [3424, 3427], [3428, 3430], [3431, 3432], [3433, 3439], [3440, 3443], [3444, 3446], [3447, 3451], [3452, 3454], [3455, 3463], [3464, 3471], [3472, 3476], [3477, 3481], [3482, 3484], [3485, 3490], [3491, 3492], [3492, 3493], [3493, 3495], [3496, 3498], [3499, 3501], [3502, 3503], [3503, 3505], [3506, 3511], [3511, 3512], [3512, 3513], [3514, 3519], [3520, 3522], [3523, 3527], [3527, 3528], [3529, 3532], [3533, 3536], [3537, 3540], [3541, 3547], [3547, 3548]]}) 
answer: set([u'operate', u'invent', u'remotely'])
candidate Sentence: (0.018738878890872002, {u'tokens': [u'He', u'is', u'buried', u'in', u'Camnago', u'Volta', u'.'], u'lemmas': [u'he', u'be', u'bury', u'in', u'Camnago', u'Volta', u'.'], u'pos': [u'PRP', u'VBZ', u'VBN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[5290, 5292], [5293, 5295], [5296, 5302], [5303, 5305], [5306, 5313], [5314, 5319], [5319, 5320]]}) 
answer: set([u'remotely', u'pistol', u'invent', u'operate'])
candidate Sentence: (0.015905650332570076, {u'tokens': [u'This', u'may', u'be', u'called', u'Volta', u"'s", u'Law', u'of', u'the', u'electrochemical', u'series', u'.'], u'lemmas': [u'this', u'may', u'be', u'call', u'Volta', u"'s", u'law', u'of', u'the', u'electrochemical', u'series', u'.'], u'pos': [u'DT', u'MD', u'VB', u'VBN', u'NNP', u'POS', u'NN', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[2389, 2393], [2394, 2397], [2398, 2400], [2401, 2407], [2408, 2413], [2413, 2415], [2416, 2419], [2420, 2422], [2423, 2426], [2427, 2442], [2443, 2449], [2449, 2450]]}) 
answer: set([u'remotely', u'pistol', u'invent', u'operate'])
candidate Sentence: (0.015103761106729507, {u'tokens': [u'For', u'a', u'photograph', u'of', u'his', u'gravesite', u',', u'and', u'other', u'Volta', u'locales', u',', u'see', u'Volta', u"'s", u'legacy', u'is', u'celebrated', u'by', u'a', u'Temple', u'on', u'the', u'shore', u'of', u'Lake', u'Como', u'in', u'the', u'centre', u'of', u'the', u'town', u'.'], u'lemmas': [u'for', u'a', u'photograph', u'of', u'he', u'gravesite', u',', u'and', u'other', u'Volta', u'locale', u',', u'see', u'Volta', u"'s", u'legacy', u'be', u'celebrate', u'by', u'a', u'Temple', u'on', u'the', u'shore', u'of', u'Lake', u'Como', u'in', u'the', u'centre', u'of', u'the', u'town', u'.'], u'pos': [u'IN', u'DT', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'JJ', u'NNP', u'NNS', u',', u'VBP', u'NNP', u'POS', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'NNP', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[5321, 5324], [5325, 5326], [5327, 5337], [5338, 5340], [5341, 5344], [5345, 5354], [5354, 5355], [5356, 5359], [5360, 5365], [5366, 5371], [5372, 5379], [5379, 5380], [5381, 5384], [5385, 5390], [5390, 5392], [5393, 5399], [5400, 5402], [5403, 5413], [5414, 5416], [5417, 5418], [5419, 5425], [5426, 5428], [5429, 5432], [5433, 5438], [5439, 5441], [5442, 5446], [5447, 5451], [5452, 5454], [5455, 5458], [5459, 5465], [5466, 5468], [5469, 5472], [5473, 5477], [5477, 5478]]}) 
answer: set([u'remotely', u'pistol', u'invent', u'operate'])
candidate Sentence: (0.01345398835837841, {u'tokens': [u'Volta', u'retired', u'in', u'1819', u'in', u'his', u'estate', u'in', u'Camnago', u',', u'a', u'frazione', u'of', u'Como', u'now', u'called', u'Camnago', u'Volta', u'after', u'him', u',', u'where', u'he', u'died', u'on', u'March', u'5', u',', u'1827', u'.'], u'lemmas': [u'Volta', u'retire', u'in', u'1819', u'in', u'he', u'estate', u'in', u'Camnago', u',', u'a', u'frazione', u'of', u'Como', u'now', u'call', u'Camnago', u'Volta', u'after', u'he', u',', u'where', u'he', u'die', u'on', u'March', u'5', u',', u'1827', u'.'], u'pos': [u'NNP', u'VBD', u'IN', u'CD', u'IN', u'PRP$', u'NN', u'IN', u'NNP', u',', u'DT', u'NN', u'IN', u'NNP', u'RB', u'VBD', u'NNP', u'NNP', u'IN', u'PRP', u',', u'WRB', u'PRP', u'VBD', u'IN', u'NNP', u'CD', u',', u'CD', u'.'], u'char_offsets': [[5151, 5156], [5157, 5164], [5165, 5167], [5168, 5172], [5173, 5175], [5176, 5179], [5180, 5186], [5187, 5189], [5190, 5197], [5197, 5198], [5199, 5200], [5201, 5209], [5210, 5212], [5213, 5217], [5218, 5221], [5222, 5228], [5229, 5236], [5237, 5242], [5243, 5248], [5249, 5252], [5252, 5253], [5254, 5259], [5260, 5262], [5263, 5267], [5268, 5270], [5271, 5276], [5277, 5278], [5278, 5279], [5280, 5284], [5284, 5285]]}) 
answer: set([u'remotely', u'pistol', u'invent', u'operate'])

Did Alessandro Volta invent the remotely operated pistol?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
INFO:CoreNLP_JavaServer: INPUT: 7 documents, 355 characters, 59 tokens, 50.7 char/doc, 8.4 tok/doc RATES: 3.698 doc/sec, 31.2 tok/sec

INFO:CoreNLP_JavaServer: INPUT: 8 documents, 412 characters, 68 tokens, 51.5 char/doc, 8.5 tok/doc RATES: 3.895 doc/sec, 33.1 tok/sec

Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114c4128>.answer
______________________________ test_yesno[param4] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114c4368>, (<src.tfidf.TF_IDF object at 0x10a445d10>, set(['alessandro', 'alessandro_volta', 'volta'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Volta was taught in public schools.') == True
E                +  where 'Volta was taught in public schools.' = <src.question_processing.Question_parser instance at 0x1114c4368>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.61436331272125244, {u'tokens': [u'Volta', u'was', u'born', u'in', u'Como', u',', u'Italy', u'and', u'was', u'taught', u'in', u'the', u'public', u'schools', u'there', u'.'], u'lemmas': [u'Volta', u'be', u'bear', u'in', u'Como', u',', u'Italy', u'and', u'be', u'teach', u'in', u'the', u'public', u'school', u'there', u'.'], u'pos': [u'NNP', u'VBD', u'VBN', u'IN', u'NNP', u',', u'NNP', u'CC', u'VBD', u'VBN', u'IN', u'DT', u'JJ', u'NNS', u'RB', u'.'], u'char_offsets': [[375, 380], [381, 384], [385, 389], [390, 392], [393, 397], [397, 398], [399, 404], [405, 408], [409, 412], [413, 419], [420, 422], [423, 426], [427, 433], [434, 441], [442, 447], [447, 448]]}) 
answer: set([])
candidate Sentence: (0.14638951420783997, {u'tokens': [u'The', u'primitive', u'cell', u'is', u'widely', u'used', u'in', u'schools', u'to', u'demonstrate', u'the', u'laws', u'of', u'electricity', u'and', u'is', u'known', u'as', u'the', u'Lemon', u'battery', u'.'], u'lemmas': [u'the', u'primitive', u'cell', u'be', u'widely', u'use', u'in', u'school', u'to', u'demonstrate', u'the', u'law', u'of', u'electricity', u'and', u'be', u'know', u'as', u'the', u'Lemon', u'battery', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'RB', u'VBN', u'IN', u'NNS', u'TO', u'VB', u'DT', u'NNS', u'IN', u'NN', u'CC', u'VBZ', u'VBN', u'IN', u'DT', u'NNP', u'NN', u'.'], u'char_offsets': [[4966, 4969], [4970, 4979], [4980, 4984], [4985, 4987], [4988, 4994], [4995, 4999], [5000, 5002], [5003, 5010], [5011, 5013], [5014, 5025], [5026, 5029], [5030, 5034], [5035, 5037], [5038, 5049], [5050, 5053], [5054, 5056], [5057, 5062], [5063, 5065], [5066, 5069], [5070, 5075], [5076, 5083], [5083, 5084]]}) 
answer: set([u'teach', u'public'])
candidate Sentence: (0.096548967063426971, {u'tokens': [u'Count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u'-LRB-', u'February', u'18', u',', u'1745', u'--', u'March', u'5', u',', u'1827', u'-RRB-', u'was', u'an', u'Italian', u'Giuliano', u'Pancaldi', u',', u'``', u'Volta', u':', u'Science', u'and', u'culture', u'in', u'the', u'age', u'of', u'enlightenment', u"''", u',', u'Princeton', u'University', u'Press', u',', u'2003', u'.'], u'lemmas': [u'count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u'-lrb-', u'February', u'18', u',', u'1745', u'--', u'March', u'5', u',', u'1827', u'-rrb-', u'be', u'a', u'italian', u'Giuliano', u'Pancaldi', u',', u'``', u'Volta', u':', u'Science', u'and', u'culture', u'in', u'the', u'age', u'of', u'enlightenment', u"''", u',', u'Princeton', u'University', u'Press', u',', u'2003', u'.'], u'pos': [u'VB', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'CD', u',', u'CD', u':', u'NNP', u'CD', u',', u'CD', u'-RRB-', u'VBD', u'DT', u'JJ', u'NNP', u'NNP', u',', u'``', u'NNP', u':', u'NNP', u'CC', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u"''", u',', u'NNP', u'NNP', u'NNP', u',', u'CD', u'.'], u'char_offsets': [[0, 5], [6, 16], [17, 25], [26, 33], [34, 43], [44, 49], [50, 51], [51, 59], [60, 62], [62, 63], [64, 68], [69, 70], [71, 76], [77, 78], [78, 79], [80, 84], [84, 85], [86, 89], [90, 92], [93, 100], [101, 109], [110, 118], [118, 119], [120, 121], [121, 126], [126, 127], [128, 135], [136, 139], [140, 147], [148, 150], [151, 154], [155, 158], [159, 161], [162, 175], [175, 176], [176, 177], [178, 187], [188, 198], [199, 204], [204, 205], [206, 210], [210, 211]]}) 
answer: set([u'school', u'teach', u'public'])
candidate Sentence: (0.085345305502414703, {u'tokens': [u'*', u'History', u'of', u'the', u'battery', u'*', u'History', u'of', u'the', u'internal', u'combustion', u'engine', u'*', u'Volta', u'and', u'the', u'``', u'Pile', u"''", u'*', u'Count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u':', u'A', u'Pioneer', u'in', u'Electrochemistry'], u'lemmas': [u'*', u'history', u'of', u'the', u'battery', u'*', u'history', u'of', u'the', u'internal', u'combustion', u'engine', u'*', u'Volta', u'and', u'the', u'``', u'pile', u"''", u'*', u'count', u'Alessandro', u'Giuseppe', u'Antonio', u'Anastasio', u'Volta', u':', u'A', u'Pioneer', u'in', u'Electrochemistry'], u'pos': [u'SYM', u'NN', u'IN', u'DT', u'NN', u'SYM', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u'SYM', u'NNP', u'CC', u'DT', u'``', u'VB', u"''", u'SYM', u'VB', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u':', u'NNP', u'NNP', u'IN', u'NNP'], u'char_offsets': [[5833, 5834], [5835, 5842], [5843, 5845], [5846, 5849], [5850, 5857], [5858, 5859], [5860, 5867], [5868, 5870], [5871, 5874], [5875, 5883], [5884, 5894], [5895, 5901], [5902, 5903], [5905, 5910], [5911, 5914], [5915, 5918], [5919, 5920], [5920, 5924], [5924, 5925], [5926, 5927], [5929, 5934], [5935, 5945], [5946, 5954], [5955, 5962], [5963, 5972], [5973, 5978], [5978, 5979], [5980, 5981], [5982, 5989], [5990, 5992], [5993, 6009]]}) 
answer: set([u'school', u'teach', u'public'])
candidate Sentence: (0.044516365975141525, {u'tokens': [u'He', u'is', u'buried', u'in', u'Camnago', u'Volta', u'.'], u'lemmas': [u'he', u'be', u'bury', u'in', u'Camnago', u'Volta', u'.'], u'pos': [u'PRP', u'VBZ', u'VBN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[5290, 5292], [5293, 5295], [5296, 5302], [5303, 5305], [5306, 5313], [5314, 5319], [5319, 5320]]}) 
answer: set([u'teach', u'public', u'school'])
candidate Sentence: (0.034307383000850677, {u'tokens': [u'In', u'honor', u'of', u'his', u'work', u',', u'Volta', u'was', u'made', u'a', u'count', u'by', u'Napoleon', u'in', u'1810', u'.'], u'lemmas': [u'in', u'honor', u'of', u'he', u'work', u',', u'Volta', u'be', u'make', u'a', u'count', u'by', u'Napoleon', u'in', u'1810', u'.'], u'pos': [u'IN', u'NN', u'IN', u'PRP$', u'NN', u',', u'NNP', u'VBD', u'VBN', u'DT', u'NN', u'IN', u'NNP', u'IN', u'CD', u'.'], u'char_offsets': [[5085, 5087], [5088, 5093], [5094, 5096], [5097, 5100], [5101, 5105], [5105, 5106], [5107, 5112], [5113, 5116], [5117, 5121], [5122, 5123], [5124, 5129], [5130, 5132], [5133, 5141], [5142, 5144], [5145, 5149], [5149, 5150]]}) 
answer: set([u'teach', u'public', u'school'])
candidate Sentence: (0.028604079037904739, {u'tokens': [u'This', u'may', u'be', u'called', u'Volta', u"'s", u'Law', u'of', u'the', u'electrochemical', u'series', u'.'], u'lemmas': [u'this', u'may', u'be', u'call', u'Volta', u"'s", u'law', u'of', u'the', u'electrochemical', u'series', u'.'], u'pos': [u'DT', u'MD', u'VB', u'VBN', u'NNP', u'POS', u'NN', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[2389, 2393], [2394, 2397], [2398, 2400], [2401, 2407], [2408, 2413], [2413, 2415], [2416, 2419], [2420, 2422], [2423, 2426], [2427, 2442], [2443, 2449], [2449, 2450]]}) 
answer: set([u'teach', u'school', u'public'])
candidate Sentence: (0.026803376153111458, {u'tokens': [u'Volta', u'retired', u'in', u'1819', u'in', u'his', u'estate', u'in', u'Camnago', u',', u'a', u'frazione', u'of', u'Como', u'now', u'called', u'Camnago', u'Volta', u'after', u'him', u',', u'where', u'he', u'died', u'on', u'March', u'5', u',', u'1827', u'.'], u'lemmas': [u'Volta', u'retire', u'in', u'1819', u'in', u'he', u'estate', u'in', u'Camnago', u',', u'a', u'frazione', u'of', u'Como', u'now', u'call', u'Camnago', u'Volta', u'after', u'he', u',', u'where', u'he', u'die', u'on', u'March', u'5', u',', u'1827', u'.'], u'pos': [u'NNP', u'VBD', u'IN', u'CD', u'IN', u'PRP$', u'NN', u'IN', u'NNP', u',', u'DT', u'NN', u'IN', u'NNP', u'RB', u'VBD', u'NNP', u'NNP', u'IN', u'PRP', u',', u'WRB', u'PRP', u'VBD', u'IN', u'NNP', u'CD', u',', u'CD', u'.'], u'char_offsets': [[5151, 5156], [5157, 5164], [5165, 5167], [5168, 5172], [5173, 5175], [5176, 5179], [5180, 5186], [5187, 5189], [5190, 5197], [5197, 5198], [5199, 5200], [5201, 5209], [5210, 5212], [5213, 5217], [5218, 5221], [5222, 5228], [5229, 5236], [5237, 5242], [5243, 5248], [5249, 5252], [5252, 5253], [5254, 5259], [5260, 5262], [5263, 5267], [5268, 5270], [5271, 5276], [5277, 5278], [5278, 5279], [5280, 5284], [5284, 5285]]}) 
answer: set([u'school', u'teach', u'public'])
candidate Sentence: (0.02561786025762558, {u'tokens': [u'For', u'a', u'photograph', u'of', u'his', u'gravesite', u',', u'and', u'other', u'Volta', u'locales', u',', u'see', u'Volta', u"'s", u'legacy', u'is', u'celebrated', u'by', u'a', u'Temple', u'on', u'the', u'shore', u'of', u'Lake', u'Como', u'in', u'the', u'centre', u'of', u'the', u'town', u'.'], u'lemmas': [u'for', u'a', u'photograph', u'of', u'he', u'gravesite', u',', u'and', u'other', u'Volta', u'locale', u',', u'see', u'Volta', u"'s", u'legacy', u'be', u'celebrate', u'by', u'a', u'Temple', u'on', u'the', u'shore', u'of', u'Lake', u'Como', u'in', u'the', u'centre', u'of', u'the', u'town', u'.'], u'pos': [u'IN', u'DT', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'JJ', u'NNP', u'NNS', u',', u'VBP', u'NNP', u'POS', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'NNP', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[5321, 5324], [5325, 5326], [5327, 5337], [5338, 5340], [5341, 5344], [5345, 5354], [5354, 5355], [5356, 5359], [5360, 5365], [5366, 5371], [5372, 5379], [5379, 5380], [5381, 5384], [5385, 5390], [5390, 5392], [5393, 5399], [5400, 5402], [5403, 5413], [5414, 5416], [5417, 5418], [5419, 5425], [5426, 5428], [5429, 5432], [5433, 5438], [5439, 5441], [5442, 5446], [5447, 5451], [5452, 5454], [5455, 5458], [5459, 5465], [5466, 5468], [5469, 5472], [5473, 5477], [5477, 5478]]}) 
answer: set([u'teach', u'public', u'school'])
candidate Sentence: (0.021168798208236694, {u'tokens': [u'Volta', u'carried', u'out', u'his', u'experimental', u'studies', u'and', u'made', u'his', u'first', u'inventions', u'in', u'Como', u'.'], u'lemmas': [u'Volta', u'carry', u'out', u'he', u'experimental', u'study', u'and', u'make', u'he', u'first', u'invention', u'in', u'Como', u'.'], u'pos': [u'NNP', u'VBD', u'RP', u'PRP$', u'JJ', u'NNS', u'CC', u'VBD', u'PRP$', u'JJ', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[5751, 5756], [5757, 5764], [5765, 5768], [5769, 5772], [5773, 5785], [5786, 5793], [5794, 5797], [5798, 5802], [5803, 5806], [5807, 5812], [5813, 5823], [5824, 5826], [5827, 5831], [5831, 5832]]}) 
answer: set([u'school', u'teach', u'public'])

Was Alessandro Volta taught in public schools?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Volta was taught in public schools.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
INFO:CoreNLP_JavaServer: INPUT: 9 documents, 458 characters, 76 tokens, 50.9 char/doc, 8.4 tok/doc RATES: 4.157 doc/sec, 35.1 tok/sec

INFO:CoreNLP_JavaServer: INPUT: 10 documents, 504 characters, 84 tokens, 50.4 char/doc, 8.4 tok/doc RATES: 4.382 doc/sec, 36.8 tok/sec

Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Volta was taught in public schools.') == True
 +  where 'Volta was taught in public schools.' = <src.question_processing.Question_parser instance at 0x1114c4368>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param34] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cabd8>, (<src.tfidf.TF_IDF object at 0x10e16fd50>, set(['antwerp'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114cabd8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.37896206974983215, {u'tokens': [u'The', u'municipality', u'comprises', u'the', u'city', u'of', u'Antwerp', u'proper', u'and', u'several', u'towns', u'.'], u'lemmas': [u'the', u'municipality', u'comprise', u'the', u'city', u'of', u'Antwerp', u'proper', u'and', u'several', u'town', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'DT', u'NN', u'IN', u'NNP', u'JJ', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[10320, 10323], [10324, 10336], [10337, 10346], [10347, 10350], [10351, 10355], [10356, 10358], [10359, 10366], [10367, 10373], [10374, 10377], [10378, 10385], [10386, 10391], [10391, 10392]]}) 
answer: set([])
candidate Sentence: (0.32088583707809448, {u'tokens': [u'This', u'is', u'the', u'population', u'of', u'the', u'city', u'of', u'Antwerp', u'only', u',', u'not', u'of', u'the', u'larger', u'current', u'municipality', u'of', u'the', u'same', u'name', u'.'], u'lemmas': [u'this', u'be', u'the', u'population', u'of', u'the', u'city', u'of', u'Antwerp', u'only', u',', u'not', u'of', u'the', u'larger', u'current', u'municipality', u'of', u'the', u'same', u'name', u'.'], u'pos': [u'DT', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'NNP', u'RB', u',', u'RB', u'IN', u'DT', u'JJR', u'JJ', u'NN', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[10211, 10215], [10216, 10218], [10219, 10222], [10223, 10233], [10234, 10236], [10237, 10240], [10241, 10245], [10246, 10248], [10249, 10256], [10257, 10261], [10261, 10262], [10263, 10266], [10267, 10269], [10270, 10273], [10274, 10280], [10281, 10288], [10289, 10301], [10302, 10304], [10305, 10308], [10309, 10313], [10314, 10318], [10318, 10319]]}) 
answer: set([])
candidate Sentence: (0.29252937436103821, {u'tokens': [u'Antwerp', u'-LRB-', u',', u'Dutch', u':', u',', u'-RRB-', u'is', u'a', u'city', u'and', u'municipality', u'in', u'Belgium', u'and', u'the', u'capital', u'of', u'the', u'Antwerp', u'province', u'in', u'Flanders', u',', u'one', u'of', u'Belgium', u"'s", u'three', u'regions', u'.'], u'lemmas': [u'Antwerp', u'-lrb-', u',', u'Dutch', u':', u',', u'-rrb-', u'be', u'a', u'city', u'and', u'municipality', u'in', u'Belgium', u'and', u'the', u'capital', u'of', u'the', u'Antwerp', u'province', u'in', u'Flanders', u',', u'one', u'of', u'Belgium', u"'s", u'three', u'region', u'.'], u'pos': [u'NNP', u'-LRB-', u',', u'NNPS', u':', u',', u'-RRB-', u'VBZ', u'DT', u'NN', u'CC', u'NN', u'IN', u'NNP', u'CC', u'DT', u'NN', u'IN', u'DT', u'NNP', u'NN', u'IN', u'NNP', u',', u'CD', u'IN', u'NNP', u'POS', u'CD', u'NNS', u'.'], u'char_offsets': [[179, 186], [187, 188], [189, 190], [191, 196], [196, 197], [199, 200], [202, 203], [204, 206], [207, 208], [209, 213], [214, 217], [218, 230], [231, 233], [234, 241], [242, 245], [246, 249], [250, 257], [258, 260], [261, 264], [265, 272], [273, 281], [282, 284], [285, 293], [293, 294], [295, 298], [299, 301], [302, 309], [309, 311], [312, 317], [318, 325], [325, 326]]}) 
answer: set([])
candidate Sentence: (0.12764178216457367, {u'tokens': [u'Antwerp', u"'s", u'total', u'population', u'is', u'472,071', u'-LRB-', u'as', u'of', u'1', u'January', u'2008', u'-RRB-', u'Statistics', u'Belgium', u';', u'Population', u'de', u'droit', u'par', u'commune', u'au', u'1', u'janvier', u'2008', u'-LRB-', u'excel-file', u'-RRB-', u'Population', u'of', u'all', u'municipalities', u'in', u'Belgium', u',', u'as', u'of', u'1', u'January', u'2008', u'.'], u'lemmas': [u'Antwerp', u"'s", u'total', u'population', u'be', u'472,071', u'-lrb-', u'as', u'of', u'1', u'January', u'2008', u'-rrb-', u'Statistics', u'Belgium', u';', u'Population', u'de', u'droit', u'par', u'commune', u'au', u'1', u'janvier', u'2008', u'-lrb-', u'excel-file', u'-rrb-', u'Population', u'of', u'all', u'municipality', u'in', u'Belgium', u',', u'as', u'of', u'1', u'January', u'2008', u'.'], u'pos': [u'NNP', u'POS', u'JJ', u'NN', u'VBZ', u'CD', u'-LRB-', u'IN', u'IN', u'CD', u'NNP', u'CD', u'-RRB-', u'NNPS', u'NNP', u':', u'NNP', u'NNP', u'JJ', u'NN', u'NN', u'NN', u'CD', u'NN', u'CD', u'-LRB-', u'NN', u'-RRB-', u'NNP', u'IN', u'DT', u'NNS', u'IN', u'NNP', u',', u'IN', u'IN', u'CD', u'NNP', u'CD', u'.'], u'char_offsets': [[327, 334], [334, 336], [337, 342], [343, 353], [354, 356], [357, 364], [365, 366], [366, 368], [369, 371], [372, 373], [374, 381], [382, 386], [386, 387], [390, 400], [401, 408], [408, 409], [410, 420], [421, 423], [424, 429], [430, 433], [434, 441], [442, 444], [445, 446], [447, 454], [455, 459], [460, 461], [461, 471], [471, 472], [473, 483], [484, 486], [487, 490], [491, 505], [506, 508], [509, 516], [516, 517], [518, 520], [521, 523], [524, 525], [526, 533], [534, 538], [538, 539]]}) 
answer: set([])
candidate Sentence: (0.059413038194179535, {u'tokens': [u'Antwerp', u'is', u'a', u'rising', u'fashion', u'city', u',', u'and', u'has', u'produced', u'designers', u'such', u'as', u'the', u'Antwerp', u'Six', u'.'], u'lemmas': [u'Antwerp', u'be', u'a', u'rise', u'fashion', u'city', u',', u'and', u'have', u'produce', u'designer', u'such', u'as', u'the', u'Antwerp', u'six', u'.'], u'pos': [u'NNP', u'VBZ', u'DT', u'VBG', u'NN', u'NN', u',', u'CC', u'VBZ', u'VBN', u'NNS', u'JJ', u'IN', u'DT', u'NNP', u'CD', u'.'], u'char_offsets': [[19739, 19746], [19747, 19749], [19750, 19751], [19752, 19758], [19759, 19766], [19767, 19771], [19771, 19772], [19773, 19776], [19777, 19780], [19781, 19789], [19790, 19799], [19800, 19804], [19805, 19807], [19808, 19811], [19812, 19819], [19820, 19823], [19823, 19824]]}) 
answer: set([u'municipality'])
candidate Sentence: (0.049288515001535416, {u'tokens': [u'Antwerp', u'became', u'a', u'margraviate', u',', u'a', u'border', u'province', u'facing', u'the', u'County', u'of', u'Flanders', u'.'], u'lemmas': [u'Antwerp', u'become', u'a', u'margraviate', u',', u'a', u'border', u'province', u'face', u'the', u'County', u'of', u'Flanders', u'.'], u'pos': [u'NNP', u'VBD', u'DT', u'NN', u',', u'DT', u'NN', u'NN', u'VBG', u'DT', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[4021, 4028], [4029, 4035], [4036, 4037], [4038, 4049], [4049, 4050], [4051, 4052], [4053, 4059], [4060, 4068], [4069, 4075], [4076, 4079], [4080, 4086], [4087, 4089], [4090, 4098], [4098, 4099]]}) 
answer: set([u'municipality'])
candidate Sentence: (0.04727683961391449, {u'tokens': [u'Antwerp', u'had', u'a', u'policy', u'of', u'toleration', u',', u'which', u'attracted', u'a', u'large', u'orthodox', u'Jewish', u'community', u'.'], u'lemmas': [u'Antwerp', u'have', u'a', u'policy', u'of', u'toleration', u',', u'which', u'attract', u'a', u'large', u'orthodox', u'jewish', u'community', u'.'], u'pos': [u'NNP', u'VBD', u'DT', u'NN', u'IN', u'NN', u',', u'WDT', u'VBD', u'DT', u'JJ', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[5776, 5783], [5784, 5787], [5788, 5789], [5790, 5796], [5797, 5799], [5800, 5810], [5810, 5811], [5812, 5817], [5818, 5827], [5828, 5829], [5830, 5835], [5836, 5844], [5845, 5851], [5852, 5861], [5861, 5862]]}) 
answer: set([u'municipality'])
candidate Sentence: (0.046874769032001495, {u'tokens': [u'Antwerp', u'was', u'transformed', u'into', u'a', u'fortified', u'position', u'by', u'constructing', u'an', u'outer', u'line', u'of', u'forts', u'and', u'batteries', u'6', u'to', u'from', u'the', u'enceinte', u'.'], u'lemmas': [u'Antwerp', u'be', u'transform', u'into', u'a', u'fortified', u'position', u'by', u'construct', u'a', u'outer', u'line', u'of', u'fort', u'and', u'battery', u'6', u'to', u'from', u'the', u'enceinte', u'.'], u'pos': [u'NNP', u'VBD', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'VBG', u'DT', u'JJ', u'NN', u'IN', u'NNS', u'CC', u'NNS', u'CD', u'TO', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[15057, 15064], [15065, 15068], [15069, 15080], [15081, 15085], [15086, 15087], [15088, 15097], [15098, 15106], [15107, 15109], [15110, 15122], [15123, 15125], [15126, 15131], [15132, 15136], [15137, 15139], [15140, 15145], [15146, 15149], [15150, 15159], [15160, 15161], [15162, 15164], [15167, 15171], [15172, 15175], [15176, 15184], [15184, 15185]]}) 
answer: set([u'municipality'])
candidate Sentence: (0.046100780367851257, {u'tokens': [u'It', u'is', u'now', u'a', u'museum', u'.'], u'lemmas': [u'it', u'be', u'now', u'a', u'museum', u'.'], u'pos': [u'PRP', u'VBZ', u'RB', u'DT', u'NN', u'.'], u'char_offsets': [[12614, 12616], [12617, 12619], [12620, 12623], [12624, 12625], [12626, 12632], [12632, 12633]]}) 
answer: set([u'municipality'])
candidate Sentence: (0.043384205549955368, {u'tokens': [u'*', u'Den', u'Dam', u'--', u'an', u'area', u'in', u'northern', u'Antwerp', u'*', u'Linkeroever', u'-', u'an', u'area', u'on', u'the', u'left', u'bank', u'of', u'the', u'Scheldt', u'with', u'a', u'lot', u'of', u'apartment', u'buildings', u'*', u'Meir', u'--', u'Antwerp', u"'s", u'largest', u'shopping', u'street', u'*', u'Seefhoek', u'-', u'an', u'area', u'in', u'north-east', u'Antwerp', u',', u'situated', u'around', u'the', u'Stuyvenbergplein', u'*', u'Van', u'Wesenbekestraat', u'--', u'the', u'Chinatown', u'of', u'Antwerp', u'*', u'Zuid', u'--', u'the', u'south', u'of', u'Antwerp', u'*', u'Antwerp', u'Water', u'Works', u'-LRB-', u'AWW', u'-RRB-', u'*', u'Archief', u'en', u'Museum', u'voor', u'het', u'Vlaams', u'Cultuurleven', u'*', u'Jewish', u'Community', u'of', u'Antwerp', u'*', u'List', u'of', u'mayors', u'of', u'Antwerp', u'*', u'Pshevorsk', u'--', u'Hassidic', u'Jewish', u'movement', u'based', u'in', u'Antwerp', u'*', u'Carolus', u'Scribani', u',', u'Origines', u'Antwerpiensium', u',', u'1610', u'*', u'Gens', u',', u'Histoire', u'de', u'la', u'ville', u"d'Anvers", u'*', u'F.H.', u'Mertens', u',', u'K.L.', u'Torfs', u',', u'Geschiedenis', u'van', u'Antwerpen', u'sedert', u'de', u'stichting', u'der', u'.'], u'lemmas': [u'*', u'Den', u'dam', u'--', u'a', u'area', u'in', u'northern', u'Antwerp', u'*', u'linkeroever', u'-', u'a', u'area', u'on', u'the', u'left', u'bank', u'of', u'the', u'scheldt', u'with', u'a', u'lot', u'of', u'apartment', u'building', u'*', u'Meir', u'--', u'Antwerp', u"'s", u'largest', u'shopping', u'street', u'*', u'Seefhoek', u'-', u'a', u'area', u'in', u'north-east', u'Antwerp', u',', u'situate', u'around', u'the', u'Stuyvenbergplein', u'*', u'Van', u'Wesenbekestraat', u'--', u'the', u'Chinatown', u'of', u'Antwerp', u'*', u'Zuid', u'--', u'the', u'south', u'of', u'Antwerp', u'*', u'Antwerp', u'Water', u'Works', u'-lrb-', u'AWW', u'-rrb-', u'*', u'archief', u'en', u'museum', u'voor', u'het', u'Vlaams', u'Cultuurleven', u'*', u'Jewish', u'Community', u'of', u'Antwerp', u'*', u'list', u'of', u'mayor', u'of', u'Antwerp', u'*', u'Pshevorsk', u'--', u'hassidic', u'jewish', u'movement', u'base', u'in', u'Antwerp', u'*', u'Carolus', u'Scribani', u',', u'Origines', u'Antwerpiensium', u',', u'1610', u'*', u'gen', u',', u'histoire', u'de', u'la', u'ville', u"d'anver", u'*', u'F.H.', u'Mertens', u',', u'K.L.', u'Torfs', u',', u'Geschiedenis', u'van', u'Antwerpen', u'sedert', u'de', u'stichting', u'der', u'.'], u'pos': [u'SYM', u'NNP', u'NN', u':', u'DT', u'NN', u'IN', u'JJ', u'NNP', u'SYM', u'SYM', u':', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'NNS', u'SYM', u'NNP', u':', u'NNP', u'POS', u'JJS', u'NN', u'NN', u'SYM', u'NNP', u':', u'DT', u'NN', u'IN', u'NN', u'NNP', u',', u'VBN', u'IN', u'DT', u'NNP', u'SYM', u'NNP', u'NNP', u':', u'DT', u'NNP', u'IN', u'NNP', u'SYM', u'NNP', u':', u'DT', u'NN', u'IN', u'NNP', u'SYM', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u'SYM', u'FW', u'FW', u'NN', u'NN', u'NN', u'NNP', u'NNP', u'SYM', u'NNP', u'NNP', u'IN', u'NNP', u'SYM', u'NN', u'IN', u'NNS', u'IN', u'NNP', u'SYM', u'NNP', u':', u'JJ', u'JJ', u'NN', u'VBN', u'IN', u'NNP', u'SYM', u'NNPS', u'NNP', u',', u'NNP', u'NNP', u',', u'CD', u'SYM', u'NNS', u',', u'FW', u'FW', u'FW', u'FW', u'NNS', u'SYM', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'FW', u'FW', u'NN', u'NN', u'.'], u'char_offsets': [[26468, 26469], [26470, 26473], [26474, 26477], [26478, 26479], [26480, 26482], [26483, 26487], [26488, 26490], [26491, 26499], [26500, 26507], [26508, 26509], [26510, 26521], [26522, 26523], [26524, 26526], [26527, 26531], [26532, 26534], [26535, 26538], [26539, 26543], [26544, 26548], [26549, 26551], [26552, 26555], [26556, 26563], [26564, 26568], [26569, 26570], [26571, 26574], [26575, 26577], [26578, 26587], [26588, 26597], [26598, 26599], [26600, 26604], [26605, 26606], [26607, 26614], [26614, 26616], [26617, 26624], [26625, 26633], [26634, 26640], [26641, 26642], [26643, 26651], [26652, 26653], [26654, 26656], [26657, 26661], [26662, 26664], [26665, 26675], [26676, 26683], [26683, 26684], [26685, 26693], [26694, 26700], [26701, 26704], [26705, 26721], [26722, 26723], [26724, 26727], [26728, 26743], [26744, 26745], [26746, 26749], [26750, 26759], [26760, 26762], [26763, 26770], [26771, 26772], [26773, 26777], [26778, 26779], [26781, 26784], [26785, 26790], [26791, 26793], [26794, 26801], [26802, 26803], [26804, 26811], [26812, 26817], [26818, 26823], [26824, 26825], [26825, 26828], [26828, 26829], [26830, 26831], [26832, 26839], [26840, 26842], [26843, 26849], [26850, 26854], [26855, 26858], [26859, 26865], [26866, 26878], [26879, 26880], [26881, 26887], [26888, 26897], [26898, 26900], [26901, 26908], [26909, 26910], [26911, 26915], [26916, 26918], [26919, 26925], [26926, 26928], [26929, 26936], [26937, 26938], [26939, 26948], [26949, 26950], [26951, 26959], [26960, 26966], [26967, 26975], [26976, 26981], [26982, 26984], [26985, 26992], [26993, 26994], [26995, 27002], [27003, 27011], [27011, 27012], [27013, 27021], [27022, 27036], [27036, 27037], [27038, 27042], [27043, 27044], [27045, 27049], [27049, 27050], [27051, 27059], [27060, 27062], [27063, 27065], [27066, 27071], [27072, 27080], [27081, 27082], [27083, 27087], [27088, 27095], [27095, 27096], [27097, 27101], [27102, 27107], [27107, 27108], [27109, 27121], [27122, 27125], [27126, 27135], [27136, 27142], [27143, 27145], [27146, 27155], [27156, 27159], [27159, 27160]]}) 
answer: set([u'municipality'])

Is Antwerp a municipality?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114cabd8>.answer
_____________________________ test_yesno[param45] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114caef0>, (<src.tfidf.TF_IDF object at 0x10a4d47d0>, set(['berlin'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Berlin is the capital city of Germany.') == True
E                +  where 'Berlin is the capital city of Germany.' = <src.question_processing.Question_parser instance at 0x1114caef0>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.31385570764541626, {u'tokens': [u'The', u'Berlin', u'Philharmonic', u'Orchestra', u'is', u'one', u'of', u'the', u'preeminent', u'orchestras', u'in', u'the', u'world', u';', u'Is', u'Rattle', u"'s", u'Berlin', u'honeymoon', u'over', u'?'], u'lemmas': [u'the', u'Berlin', u'Philharmonic', u'Orchestra', u'be', u'one', u'of', u'the', u'preeminent', u'orchestra', u'in', u'the', u'world', u';', u'be', u'rattle', u"'s", u'Berlin', u'honeymoon', u'over', u'?'], u'pos': [u'DT', u'NNP', u'NNP', u'NNP', u'VBZ', u'CD', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'NN', u':', u'VBZ', u'NN', u'POS', u'NNP', u'NN', u'IN', u'.'], u'char_offsets': [[43005, 43008], [43009, 43015], [43016, 43028], [43029, 43038], [43039, 43041], [43042, 43045], [43046, 43048], [43049, 43052], [43053, 43063], [43064, 43074], [43075, 43077], [43078, 43081], [43082, 43087], [43087, 43088], [43090, 43092], [43093, 43099], [43099, 43101], [43102, 43108], [43109, 43118], [43119, 43123], [43123, 43124]]}) 
answer: set([u'city', u'germany', u'capital'])
candidate Sentence: (0.28370743989944458, {u'tokens': [u'Berlin', u'-LRB-', u';', u'-RRB-', u'is', u'the', u'capital', u'city', u'and', u'one', u'of', u'16', u'states', u'of', u'Germany', u'.'], u'lemmas': [u'Berlin', u'-lrb-', u';', u'-rrb-', u'be', u'the', u'capital', u'city', u'and', u'one', u'of', u'16', u'state', u'of', u'Germany', u'.'], u'pos': [u'NNP', u'-LRB-', u':', u'-RRB-', u'VBZ', u'DT', u'NN', u'NN', u'CC', u'CD', u'IN', u'CD', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[0, 6], [7, 8], [9, 10], [12, 13], [14, 16], [17, 20], [21, 28], [29, 33], [34, 37], [38, 41], [42, 44], [45, 47], [48, 54], [55, 57], [58, 65], [65, 66]]}) 
answer: set([])
candidate Sentence: (0.22739590704441071, {u'tokens': [u'Berlin', u'is', u'the', u'capital', u'of', u'the', u'Federal', u'Republic', u'of', u'Germany', u'and', u'is', u'the', u'seat', u'of', u'the', u'President', u'of', u'Germany', u',', u'whose', u'official', u'residence', u'is', u'Schloss', u'Bellevue', u'.'], u'lemmas': [u'Berlin', u'be', u'the', u'capital', u'of', u'the', u'Federal', u'Republic', u'of', u'Germany', u'and', u'be', u'the', u'seat', u'of', u'the', u'President', u'of', u'Germany', u',', u'whose', u'official', u'residence', u'be', u'Schloss', u'Bellevue', u'.'], u'pos': [u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'NNP', u'CC', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NNP', u'IN', u'NNP', u',', u'WP$', u'JJ', u'NN', u'VBZ', u'NNP', u'NNP', u'.'], u'char_offsets': [[18681, 18687], [18688, 18690], [18691, 18694], [18695, 18702], [18703, 18705], [18706, 18709], [18710, 18717], [18718, 18726], [18727, 18729], [18730, 18737], [18738, 18741], [18742, 18744], [18745, 18748], [18749, 18753], [18754, 18756], [18757, 18760], [18761, 18770], [18771, 18773], [18774, 18781], [18781, 18782], [18783, 18788], [18789, 18797], [18798, 18807], [18808, 18810], [18811, 18818], [18819, 18827], [18827, 18828]]}) 
answer: set([u'city'])
candidate Sentence: (0.18738408386707306, {u'tokens': [u'On', u'3', u'October', u'1990', u'the', u'two', u'parts', u'of', u'Germany', u'were', u'reunified', u'as', u'the', u'Federal', u'Republic', u'of', u'Germany', u',', u'and', u'Berlin', u'became', u'the', u'German', u'capital', u'according', u'to', u'the', u'unification', u'treaty', u'.'], u'lemmas': [u'on', u'3', u'October', u'1990', u'the', u'two', u'part', u'of', u'Germany', u'be', u'reunify', u'as', u'the', u'Federal', u'Republic', u'of', u'Germany', u',', u'and', u'Berlin', u'become', u'the', u'german', u'capital', u'accord', u'to', u'the', u'unification', u'treaty', u'.'], u'pos': [u'IN', u'CD', u'NNP', u'CD', u'DT', u'CD', u'NNS', u'IN', u'NNP', u'VBD', u'VBN', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'NNP', u',', u'CC', u'NNP', u'VBD', u'DT', u'JJ', u'NN', u'VBG', u'TO', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[10050, 10052], [10053, 10054], [10055, 10062], [10063, 10067], [10068, 10071], [10072, 10075], [10076, 10081], [10082, 10084], [10085, 10092], [10093, 10097], [10098, 10107], [10108, 10110], [10111, 10114], [10115, 10122], [10123, 10131], [10132, 10134], [10135, 10142], [10142, 10143], [10144, 10147], [10148, 10154], [10155, 10161], [10162, 10165], [10166, 10172], [10173, 10180], [10181, 10190], [10191, 10193], [10194, 10197], [10198, 10209], [10210, 10216], [10216, 10217]]}) 
answer: set([u'city'])
candidate Sentence: (0.16097559034824371, {u'tokens': [u'Following', u'German', u'reunification', u'in', u'1990', u',', u'the', u'city', u'regained', u'its', u'status', u'as', u'the', u'capital', u'of', u'all', u'Germany', u'hosting', u'147', u'foreign', u'embassies', u'.'], u'lemmas': [u'follow', u'german', u'reunification', u'in', u'1990', u',', u'the', u'city', u'regain', u'its', u'status', u'as', u'the', u'capital', u'of', u'all', u'Germany', u'host', u'147', u'foreign', u'embassy', u'.'], u'pos': [u'VBG', u'JJ', u'NN', u'IN', u'CD', u',', u'DT', u'NN', u'VBD', u'PRP$', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNP', u'VBG', u'CD', u'JJ', u'NNS', u'.'], u'char_offsets': [[1061, 1070], [1071, 1077], [1078, 1091], [1092, 1094], [1095, 1099], [1099, 1100], [1101, 1104], [1105, 1109], [1110, 1118], [1119, 1122], [1123, 1129], [1130, 1132], [1133, 1136], [1137, 1144], [1145, 1147], [1148, 1151], [1152, 1159], [1160, 1167], [1168, 1171], [1172, 1179], [1180, 1189], [1189, 1190]]}) 
answer: set([])
candidate Sentence: (0.15590570867061615, {u'tokens': [u'After', u'World', u'War', u'II', u',', u'the', u'city', u'was', u'divided', u';', u'East', u'Berlin', u'became', u'the', u'capital', u'of', u'East', u'Germany', u'while', u'West', u'Berlin', u'became', u'a', u'Western', u'exclave', u',', u'surrounded', u'by', u'the', u'Berlin', u'Wall', u'-LRB-', u'1961', u'--', u'1989', u'-RRB-', u'.'], u'lemmas': [u'after', u'World', u'War', u'II', u',', u'the', u'city', u'be', u'divide', u';', u'East', u'Berlin', u'become', u'the', u'capital', u'of', u'East', u'Germany', u'while', u'West', u'Berlin', u'become', u'a', u'western', u'exclave', u',', u'surround', u'by', u'the', u'Berlin', u'Wall', u'-lrb-', u'1961', u'--', u'1989', u'-rrb-', u'.'], u'pos': [u'IN', u'NNP', u'NNP', u'NNP', u',', u'DT', u'NN', u'VBD', u'VBN', u':', u'NNP', u'NNP', u'VBD', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'VBD', u'DT', u'JJ', u'NN', u',', u'VBN', u'IN', u'DT', u'NNP', u'NNP', u'-LRB-', u'CD', u':', u'CD', u'-RRB-', u'.'], u'char_offsets': [[882, 887], [888, 893], [894, 897], [898, 900], [900, 901], [902, 905], [906, 910], [911, 914], [915, 922], [922, 923], [924, 928], [929, 935], [936, 942], [943, 946], [947, 954], [955, 957], [958, 962], [963, 970], [971, 976], [977, 981], [982, 988], [989, 995], [996, 997], [998, 1005], [1006, 1013], [1013, 1014], [1015, 1025], [1026, 1028], [1029, 1032], [1033, 1039], [1040, 1044], [1045, 1046], [1046, 1050], [1050, 1051], [1051, 1055], [1055, 1056], [1056, 1057]]}) 
answer: set([])
candidate Sentence: (0.15018309652805328, {u'tokens': [u'In', u'1871', u',', u'Berlin', u'became', u'capital', u'of', u'the', u'newly', u'founded', u'German', u'Empire', u'.'], u'lemmas': [u'in', u'1871', u',', u'Berlin', u'become', u'capital', u'of', u'the', u'newly', u'found', u'german', u'empire', u'.'], u'pos': [u'IN', u'CD', u',', u'NNP', u'VBD', u'NN', u'IN', u'DT', u'RB', u'VBN', u'JJ', u'NN', u'.'], u'char_offsets': [[5835, 5837], [5838, 5842], [5842, 5843], [5844, 5850], [5851, 5857], [5858, 5865], [5866, 5868], [5869, 5872], [5873, 5878], [5879, 5886], [5887, 5893], [5894, 5900], [5900, 5901]]}) 
answer: set([u'city', u'germany'])
candidate Sentence: (0.13500908017158508, {u'tokens': [u'East', u'Germany', u',', u'however', u',', u'proclaimed', u'East', u'Berlin', u'-LRB-', u'which', u'it', u'described', u'only', u'as', u'``', u'Berlin', u"''", u'-RRB-', u'as', u'its', u'capital', u',', u'a', u'move', u'that', u'was', u'not', u'recognized', u'by', u'the', u'Western', u'powers', u'.'], u'lemmas': [u'East', u'Germany', u',', u'however', u',', u'proclaim', u'East', u'Berlin', u'-lrb-', u'which', u'it', u'describe', u'only', u'as', u'``', u'Berlin', u"''", u'-rrb-', u'as', u'its', u'capital', u',', u'a', u'move', u'that', u'be', u'not', u'recognize', u'by', u'the', u'western', u'power', u'.'], u'pos': [u'NNP', u'NNP', u',', u'RB', u',', u'VBD', u'NNP', u'NNP', u'-LRB-', u'WDT', u'PRP', u'VBD', u'RB', u'IN', u'``', u'NNP', u"''", u'-RRB-', u'IN', u'PRP$', u'NN', u',', u'DT', u'NN', u'WDT', u'VBD', u'RB', u'VBN', u'IN', u'DT', u'JJ', u'NNS', u'.'], u'char_offsets': [[8540, 8544], [8545, 8552], [8552, 8553], [8554, 8561], [8561, 8562], [8563, 8573], [8574, 8578], [8579, 8585], [8586, 8587], [8587, 8592], [8593, 8595], [8596, 8605], [8606, 8610], [8611, 8613], [8614, 8615], [8615, 8621], [8621, 8622], [8622, 8623], [8624, 8626], [8627, 8630], [8631, 8638], [8638, 8639], [8640, 8641], [8642, 8646], [8647, 8651], [8652, 8655], [8656, 8659], [8660, 8670], [8671, 8673], [8674, 8677], [8678, 8685], [8686, 8692], [8692, 8693]]}) 
answer: set([u'city'])
candidate Sentence: (0.13185998797416687, {u'tokens': [u'Though', u'most', u'of', u'the', u'ministries', u'are', u'seated', u'in', u'Berlin', u',', u'some', u'of', u'them', u',', u'as', u'well', u'as', u'some', u'minor', u'departments', u',', u'are', u'seated', u'in', u'Bonn', u',', u'the', u'former', u'capital', u'of', u'West', u'Germany', u'.'], u'lemmas': [u'though', u'most', u'of', u'the', u'ministry', u'be', u'seat', u'in', u'Berlin', u',', u'some', u'of', u'they', u',', u'as', u'well', u'as', u'some', u'minor', u'department', u',', u'be', u'seat', u'in', u'Bonn', u',', u'the', u'former', u'capital', u'of', u'West', u'Germany', u'.'], u'pos': [u'IN', u'JJS', u'IN', u'DT', u'NNS', u'VBP', u'VBN', u'IN', u'NNP', u',', u'DT', u'IN', u'PRP', u',', u'RB', u'RB', u'IN', u'DT', u'JJ', u'NNS', u',', u'VBP', u'VBN', u'IN', u'NNP', u',', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[19254, 19260], [19261, 19265], [19266, 19268], [19269, 19272], [19273, 19283], [19284, 19287], [19288, 19294], [19295, 19297], [19298, 19304], [19304, 19305], [19306, 19310], [19311, 19313], [19314, 19318], [19318, 19319], [19320, 19322], [19323, 19327], [19328, 19330], [19331, 19335], [19336, 19341], [19342, 19353], [19353, 19354], [19355, 19358], [19359, 19365], [19366, 19368], [19369, 19373], [19373, 19374], [19375, 19378], [19379, 19385], [19386, 19393], [19394, 19396], [19397, 19401], [19402, 19409], [19409, 19410]]}) 
answer: set([u'city'])
candidate Sentence: (0.13083936274051666, {u'tokens': [u'Berlin', u'became', u'the', u'capital', u'of', u'the', u'German', u'Empire', u'in', u'1871', u'and', u'expanded', u'rapidly', u'in', u'the', u'following', u'years', u'.'], u'lemmas': [u'Berlin', u'become', u'the', u'capital', u'of', u'the', u'german', u'empire', u'in', u'1871', u'and', u'expand', u'rapidly', u'in', u'the', u'follow', u'year', u'.'], u'pos': [u'NNP', u'VBD', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'CD', u'CC', u'VBD', u'RB', u'IN', u'DT', u'VBG', u'NNS', u'.'], u'char_offsets': [[4808, 4814], [4815, 4821], [4822, 4825], [4826, 4833], [4834, 4836], [4837, 4840], [4841, 4847], [4848, 4854], [4855, 4857], [4858, 4862], [4863, 4866], [4867, 4875], [4876, 4883], [4884, 4886], [4887, 4890], [4891, 4900], [4901, 4906], [4906, 4907]]}) 
answer: set([u'city', u'germany'])

Is Berlin the capital city of Germany?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Berlin is the capital city of Germany.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Berlin is the capital city of Germany.') == True
 +  where 'Berlin is the capital city of Germany.' = <src.question_processing.Question_parser instance at 0x1114caef0>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param47] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114caf80>, (<src.tfidf.TF_IDF object at 0x10a4d47d0>, set(['berlin'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool("Berlin is Germany's largest city.") == True
E                +  where "Berlin is Germany's largest city." = <src.question_processing.Question_parser instance at 0x1114caf80>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.32446944713592529, {u'tokens': [u'The', u'Berlin', u'Philharmonic', u'Orchestra', u'is', u'one', u'of', u'the', u'preeminent', u'orchestras', u'in', u'the', u'world', u';', u'Is', u'Rattle', u"'s", u'Berlin', u'honeymoon', u'over', u'?'], u'lemmas': [u'the', u'Berlin', u'Philharmonic', u'Orchestra', u'be', u'one', u'of', u'the', u'preeminent', u'orchestra', u'in', u'the', u'world', u';', u'be', u'rattle', u"'s", u'Berlin', u'honeymoon', u'over', u'?'], u'pos': [u'DT', u'NNP', u'NNP', u'NNP', u'VBZ', u'CD', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'NN', u':', u'VBZ', u'NN', u'POS', u'NNP', u'NN', u'IN', u'.'], u'char_offsets': [[43005, 43008], [43009, 43015], [43016, 43028], [43029, 43038], [43039, 43041], [43042, 43045], [43046, 43048], [43049, 43052], [43053, 43063], [43064, 43074], [43075, 43077], [43078, 43081], [43082, 43087], [43087, 43088], [43090, 43092], [43093, 43099], [43099, 43101], [43102, 43108], [43109, 43118], [43119, 43123], [43123, 43124]]}) 
answer: set([u'city', u'germany', u'largest'])
candidate Sentence: (0.23051321506500244, {u'tokens': [u'With', u'a', u'population', u'of', u'3.4', u'million', u'people', u',', u'Berlin', u'is', u'Germany', u"'s", u'largest', u'city', u'.'], u'lemmas': [u'with', u'a', u'population', u'of', u'3.4', u'million', u'people', u',', u'Berlin', u'be', u'Germany', u"'s", u'largest', u'city', u'.'], u'pos': [u'IN', u'DT', u'NN', u'IN', u'CD', u'CD', u'NNS', u',', u'NNP', u'VBZ', u'NNP', u'POS', u'JJS', u'NN', u'.'], u'char_offsets': [[67, 71], [72, 73], [74, 84], [85, 87], [88, 91], [92, 99], [100, 106], [106, 107], [108, 114], [115, 117], [118, 125], [125, 127], [128, 135], [136, 140], [140, 141]]}) 
answer: set([])
candidate Sentence: (0.14989200234413147, {u'tokens': [u'The', u'Berlin', u'Hauptbahnhof', u'is', u'the', u'largest', u'crossing', u'station', u'in', u'Europe', u'.'], u'lemmas': [u'the', u'Berlin', u'Hauptbahnhof', u'be', u'the', u'largest', u'cross', u'station', u'in', u'Europe', u'.'], u'pos': [u'DT', u'NNP', u'NNP', u'VBZ', u'DT', u'JJS', u'VBG', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[48115, 48118], [48119, 48125], [48126, 48138], [48139, 48141], [48142, 48145], [48146, 48153], [48154, 48162], [48163, 48170], [48171, 48173], [48174, 48180], [48180, 48181]]}) 
answer: set([u'city', u'germany'])
candidate Sentence: (0.13640093803405762, {u'tokens': [u'It', u'is', u'the', u'largest', u'remaining', u'evidence', u'of', u'the', u'city', u"'s", u'historical', u'division', u'.'], u'lemmas': [u'it', u'be', u'the', u'largest', u'remain', u'evidence', u'of', u'the', u'city', u"'s", u'historical', u'division', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'JJS', u'VBG', u'NN', u'IN', u'DT', u'NN', u'POS', u'JJ', u'NN', u'.'], u'char_offsets': [[14574, 14576], [14577, 14579], [14580, 14583], [14584, 14591], [14592, 14601], [14602, 14610], [14611, 14613], [14614, 14617], [14618, 14622], [14622, 14624], [14625, 14635], [14636, 14644], [14644, 14645]]}) 
answer: set([u'germany'])
candidate Sentence: (0.13175135850906372, {u'tokens': [u'Berlin', u'-LRB-', u';', u'-RRB-', u'is', u'the', u'capital', u'city', u'and', u'one', u'of', u'16', u'states', u'of', u'Germany', u'.'], u'lemmas': [u'Berlin', u'-lrb-', u';', u'-rrb-', u'be', u'the', u'capital', u'city', u'and', u'one', u'of', u'16', u'state', u'of', u'Germany', u'.'], u'pos': [u'NNP', u'-LRB-', u':', u'-RRB-', u'VBZ', u'DT', u'NN', u'NN', u'CC', u'CD', u'IN', u'CD', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[0, 6], [7, 8], [9, 10], [12, 13], [14, 16], [17, 20], [21, 28], [29, 33], [34, 37], [38, 41], [42, 44], [45, 47], [48, 54], [55, 57], [58, 65], [65, 66]]}) 
answer: set([u'largest'])
candidate Sentence: (0.12626650929450989, {u'tokens': [u'Schloss', u'Charlottenburg', u'is', u'the', u'largest', u'existing', u'palace', u'in', u'Berlin', u'.'], u'lemmas': [u'Schloss', u'Charlottenburg', u'be', u'the', u'largest', u'exist', u'palace', u'in', u'Berlin', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'DT', u'JJS', u'VBG', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[17134, 17141], [17142, 17156], [17157, 17159], [17160, 17163], [17164, 17171], [17172, 17180], [17181, 17187], [17188, 17190], [17191, 17197], [17197, 17198]]}) 
answer: set([u'city', u'germany'])
candidate Sentence: (0.1259145587682724, {u'tokens': [u'During', u'the', u'1920s', u',', u'Berlin', u'was', u'the', u'third', u'largest', u'municipality', u'in', u'the', u'world', u'.'], u'lemmas': [u'during', u'the', u'1920s', u',', u'Berlin', u'be', u'the', u'third', u'largest', u'municipality', u'in', u'the', u'world', u'.'], u'pos': [u'IN', u'DT', u'CD', u',', u'NNP', u'VBD', u'DT', u'JJ', u'JJS', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[805, 811], [812, 815], [816, 821], [821, 822], [823, 829], [830, 833], [834, 837], [838, 843], [844, 851], [852, 864], [865, 867], [868, 871], [872, 877], [877, 878]]}) 
answer: set([u'city', u'germany'])
candidate Sentence: (0.12337563931941986, {u'tokens': [u'Berlin', u'is', u'the', u'capital', u'of', u'the', u'Federal', u'Republic', u'of', u'Germany', u'and', u'is', u'the', u'seat', u'of', u'the', u'President', u'of', u'Germany', u',', u'whose', u'official', u'residence', u'is', u'Schloss', u'Bellevue', u'.'], u'lemmas': [u'Berlin', u'be', u'the', u'capital', u'of', u'the', u'Federal', u'Republic', u'of', u'Germany', u'and', u'be', u'the', u'seat', u'of', u'the', u'President', u'of', u'Germany', u',', u'whose', u'official', u'residence', u'be', u'Schloss', u'Bellevue', u'.'], u'pos': [u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'NNP', u'CC', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NNP', u'IN', u'NNP', u',', u'WP$', u'JJ', u'NN', u'VBZ', u'NNP', u'NNP', u'.'], u'char_offsets': [[18681, 18687], [18688, 18690], [18691, 18694], [18695, 18702], [18703, 18705], [18706, 18709], [18710, 18717], [18718, 18726], [18727, 18729], [18730, 18737], [18738, 18741], [18742, 18744], [18745, 18748], [18749, 18753], [18754, 18756], [18757, 18760], [18761, 18770], [18771, 18773], [18774, 18781], [18781, 18782], [18783, 18788], [18789, 18797], [18798, 18807], [18808, 18810], [18811, 18818], [18819, 18827], [18827, 18828]]}) 
answer: set([u'city', u'largest'])
candidate Sentence: (0.11399579048156738, {u'tokens': [u'Berlin', u'Hauptbahnhof', u'is', u'the', u'largest', u'crossing', u'station', u'in', u'Europe', u'and', u'has', u'operated', u'since', u'2006', u'.'], u'lemmas': [u'Berlin', u'Hauptbahnhof', u'be', u'the', u'largest', u'cross', u'station', u'in', u'Europe', u'and', u'have', u'operate', u'since', u'2006', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'DT', u'JJS', u'VBG', u'NN', u'IN', u'NNP', u'CC', u'VBZ', u'VBN', u'IN', u'CD', u'.'], u'char_offsets': [[47299, 47305], [47306, 47318], [47319, 47321], [47322, 47325], [47326, 47333], [47334, 47342], [47343, 47350], [47351, 47353], [47354, 47360], [47361, 47364], [47365, 47368], [47369, 47377], [47378, 47383], [47384, 47388], [47388, 47389]]}) 
answer: set([u'city', u'germany'])
candidate Sentence: (0.11373734474182129, {u'tokens': [u'In', u'1949', u',', u'the', u'Federal', u'Republic', u'of', u'Germany', u'was', u'founded', u'in', u'West', u'Germany', u',', u'and', u'eventually', u'included', u'all', u'of', u'the', u'American', u',', u'British', u',', u'and', u'French', u'zones', u',', u'but', u'excluded', u'those', u'three', u'countries', u"'", u'zones', u'of', u'Berlin', u',', u'while', u'the', u'Marxist-Leninist', u'German', u'Democratic', u'Republic', u'was', u'proclaimed', u'in', u'East', u'Germany', u'.'], u'lemmas': [u'in', u'1949', u',', u'the', u'Federal', u'Republic', u'of', u'Germany', u'be', u'found', u'in', u'West', u'Germany', u',', u'and', u'eventually', u'include', u'all', u'of', u'the', u'American', u',', u'British', u',', u'and', u'french', u'zone', u',', u'but', u'exclude', u'those', u'three', u'country', u"'", u'zone', u'of', u'Berlin', u',', u'while', u'the', u'marxist-leninist', u'german', u'democratic', u'republic', u'be', u'proclaim', u'in', u'East', u'Germany', u'.'], u'pos': [u'IN', u'CD', u',', u'DT', u'NNP', u'NNP', u'IN', u'NNP', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u',', u'CC', u'RB', u'VBD', u'DT', u'IN', u'DT', u'NNP', u',', u'NNP', u',', u'CC', u'JJ', u'NNS', u',', u'CC', u'VBN', u'DT', u'CD', u'NNS', u'POS', u'NNS', u'IN', u'NNP', u',', u'IN', u'DT', u'JJ', u'JJ', u'JJ', u'NN', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[7924, 7926], [7927, 7931], [7931, 7932], [7933, 7936], [7937, 7944], [7945, 7953], [7954, 7956], [7957, 7964], [7965, 7968], [7969, 7976], [7977, 7979], [7980, 7984], [7985, 7992], [7992, 7993], [7994, 7997], [7998, 8008], [8009, 8017], [8018, 8021], [8022, 8024], [8025, 8028], [8029, 8037], [8037, 8038], [8039, 8046], [8046, 8047], [8048, 8051], [8052, 8058], [8059, 8064], [8064, 8065], [8066, 8069], [8070, 8078], [8079, 8084], [8085, 8090], [8091, 8100], [8100, 8101], [8102, 8107], [8108, 8110], [8111, 8117], [8117, 8118], [8119, 8124], [8125, 8128], [8129, 8145], [8146, 8152], [8153, 8163], [8164, 8172], [8173, 8176], [8177, 8187], [8188, 8190], [8191, 8195], [8196, 8203], [8203, 8204]]}) 
answer: set([u'city', u'largest'])

Is Berlin the largest city in Germany?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Berlin is Germany's largest city.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool("Berlin is Germany's largest city.") == True
 +  where "Berlin is Germany's largest city." = <src.question_processing.Question_parser instance at 0x1114caf80>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param60] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb368>, (<src.tfidf.TF_IDF object at 0x10a4acb90>, set(['butterfly'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Some butterflies make sounds.') == True
E                +  where 'Some butterflies make sounds.' = <src.question_processing.Question_parser instance at 0x1114cb368>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.24590303003787994, {u'tokens': [u'The', u'Journal', u'of', u'Experimental', u'Biology', u'202:95', u'--', u'102', u'Some', u'butterflies', u'have', u'organs', u'of', u'hearing', u'and', u'some', u'species', u'are', u'also', u'known', u'to', u'make', u'stridulatory', u'and', u'clicking', u'sounds', u'.'], u'lemmas': [u'the', u'Journal', u'of', u'experimental', u'biology', u'202:95', u'--', u'102', u'some', u'butterfly', u'have', u'organ', u'of', u'hearing', u'and', u'some', u'species', u'be', u'also', u'know', u'to', u'make', u'stridulatory', u'and', u'click', u'sound', u'.'], u'pos': [u'DT', u'NNP', u'IN', u'JJ', u'NN', u'CD', u':', u'CD', u'DT', u'NNS', u'VBP', u'NNS', u'IN', u'NN', u'CC', u'DT', u'NNS', u'VBP', u'RB', u'VBN', u'TO', u'VB', u'JJ', u'CC', u'VBG', u'NNS', u'.'], u'char_offsets': [[17939, 17942], [17943, 17950], [17951, 17953], [17954, 17966], [17967, 17974], [17975, 17981], [17982, 17983], [17984, 17987], [17988, 17992], [17993, 18004], [18005, 18009], [18010, 18016], [18017, 18019], [18020, 18027], [18028, 18031], [18032, 18036], [18037, 18044], [18045, 18048], [18049, 18053], [18054, 18059], [18060, 18062], [18063, 18067], [18068, 18080], [18081, 18084], [18085, 18093], [18094, 18100], [18100, 18101]]}) 
answer: set([])
candidate Sentence: (0.17804233729839325, {u'tokens': [u'This', u'helps', u'making', u'them', u'unpalatable', u'to', u'birds', u'and', u'other', u'predators', u'.'], u'lemmas': [u'this', u'help', u'make', u'they', u'unpalatable', u'to', u'bird', u'and', u'other', u'predator', u'.'], u'pos': [u'DT', u'VBZ', u'VBG', u'PRP', u'JJ', u'TO', u'NNS', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[5076, 5080], [5081, 5086], [5087, 5093], [5094, 5098], [5099, 5110], [5111, 5113], [5114, 5119], [5120, 5123], [5124, 5129], [5130, 5139], [5139, 5140]]}) 
answer: set([u'sound'])
candidate Sentence: (0.1641799658536911, {u'tokens': [u'Dennis', u',', u'R', u'L', u'H', u',', u'Tim', u'G.', u'Shreeve', u',', u'Henry', u'R.', u'Arnold', u'and', u'David', u'B.', u'Roy', u'-LRB-', u'2005', u'-RRB-', u'Does', u'diet', u'breadth', u'control', u'herbivorous', u'insect', u'distribution', u'size', u'?'], u'lemmas': [u'Dennis', u',', u'r', u'l', u'h', u',', u'Tim', u'G.', u'Shreeve', u',', u'Henry', u'R.', u'Arnold', u'and', u'David', u'B.', u'Roy', u'-lrb-', u'2005', u'-rrb-', u'do', u'diet', u'breadth', u'control', u'herbivorous', u'insect', u'distribution', u'size', u'?'], u'pos': [u'NNP', u',', u'NN', u'NN', u'NN', u',', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u'-RRB-', u'VBZ', u'NN', u'NN', u'NN', u'JJ', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[22012, 22018], [22018, 22019], [22020, 22021], [22022, 22023], [22024, 22025], [22025, 22026], [22027, 22030], [22031, 22033], [22034, 22041], [22041, 22042], [22043, 22048], [22049, 22051], [22052, 22058], [22059, 22062], [22063, 22068], [22069, 22071], [22072, 22075], [22076, 22077], [22077, 22081], [22081, 22082], [22083, 22087], [22088, 22092], [22093, 22100], [22101, 22108], [22109, 22120], [22121, 22127], [22128, 22140], [22141, 22145], [22145, 22146]]}) 
answer: set([u'sound', u'make'])
candidate Sentence: (0.15060018002986908, {u'tokens': [u'The', u'chrysalis', u'is', u'usually', u'incapable', u'of', u'movement', u',', u'although', u'some', u'species', u'can', u'rapidly', u'move', u'the', u'abdominal', u'segments', u'or', u'produce', u'sounds', u'to', u'scare', u'potential', u'predators', u'.'], u'lemmas': [u'the', u'chrysali', u'be', u'usually', u'incapable', u'of', u'movement', u',', u'although', u'some', u'species', u'can', u'rapidly', u'move', u'the', u'abdominal', u'segment', u'or', u'produce', u'sound', u'to', u'scare', u'potential', u'predator', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'RB', u'JJ', u'IN', u'NN', u',', u'IN', u'DT', u'NNS', u'MD', u'RB', u'VB', u'DT', u'JJ', u'NNS', u'CC', u'VB', u'NNS', u'TO', u'VB', u'JJ', u'NNS', u'.'], u'char_offsets': [[7182, 7185], [7186, 7195], [7196, 7198], [7199, 7206], [7207, 7216], [7217, 7219], [7220, 7228], [7228, 7229], [7230, 7238], [7239, 7243], [7244, 7251], [7252, 7255], [7256, 7263], [7264, 7268], [7269, 7272], [7273, 7282], [7283, 7291], [7292, 7294], [7295, 7302], [7303, 7309], [7310, 7312], [7313, 7318], [7319, 7328], [7329, 7338], [7338, 7339]]}) 
answer: set([u'make'])
candidate Sentence: (0.13623714447021484, {u'tokens': [u'Does', u'predation', u'maintain', u'eyespot', u'plasticity', u'in', u'Bicyclus', u'anynana', u'.'], u'lemmas': [u'do', u'predation', u'maintain', u'eyespot', u'plasticity', u'in', u'bicyclus', u'anynana', u'.'], u'pos': [u'VBZ', u'NN', u'VB', u'NN', u'NN', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[13459, 13463], [13464, 13473], [13474, 13482], [13483, 13490], [13491, 13501], [13502, 13504], [13505, 13513], [13514, 13521], [13521, 13522]]}) 
answer: set([u'sound', u'make'])
candidate Sentence: (0.13425792753696442, {u'tokens': [u'Insects', u'in', u'turn', u'develop', u'countermeasures', u'or', u'make', u'use', u'of', u'these', u'toxins', u'for', u'their', u'own', u'survival', u'.'], u'lemmas': [u'insect', u'in', u'turn', u'develop', u'countermeasure', u'or', u'make', u'use', u'of', u'these', u'toxin', u'for', u'they', u'own', u'survival', u'.'], u'pos': [u'NNS', u'IN', u'NN', u'VBP', u'NNS', u'CC', u'VB', u'NN', u'IN', u'DT', u'NNS', u'IN', u'PRP$', u'JJ', u'NN', u'.'], u'char_offsets': [[5339, 5346], [5347, 5349], [5350, 5354], [5355, 5362], [5363, 5378], [5379, 5381], [5382, 5386], [5387, 5390], [5391, 5393], [5394, 5399], [5400, 5406], [5407, 5410], [5411, 5416], [5417, 5420], [5421, 5429], [5429, 5430]]}) 
answer: set([u'sound'])
candidate Sentence: (0.1053459420800209, {u'tokens': [u'Hind', u'Wings', u'Help', u'Butterflies', u'Make', u'Swift', u'Turns', u'to', u'Evade', u'Predators', u'Newswise', u',', u'Retrieved', u'on', u'January', u'8', u',', u'2008', u'.'], u'lemmas': [u'Hind', u'Wings', u'help', u'butterfly', u'make', u'Swift', u'turn', u'to', u'evade', u'Predators', u'Newswise', u',', u'retrieve', u'on', u'January', u'8', u',', u'2008', u'.'], u'pos': [u'NNP', u'NNP', u'VB', u'NNS', u'VB', u'NNP', u'VBZ', u'TO', u'VB', u'NNP', u'NNP', u',', u'VBN', u'IN', u'NNP', u'CD', u',', u'CD', u'.'], u'char_offsets': [[24763, 24767], [24768, 24773], [24774, 24778], [24779, 24790], [24791, 24795], [24796, 24801], [24802, 24807], [24808, 24810], [24811, 24816], [24817, 24826], [24827, 24835], [24835, 24836], [24837, 24846], [24847, 24849], [24850, 24857], [24858, 24859], [24859, 24860], [24861, 24865], [24865, 24866]]}) 
answer: set([u'sound'])
candidate Sentence: (0.098238490521907806, {u'tokens': [u'Molleman', u'Freerk', u',', u'Grunsven', u'Roy', u'H.', u'A.', u',', u'Liefting', u'Maartje', u',', u'Zwaan', u'Bas', u'J.', u',', u'Brakefield', u'Paul', u'M.', u'-LRB-', u'2005', u'-RRB-', u'Is', u'male', u'puddling', u'behaviour', u'of', u'tropical', u'butterflies', u'targeted', u'at', u'sodium', u'for', u'nuptial', u'gifts', u'or', u'activity', u'?'], u'lemmas': [u'Molleman', u'Freerk', u',', u'Grunsven', u'Roy', u'H.', u'A.', u',', u'Liefting', u'Maartje', u',', u'Zwaan', u'Bas', u'J.', u',', u'Brakefield', u'Paul', u'M.', u'-lrb-', u'2005', u'-rrb-', u'be', u'male', u'puddle', u'behaviour', u'of', u'tropical', u'butterfly', u'target', u'at', u'sodium', u'for', u'nuptial', u'gift', u'or', u'activity', u'?'], u'pos': [u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u'-RRB-', u'VBZ', u'JJ', u'VBG', u'NN', u'IN', u'JJ', u'NNS', u'VBN', u'IN', u'NN', u'IN', u'JJ', u'NNS', u'CC', u'NN', u'.'], u'char_offsets': [[16239, 16247], [16248, 16254], [16254, 16255], [16256, 16264], [16265, 16268], [16269, 16271], [16272, 16274], [16274, 16275], [16276, 16284], [16285, 16292], [16292, 16293], [16294, 16299], [16300, 16303], [16304, 16306], [16306, 16307], [16308, 16318], [16319, 16323], [16324, 16326], [16327, 16328], [16328, 16332], [16332, 16333], [16334, 16336], [16337, 16341], [16342, 16350], [16351, 16360], [16361, 16363], [16364, 16372], [16373, 16384], [16385, 16393], [16394, 16396], [16397, 16403], [16404, 16407], [16408, 16415], [16416, 16421], [16422, 16424], [16425, 16433], [16433, 16434]]}) 
answer: set([u'sound', u'make'])
candidate Sentence: (0.095319770276546478, {u'tokens': [u'Batesian', u'mimics', u'imitate', u'other', u'species', u'to', u'enjoy', u'the', u'protection', u'of', u'an', u'attribute', u'they', u'do', u'not', u'share', u',', u'aposematism', u'in', u'this', u'case', u'.'], u'lemmas': [u'batesian', u'mimic', u'imitate', u'other', u'species', u'to', u'enjoy', u'the', u'protection', u'of', u'a', u'attribute', u'they', u'do', u'not', u'share', u',', u'aposematism', u'in', u'this', u'case', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'JJ', u'NNS', u'TO', u'VB', u'DT', u'NN', u'IN', u'DT', u'NN', u'PRP', u'VBP', u'RB', u'NN', u',', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[11222, 11230], [11231, 11237], [11238, 11245], [11246, 11251], [11252, 11259], [11260, 11262], [11263, 11268], [11269, 11272], [11273, 11283], [11284, 11286], [11287, 11289], [11290, 11299], [11300, 11304], [11305, 11307], [11308, 11311], [11312, 11317], [11317, 11318], [11319, 11330], [11331, 11333], [11334, 11338], [11339, 11343], [11343, 11344]]}) 
answer: set([u'sound', u'make'])
candidate Sentence: (0.091602921485900879, {u'tokens': [u'Butterflies', u'are', u'important', u'as', u'pollinators', u'for', u'some', u'species', u'of', u'plants', u'although', u'in', u'general', u'they', u'do', u'not', u'carry', u'as', u'much', u'pollen', u'load', u'as', u'the', u'Hymenoptera', u'.'], u'lemmas': [u'butterfly', u'be', u'important', u'as', u'pollinator', u'for', u'some', u'species', u'of', u'plant', u'although', u'in', u'general', u'they', u'do', u'not', u'carry', u'as', u'much', u'pollen', u'load', u'as', u'the', u'Hymenoptera', u'.'], u'pos': [u'NNS', u'VBP', u'JJ', u'IN', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'NNS', u'IN', u'IN', u'JJ', u'PRP', u'VBP', u'RB', u'VB', u'RB', u'JJ', u'NN', u'NN', u'IN', u'DT', u'NNP', u'.'], u'char_offsets': [[15037, 15048], [15049, 15052], [15053, 15062], [15063, 15065], [15066, 15077], [15078, 15081], [15082, 15086], [15087, 15094], [15095, 15097], [15098, 15104], [15105, 15113], [15114, 15116], [15117, 15124], [15125, 15129], [15130, 15132], [15133, 15136], [15137, 15142], [15143, 15145], [15146, 15150], [15151, 15157], [15158, 15162], [15163, 15165], [15166, 15169], [15170, 15181], [15181, 15182]]}) 
answer: set([u'sound', u'make'])

Do butterflies make sounds?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Some butterflies make sounds.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Some butterflies make sounds.') == True
 +  where 'Some butterflies make sounds.' = <src.question_processing.Question_parser instance at 0x1114cb368>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param62] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb3f8>, (<src.tfidf.TF_IDF object at 0x10a4acb90>, set(['butterfly'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('In the Philippines a black butterfly or moth mean that someone has died.') == True
E                +  where 'In the Philippines a black butterfly or moth mean that someone has died.' = <src.question_processing.Question_parser instance at 0x1114cb3f8>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.57508492469787598, {u'tokens': [u'Also', u',', u'in', u'the', u'Philippines', u',', u'a', u'lingering', u'black', u'butterfly', u'or', u'moth', u'in', u'the', u'house', u'is', u'taken', u'to', u'mean', u'that', u'someone', u'in', u'the', u'family', u'has', u'died', u'or', u'will', u'soon', u'die', u'.'], u'lemmas': [u'also', u',', u'in', u'the', u'Philippines', u',', u'a', u'linger', u'black', u'butterfly', u'or', u'moth', u'in', u'the', u'house', u'be', u'take', u'to', u'mean', u'that', u'someone', u'in', u'the', u'family', u'have', u'die', u'or', u'will', u'soon', u'die', u'.'], u'pos': [u'RB', u',', u'IN', u'DT', u'NNPS', u',', u'DT', u'VBG', u'JJ', u'NN', u'CC', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'TO', u'VB', u'IN', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'CC', u'MD', u'RB', u'VB', u'.'], u'char_offsets': [[30089, 30093], [30093, 30094], [30095, 30097], [30098, 30101], [30102, 30113], [30113, 30114], [30115, 30116], [30117, 30126], [30127, 30132], [30133, 30142], [30143, 30145], [30146, 30150], [30151, 30153], [30154, 30157], [30158, 30163], [30164, 30166], [30167, 30172], [30173, 30175], [30176, 30180], [30181, 30185], [30186, 30193], [30194, 30196], [30197, 30200], [30201, 30207], [30208, 30211], [30212, 30216], [30217, 30219], [30220, 30224], [30225, 30229], [30230, 30233], [30233, 30234]]}) 
answer: set([])
candidate Sentence: (0.14396923780441284, {u'tokens': [u'Some', u'people', u'say', u'that', u'when', u'a', u'butterfly', u'lands', u'on', u'you', u'it', u'means', u'good', u'luck', u'.'], u'lemmas': [u'some', u'people', u'say', u'that', u'when', u'a', u'butterfly', u'land', u'on', u'you', u'it', u'mean', u'good', u'luck', u'.'], u'pos': [u'DT', u'NNS', u'VBP', u'IN', u'WRB', u'DT', u'NN', u'NNS', u'IN', u'PRP', u'PRP', u'VBZ', u'JJ', u'NN', u'.'], u'char_offsets': [[29070, 29074], [29075, 29081], [29082, 29085], [29086, 29090], [29091, 29095], [29096, 29097], [29098, 29107], [29108, 29113], [29114, 29116], [29117, 29120], [29121, 29123], [29124, 29129], [29130, 29134], [29135, 29139], [29139, 29140]]}) 
answer: set([u'moth', u'die', u'someone', u'black'])
candidate Sentence: (0.11472988128662109, {u'tokens': [u'Dennis', u',', u'R', u'L', u'H', u',', u'Tim', u'G.', u'Shreeve', u',', u'Henry', u'R.', u'Arnold', u'and', u'David', u'B.', u'Roy', u'-LRB-', u'2005', u'-RRB-', u'Does', u'diet', u'breadth', u'control', u'herbivorous', u'insect', u'distribution', u'size', u'?'], u'lemmas': [u'Dennis', u',', u'r', u'l', u'h', u',', u'Tim', u'G.', u'Shreeve', u',', u'Henry', u'R.', u'Arnold', u'and', u'David', u'B.', u'Roy', u'-lrb-', u'2005', u'-rrb-', u'do', u'diet', u'breadth', u'control', u'herbivorous', u'insect', u'distribution', u'size', u'?'], u'pos': [u'NNP', u',', u'NN', u'NN', u'NN', u',', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u'-RRB-', u'VBZ', u'NN', u'NN', u'NN', u'JJ', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[22012, 22018], [22018, 22019], [22020, 22021], [22022, 22023], [22024, 22025], [22025, 22026], [22027, 22030], [22031, 22033], [22034, 22041], [22041, 22042], [22043, 22048], [22049, 22051], [22052, 22058], [22059, 22062], [22063, 22068], [22069, 22071], [22072, 22075], [22076, 22077], [22077, 22081], [22081, 22082], [22083, 22087], [22088, 22092], [22093, 22100], [22101, 22108], [22109, 22120], [22121, 22127], [22128, 22140], [22141, 22145], [22145, 22146]]}) 
answer: set([u'moth', u'die', u'someone', u'black', u'mean'])
candidate Sentence: (0.10745878517627716, {u'tokens': [u'According', u'to', u'the', u'``', u'Butterflies', u"''", u'chapter', u'in', u',', u'by', u'Lafcadio', u'Hearn', u',', u'a', u'butterfly', u'is', u'seen', u'as', u'the', u'personification', u'of', u'a', u'person', u"'s", u'soul', u';', u'whether', u'they', u'be', u'living', u',', u'dying', u',', u'or', u'already', u'dead', u'.'], u'lemmas': [u'accord', u'to', u'the', u'``', u'Butterflies', u"''", u'chapter', u'in', u',', u'by', u'Lafcadio', u'Hearn', u',', u'a', u'butterfly', u'be', u'see', u'as', u'the', u'personification', u'of', u'a', u'person', u"'s", u'soul', u';', u'whether', u'they', u'be', u'live', u',', u'die', u',', u'or', u'already', u'dead', u'.'], u'pos': [u'VBG', u'TO', u'DT', u'``', u'NNPS', u"''", u'NN', u'IN', u',', u'IN', u'NNP', u'NNP', u',', u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'POS', u'NN', u':', u'IN', u'PRP', u'VB', u'VBG', u',', u'VBG', u',', u'CC', u'RB', u'JJ', u'.'], u'char_offsets': [[26499, 26508], [26509, 26511], [26512, 26515], [26516, 26517], [26517, 26528], [26528, 26529], [26530, 26537], [26538, 26540], [26541, 26542], [26543, 26545], [26546, 26554], [26555, 26560], [26560, 26561], [26562, 26563], [26564, 26573], [26574, 26576], [26577, 26581], [26582, 26584], [26585, 26588], [26589, 26604], [26605, 26607], [26608, 26609], [26610, 26616], [26616, 26618], [26619, 26623], [26623, 26624], [26625, 26632], [26633, 26637], [26638, 26640], [26641, 26647], [26647, 26648], [26649, 26654], [26654, 26655], [26656, 26658], [26659, 26666], [26667, 26671], [26671, 26672]]}) 
answer: set([u'moth', u'someone', u'black', u'mean'])
candidate Sentence: (0.10648003965616226, {u'tokens': [u'Such', u'unpalatibility', u'is', u'advertised', u'using', u'bright', u'red', u',', u'orange', u',', u'black', u'or', u'white', u'warning', u'colours', u'.'], u'lemmas': [u'such', u'unpalatibility', u'be', u'advertise', u'use', u'bright', u'red', u',', u'orange', u',', u'black', u'or', u'white', u'warning', u'colour', u'.'], u'pos': [u'JJ', u'NN', u'VBZ', u'VBN', u'VBG', u'JJ', u'NN', u',', u'NN', u',', u'JJ', u'CC', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[5141, 5145], [5146, 5160], [5161, 5163], [5164, 5174], [5175, 5180], [5181, 5187], [5188, 5191], [5191, 5192], [5193, 5199], [5199, 5200], [5201, 5206], [5207, 5209], [5210, 5215], [5216, 5223], [5224, 5231], [5231, 5232]]}) 
answer: set([u'moth', u'die', u'someone', u'mean'])
candidate Sentence: (0.097075425088405609, {u'tokens': [u'Most', u'butterflies', u'and', u'moths', u'will', u'excrete', u'excess', u'dye', u'after', u'hatching', u'.'], u'lemmas': [u'most', u'butterfly', u'and', u'moth', u'will', u'excrete', u'excess', u'dye', u'after', u'hatch', u'.'], u'pos': [u'JJS', u'NNS', u'CC', u'NNS', u'MD', u'VB', u'JJ', u'VB', u'IN', u'VBG', u'.'], u'char_offsets': [[8733, 8737], [8738, 8749], [8750, 8753], [8754, 8759], [8760, 8764], [8765, 8772], [8773, 8779], [8780, 8783], [8784, 8789], [8790, 8798], [8798, 8799]]}) 
answer: set([u'die', u'someone', u'black', u'mean'])
candidate Sentence: (0.095203272998332977, {u'tokens': [u'Does', u'predation', u'maintain', u'eyespot', u'plasticity', u'in', u'Bicyclus', u'anynana', u'.'], u'lemmas': [u'do', u'predation', u'maintain', u'eyespot', u'plasticity', u'in', u'bicyclus', u'anynana', u'.'], u'pos': [u'VBZ', u'NN', u'VB', u'NN', u'NN', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[13459, 13463], [13464, 13473], [13474, 13482], [13483, 13490], [13491, 13501], [13502, 13504], [13505, 13513], [13514, 13521], [13521, 13522]]}) 
answer: set([u'moth', u'die', u'someone', u'black', u'mean'])
candidate Sentence: (0.092301011085510254, {u'tokens': [u'These', u'scales', u'are', u'pigmented', u'with', u'melanins', u'that', u'give', u'them', u'blacks', u'and', u'browns', u',', u'but', u'blues', u',', u'greens', u',', u'reds', u'and', u'iridescence', u'are', u'usually', u'created', u'not', u'by', u'pigments', u'but', u'the', u'microstructure', u'of', u'the', u'scales', u'.'], u'lemmas': [u'these', u'scale', u'be', u'pigment', u'with', u'melanin', u'that', u'give', u'they', u'black', u'and', u'brown', u',', u'but', u'blues', u',', u'green', u',', u'red', u'and', u'iridescence', u'be', u'usually', u'create', u'not', u'by', u'pigment', u'but', u'the', u'microstructure', u'of', u'the', u'scale', u'.'], u'pos': [u'DT', u'NNS', u'VBP', u'VBN', u'IN', u'NNS', u'WDT', u'VBP', u'PRP', u'NNS', u'CC', u'NNS', u',', u'CC', u'NNS', u',', u'NNS', u',', u'NNS', u'CC', u'NN', u'VBP', u'RB', u'VBN', u'RB', u'IN', u'NNS', u'CC', u'DT', u'NN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[9323, 9328], [9329, 9335], [9336, 9339], [9340, 9349], [9350, 9354], [9355, 9363], [9364, 9368], [9369, 9373], [9374, 9378], [9379, 9385], [9386, 9389], [9390, 9396], [9396, 9397], [9398, 9401], [9402, 9407], [9407, 9408], [9409, 9415], [9415, 9416], [9417, 9421], [9422, 9425], [9426, 9437], [9438, 9441], [9442, 9449], [9450, 9457], [9458, 9461], [9462, 9464], [9465, 9473], [9474, 9477], [9478, 9481], [9482, 9496], [9497, 9499], [9500, 9503], [9504, 9510], [9510, 9511]]}) 
answer: set([u'moth', u'die', u'someone', u'mean'])
candidate Sentence: (0.08433493971824646, {u'tokens': [u'The', u'Russian', u'word', u'for', u'``', u'butterfly', u"''", u',', u'\u0431\u0430\u0431\u043e\u0447\u043a\u0430', u'-LRB-', u'b\xe1bochka', u'-RRB-', u',', u'also', u'means', u'``', u'bow', u'tie', u"''", u'.'], u'lemmas': [u'the', u'russian', u'word', u'for', u'``', u'butterfly', u"''", u',', u'\u0431\u0430\u0431\u043e\u0447\u043a\u0430', u'-lrb-', u'b\xe1bochka', u'-rrb-', u',', u'also', u'mean', u'``', u'bow', u'tie', u"''", u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'``', u'NN', u"''", u',', u'NN', u'-LRB-', u'NN', u'-RRB-', u',', u'RB', u'VBZ', u'``', u'VB', u'NN', u"''", u'.'], u'char_offsets': [[27114, 27117], [27118, 27125], [27126, 27130], [27131, 27134], [27135, 27136], [27136, 27145], [27145, 27146], [27146, 27147], [27148, 27155], [27156, 27157], [27157, 27165], [27165, 27166], [27166, 27167], [27168, 27172], [27173, 27178], [27179, 27180], [27180, 27183], [27184, 27187], [27187, 27188], [27188, 27189]]}) 
answer: set([u'moth', u'die', u'someone', u'black'])
candidate Sentence: (0.080716706812381744, {u'tokens': [u'Butterfly', u'and', u'moth', u'eggs', u'vary', u'greatly', u'in', u'size', u'between', u'species', u',', u'but', u'they', u'are', u'all', u'either', u'spherical', u'or', u'ovate', u'.'], u'lemmas': [u'butterfly', u'and', u'moth', u'egg', u'vary', u'greatly', u'in', u'size', u'between', u'species', u',', u'but', u'they', u'be', u'all', u'either', u'spherical', u'or', u'ovate', u'.'], u'pos': [u'NN', u'CC', u'NN', u'NNS', u'VBP', u'RB', u'IN', u'NN', u'IN', u'NNS', u',', u'CC', u'PRP', u'VBP', u'DT', u'DT', u'JJ', u'CC', u'NN', u'.'], u'char_offsets': [[2057, 2066], [2067, 2070], [2071, 2075], [2076, 2080], [2081, 2085], [2086, 2093], [2094, 2096], [2097, 2101], [2102, 2109], [2110, 2117], [2117, 2118], [2119, 2122], [2123, 2127], [2128, 2131], [2132, 2135], [2136, 2142], [2143, 2152], [2153, 2155], [2156, 2161], [2161, 2162]]}) 
answer: set([u'die', u'someone', u'black', u'mean'])

Does a black moth mean that someone has died?
Validity= False
Question Type = NA
Answer Type = NA
Answer = In the Philippines a black butterfly or moth mean that someone has died.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('In the Philippines a black butterfly or moth mean that someone has died.') == True
 +  where 'In the Philippines a black butterfly or moth mean that someone has died.' = <src.question_processing.Question_parser instance at 0x1114cb3f8>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param67] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb5a8>, (<src.tfidf.TF_IDF object at 0x10a4ace50>, set(['charles-augustin', 'charles-augustin_de_coulomb', 'coulomb', 'de'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114cb5a8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.45635640621185303, {u'tokens': [u'Upon', u'his', u'return', u'to', u'France', u',', u'with', u'the', u'rank', u'of', u'Captain', u',', u'he', u'was', u'employed', u'at', u'La', u'Rochelle', u',', u'the', u'Isle', u'of', u'Aix', u'and', u'Cherbourg', u'.'], u'lemmas': [u'upon', u'he', u'return', u'to', u'France', u',', u'with', u'the', u'rank', u'of', u'Captain', u',', u'he', u'be', u'employ', u'at', u'La', u'Rochelle', u',', u'the', u'Isle', u'of', u'Aix', u'and', u'Cherbourg', u'.'], u'pos': [u'IN', u'PRP$', u'NN', u'TO', u'NNP', u',', u'IN', u'DT', u'NN', u'IN', u'NNP', u',', u'PRP', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u',', u'DT', u'NNP', u'IN', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[1725, 1729], [1730, 1733], [1734, 1740], [1741, 1743], [1744, 1750], [1750, 1751], [1752, 1756], [1757, 1760], [1761, 1765], [1766, 1768], [1769, 1776], [1776, 1777], [1778, 1780], [1781, 1784], [1785, 1793], [1794, 1796], [1797, 1799], [1800, 1808], [1808, 1809], [1810, 1813], [1814, 1818], [1819, 1821], [1822, 1825], [1826, 1829], [1830, 1839], [1839, 1840]]}) 
answer: set([u'ever'])
candidate Sentence: (0.19706469774246216, {u'tokens': [u'Charles-Augustin', u'de', u'Coulomb', u'-LRB-', u'14', u'June', u'1736', u'--', u'23', u'August', u'1806', u'-RRB-', u'was', u'a', u'French', u'physicist', u'.'], u'lemmas': [u'Charles-Augustin', u'de', u'Coulomb', u'-lrb-', u'14', u'June', u'1736', u'--', u'23', u'August', u'1806', u'-rrb-', u'be', u'a', u'french', u'physicist', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u'NNP', u'CD', u':', u'CD', u'NNP', u'CD', u'-RRB-', u'VBD', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[0, 16], [17, 19], [20, 27], [28, 29], [29, 31], [32, 36], [37, 41], [42, 43], [44, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 65], [66, 72], [73, 82], [82, 83]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.07401999831199646, {u'tokens': [u'In', u'1781', u',', u'he', u'was', u'stationed', u'permanently', u'at', u'Paris', u'.'], u'lemmas': [u'in', u'1781', u',', u'he', u'be', u'station', u'permanently', u'at', u'Paris', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP', u'VBD', u'VBN', u'RB', u'IN', u'NNP', u'.'], u'char_offsets': [[1989, 1991], [1992, 1996], [1996, 1997], [1998, 2000], [2001, 2004], [2005, 2014], [2015, 2026], [2027, 2029], [2030, 2035], [2035, 2036]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.068351730704307556, {u'tokens': [u'When', u'Coulomb', u'was', u'a', u'boy', u',', u'the', u'family', u'moved', u'to', u'Paris', u'and', u'there', u'Coulomb', u'studied', u'at', u'the', u'prestigious', u'Coll\xe8ge', u'des', u'Quatre-Nations', u'.'], u'lemmas': [u'when', u'Coulomb', u'be', u'a', u'boy', u',', u'the', u'family', u'move', u'to', u'Paris', u'and', u'there', u'Coulomb', u'study', u'at', u'the', u'prestigious', u'Coll\xe8ge', u'des', u'Quatre-Nations', u'.'], u'pos': [u'WRB', u'NNP', u'VBD', u'DT', u'NN', u',', u'DT', u'NN', u'VBD', u'TO', u'NNP', u'CC', u'EX', u'NNP', u'VBN', u'IN', u'DT', u'JJ', u'NNP', u'FW', u'NNP', u'.'], u'char_offsets': [[474, 478], [479, 486], [487, 490], [491, 492], [493, 496], [496, 497], [498, 501], [502, 508], [509, 514], [515, 517], [518, 523], [524, 527], [528, 533], [534, 541], [542, 549], [550, 552], [553, 556], [557, 568], [569, 576], [577, 580], [581, 595], [595, 596]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.068322256207466125, {u'tokens': [u'In', u'1784', u',', u'his', u'Recherches', u'th\xe9oriques', u'et', u'exp\xe9rimentales', u'sur', u'la', u'force', u'de', u'torsion', u'et', u'sur', u"l'\xe9lasticit\xe9", u'des', u'fils', u'de', u'metal', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'229-269', u',', u'1784', u'-LRB-', u'Theoretical', u'research', u'and', u'experimentation', u'on', u'torsion', u'and', u'the', u'elasticity', u'of', u'metal', u'wire', u'-RRB-', u'appeared', u'.'], u'lemmas': [u'in', u'1784', u',', u'he', u'recherch', u'th\xe9oriques', u'et', u'exp\xe9rimentales', u'sur', u'la', u'force', u'de', u'torsion', u'et', u'sur', u"l'\xe9lasticit\xe9", u'des', u'fils', u'de', u'metal', u'histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'229-269', u',', u'1784', u'-lrb-', u'theoretical', u'research', u'and', u'experimentation', u'on', u'torsion', u'and', u'the', u'elasticity', u'of', u'metal', u'wire', u'-rrb-', u'appear', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP$', u'NNS', u'NNS', u'FW', u'FW', u'FW', u'FW', u'NN', u'IN', u'NN', u'FW', u'FW', u'FW', u'FW', u'FW', u'FW', u'NN', u'FW', u'FW', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'-LRB-', u'JJ', u'NN', u'CC', u'NN', u'IN', u'NN', u'CC', u'DT', u'NN', u'IN', u'NN', u'NN', u'-RRB-', u'VBD', u'.'], u'char_offsets': [[2685, 2687], [2688, 2692], [2692, 2693], [2694, 2697], [2698, 2708], [2709, 2719], [2720, 2722], [2723, 2737], [2738, 2741], [2742, 2744], [2745, 2750], [2751, 2753], [2754, 2761], [2762, 2764], [2765, 2768], [2769, 2781], [2782, 2785], [2786, 2790], [2791, 2793], [2794, 2799], [2800, 2808], [2809, 2811], [2812, 2822], [2823, 2829], [2830, 2833], [2834, 2842], [2842, 2843], [2844, 2851], [2851, 2852], [2853, 2857], [2859, 2860], [2860, 2871], [2872, 2880], [2881, 2884], [2885, 2900], [2901, 2903], [2904, 2911], [2912, 2915], [2916, 2919], [2920, 2930], [2931, 2933], [2934, 2939], [2940, 2944], [2944, 2945], [2946, 2954], [2954, 2955]]}) 
answer: set([u'employ', u'rochelle', u'ever'])
candidate Sentence: (0.052426088601350784, {u'tokens': [u'Determination', u'of', u'electric', u'density', u'at', u'different', u'points', u'on', u'the', u'surface', u'of', u'these', u'bodies', u'.', u"''"], u'lemmas': [u'determination', u'of', u'electric', u'density', u'at', u'different', u'point', u'on', u'the', u'surface', u'of', u'these', u'body', u'.', u"''"], u'pos': [u'NN', u'IN', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNS', u'.', u"''"], u'char_offsets': [[5567, 5580], [5581, 5583], [5584, 5592], [5593, 5600], [5601, 5603], [5604, 5613], [5614, 5620], [5621, 5623], [5624, 5627], [5628, 5635], [5636, 5638], [5639, 5644], [5645, 5651], [5651, 5652], [5652, 5653]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.052361883223056793, {u'tokens': [u'With', u'his', u'father', u"'s", u'approval', u',', u'Coulomb', u'returned', u'to', u'Paris', u'in', u'1759', u'where', u'he', u'was', u'successful', u'in', u'the', u'entrance', u'examination', u'for', u'the', u'military', u'school', u'at', u'M\xe9zi\xe8res', u'.'], u'lemmas': [u'with', u'he', u'father', u"'s", u'approval', u',', u'Coulomb', u'return', u'to', u'Paris', u'in', u'1759', u'where', u'he', u'be', u'successful', u'in', u'the', u'entrance', u'examination', u'for', u'the', u'military', u'school', u'at', u'M\xe9zi\xe8res', u'.'], u'pos': [u'IN', u'PRP$', u'NN', u'POS', u'NN', u',', u'NNP', u'VBD', u'TO', u'NNP', u'IN', u'CD', u'WRB', u'PRP', u'VBD', u'JJ', u'IN', u'DT', u'NN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNPS', u'.'], u'char_offsets': [[912, 916], [917, 920], [921, 927], [927, 929], [930, 938], [938, 939], [940, 947], [948, 956], [957, 959], [960, 965], [966, 968], [969, 973], [974, 979], [980, 982], [983, 986], [987, 997], [998, 1000], [1001, 1004], [1005, 1013], [1014, 1025], [1026, 1029], [1030, 1033], [1034, 1042], [1043, 1049], [1050, 1052], [1053, 1061], [1061, 1062]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.044862888753414154, {u'tokens': [u'-', u'Deuxieme', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'578-611', u',', u'1785', u'.'], u'lemmas': [u'-', u'Deuxieme', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'578-611', u',', u'1785', u'.'], u'pos': [u':', u'NNP', u'NNP', u'NN', u'NNP', u'FW', u'FW', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'.'], u'char_offsets': [[4135, 4136], [4137, 4145], [4146, 4153], [4154, 4157], [4158, 4171], [4172, 4174], [4175, 4177], [4178, 4188], [4190, 4198], [4199, 4201], [4202, 4212], [4213, 4219], [4220, 4223], [4224, 4232], [4232, 4233], [4234, 4241], [4241, 4242], [4243, 4247], [4248, 4249]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.04275265708565712, {u'tokens': [u'-', u'Troisi\xe8me', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'612-638', u',', u'1785', u'.'], u'lemmas': [u'-', u'troisi\xe8me', u'm\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'612-638', u',', u'1785', u'.'], u'pos': [u':', u'NN', u'NN', u'NN', u'NNP', u'FW', u'FW', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'.'], u'char_offsets': [[4420, 4421], [4422, 4431], [4432, 4439], [4440, 4443], [4444, 4457], [4458, 4460], [4461, 4463], [4464, 4474], [4476, 4484], [4485, 4487], [4488, 4498], [4499, 4505], [4506, 4509], [4510, 4518], [4518, 4519], [4520, 4527], [4527, 4528], [4529, 4533], [4534, 4535]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.041335493326187134, {u'tokens': [u'In', u'1785', u',', u'Coulomb', u'presented', u'his', u'three', u'reports', u'on', u'Electricity', u'and', u'Magnetism', u':', u'-', u'Premier', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'569-577', u',', u'1785', u'.'], u'lemmas': [u'in', u'1785', u',', u'Coulomb', u'present', u'he', u'three', u'report', u'on', u'Electricity', u'and', u'Magnetism', u':', u'-', u'Premier', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'569-577', u',', u'1785', u'.'], u'pos': [u'IN', u'CD', u',', u'NNP', u'VBD', u'PRP$', u'CD', u'NNS', u'IN', u'NNP', u'CC', u'NNP', u':', u':', u'NNP', u'NNP', u'NN', u'NNP', u'FW', u'FW', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'.'], u'char_offsets': [[3587, 3589], [3590, 3594], [3594, 3595], [3596, 3603], [3604, 3613], [3614, 3617], [3618, 3623], [3624, 3631], [3632, 3634], [3635, 3646], [3647, 3650], [3651, 3660], [3660, 3661], [3662, 3663], [3664, 3671], [3672, 3679], [3680, 3683], [3684, 3697], [3698, 3700], [3701, 3703], [3704, 3714], [3716, 3724], [3725, 3727], [3728, 3738], [3739, 3745], [3746, 3749], [3750, 3758], [3758, 3759], [3760, 3767], [3767, 3768], [3769, 3773], [3774, 3775]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])

Was Charles-Augustin de Coulomb ever employed at La Rochelle?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
INFO:CoreNLP_JavaServer: INPUT: 500 documents, 1406086 characters, 264619 tokens, 2812.2 char/doc, 529.2 tok/doc RATES: 18.163 doc/sec, 9612.4 tok/sec

Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114cb5a8>.answer
_____________________________ test_yesno[param68] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb5f0>, (<src.tfidf.TF_IDF object at 0x10a4ace50>, set(['charles-augustin', 'charles-augustin_de_coulomb', 'coulomb', 'de'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, upon his return to France, with the rank of Captain, he was employed at La Rochelle.')
E                +    where 'Yes, upon his return to France, with the rank of Captain, he was employed at La Rochelle.' = <src.question_processing.Question_parser instance at 0x1114cb5f0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.45635640621185303, {u'tokens': [u'Upon', u'his', u'return', u'to', u'France', u',', u'with', u'the', u'rank', u'of', u'Captain', u',', u'he', u'was', u'employed', u'at', u'La', u'Rochelle', u',', u'the', u'Isle', u'of', u'Aix', u'and', u'Cherbourg', u'.'], u'lemmas': [u'upon', u'he', u'return', u'to', u'France', u',', u'with', u'the', u'rank', u'of', u'Captain', u',', u'he', u'be', u'employ', u'at', u'La', u'Rochelle', u',', u'the', u'Isle', u'of', u'Aix', u'and', u'Cherbourg', u'.'], u'pos': [u'IN', u'PRP$', u'NN', u'TO', u'NNP', u',', u'IN', u'DT', u'NN', u'IN', u'NNP', u',', u'PRP', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u',', u'DT', u'NNP', u'IN', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[1725, 1729], [1730, 1733], [1734, 1740], [1741, 1743], [1744, 1750], [1750, 1751], [1752, 1756], [1757, 1760], [1761, 1765], [1766, 1768], [1769, 1776], [1776, 1777], [1778, 1780], [1781, 1784], [1785, 1793], [1794, 1796], [1797, 1799], [1800, 1808], [1808, 1809], [1810, 1813], [1814, 1818], [1819, 1821], [1822, 1825], [1826, 1829], [1830, 1839], [1839, 1840]]}) 
answer: set([u'ever'])
candidate Sentence: (0.19706469774246216, {u'tokens': [u'Charles-Augustin', u'de', u'Coulomb', u'-LRB-', u'14', u'June', u'1736', u'--', u'23', u'August', u'1806', u'-RRB-', u'was', u'a', u'French', u'physicist', u'.'], u'lemmas': [u'Charles-Augustin', u'de', u'Coulomb', u'-lrb-', u'14', u'June', u'1736', u'--', u'23', u'August', u'1806', u'-rrb-', u'be', u'a', u'french', u'physicist', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u'NNP', u'CD', u':', u'CD', u'NNP', u'CD', u'-RRB-', u'VBD', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[0, 16], [17, 19], [20, 27], [28, 29], [29, 31], [32, 36], [37, 41], [42, 43], [44, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 65], [66, 72], [73, 82], [82, 83]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.07401999831199646, {u'tokens': [u'In', u'1781', u',', u'he', u'was', u'stationed', u'permanently', u'at', u'Paris', u'.'], u'lemmas': [u'in', u'1781', u',', u'he', u'be', u'station', u'permanently', u'at', u'Paris', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP', u'VBD', u'VBN', u'RB', u'IN', u'NNP', u'.'], u'char_offsets': [[1989, 1991], [1992, 1996], [1996, 1997], [1998, 2000], [2001, 2004], [2005, 2014], [2015, 2026], [2027, 2029], [2030, 2035], [2035, 2036]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.068351730704307556, {u'tokens': [u'When', u'Coulomb', u'was', u'a', u'boy', u',', u'the', u'family', u'moved', u'to', u'Paris', u'and', u'there', u'Coulomb', u'studied', u'at', u'the', u'prestigious', u'Coll\xe8ge', u'des', u'Quatre-Nations', u'.'], u'lemmas': [u'when', u'Coulomb', u'be', u'a', u'boy', u',', u'the', u'family', u'move', u'to', u'Paris', u'and', u'there', u'Coulomb', u'study', u'at', u'the', u'prestigious', u'Coll\xe8ge', u'des', u'Quatre-Nations', u'.'], u'pos': [u'WRB', u'NNP', u'VBD', u'DT', u'NN', u',', u'DT', u'NN', u'VBD', u'TO', u'NNP', u'CC', u'EX', u'NNP', u'VBN', u'IN', u'DT', u'JJ', u'NNP', u'FW', u'NNP', u'.'], u'char_offsets': [[474, 478], [479, 486], [487, 490], [491, 492], [493, 496], [496, 497], [498, 501], [502, 508], [509, 514], [515, 517], [518, 523], [524, 527], [528, 533], [534, 541], [542, 549], [550, 552], [553, 556], [557, 568], [569, 576], [577, 580], [581, 595], [595, 596]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.068322256207466125, {u'tokens': [u'In', u'1784', u',', u'his', u'Recherches', u'th\xe9oriques', u'et', u'exp\xe9rimentales', u'sur', u'la', u'force', u'de', u'torsion', u'et', u'sur', u"l'\xe9lasticit\xe9", u'des', u'fils', u'de', u'metal', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'229-269', u',', u'1784', u'-LRB-', u'Theoretical', u'research', u'and', u'experimentation', u'on', u'torsion', u'and', u'the', u'elasticity', u'of', u'metal', u'wire', u'-RRB-', u'appeared', u'.'], u'lemmas': [u'in', u'1784', u',', u'he', u'recherch', u'th\xe9oriques', u'et', u'exp\xe9rimentales', u'sur', u'la', u'force', u'de', u'torsion', u'et', u'sur', u"l'\xe9lasticit\xe9", u'des', u'fils', u'de', u'metal', u'histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'229-269', u',', u'1784', u'-lrb-', u'theoretical', u'research', u'and', u'experimentation', u'on', u'torsion', u'and', u'the', u'elasticity', u'of', u'metal', u'wire', u'-rrb-', u'appear', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP$', u'NNS', u'NNS', u'FW', u'FW', u'FW', u'FW', u'NN', u'IN', u'NN', u'FW', u'FW', u'FW', u'FW', u'FW', u'FW', u'NN', u'FW', u'FW', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'-LRB-', u'JJ', u'NN', u'CC', u'NN', u'IN', u'NN', u'CC', u'DT', u'NN', u'IN', u'NN', u'NN', u'-RRB-', u'VBD', u'.'], u'char_offsets': [[2685, 2687], [2688, 2692], [2692, 2693], [2694, 2697], [2698, 2708], [2709, 2719], [2720, 2722], [2723, 2737], [2738, 2741], [2742, 2744], [2745, 2750], [2751, 2753], [2754, 2761], [2762, 2764], [2765, 2768], [2769, 2781], [2782, 2785], [2786, 2790], [2791, 2793], [2794, 2799], [2800, 2808], [2809, 2811], [2812, 2822], [2823, 2829], [2830, 2833], [2834, 2842], [2842, 2843], [2844, 2851], [2851, 2852], [2853, 2857], [2859, 2860], [2860, 2871], [2872, 2880], [2881, 2884], [2885, 2900], [2901, 2903], [2904, 2911], [2912, 2915], [2916, 2919], [2920, 2930], [2931, 2933], [2934, 2939], [2940, 2944], [2944, 2945], [2946, 2954], [2954, 2955]]}) 
answer: set([u'employ', u'rochelle', u'ever'])
candidate Sentence: (0.052426088601350784, {u'tokens': [u'Determination', u'of', u'electric', u'density', u'at', u'different', u'points', u'on', u'the', u'surface', u'of', u'these', u'bodies', u'.', u"''"], u'lemmas': [u'determination', u'of', u'electric', u'density', u'at', u'different', u'point', u'on', u'the', u'surface', u'of', u'these', u'body', u'.', u"''"], u'pos': [u'NN', u'IN', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNS', u'.', u"''"], u'char_offsets': [[5567, 5580], [5581, 5583], [5584, 5592], [5593, 5600], [5601, 5603], [5604, 5613], [5614, 5620], [5621, 5623], [5624, 5627], [5628, 5635], [5636, 5638], [5639, 5644], [5645, 5651], [5651, 5652], [5652, 5653]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.052361883223056793, {u'tokens': [u'With', u'his', u'father', u"'s", u'approval', u',', u'Coulomb', u'returned', u'to', u'Paris', u'in', u'1759', u'where', u'he', u'was', u'successful', u'in', u'the', u'entrance', u'examination', u'for', u'the', u'military', u'school', u'at', u'M\xe9zi\xe8res', u'.'], u'lemmas': [u'with', u'he', u'father', u"'s", u'approval', u',', u'Coulomb', u'return', u'to', u'Paris', u'in', u'1759', u'where', u'he', u'be', u'successful', u'in', u'the', u'entrance', u'examination', u'for', u'the', u'military', u'school', u'at', u'M\xe9zi\xe8res', u'.'], u'pos': [u'IN', u'PRP$', u'NN', u'POS', u'NN', u',', u'NNP', u'VBD', u'TO', u'NNP', u'IN', u'CD', u'WRB', u'PRP', u'VBD', u'JJ', u'IN', u'DT', u'NN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNPS', u'.'], u'char_offsets': [[912, 916], [917, 920], [921, 927], [927, 929], [930, 938], [938, 939], [940, 947], [948, 956], [957, 959], [960, 965], [966, 968], [969, 973], [974, 979], [980, 982], [983, 986], [987, 997], [998, 1000], [1001, 1004], [1005, 1013], [1014, 1025], [1026, 1029], [1030, 1033], [1034, 1042], [1043, 1049], [1050, 1052], [1053, 1061], [1061, 1062]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.044862888753414154, {u'tokens': [u'-', u'Deuxieme', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'578-611', u',', u'1785', u'.'], u'lemmas': [u'-', u'Deuxieme', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'578-611', u',', u'1785', u'.'], u'pos': [u':', u'NNP', u'NNP', u'NN', u'NNP', u'FW', u'FW', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'.'], u'char_offsets': [[4135, 4136], [4137, 4145], [4146, 4153], [4154, 4157], [4158, 4171], [4172, 4174], [4175, 4177], [4178, 4188], [4190, 4198], [4199, 4201], [4202, 4212], [4213, 4219], [4220, 4223], [4224, 4232], [4232, 4233], [4234, 4241], [4241, 4242], [4243, 4247], [4248, 4249]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.04275265708565712, {u'tokens': [u'-', u'Troisi\xe8me', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'612-638', u',', u'1785', u'.'], u'lemmas': [u'-', u'troisi\xe8me', u'm\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'612-638', u',', u'1785', u'.'], u'pos': [u':', u'NN', u'NN', u'NN', u'NNP', u'FW', u'FW', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'.'], u'char_offsets': [[4420, 4421], [4422, 4431], [4432, 4439], [4440, 4443], [4444, 4457], [4458, 4460], [4461, 4463], [4464, 4474], [4476, 4484], [4485, 4487], [4488, 4498], [4499, 4505], [4506, 4509], [4510, 4518], [4518, 4519], [4520, 4527], [4527, 4528], [4529, 4533], [4534, 4535]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])
candidate Sentence: (0.041335493326187134, {u'tokens': [u'In', u'1785', u',', u'Coulomb', u'presented', u'his', u'three', u'reports', u'on', u'Electricity', u'and', u'Magnetism', u':', u'-', u'Premier', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'569-577', u',', u'1785', u'.'], u'lemmas': [u'in', u'1785', u',', u'Coulomb', u'present', u'he', u'three', u'report', u'on', u'Electricity', u'and', u'Magnetism', u':', u'-', u'Premier', u'M\xe9moire', u'sur', u'l\u2019Electricit\xe9', u'et', u'le', u'Magn\xe9tisme', u'Histoire', u'de', u'l\u2019Acad\xe9mie', u'Royale', u'des', u'Sciences', u',', u'569-577', u',', u'1785', u'.'], u'pos': [u'IN', u'CD', u',', u'NNP', u'VBD', u'PRP$', u'CD', u'NNS', u'IN', u'NNP', u'CC', u'NNP', u':', u':', u'NNP', u'NNP', u'NN', u'NNP', u'FW', u'FW', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNPS', u',', u'CD', u',', u'CD', u'.'], u'char_offsets': [[3587, 3589], [3590, 3594], [3594, 3595], [3596, 3603], [3604, 3613], [3614, 3617], [3618, 3623], [3624, 3631], [3632, 3634], [3635, 3646], [3647, 3650], [3651, 3660], [3660, 3661], [3662, 3663], [3664, 3671], [3672, 3679], [3680, 3683], [3684, 3697], [3698, 3700], [3701, 3703], [3704, 3714], [3716, 3724], [3725, 3727], [3728, 3738], [3739, 3745], [3746, 3749], [3750, 3758], [3758, 3759], [3760, 3767], [3767, 3768], [3769, 3773], [3774, 3775]]}) 
answer: set([u'employ', u'rochelle', u'ever', u'la'])

Was Charles-Augustin de Coulomb ever employed at La Rochelle?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, upon his return to France, with the rank of Captain, he was employed at La Rochelle.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, upon his return to France, with the rank of Captain, he was employed at La Rochelle.')
 +    where 'Yes, upon his return to France, with the rank of Captain, he was employed at La Rochelle.' = <src.question_processing.Question_parser instance at 0x1114cb5f0>.answer
_____________________________ test_yesno[param69] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb4d0>, (<src.tfidf.TF_IDF object at 0x10a4b03d0>, set(['chinese', 'chinese_language', 'language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cb4d0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39408707618713379, {u'tokens': [u'All', u'varieties', u'of', u'spoken', u'Chinese', u'use', u'tones', u'.'], u'lemmas': [u'all', u'variety', u'of', u'speak', u'chinese', u'use', u'tone', u'.'], u'pos': [u'DT', u'NNS', u'IN', u'VBN', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[24814, 24817], [24818, 24827], [24828, 24830], [24831, 24837], [24838, 24845], [24846, 24849], [24850, 24855], [24855, 24856]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.34200888872146606, {u'tokens': [u'Spoken', u'Chinese', u'is', u'distinguished', u'by', u'its', u'high', u'level', u'of', u'internal', u'diversity', u',', u'although', u'all', u'spoken', u'varieties', u'of', u'Chinese', u'are', u'tonal', u'and', u'analytic', u'.'], u'lemmas': [u'speak', u'Chinese', u'be', u'distinguish', u'by', u'its', u'high', u'level', u'of', u'internal', u'diversity', u',', u'although', u'all', u'speak', u'variety', u'of', u'Chinese', u'be', u'tonal', u'and', u'analytic', u'.'], u'pos': [u'VBN', u'NNPS', u'VBZ', u'VBN', u'IN', u'PRP$', u'JJ', u'NN', u'IN', u'JJ', u'NN', u',', u'IN', u'DT', u'VBN', u'NNS', u'IN', u'NNP', u'VBP', u'JJ', u'CC', u'JJ', u'.'], u'char_offsets': [[1612, 1618], [1619, 1626], [1627, 1629], [1630, 1643], [1644, 1646], [1647, 1650], [1651, 1655], [1656, 1661], [1662, 1664], [1665, 1673], [1674, 1683], [1683, 1684], [1685, 1693], [1694, 1697], [1698, 1704], [1705, 1714], [1715, 1717], [1718, 1725], [1726, 1729], [1730, 1735], [1736, 1739], [1740, 1748], [1748, 1749]]}) 
answer: set([u'analytical'])
candidate Sentence: (0.17520058155059814, {u'tokens': [u'The', u'total', u'number', u'of', u'syllables', u'in', u'some', u'varieties', u'is', u'therefore', u'only', u'about', u'a', u'thousand', u',', u'including', u'tonal', u'variation', u',', u'which', u'is', u'only', u'about', u'an', u'eighth', u'as', u'many', u'as', u'English', u'DeFrancis', u'-LRB-', u'1984', u'-RRB-', u'p.', u'42', u'counts', u'Chinese', u'as', u'having', u'1,277', u'tonal', u'syllables', u',', u'and', u'about', u'398', u'to', u'418', u'if', u'tones', u'are', u'disregarded', u';', u'he', u'cites', u'Jespersen', u',', u'Otto', u'-LRB-', u'1928', u'-RRB-', u'Monosyllabism', u'in', u'English', u';', u'London', u',', u'p.', u'15', u'for', u'a', u'count', u'of', u'over', u'8000', u'syllables', u'for', u'English', u'.'], u'lemmas': [u'the', u'total', u'number', u'of', u'syllable', u'in', u'some', u'variety', u'be', u'therefore', u'only', u'about', u'a', u'thousand', u',', u'include', u'tonal', u'variation', u',', u'which', u'be', u'only', u'about', u'a', u'eighth', u'as', u'many', u'as', u'english', u'defranci', u'-lrb-', u'1984', u'-rrb-', u'p.', u'42', u'count', u'chinese', u'as', u'have', u'1,277', u'tonal', u'syllable', u',', u'and', u'about', u'398', u'to', u'418', u'if', u'tone', u'be', u'disregard', u';', u'he', u'cite', u'Jespersen', u',', u'Otto', u'-lrb-', u'1928', u'-rrb-', u'Monosyllabism', u'in', u'English', u';', u'London', u',', u'p.', u'15', u'for', u'a', u'count', u'of', u'over', u'8000', u'syllable', u'for', u'English', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNS', u'IN', u'DT', u'NNS', u'VBZ', u'RB', u'RB', u'IN', u'DT', u'CD', u',', u'VBG', u'JJ', u'NN', u',', u'WDT', u'VBZ', u'RB', u'IN', u'DT', u'JJ', u'IN', u'JJ', u'IN', u'JJ', u'NN', u'-LRB-', u'CD', u'-RRB-', u'NN', u'CD', u'NNS', u'JJ', u'IN', u'VBG', u'CD', u'JJ', u'NNS', u',', u'CC', u'IN', u'CD', u'TO', u'CD', u'IN', u'NNS', u'VBP', u'VBN', u':', u'PRP', u'VBZ', u'NNP', u',', u'NNP', u'-LRB-', u'CD', u'-RRB-', u'NNP', u'IN', u'NNP', u':', u'NNP', u',', u'NN', u'CD', u'IN', u'DT', u'NN', u'IN', u'IN', u'CD', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[24416, 24419], [24420, 24425], [24426, 24432], [24433, 24435], [24436, 24445], [24446, 24448], [24449, 24453], [24454, 24463], [24464, 24466], [24467, 24476], [24477, 24481], [24482, 24487], [24488, 24489], [24490, 24498], [24498, 24499], [24500, 24509], [24510, 24515], [24516, 24525], [24525, 24526], [24527, 24532], [24533, 24535], [24536, 24540], [24541, 24546], [24547, 24549], [24550, 24556], [24557, 24559], [24560, 24564], [24565, 24567], [24568, 24575], [24576, 24585], [24586, 24587], [24587, 24591], [24591, 24592], [24593, 24595], [24595, 24597], [24598, 24604], [24605, 24612], [24613, 24615], [24616, 24622], [24623, 24628], [24629, 24634], [24635, 24644], [24644, 24645], [24646, 24649], [24650, 24655], [24656, 24659], [24660, 24662], [24663, 24666], [24667, 24669], [24670, 24675], [24676, 24679], [24680, 24691], [24691, 24692], [24693, 24695], [24696, 24701], [24702, 24711], [24711, 24712], [24713, 24717], [24718, 24719], [24719, 24723], [24723, 24724], [24725, 24738], [24739, 24741], [24742, 24749], [24749, 24750], [24751, 24757], [24757, 24758], [24759, 24761], [24761, 24763], [24764, 24767], [24768, 24769], [24770, 24775], [24776, 24778], [24779, 24783], [24784, 24788], [24789, 24798], [24799, 24802], [24803, 24810], [24810, 24811]]}) 
answer: set([u'analytical', u'speak'])
candidate Sentence: (0.16429184377193451, {u'tokens': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'How', u'hard', u'is', u'it', u'to', u'learn', u'Chinese', u'?'], u'lemmas': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'how', u'hard', u'be', u'it', u'to', u'learn', u'chinese', u'?'], u'pos': [u'NNP', u'NNP', u'VBD', u'NNP', u'NNP', u'NNP', u'NNP', u'WRB', u'JJ', u'VBZ', u'PRP', u'TO', u'VB', u'JJ', u'.'], u'char_offsets': [[40429, 40432], [40433, 40437], [40438, 40439], [40440, 40442], [40443, 40444], [40445, 40453], [40454, 40455], [40456, 40459], [40460, 40464], [40465, 40467], [40468, 40470], [40471, 40473], [40474, 40479], [40480, 40487], [40487, 40488]]}) 
answer: set([u'analytical', u'variety', u'tonal', u'speak'])
candidate Sentence: (0.15410527586936951, {u'tokens': [u'The', u'government', u'intends', u'for', u'speakers', u'of', u'all', u'Chinese', u'speech', u'varieties', u'to', u'use', u'it', u'as', u'a', u'common', u'language', u'of', u'communication', u'.'], u'lemmas': [u'the', u'government', u'intend', u'for', u'speaker', u'of', u'all', u'chinese', u'speech', u'variety', u'to', u'use', u'it', u'as', u'a', u'common', u'language', u'of', u'communication', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'IN', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'NNS', u'TO', u'VB', u'PRP', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[5920, 5923], [5924, 5934], [5935, 5942], [5943, 5946], [5947, 5955], [5956, 5958], [5959, 5962], [5963, 5970], [5971, 5977], [5978, 5987], [5988, 5990], [5991, 5994], [5995, 5997], [5998, 6000], [6001, 6002], [6003, 6009], [6010, 6018], [6019, 6021], [6022, 6035], [6035, 6036]]}) 
answer: set([u'analytical', u'tonal', u'speak'])
candidate Sentence: (0.13838239014148712, {u'tokens': [u'Most', u'linguists', u'classify', u'all', u'varieties', u'of', u'modern', u'spoken', u'Chinese', u'as', u'part', u'of', u'the', u'Sino-Tibetan', u'language', u'family', u'and', u'believe', u'that', u'there', u'was', u'an', u'original', u'language', u',', u'termed', u'Proto-Sino-Tibetan', u',', u'from', u'which', u'the', u'Sinitic', u'and', u'Tibeto-Burman', u'languages', u'descended', u'.'], u'lemmas': [u'most', u'linguist', u'classify', u'all', u'variety', u'of', u'modern', u'speak', u'chinese', u'as', u'part', u'of', u'the', u'sino-tibetan', u'language', u'family', u'and', u'believe', u'that', u'there', u'be', u'a', u'original', u'language', u',', u'term', u'Proto-Sino-Tibetan', u',', u'from', u'which', u'the', u'sinitic', u'and', u'tibeto-burman', u'language', u'descend', u'.'], u'pos': [u'JJS', u'NNS', u'VBP', u'DT', u'NNS', u'IN', u'JJ', u'VBN', u'JJ', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u'CC', u'VB', u'IN', u'EX', u'VBD', u'DT', u'JJ', u'NN', u',', u'VBN', u'NNP', u',', u'IN', u'WDT', u'DT', u'JJ', u'CC', u'JJ', u'NNS', u'VBD', u'.'], u'char_offsets': [[14307, 14311], [14312, 14321], [14322, 14330], [14331, 14334], [14335, 14344], [14345, 14347], [14348, 14354], [14355, 14361], [14362, 14369], [14370, 14372], [14373, 14377], [14378, 14380], [14381, 14384], [14385, 14397], [14398, 14406], [14407, 14413], [14414, 14417], [14418, 14425], [14426, 14430], [14431, 14436], [14437, 14440], [14441, 14443], [14444, 14452], [14453, 14461], [14461, 14462], [14463, 14469], [14470, 14488], [14488, 14489], [14490, 14494], [14495, 14500], [14501, 14504], [14505, 14512], [14513, 14516], [14517, 14530], [14531, 14540], [14541, 14550], [14550, 14551]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.12350723147392273, {u'tokens': [u'Other', u'notable', u'grammatical', u'features', u'common', u'to', u'all', u'the', u'spoken', u'varieties', u'of', u'Chinese', u'include', u'the', u'use', u'of', u'serial', u'verb', u'construction', u',', u'pronoun', u'dropping', u'and', u'the', u'related', u'subject', u'dropping', u'.'], u'lemmas': [u'other', u'notable', u'grammatical', u'feature', u'common', u'to', u'all', u'the', u'speak', u'variety', u'of', u'chinese', u'include', u'the', u'use', u'of', u'serial', u'verb', u'construction', u',', u'pronoun', u'drop', u'and', u'the', u'related', u'subject', u'drop', u'.'], u'pos': [u'JJ', u'JJ', u'JJ', u'NNS', u'JJ', u'TO', u'PDT', u'DT', u'VBN', u'NNS', u'IN', u'JJ', u'VBP', u'DT', u'NN', u'IN', u'NN', u'VBP', u'NN', u',', u'NN', u'VBG', u'CC', u'DT', u'JJ', u'JJ', u'VBG', u'.'], u'char_offsets': [[31373, 31378], [31379, 31386], [31387, 31398], [31399, 31407], [31408, 31414], [31415, 31417], [31418, 31421], [31422, 31425], [31426, 31432], [31433, 31442], [31443, 31445], [31446, 31453], [31454, 31461], [31462, 31465], [31466, 31469], [31470, 31472], [31473, 31479], [31480, 31484], [31485, 31497], [31497, 31498], [31499, 31506], [31507, 31515], [31516, 31519], [31520, 31523], [31524, 31531], [31532, 31539], [31540, 31548], [31548, 31549]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.11728067696094513, {u'tokens': [u'Linguists', u'often', u'view', u'Chinese', u'as', u'a', u'language', u'family', u',', u'though', u'owing', u'to', u'China', u"'s", u'socio-political', u'and', u'cultural', u'situation', u',', u'and', u'the', u'fact', u'that', u'all', u'spoken', u'varieties', u'use', u'one', u'common', u'written', u'system', u',', u'it', u'is', u'customary', u'to', u'refer', u'to', u'these', u'generally', u'mutually', u'unintelligible', u'variants', u'as', u'``', u'the', u'Chinese', u'language', u"''", u'.'], u'lemmas': [u'linguist', u'often', u'view', u'chinese', u'as', u'a', u'language', u'family', u',', u'though', u'owe', u'to', u'China', u"'s", u'socio-political', u'and', u'cultural', u'situation', u',', u'and', u'the', u'fact', u'that', u'all', u'speak', u'variety', u'use', u'one', u'common', u'written', u'system', u',', u'it', u'be', u'customary', u'to', u'refer', u'to', u'these', u'generally', u'mutually', u'unintelligible', u'variant', u'as', u'``', u'the', u'chinese', u'language', u"''", u'.'], u'pos': [u'NNS', u'RB', u'VBP', u'JJ', u'IN', u'DT', u'NN', u'NN', u',', u'IN', u'VBG', u'TO', u'NNP', u'POS', u'JJ', u'CC', u'JJ', u'NN', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'VBN', u'NNS', u'VBP', u'CD', u'JJ', u'JJ', u'NN', u',', u'PRP', u'VBZ', u'JJ', u'TO', u'VB', u'TO', u'DT', u'RB', u'RB', u'JJ', u'NNS', u'IN', u'``', u'DT', u'JJ', u'NN', u"''", u'.'], u'char_offsets': [[6943, 6952], [6953, 6958], [6959, 6963], [6964, 6971], [6972, 6974], [6975, 6976], [6977, 6985], [6986, 6992], [6992, 6993], [6994, 7000], [7001, 7006], [7007, 7009], [7010, 7015], [7015, 7017], [7018, 7033], [7034, 7037], [7038, 7046], [7047, 7056], [7056, 7057], [7058, 7061], [7062, 7065], [7066, 7070], [7071, 7075], [7076, 7079], [7080, 7086], [7087, 7096], [7097, 7100], [7101, 7104], [7105, 7111], [7112, 7119], [7120, 7126], [7126, 7127], [7128, 7130], [7131, 7133], [7134, 7143], [7144, 7146], [7147, 7152], [7153, 7155], [7156, 7161], [7162, 7171], [7172, 7180], [7181, 7195], [7196, 7204], [7205, 7207], [7208, 7209], [7209, 7212], [7213, 7220], [7221, 7229], [7229, 7230], [7230, 7231]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.11195456981658936, {u'tokens': [u'As', u'a', u'result', u',', u'Mandarin', u'is', u'now', u'spoken', u'by', u'virtually', u'all', u'young', u'and', u'middle-aged', u'citizens', u'of', u'mainland', u'China', u'and', u'on', u'Taiwan', u'.'], u'lemmas': [u'as', u'a', u'result', u',', u'Mandarin', u'be', u'now', u'speak', u'by', u'virtually', u'all', u'young', u'and', u'middle-aged', u'citizen', u'of', u'mainland', u'China', u'and', u'on', u'Taiwan', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'NNP', u'VBZ', u'RB', u'VBN', u'IN', u'RB', u'DT', u'JJ', u'CC', u'JJ', u'NNS', u'IN', u'NN', u'NNP', u'CC', u'IN', u'NNP', u'.'], u'char_offsets': [[19871, 19873], [19874, 19875], [19876, 19882], [19882, 19883], [19884, 19892], [19893, 19895], [19896, 19899], [19900, 19906], [19907, 19909], [19910, 19919], [19920, 19923], [19924, 19929], [19930, 19933], [19934, 19945], [19946, 19954], [19955, 19957], [19958, 19966], [19967, 19972], [19973, 19976], [19977, 19979], [19980, 19986], [19986, 19987]]}) 
answer: set([u'analytical', u'tonal', u'variety'])
candidate Sentence: (0.10803401470184326, {u'tokens': [u'Across', u'all', u'the', u'spoken', u'varieties', u',', u'most', u'syllables', u'tend', u'to', u'be', u'open', u'syllables', u',', u'meaning', u'they', u'have', u'no', u'coda', u',', u'but', u'syllables', u'that', u'do', u'have', u'codas', u'are', u'restricted', u'to', u',', u',', u',', u',', u',', u',', u'or', u'.'], u'lemmas': [u'across', u'all', u'the', u'speak', u'variety', u',', u'most', u'syllable', u'tend', u'to', u'be', u'open', u'syllable', u',', u'mean', u'they', u'have', u'no', u'coda', u',', u'but', u'syllable', u'that', u'do', u'have', u'coda', u'be', u'restricted', u'to', u',', u',', u',', u',', u',', u',', u'or', u'.'], u'pos': [u'IN', u'PDT', u'DT', u'VBN', u'NNS', u',', u'JJS', u'NNS', u'VBP', u'TO', u'VB', u'JJ', u'NNS', u',', u'VBG', u'PRP', u'VBP', u'DT', u'NN', u',', u'CC', u'NNS', u'WDT', u'VBP', u'VB', u'NNS', u'VBP', u'JJ', u'TO', u',', u',', u',', u',', u',', u',', u'CC', u'.'], u'char_offsets': [[23615, 23621], [23622, 23625], [23626, 23629], [23630, 23636], [23637, 23646], [23646, 23647], [23648, 23652], [23653, 23662], [23663, 23667], [23668, 23670], [23671, 23673], [23674, 23678], [23679, 23688], [23688, 23689], [23690, 23697], [23698, 23702], [23703, 23707], [23708, 23710], [23711, 23715], [23715, 23716], [23717, 23720], [23721, 23730], [23731, 23735], [23736, 23738], [23739, 23743], [23744, 23749], [23750, 23753], [23754, 23764], [23765, 23767], [23769, 23770], [23772, 23773], [23775, 23776], [23778, 23779], [23781, 23782], [23784, 23785], [23786, 23788], [23790, 23791]]}) 
answer: set([u'analytical', u'tonal'])

Are all spoken varieties of Chinese tonal and analytical?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cb4d0>.answer
_____________________________ test_yesno[param70] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb638>, (<src.tfidf.TF_IDF object at 0x10a4b03d0>, set(['chinese', 'chinese_language', 'language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cb638>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39408707618713379, {u'tokens': [u'All', u'varieties', u'of', u'spoken', u'Chinese', u'use', u'tones', u'.'], u'lemmas': [u'all', u'variety', u'of', u'speak', u'chinese', u'use', u'tone', u'.'], u'pos': [u'DT', u'NNS', u'IN', u'VBN', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[24814, 24817], [24818, 24827], [24828, 24830], [24831, 24837], [24838, 24845], [24846, 24849], [24850, 24855], [24855, 24856]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.34200888872146606, {u'tokens': [u'Spoken', u'Chinese', u'is', u'distinguished', u'by', u'its', u'high', u'level', u'of', u'internal', u'diversity', u',', u'although', u'all', u'spoken', u'varieties', u'of', u'Chinese', u'are', u'tonal', u'and', u'analytic', u'.'], u'lemmas': [u'speak', u'Chinese', u'be', u'distinguish', u'by', u'its', u'high', u'level', u'of', u'internal', u'diversity', u',', u'although', u'all', u'speak', u'variety', u'of', u'Chinese', u'be', u'tonal', u'and', u'analytic', u'.'], u'pos': [u'VBN', u'NNPS', u'VBZ', u'VBN', u'IN', u'PRP$', u'JJ', u'NN', u'IN', u'JJ', u'NN', u',', u'IN', u'DT', u'VBN', u'NNS', u'IN', u'NNP', u'VBP', u'JJ', u'CC', u'JJ', u'.'], u'char_offsets': [[1612, 1618], [1619, 1626], [1627, 1629], [1630, 1643], [1644, 1646], [1647, 1650], [1651, 1655], [1656, 1661], [1662, 1664], [1665, 1673], [1674, 1683], [1683, 1684], [1685, 1693], [1694, 1697], [1698, 1704], [1705, 1714], [1715, 1717], [1718, 1725], [1726, 1729], [1730, 1735], [1736, 1739], [1740, 1748], [1748, 1749]]}) 
answer: set([u'analytical'])
candidate Sentence: (0.17520058155059814, {u'tokens': [u'The', u'total', u'number', u'of', u'syllables', u'in', u'some', u'varieties', u'is', u'therefore', u'only', u'about', u'a', u'thousand', u',', u'including', u'tonal', u'variation', u',', u'which', u'is', u'only', u'about', u'an', u'eighth', u'as', u'many', u'as', u'English', u'DeFrancis', u'-LRB-', u'1984', u'-RRB-', u'p.', u'42', u'counts', u'Chinese', u'as', u'having', u'1,277', u'tonal', u'syllables', u',', u'and', u'about', u'398', u'to', u'418', u'if', u'tones', u'are', u'disregarded', u';', u'he', u'cites', u'Jespersen', u',', u'Otto', u'-LRB-', u'1928', u'-RRB-', u'Monosyllabism', u'in', u'English', u';', u'London', u',', u'p.', u'15', u'for', u'a', u'count', u'of', u'over', u'8000', u'syllables', u'for', u'English', u'.'], u'lemmas': [u'the', u'total', u'number', u'of', u'syllable', u'in', u'some', u'variety', u'be', u'therefore', u'only', u'about', u'a', u'thousand', u',', u'include', u'tonal', u'variation', u',', u'which', u'be', u'only', u'about', u'a', u'eighth', u'as', u'many', u'as', u'english', u'defranci', u'-lrb-', u'1984', u'-rrb-', u'p.', u'42', u'count', u'chinese', u'as', u'have', u'1,277', u'tonal', u'syllable', u',', u'and', u'about', u'398', u'to', u'418', u'if', u'tone', u'be', u'disregard', u';', u'he', u'cite', u'Jespersen', u',', u'Otto', u'-lrb-', u'1928', u'-rrb-', u'Monosyllabism', u'in', u'English', u';', u'London', u',', u'p.', u'15', u'for', u'a', u'count', u'of', u'over', u'8000', u'syllable', u'for', u'English', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNS', u'IN', u'DT', u'NNS', u'VBZ', u'RB', u'RB', u'IN', u'DT', u'CD', u',', u'VBG', u'JJ', u'NN', u',', u'WDT', u'VBZ', u'RB', u'IN', u'DT', u'JJ', u'IN', u'JJ', u'IN', u'JJ', u'NN', u'-LRB-', u'CD', u'-RRB-', u'NN', u'CD', u'NNS', u'JJ', u'IN', u'VBG', u'CD', u'JJ', u'NNS', u',', u'CC', u'IN', u'CD', u'TO', u'CD', u'IN', u'NNS', u'VBP', u'VBN', u':', u'PRP', u'VBZ', u'NNP', u',', u'NNP', u'-LRB-', u'CD', u'-RRB-', u'NNP', u'IN', u'NNP', u':', u'NNP', u',', u'NN', u'CD', u'IN', u'DT', u'NN', u'IN', u'IN', u'CD', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[24416, 24419], [24420, 24425], [24426, 24432], [24433, 24435], [24436, 24445], [24446, 24448], [24449, 24453], [24454, 24463], [24464, 24466], [24467, 24476], [24477, 24481], [24482, 24487], [24488, 24489], [24490, 24498], [24498, 24499], [24500, 24509], [24510, 24515], [24516, 24525], [24525, 24526], [24527, 24532], [24533, 24535], [24536, 24540], [24541, 24546], [24547, 24549], [24550, 24556], [24557, 24559], [24560, 24564], [24565, 24567], [24568, 24575], [24576, 24585], [24586, 24587], [24587, 24591], [24591, 24592], [24593, 24595], [24595, 24597], [24598, 24604], [24605, 24612], [24613, 24615], [24616, 24622], [24623, 24628], [24629, 24634], [24635, 24644], [24644, 24645], [24646, 24649], [24650, 24655], [24656, 24659], [24660, 24662], [24663, 24666], [24667, 24669], [24670, 24675], [24676, 24679], [24680, 24691], [24691, 24692], [24693, 24695], [24696, 24701], [24702, 24711], [24711, 24712], [24713, 24717], [24718, 24719], [24719, 24723], [24723, 24724], [24725, 24738], [24739, 24741], [24742, 24749], [24749, 24750], [24751, 24757], [24757, 24758], [24759, 24761], [24761, 24763], [24764, 24767], [24768, 24769], [24770, 24775], [24776, 24778], [24779, 24783], [24784, 24788], [24789, 24798], [24799, 24802], [24803, 24810], [24810, 24811]]}) 
answer: set([u'analytical', u'speak'])
candidate Sentence: (0.16429184377193451, {u'tokens': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'How', u'hard', u'is', u'it', u'to', u'learn', u'Chinese', u'?'], u'lemmas': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'how', u'hard', u'be', u'it', u'to', u'learn', u'chinese', u'?'], u'pos': [u'NNP', u'NNP', u'VBD', u'NNP', u'NNP', u'NNP', u'NNP', u'WRB', u'JJ', u'VBZ', u'PRP', u'TO', u'VB', u'JJ', u'.'], u'char_offsets': [[40429, 40432], [40433, 40437], [40438, 40439], [40440, 40442], [40443, 40444], [40445, 40453], [40454, 40455], [40456, 40459], [40460, 40464], [40465, 40467], [40468, 40470], [40471, 40473], [40474, 40479], [40480, 40487], [40487, 40488]]}) 
answer: set([u'analytical', u'variety', u'tonal', u'speak'])
candidate Sentence: (0.15410527586936951, {u'tokens': [u'The', u'government', u'intends', u'for', u'speakers', u'of', u'all', u'Chinese', u'speech', u'varieties', u'to', u'use', u'it', u'as', u'a', u'common', u'language', u'of', u'communication', u'.'], u'lemmas': [u'the', u'government', u'intend', u'for', u'speaker', u'of', u'all', u'chinese', u'speech', u'variety', u'to', u'use', u'it', u'as', u'a', u'common', u'language', u'of', u'communication', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'IN', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'NNS', u'TO', u'VB', u'PRP', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[5920, 5923], [5924, 5934], [5935, 5942], [5943, 5946], [5947, 5955], [5956, 5958], [5959, 5962], [5963, 5970], [5971, 5977], [5978, 5987], [5988, 5990], [5991, 5994], [5995, 5997], [5998, 6000], [6001, 6002], [6003, 6009], [6010, 6018], [6019, 6021], [6022, 6035], [6035, 6036]]}) 
answer: set([u'analytical', u'tonal', u'speak'])
candidate Sentence: (0.13838239014148712, {u'tokens': [u'Most', u'linguists', u'classify', u'all', u'varieties', u'of', u'modern', u'spoken', u'Chinese', u'as', u'part', u'of', u'the', u'Sino-Tibetan', u'language', u'family', u'and', u'believe', u'that', u'there', u'was', u'an', u'original', u'language', u',', u'termed', u'Proto-Sino-Tibetan', u',', u'from', u'which', u'the', u'Sinitic', u'and', u'Tibeto-Burman', u'languages', u'descended', u'.'], u'lemmas': [u'most', u'linguist', u'classify', u'all', u'variety', u'of', u'modern', u'speak', u'chinese', u'as', u'part', u'of', u'the', u'sino-tibetan', u'language', u'family', u'and', u'believe', u'that', u'there', u'be', u'a', u'original', u'language', u',', u'term', u'Proto-Sino-Tibetan', u',', u'from', u'which', u'the', u'sinitic', u'and', u'tibeto-burman', u'language', u'descend', u'.'], u'pos': [u'JJS', u'NNS', u'VBP', u'DT', u'NNS', u'IN', u'JJ', u'VBN', u'JJ', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u'CC', u'VB', u'IN', u'EX', u'VBD', u'DT', u'JJ', u'NN', u',', u'VBN', u'NNP', u',', u'IN', u'WDT', u'DT', u'JJ', u'CC', u'JJ', u'NNS', u'VBD', u'.'], u'char_offsets': [[14307, 14311], [14312, 14321], [14322, 14330], [14331, 14334], [14335, 14344], [14345, 14347], [14348, 14354], [14355, 14361], [14362, 14369], [14370, 14372], [14373, 14377], [14378, 14380], [14381, 14384], [14385, 14397], [14398, 14406], [14407, 14413], [14414, 14417], [14418, 14425], [14426, 14430], [14431, 14436], [14437, 14440], [14441, 14443], [14444, 14452], [14453, 14461], [14461, 14462], [14463, 14469], [14470, 14488], [14488, 14489], [14490, 14494], [14495, 14500], [14501, 14504], [14505, 14512], [14513, 14516], [14517, 14530], [14531, 14540], [14541, 14550], [14550, 14551]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.12350723147392273, {u'tokens': [u'Other', u'notable', u'grammatical', u'features', u'common', u'to', u'all', u'the', u'spoken', u'varieties', u'of', u'Chinese', u'include', u'the', u'use', u'of', u'serial', u'verb', u'construction', u',', u'pronoun', u'dropping', u'and', u'the', u'related', u'subject', u'dropping', u'.'], u'lemmas': [u'other', u'notable', u'grammatical', u'feature', u'common', u'to', u'all', u'the', u'speak', u'variety', u'of', u'chinese', u'include', u'the', u'use', u'of', u'serial', u'verb', u'construction', u',', u'pronoun', u'drop', u'and', u'the', u'related', u'subject', u'drop', u'.'], u'pos': [u'JJ', u'JJ', u'JJ', u'NNS', u'JJ', u'TO', u'PDT', u'DT', u'VBN', u'NNS', u'IN', u'JJ', u'VBP', u'DT', u'NN', u'IN', u'NN', u'VBP', u'NN', u',', u'NN', u'VBG', u'CC', u'DT', u'JJ', u'JJ', u'VBG', u'.'], u'char_offsets': [[31373, 31378], [31379, 31386], [31387, 31398], [31399, 31407], [31408, 31414], [31415, 31417], [31418, 31421], [31422, 31425], [31426, 31432], [31433, 31442], [31443, 31445], [31446, 31453], [31454, 31461], [31462, 31465], [31466, 31469], [31470, 31472], [31473, 31479], [31480, 31484], [31485, 31497], [31497, 31498], [31499, 31506], [31507, 31515], [31516, 31519], [31520, 31523], [31524, 31531], [31532, 31539], [31540, 31548], [31548, 31549]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.11728067696094513, {u'tokens': [u'Linguists', u'often', u'view', u'Chinese', u'as', u'a', u'language', u'family', u',', u'though', u'owing', u'to', u'China', u"'s", u'socio-political', u'and', u'cultural', u'situation', u',', u'and', u'the', u'fact', u'that', u'all', u'spoken', u'varieties', u'use', u'one', u'common', u'written', u'system', u',', u'it', u'is', u'customary', u'to', u'refer', u'to', u'these', u'generally', u'mutually', u'unintelligible', u'variants', u'as', u'``', u'the', u'Chinese', u'language', u"''", u'.'], u'lemmas': [u'linguist', u'often', u'view', u'chinese', u'as', u'a', u'language', u'family', u',', u'though', u'owe', u'to', u'China', u"'s", u'socio-political', u'and', u'cultural', u'situation', u',', u'and', u'the', u'fact', u'that', u'all', u'speak', u'variety', u'use', u'one', u'common', u'written', u'system', u',', u'it', u'be', u'customary', u'to', u'refer', u'to', u'these', u'generally', u'mutually', u'unintelligible', u'variant', u'as', u'``', u'the', u'chinese', u'language', u"''", u'.'], u'pos': [u'NNS', u'RB', u'VBP', u'JJ', u'IN', u'DT', u'NN', u'NN', u',', u'IN', u'VBG', u'TO', u'NNP', u'POS', u'JJ', u'CC', u'JJ', u'NN', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'VBN', u'NNS', u'VBP', u'CD', u'JJ', u'JJ', u'NN', u',', u'PRP', u'VBZ', u'JJ', u'TO', u'VB', u'TO', u'DT', u'RB', u'RB', u'JJ', u'NNS', u'IN', u'``', u'DT', u'JJ', u'NN', u"''", u'.'], u'char_offsets': [[6943, 6952], [6953, 6958], [6959, 6963], [6964, 6971], [6972, 6974], [6975, 6976], [6977, 6985], [6986, 6992], [6992, 6993], [6994, 7000], [7001, 7006], [7007, 7009], [7010, 7015], [7015, 7017], [7018, 7033], [7034, 7037], [7038, 7046], [7047, 7056], [7056, 7057], [7058, 7061], [7062, 7065], [7066, 7070], [7071, 7075], [7076, 7079], [7080, 7086], [7087, 7096], [7097, 7100], [7101, 7104], [7105, 7111], [7112, 7119], [7120, 7126], [7126, 7127], [7128, 7130], [7131, 7133], [7134, 7143], [7144, 7146], [7147, 7152], [7153, 7155], [7156, 7161], [7162, 7171], [7172, 7180], [7181, 7195], [7196, 7204], [7205, 7207], [7208, 7209], [7209, 7212], [7213, 7220], [7221, 7229], [7229, 7230], [7230, 7231]]}) 
answer: set([u'analytical', u'tonal'])
candidate Sentence: (0.11195456981658936, {u'tokens': [u'As', u'a', u'result', u',', u'Mandarin', u'is', u'now', u'spoken', u'by', u'virtually', u'all', u'young', u'and', u'middle-aged', u'citizens', u'of', u'mainland', u'China', u'and', u'on', u'Taiwan', u'.'], u'lemmas': [u'as', u'a', u'result', u',', u'Mandarin', u'be', u'now', u'speak', u'by', u'virtually', u'all', u'young', u'and', u'middle-aged', u'citizen', u'of', u'mainland', u'China', u'and', u'on', u'Taiwan', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'NNP', u'VBZ', u'RB', u'VBN', u'IN', u'RB', u'DT', u'JJ', u'CC', u'JJ', u'NNS', u'IN', u'NN', u'NNP', u'CC', u'IN', u'NNP', u'.'], u'char_offsets': [[19871, 19873], [19874, 19875], [19876, 19882], [19882, 19883], [19884, 19892], [19893, 19895], [19896, 19899], [19900, 19906], [19907, 19909], [19910, 19919], [19920, 19923], [19924, 19929], [19930, 19933], [19934, 19945], [19946, 19954], [19955, 19957], [19958, 19966], [19967, 19972], [19973, 19976], [19977, 19979], [19980, 19986], [19986, 19987]]}) 
answer: set([u'analytical', u'tonal', u'variety'])
candidate Sentence: (0.10803401470184326, {u'tokens': [u'Across', u'all', u'the', u'spoken', u'varieties', u',', u'most', u'syllables', u'tend', u'to', u'be', u'open', u'syllables', u',', u'meaning', u'they', u'have', u'no', u'coda', u',', u'but', u'syllables', u'that', u'do', u'have', u'codas', u'are', u'restricted', u'to', u',', u',', u',', u',', u',', u',', u'or', u'.'], u'lemmas': [u'across', u'all', u'the', u'speak', u'variety', u',', u'most', u'syllable', u'tend', u'to', u'be', u'open', u'syllable', u',', u'mean', u'they', u'have', u'no', u'coda', u',', u'but', u'syllable', u'that', u'do', u'have', u'coda', u'be', u'restricted', u'to', u',', u',', u',', u',', u',', u',', u'or', u'.'], u'pos': [u'IN', u'PDT', u'DT', u'VBN', u'NNS', u',', u'JJS', u'NNS', u'VBP', u'TO', u'VB', u'JJ', u'NNS', u',', u'VBG', u'PRP', u'VBP', u'DT', u'NN', u',', u'CC', u'NNS', u'WDT', u'VBP', u'VB', u'NNS', u'VBP', u'JJ', u'TO', u',', u',', u',', u',', u',', u',', u'CC', u'.'], u'char_offsets': [[23615, 23621], [23622, 23625], [23626, 23629], [23630, 23636], [23637, 23646], [23646, 23647], [23648, 23652], [23653, 23662], [23663, 23667], [23668, 23670], [23671, 23673], [23674, 23678], [23679, 23688], [23688, 23689], [23690, 23697], [23698, 23702], [23703, 23707], [23708, 23710], [23711, 23715], [23715, 23716], [23717, 23720], [23721, 23730], [23731, 23735], [23736, 23738], [23739, 23743], [23744, 23749], [23750, 23753], [23754, 23764], [23765, 23767], [23769, 23770], [23772, 23773], [23775, 23776], [23778, 23779], [23781, 23782], [23784, 23785], [23786, 23788], [23790, 23791]]}) 
answer: set([u'analytical', u'tonal'])

Are all spoken varieties of Chinese tonal and analytical?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cb638>.answer
_____________________________ test_yesno[param73] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb710>, (<src.tfidf.TF_IDF object at 0x10a4b03d0>, set(['chinese', 'chinese_language', 'language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114cb710>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.54191052913665771, {u'tokens': [u'Examples', u'of', u'such', u'words', u'are', u'``', u'tea', u"''", u'from', u'the', u'Minnan', u'pronunciation', u'of', u'\u8336', u'-LRB-', u'POJ', u':', u't\xea', u'-RRB-', u',', u'``', u'ketchup', u"''", u'from', u'the', u'Minnan', u'pronunciation', u'of', u'\u9bad\u6c41', u'-LRB-', u'koe-tsiap', u'-RRB-', u',', u'and', u'``', u'kumquat', u"''", u'from', u'the', u'Cantonese', u'pronunciation', u'of', u'\u91d1\u6a58', u'-LRB-', u'kam', u'kuat', u'-RRB-', u'.'], u'lemmas': [u'example', u'of', u'such', u'word', u'be', u'``', u'tea', u"''", u'from', u'the', u'minnan', u'pronunciation', u'of', u'\u8336', u'-lrb-', u'poj', u':', u't\xea', u'-rrb-', u',', u'``', u'ketchup', u"''", u'from', u'the', u'minnan', u'pronunciation', u'of', u'\u9bad\u6c41', u'-lrb-', u'koe-tsiap', u'-rrb-', u',', u'and', u'``', u'kumquat', u"''", u'from', u'the', u'cantonese', u'pronunciation', u'of', u'\u91d1\u6a58', u'-lrb-', u'kam', u'kuat', u'-rrb-', u'.'], u'pos': [u'NNS', u'IN', u'JJ', u'NNS', u'VBP', u'``', u'NN', u"''", u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'NN', u':', u'NN', u'-RRB-', u',', u'``', u'NN', u"''", u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'NN', u'-RRB-', u',', u'CC', u'``', u'NN', u"''", u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'FW', u'FW', u'-RRB-', u'.'], u'char_offsets': [[22885, 22893], [22894, 22896], [22897, 22901], [22902, 22907], [22908, 22911], [22912, 22913], [22913, 22916], [22916, 22917], [22918, 22922], [22923, 22926], [22927, 22933], [22934, 22947], [22948, 22950], [22951, 22952], [22953, 22954], [22954, 22957], [22957, 22958], [22959, 22961], [22961, 22962], [22962, 22963], [22964, 22965], [22965, 22972], [22972, 22973], [22974, 22978], [22979, 22982], [22983, 22989], [22990, 23003], [23004, 23006], [23007, 23009], [23010, 23011], [23011, 23020], [23020, 23021], [23021, 23022], [23023, 23026], [23027, 23028], [23028, 23035], [23035, 23036], [23037, 23041], [23042, 23045], [23046, 23055], [23056, 23069], [23070, 23072], [23073, 23075], [23076, 23077], [23077, 23080], [23081, 23085], [23085, 23086], [23086, 23087]]}) 
answer: set([u'&#27713;', u'come', u'&#39853;'])
candidate Sentence: (0.17428198456764221, {u'tokens': [u'From', u'French', u'came', u'\u82ad\u857e', u'-LRB-', u'b\u0101l\xe9i', u',', u'``', u'ballet', u"''", u'-RRB-', u',', u'\u9999\u69df', u'-LRB-', u'xi\u0101ngb\u012bn', u',', u'``', u'champagne', u"''", u'-RRB-', u',', u'via', u'Italian', u'\u5496\u5561', u'-LRB-', u'k\u0101f\u0113i', u',', u'``', u'caff\xe8', u"''", u'-RRB-', u'.'], u'lemmas': [u'from', u'French', u'come', u'\u82ad\u857e', u'-lrb-', u'b\u0101l\xe9i', u',', u'``', u'ballet', u"''", u'-rrb-', u',', u'\u9999\u69df', u'-lrb-', u'xi\u0101ngb\u012bn', u',', u'``', u'champagne', u"''", u'-rrb-', u',', u'via', u'italian', u'\u5496\u5561', u'-lrb-', u'k\u0101f\u0113i', u',', u'``', u'caff\xe8', u"''", u'-rrb-', u'.'], u'pos': [u'IN', u'NNP', u'VBD', u'CD', u'-LRB-', u'NN', u',', u'``', u'JJ', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'IN', u'JJ', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[36511, 36515], [36516, 36522], [36523, 36527], [36528, 36530], [36531, 36532], [36532, 36537], [36537, 36538], [36539, 36540], [36540, 36546], [36546, 36547], [36547, 36548], [36548, 36549], [36550, 36552], [36553, 36554], [36554, 36562], [36562, 36563], [36564, 36565], [36565, 36574], [36574, 36575], [36575, 36576], [36576, 36577], [36578, 36581], [36582, 36589], [36590, 36592], [36593, 36594], [36594, 36599], [36599, 36600], [36601, 36602], [36602, 36607], [36607, 36608], [36608, 36609], [36609, 36610]]}) 
answer: set([u'minnan', u'pronunciation', u'&#39853;', u'&#27713;', u'ketchup', u'koe-tsiap'])
candidate Sentence: (0.17395338416099548, {u'tokens': [u'Other', u'words', u'came', u'from', u'nomadic', u'peoples', u'to', u'the', u'north', u',', u'such', u'as', u'\u80e1\u540c', u'``', u'hutong', u'.', u"''"], u'lemmas': [u'other', u'word', u'come', u'from', u'nomadic', u'people', u'to', u'the', u'north', u',', u'such', u'as', u'\u80e1\u540c', u'``', u'hutong', u'.', u"''"], u'pos': [u'JJ', u'NNS', u'VBD', u'IN', u'JJ', u'NNS', u'TO', u'DT', u'NN', u',', u'JJ', u'IN', u'CD', u'``', u'FW', u'.', u"''"], u'char_offsets': [[35020, 35025], [35026, 35031], [35032, 35036], [35037, 35041], [35042, 35049], [35050, 35057], [35058, 35060], [35061, 35064], [35065, 35070], [35070, 35071], [35072, 35076], [35077, 35079], [35080, 35082], [35083, 35084], [35084, 35090], [35090, 35091], [35091, 35092]]}) 
answer: set([u'-rrb-', u'ketchup', u'pronunciation', u'&#39853;', u'-lrb-', u'&#27713;', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.16458417475223541, {u'tokens': [u'This', u'is', u'done', u'by', u'employing', u'Chinese', u'characters', u'with', u'similar', u'pronunciations', u'.'], u'lemmas': [u'this', u'be', u'do', u'by', u'employ', u'chinese', u'character', u'with', u'similar', u'pronunciation', u'.'], u'pos': [u'DT', u'VBZ', u'VBN', u'IN', u'VBG', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[35682, 35686], [35687, 35689], [35690, 35694], [35695, 35697], [35698, 35707], [35708, 35715], [35716, 35726], [35727, 35731], [35732, 35739], [35740, 35754], [35754, 35755]]}) 
answer: set([u'-rrb-', u'ketchup', u'&#39853;', u'-lrb-', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.13105340301990509, {u'tokens': [u'The', u'evidence', u'for', u'the', u'pronunciation', u'of', u'Middle', u'Chinese', u'comes', u'from', u'several', u'sources', u':', u'modern', u'dialect', u'variations', u',', u'rhyming', u'dictionaries', u',', u'foreign', u'transliterations', u',', u'``', u'rhyming', u'tables', u"''", u'constructed', u'by', u'ancient', u'Chinese', u'philologists', u'to', u'summarize', u'the', u'phonetic', u'system', u',', u'and', u'Chinese', u'phonetic', u'translations', u'of', u'foreign', u'words', u'.'], u'lemmas': [u'the', u'evidence', u'for', u'the', u'pronunciation', u'of', u'Middle', u'Chinese', u'come', u'from', u'several', u'source', u':', u'modern', u'dialect', u'variation', u',', u'rhyme', u'dictionary', u',', u'foreign', u'transliteration', u',', u'``', u'rhyming', u'table', u"''", u'construct', u'by', u'ancient', u'chinese', u'philologist', u'to', u'summarize', u'the', u'phonetic', u'system', u',', u'and', u'chinese', u'phonetic', u'translation', u'of', u'foreign', u'word', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'VBZ', u'IN', u'JJ', u'NNS', u':', u'JJ', u'NN', u'NNS', u',', u'VBG', u'NNS', u',', u'JJ', u'NNS', u',', u'``', u'JJ', u'NNS', u"''", u'VBN', u'IN', u'JJ', u'JJ', u'NNS', u'TO', u'VB', u'DT', u'JJ', u'NN', u',', u'CC', u'JJ', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[17998, 18001], [18002, 18010], [18011, 18014], [18015, 18018], [18019, 18032], [18033, 18035], [18036, 18042], [18043, 18050], [18051, 18056], [18057, 18061], [18062, 18069], [18070, 18077], [18077, 18078], [18079, 18085], [18086, 18093], [18094, 18104], [18104, 18105], [18106, 18113], [18114, 18126], [18126, 18127], [18128, 18135], [18136, 18152], [18152, 18153], [18154, 18155], [18155, 18162], [18163, 18169], [18169, 18170], [18171, 18182], [18183, 18185], [18186, 18193], [18194, 18201], [18202, 18214], [18215, 18217], [18218, 18227], [18228, 18231], [18232, 18240], [18241, 18247], [18247, 18248], [18249, 18252], [18253, 18260], [18261, 18269], [18270, 18282], [18283, 18285], [18286, 18293], [18294, 18299], [18299, 18300]]}) 
answer: set([u'-rrb-', u'minnan', u'&#39853;', u'-lrb-', u'&#27713;', u'ketchup', u'koe-tsiap'])
candidate Sentence: (0.10738074034452438, {u'tokens': [u'the', u'above-mentioned', u'\u6c99\u767c', u'-LRB-', u'sh\u0101f\u0101', u'``', u'sofa', u"''", u'-RRB-', u',', u'\u5e7d\u9ed8', u'-LRB-', u'y\u014dum\xf2', u'``', u'humour', u"''", u'-RRB-', u',', u'and', u'\u9ad8\u5c14\u592b', u'-LRB-', u'g\u0101o\u011brf\u016b', u',', u'``', u'golf', u"''", u'-RRB-', u'.'], u'lemmas': [u'the', u'above-mentioned', u'\u6c99\u767c', u'-lrb-', u'sh\u0101f\u0101', u'``', u'sofa', u"''", u'-rrb-', u',', u'\u5e7d\u9ed8', u'-lrb-', u'y\u014dum\xf2', u'``', u'humour', u"''", u'-rrb-', u',', u'and', u'\u9ad8\u5c14\u592b', u'-lrb-', u'g\u0101o\u011brf\u016b', u',', u'``', u'golf', u"''", u'-rrb-', u'.'], u'pos': [u'DT', u'JJ', u'CD', u'-LRB-', u'NN', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u'``', u'NN', u"''", u'-RRB-', u',', u'CC', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[36736, 36739], [36740, 36755], [36756, 36758], [36759, 36760], [36760, 36765], [36766, 36767], [36767, 36771], [36771, 36772], [36772, 36773], [36773, 36774], [36775, 36777], [36778, 36779], [36779, 36784], [36785, 36786], [36786, 36792], [36792, 36793], [36793, 36794], [36794, 36795], [36796, 36799], [36800, 36803], [36804, 36805], [36805, 36812], [36812, 36813], [36814, 36815], [36815, 36819], [36819, 36820], [36820, 36821], [36821, 36822]]}) 
answer: set([u'ketchup', u'pronunciation', u'&#39853;', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.10313067585229874, {u'tokens': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'How', u'hard', u'is', u'it', u'to', u'learn', u'Chinese', u'?'], u'lemmas': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'how', u'hard', u'be', u'it', u'to', u'learn', u'chinese', u'?'], u'pos': [u'NNP', u'NNP', u'VBD', u'NNP', u'NNP', u'NNP', u'NNP', u'WRB', u'JJ', u'VBZ', u'PRP', u'TO', u'VB', u'JJ', u'.'], u'char_offsets': [[40429, 40432], [40433, 40437], [40438, 40439], [40440, 40442], [40443, 40444], [40445, 40453], [40454, 40455], [40456, 40459], [40460, 40464], [40465, 40467], [40468, 40470], [40471, 40473], [40474, 40479], [40480, 40487], [40487, 40488]]}) 
answer: set([u'-rrb-', u'ketchup', u'pronunciation', u'&#39853;', u'-lrb-', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.10184904932975769, {u'tokens': [u'The', u'previous', u'examples', u'of', u'j\u012b', u',', u'for', u'instance', u',', u'for', u'``', u'stimulated', u"''", u',', u'``', u'chicken', u"''", u',', u'and', u'``', u'machine', u"''", u',', u'have', u'distinct', u'pronunciations', u'in', u'Cantonese', u'-LRB-', u'romanized', u'using', u'jyutping', u'-RRB-', u':', u'gik1', u',', u'gai1', u',', u'and', u'gei1', u',', u'respectively', u'.'], u'lemmas': [u'the', u'previous', u'example', u'of', u'j\u012b', u',', u'for', u'instance', u',', u'for', u'``', u'stimulate', u"''", u',', u'``', u'chicken', u"''", u',', u'and', u'``', u'machine', u"''", u',', u'have', u'distinct', u'pronunciation', u'in', u'cantonese', u'-lrb-', u'romanize', u'use', u'jyutping', u'-rrb-', u':', u'gik1', u',', u'gai1', u',', u'and', u'gei1', u',', u'respectively', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u'IN', u'NN', u',', u'IN', u'NN', u',', u'IN', u'``', u'VBN', u"''", u',', u'``', u'NN', u"''", u',', u'CC', u'``', u'NN', u"''", u',', u'VBP', u'JJ', u'NNS', u'IN', u'NN', u'-LRB-', u'VBN', u'VBG', u'NN', u'-RRB-', u':', u'NN', u',', u'NN', u',', u'CC', u'NN', u',', u'RB', u'.'], u'char_offsets': [[32805, 32808], [32809, 32817], [32818, 32826], [32827, 32829], [32830, 32832], [32832, 32833], [32834, 32837], [32838, 32846], [32846, 32847], [32848, 32851], [32852, 32853], [32853, 32863], [32863, 32864], [32864, 32865], [32866, 32867], [32867, 32874], [32874, 32875], [32875, 32876], [32877, 32880], [32881, 32882], [32882, 32889], [32889, 32890], [32890, 32891], [32892, 32896], [32897, 32905], [32906, 32920], [32921, 32923], [32924, 32933], [32934, 32935], [32935, 32944], [32945, 32950], [32951, 32959], [32959, 32960], [32960, 32961], [32962, 32966], [32966, 32967], [32968, 32972], [32972, 32973], [32974, 32977], [32978, 32982], [32982, 32983], [32984, 32996], [32996, 32997]]}) 
answer: set([u'minnan', u'&#39853;', u'&#27713;', u'come', u'ketchup', u'koe-tsiap'])
candidate Sentence: (0.09852735698223114, {u'tokens': [u'Examples', u'include', u'di\xe0nhu\xe0', u'-LRB-', u'\u7535\u8bdd', u'/', u'\u96fb\u8a71', u',', u'denwa', u',', u'``', u'telephone', u"''", u'-RRB-', u',', u'sh\xe8hu\xec', u'-LRB-', u'\u793e\u4f1a', u',', u'shakai', u',', u'``', u'society', u"''", u'-RRB-', u',', u'k\u0113xu\xe9', u'-LRB-', u'\u79d1\u5b66', u'/', u'\u79d1\u5b78', u',', u'kagaku', u',', u'``', u'science', u"''", u'-RRB-', u'and', u'ch\u014duxi\xe0ng', u'-LRB-', u'\u62bd\u8c61', u',', u'ch\u016bsh\u014d', u',', u'``', u'abstract', u"''", u'-RRB-', u'.'], u'lemmas': [u'example', u'include', u'di\xe0nhu\xe0', u'-lrb-', u'\u7535\u8bdd', u'/', u'\u96fb\u8a71', u',', u'denwa', u',', u'``', u'telephone', u"''", u'-rrb-', u',', u'sh\xe8hu\xec', u'-lrb-', u'\u793e\u4f1a', u',', u'shakaus', u',', u'``', u'society', u"''", u'-rrb-', u',', u'k\u0113xu\xe9', u'-lrb-', u'\u79d1\u5b66', u'/', u'\u79d1\u5b78', u',', u'kagaku', u',', u'``', u'science', u"''", u'-rrb-', u'and', u'ch\u014duxi\xe0ng', u'-lrb-', u'\u62bd\u8c61', u',', u'ch\u016bsh\u014d', u',', u'``', u'abstract', u"''", u'-rrb-', u'.'], u'pos': [u'NNS', u'VBP', u'NN', u'-LRB-', u'CD', u':', u'CD', u',', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u',', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'CD', u':', u'CD', u',', u'FW', u',', u'``', u'NN', u"''", u'-RRB-', u'CC', u'NN', u'-LRB-', u'CD', u',', u'NN', u',', u'``', u'JJ', u"''", u'-RRB-', u'.'], u'char_offsets': [[39024, 39032], [39033, 39040], [39041, 39048], [39049, 39050], [39050, 39052], [39052, 39053], [39053, 39055], [39055, 39056], [39057, 39062], [39062, 39063], [39064, 39065], [39065, 39074], [39074, 39075], [39075, 39076], [39076, 39077], [39078, 39084], [39085, 39086], [39086, 39088], [39088, 39089], [39090, 39096], [39096, 39097], [39098, 39099], [39099, 39106], [39106, 39107], [39107, 39108], [39108, 39109], [39110, 39115], [39116, 39117], [39117, 39119], [39119, 39120], [39120, 39122], [39122, 39123], [39124, 39130], [39130, 39131], [39132, 39133], [39133, 39140], [39140, 39141], [39141, 39142], [39143, 39146], [39147, 39156], [39157, 39158], [39158, 39160], [39160, 39161], [39162, 39168], [39168, 39169], [39170, 39171], [39171, 39179], [39179, 39180], [39180, 39181], [39181, 39182]]}) 
answer: set([u'ketchup', u'pronunciation', u'&#39853;', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.096354469656944275, {u'tokens': [u'Later', u'United', u'States', u'soft', u'influences', u'gave', u'rise', u'to', u'\u8fea\u65af\u79d1', u'-LRB-', u'd\xeds\u012bk\xe8', u',', u'``', u'disco', u"''", u'-RRB-', u',', u'\u53ef\u4e50', u'-LRB-', u'k\u011bl\xe8', u',', u'``', u'cola', u"''", u'-RRB-', u'and', u'\u8ff7\u4f60', u'-LRB-', u'm\xedn\u01d0', u',', u'``', u'mini', u'-LRB-', u'skirt', u'-RRB-', u"''", u'-RRB-', u'.'], u'lemmas': [u'later', u'United', u'States', u'soft', u'influence', u'give', u'rise', u'to', u'\u8fea\u65af\u79d1', u'-lrb-', u'd\xeds\u012bk\xe8', u',', u'``', u'disco', u"''", u'-rrb-', u',', u'\u53ef\u4e50', u'-lrb-', u'k\u011bl\xe8', u',', u'``', u'cola', u"''", u'-rrb-', u'and', u'\u8ff7\u4f60', u'-lrb-', u'm\xedn\u01d0', u',', u'``', u'minus', u'-lrb-', u'skirt', u'-rrb-', u"''", u'-rrb-', u'.'], u'pos': [u'RB', u'NNP', u'NNPS', u'JJ', u'NNS', u'VBD', u'NN', u'TO', u'CD', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u'CC', u'NN', u'-LRB-', u'NN', u',', u'``', u'NNS', u'-LRB-', u'NN', u'-RRB-', u"''", u'-RRB-', u'.'], u'char_offsets': [[36823, 36828], [36829, 36835], [36836, 36842], [36843, 36847], [36848, 36858], [36859, 36863], [36864, 36868], [36869, 36871], [36872, 36875], [36876, 36877], [36877, 36883], [36883, 36884], [36885, 36886], [36886, 36891], [36891, 36892], [36892, 36893], [36893, 36894], [36895, 36897], [36898, 36899], [36899, 36903], [36903, 36904], [36905, 36906], [36906, 36910], [36910, 36911], [36911, 36912], [36913, 36916], [36917, 36919], [36920, 36921], [36921, 36925], [36925, 36926], [36927, 36928], [36928, 36932], [36932, 36933], [36933, 36938], [36938, 36939], [36939, 36940], [36940, 36941], [36941, 36942]]}) 
answer: set([u'ketchup', u'pronunciation', u'&#39853;', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])

Does "ketchup" come from the Minnan pronunciation of &#39853;&#27713; (koe-tsiap)?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114cb710>.answer
_____________________________ test_yesno[param74] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb758>, (<src.tfidf.TF_IDF object at 0x10a4b03d0>, set(['chinese', 'chinese_language', 'language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cb758>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.54191052913665771, {u'tokens': [u'Examples', u'of', u'such', u'words', u'are', u'``', u'tea', u"''", u'from', u'the', u'Minnan', u'pronunciation', u'of', u'\u8336', u'-LRB-', u'POJ', u':', u't\xea', u'-RRB-', u',', u'``', u'ketchup', u"''", u'from', u'the', u'Minnan', u'pronunciation', u'of', u'\u9bad\u6c41', u'-LRB-', u'koe-tsiap', u'-RRB-', u',', u'and', u'``', u'kumquat', u"''", u'from', u'the', u'Cantonese', u'pronunciation', u'of', u'\u91d1\u6a58', u'-LRB-', u'kam', u'kuat', u'-RRB-', u'.'], u'lemmas': [u'example', u'of', u'such', u'word', u'be', u'``', u'tea', u"''", u'from', u'the', u'minnan', u'pronunciation', u'of', u'\u8336', u'-lrb-', u'poj', u':', u't\xea', u'-rrb-', u',', u'``', u'ketchup', u"''", u'from', u'the', u'minnan', u'pronunciation', u'of', u'\u9bad\u6c41', u'-lrb-', u'koe-tsiap', u'-rrb-', u',', u'and', u'``', u'kumquat', u"''", u'from', u'the', u'cantonese', u'pronunciation', u'of', u'\u91d1\u6a58', u'-lrb-', u'kam', u'kuat', u'-rrb-', u'.'], u'pos': [u'NNS', u'IN', u'JJ', u'NNS', u'VBP', u'``', u'NN', u"''", u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'NN', u':', u'NN', u'-RRB-', u',', u'``', u'NN', u"''", u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'NN', u'-RRB-', u',', u'CC', u'``', u'NN', u"''", u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'FW', u'FW', u'-RRB-', u'.'], u'char_offsets': [[22885, 22893], [22894, 22896], [22897, 22901], [22902, 22907], [22908, 22911], [22912, 22913], [22913, 22916], [22916, 22917], [22918, 22922], [22923, 22926], [22927, 22933], [22934, 22947], [22948, 22950], [22951, 22952], [22953, 22954], [22954, 22957], [22957, 22958], [22959, 22961], [22961, 22962], [22962, 22963], [22964, 22965], [22965, 22972], [22972, 22973], [22974, 22978], [22979, 22982], [22983, 22989], [22990, 23003], [23004, 23006], [23007, 23009], [23010, 23011], [23011, 23020], [23020, 23021], [23021, 23022], [23023, 23026], [23027, 23028], [23028, 23035], [23035, 23036], [23037, 23041], [23042, 23045], [23046, 23055], [23056, 23069], [23070, 23072], [23073, 23075], [23076, 23077], [23077, 23080], [23081, 23085], [23085, 23086], [23086, 23087]]}) 
answer: set([u'&#27713;', u'come', u'&#39853;'])
candidate Sentence: (0.17428198456764221, {u'tokens': [u'From', u'French', u'came', u'\u82ad\u857e', u'-LRB-', u'b\u0101l\xe9i', u',', u'``', u'ballet', u"''", u'-RRB-', u',', u'\u9999\u69df', u'-LRB-', u'xi\u0101ngb\u012bn', u',', u'``', u'champagne', u"''", u'-RRB-', u',', u'via', u'Italian', u'\u5496\u5561', u'-LRB-', u'k\u0101f\u0113i', u',', u'``', u'caff\xe8', u"''", u'-RRB-', u'.'], u'lemmas': [u'from', u'French', u'come', u'\u82ad\u857e', u'-lrb-', u'b\u0101l\xe9i', u',', u'``', u'ballet', u"''", u'-rrb-', u',', u'\u9999\u69df', u'-lrb-', u'xi\u0101ngb\u012bn', u',', u'``', u'champagne', u"''", u'-rrb-', u',', u'via', u'italian', u'\u5496\u5561', u'-lrb-', u'k\u0101f\u0113i', u',', u'``', u'caff\xe8', u"''", u'-rrb-', u'.'], u'pos': [u'IN', u'NNP', u'VBD', u'CD', u'-LRB-', u'NN', u',', u'``', u'JJ', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'IN', u'JJ', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[36511, 36515], [36516, 36522], [36523, 36527], [36528, 36530], [36531, 36532], [36532, 36537], [36537, 36538], [36539, 36540], [36540, 36546], [36546, 36547], [36547, 36548], [36548, 36549], [36550, 36552], [36553, 36554], [36554, 36562], [36562, 36563], [36564, 36565], [36565, 36574], [36574, 36575], [36575, 36576], [36576, 36577], [36578, 36581], [36582, 36589], [36590, 36592], [36593, 36594], [36594, 36599], [36599, 36600], [36601, 36602], [36602, 36607], [36607, 36608], [36608, 36609], [36609, 36610]]}) 
answer: set([u'minnan', u'pronunciation', u'&#39853;', u'&#27713;', u'ketchup', u'koe-tsiap'])
candidate Sentence: (0.17395338416099548, {u'tokens': [u'Other', u'words', u'came', u'from', u'nomadic', u'peoples', u'to', u'the', u'north', u',', u'such', u'as', u'\u80e1\u540c', u'``', u'hutong', u'.', u"''"], u'lemmas': [u'other', u'word', u'come', u'from', u'nomadic', u'people', u'to', u'the', u'north', u',', u'such', u'as', u'\u80e1\u540c', u'``', u'hutong', u'.', u"''"], u'pos': [u'JJ', u'NNS', u'VBD', u'IN', u'JJ', u'NNS', u'TO', u'DT', u'NN', u',', u'JJ', u'IN', u'CD', u'``', u'FW', u'.', u"''"], u'char_offsets': [[35020, 35025], [35026, 35031], [35032, 35036], [35037, 35041], [35042, 35049], [35050, 35057], [35058, 35060], [35061, 35064], [35065, 35070], [35070, 35071], [35072, 35076], [35077, 35079], [35080, 35082], [35083, 35084], [35084, 35090], [35090, 35091], [35091, 35092]]}) 
answer: set([u'-rrb-', u'ketchup', u'pronunciation', u'&#39853;', u'-lrb-', u'&#27713;', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.16458417475223541, {u'tokens': [u'This', u'is', u'done', u'by', u'employing', u'Chinese', u'characters', u'with', u'similar', u'pronunciations', u'.'], u'lemmas': [u'this', u'be', u'do', u'by', u'employ', u'chinese', u'character', u'with', u'similar', u'pronunciation', u'.'], u'pos': [u'DT', u'VBZ', u'VBN', u'IN', u'VBG', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[35682, 35686], [35687, 35689], [35690, 35694], [35695, 35697], [35698, 35707], [35708, 35715], [35716, 35726], [35727, 35731], [35732, 35739], [35740, 35754], [35754, 35755]]}) 
answer: set([u'-rrb-', u'ketchup', u'&#39853;', u'-lrb-', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.13105340301990509, {u'tokens': [u'The', u'evidence', u'for', u'the', u'pronunciation', u'of', u'Middle', u'Chinese', u'comes', u'from', u'several', u'sources', u':', u'modern', u'dialect', u'variations', u',', u'rhyming', u'dictionaries', u',', u'foreign', u'transliterations', u',', u'``', u'rhyming', u'tables', u"''", u'constructed', u'by', u'ancient', u'Chinese', u'philologists', u'to', u'summarize', u'the', u'phonetic', u'system', u',', u'and', u'Chinese', u'phonetic', u'translations', u'of', u'foreign', u'words', u'.'], u'lemmas': [u'the', u'evidence', u'for', u'the', u'pronunciation', u'of', u'Middle', u'Chinese', u'come', u'from', u'several', u'source', u':', u'modern', u'dialect', u'variation', u',', u'rhyme', u'dictionary', u',', u'foreign', u'transliteration', u',', u'``', u'rhyming', u'table', u"''", u'construct', u'by', u'ancient', u'chinese', u'philologist', u'to', u'summarize', u'the', u'phonetic', u'system', u',', u'and', u'chinese', u'phonetic', u'translation', u'of', u'foreign', u'word', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'VBZ', u'IN', u'JJ', u'NNS', u':', u'JJ', u'NN', u'NNS', u',', u'VBG', u'NNS', u',', u'JJ', u'NNS', u',', u'``', u'JJ', u'NNS', u"''", u'VBN', u'IN', u'JJ', u'JJ', u'NNS', u'TO', u'VB', u'DT', u'JJ', u'NN', u',', u'CC', u'JJ', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[17998, 18001], [18002, 18010], [18011, 18014], [18015, 18018], [18019, 18032], [18033, 18035], [18036, 18042], [18043, 18050], [18051, 18056], [18057, 18061], [18062, 18069], [18070, 18077], [18077, 18078], [18079, 18085], [18086, 18093], [18094, 18104], [18104, 18105], [18106, 18113], [18114, 18126], [18126, 18127], [18128, 18135], [18136, 18152], [18152, 18153], [18154, 18155], [18155, 18162], [18163, 18169], [18169, 18170], [18171, 18182], [18183, 18185], [18186, 18193], [18194, 18201], [18202, 18214], [18215, 18217], [18218, 18227], [18228, 18231], [18232, 18240], [18241, 18247], [18247, 18248], [18249, 18252], [18253, 18260], [18261, 18269], [18270, 18282], [18283, 18285], [18286, 18293], [18294, 18299], [18299, 18300]]}) 
answer: set([u'-rrb-', u'minnan', u'&#39853;', u'-lrb-', u'&#27713;', u'ketchup', u'koe-tsiap'])
candidate Sentence: (0.10738074034452438, {u'tokens': [u'the', u'above-mentioned', u'\u6c99\u767c', u'-LRB-', u'sh\u0101f\u0101', u'``', u'sofa', u"''", u'-RRB-', u',', u'\u5e7d\u9ed8', u'-LRB-', u'y\u014dum\xf2', u'``', u'humour', u"''", u'-RRB-', u',', u'and', u'\u9ad8\u5c14\u592b', u'-LRB-', u'g\u0101o\u011brf\u016b', u',', u'``', u'golf', u"''", u'-RRB-', u'.'], u'lemmas': [u'the', u'above-mentioned', u'\u6c99\u767c', u'-lrb-', u'sh\u0101f\u0101', u'``', u'sofa', u"''", u'-rrb-', u',', u'\u5e7d\u9ed8', u'-lrb-', u'y\u014dum\xf2', u'``', u'humour', u"''", u'-rrb-', u',', u'and', u'\u9ad8\u5c14\u592b', u'-lrb-', u'g\u0101o\u011brf\u016b', u',', u'``', u'golf', u"''", u'-rrb-', u'.'], u'pos': [u'DT', u'JJ', u'CD', u'-LRB-', u'NN', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u'``', u'NN', u"''", u'-RRB-', u',', u'CC', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[36736, 36739], [36740, 36755], [36756, 36758], [36759, 36760], [36760, 36765], [36766, 36767], [36767, 36771], [36771, 36772], [36772, 36773], [36773, 36774], [36775, 36777], [36778, 36779], [36779, 36784], [36785, 36786], [36786, 36792], [36792, 36793], [36793, 36794], [36794, 36795], [36796, 36799], [36800, 36803], [36804, 36805], [36805, 36812], [36812, 36813], [36814, 36815], [36815, 36819], [36819, 36820], [36820, 36821], [36821, 36822]]}) 
answer: set([u'ketchup', u'pronunciation', u'&#39853;', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.10313067585229874, {u'tokens': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'How', u'hard', u'is', u'it', u'to', u'learn', u'Chinese', u'?'], u'lemmas': [u'BBC', u'NEWS', u'|', u'UK', u'|', u'Magazine', u'|', u'how', u'hard', u'be', u'it', u'to', u'learn', u'chinese', u'?'], u'pos': [u'NNP', u'NNP', u'VBD', u'NNP', u'NNP', u'NNP', u'NNP', u'WRB', u'JJ', u'VBZ', u'PRP', u'TO', u'VB', u'JJ', u'.'], u'char_offsets': [[40429, 40432], [40433, 40437], [40438, 40439], [40440, 40442], [40443, 40444], [40445, 40453], [40454, 40455], [40456, 40459], [40460, 40464], [40465, 40467], [40468, 40470], [40471, 40473], [40474, 40479], [40480, 40487], [40487, 40488]]}) 
answer: set([u'-rrb-', u'ketchup', u'pronunciation', u'&#39853;', u'-lrb-', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.10184904932975769, {u'tokens': [u'The', u'previous', u'examples', u'of', u'j\u012b', u',', u'for', u'instance', u',', u'for', u'``', u'stimulated', u"''", u',', u'``', u'chicken', u"''", u',', u'and', u'``', u'machine', u"''", u',', u'have', u'distinct', u'pronunciations', u'in', u'Cantonese', u'-LRB-', u'romanized', u'using', u'jyutping', u'-RRB-', u':', u'gik1', u',', u'gai1', u',', u'and', u'gei1', u',', u'respectively', u'.'], u'lemmas': [u'the', u'previous', u'example', u'of', u'j\u012b', u',', u'for', u'instance', u',', u'for', u'``', u'stimulate', u"''", u',', u'``', u'chicken', u"''", u',', u'and', u'``', u'machine', u"''", u',', u'have', u'distinct', u'pronunciation', u'in', u'cantonese', u'-lrb-', u'romanize', u'use', u'jyutping', u'-rrb-', u':', u'gik1', u',', u'gai1', u',', u'and', u'gei1', u',', u'respectively', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u'IN', u'NN', u',', u'IN', u'NN', u',', u'IN', u'``', u'VBN', u"''", u',', u'``', u'NN', u"''", u',', u'CC', u'``', u'NN', u"''", u',', u'VBP', u'JJ', u'NNS', u'IN', u'NN', u'-LRB-', u'VBN', u'VBG', u'NN', u'-RRB-', u':', u'NN', u',', u'NN', u',', u'CC', u'NN', u',', u'RB', u'.'], u'char_offsets': [[32805, 32808], [32809, 32817], [32818, 32826], [32827, 32829], [32830, 32832], [32832, 32833], [32834, 32837], [32838, 32846], [32846, 32847], [32848, 32851], [32852, 32853], [32853, 32863], [32863, 32864], [32864, 32865], [32866, 32867], [32867, 32874], [32874, 32875], [32875, 32876], [32877, 32880], [32881, 32882], [32882, 32889], [32889, 32890], [32890, 32891], [32892, 32896], [32897, 32905], [32906, 32920], [32921, 32923], [32924, 32933], [32934, 32935], [32935, 32944], [32945, 32950], [32951, 32959], [32959, 32960], [32960, 32961], [32962, 32966], [32966, 32967], [32968, 32972], [32972, 32973], [32974, 32977], [32978, 32982], [32982, 32983], [32984, 32996], [32996, 32997]]}) 
answer: set([u'minnan', u'&#39853;', u'&#27713;', u'come', u'ketchup', u'koe-tsiap'])
candidate Sentence: (0.09852735698223114, {u'tokens': [u'Examples', u'include', u'di\xe0nhu\xe0', u'-LRB-', u'\u7535\u8bdd', u'/', u'\u96fb\u8a71', u',', u'denwa', u',', u'``', u'telephone', u"''", u'-RRB-', u',', u'sh\xe8hu\xec', u'-LRB-', u'\u793e\u4f1a', u',', u'shakai', u',', u'``', u'society', u"''", u'-RRB-', u',', u'k\u0113xu\xe9', u'-LRB-', u'\u79d1\u5b66', u'/', u'\u79d1\u5b78', u',', u'kagaku', u',', u'``', u'science', u"''", u'-RRB-', u'and', u'ch\u014duxi\xe0ng', u'-LRB-', u'\u62bd\u8c61', u',', u'ch\u016bsh\u014d', u',', u'``', u'abstract', u"''", u'-RRB-', u'.'], u'lemmas': [u'example', u'include', u'di\xe0nhu\xe0', u'-lrb-', u'\u7535\u8bdd', u'/', u'\u96fb\u8a71', u',', u'denwa', u',', u'``', u'telephone', u"''", u'-rrb-', u',', u'sh\xe8hu\xec', u'-lrb-', u'\u793e\u4f1a', u',', u'shakaus', u',', u'``', u'society', u"''", u'-rrb-', u',', u'k\u0113xu\xe9', u'-lrb-', u'\u79d1\u5b66', u'/', u'\u79d1\u5b78', u',', u'kagaku', u',', u'``', u'science', u"''", u'-rrb-', u'and', u'ch\u014duxi\xe0ng', u'-lrb-', u'\u62bd\u8c61', u',', u'ch\u016bsh\u014d', u',', u'``', u'abstract', u"''", u'-rrb-', u'.'], u'pos': [u'NNS', u'VBP', u'NN', u'-LRB-', u'CD', u':', u'CD', u',', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u',', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'CD', u':', u'CD', u',', u'FW', u',', u'``', u'NN', u"''", u'-RRB-', u'CC', u'NN', u'-LRB-', u'CD', u',', u'NN', u',', u'``', u'JJ', u"''", u'-RRB-', u'.'], u'char_offsets': [[39024, 39032], [39033, 39040], [39041, 39048], [39049, 39050], [39050, 39052], [39052, 39053], [39053, 39055], [39055, 39056], [39057, 39062], [39062, 39063], [39064, 39065], [39065, 39074], [39074, 39075], [39075, 39076], [39076, 39077], [39078, 39084], [39085, 39086], [39086, 39088], [39088, 39089], [39090, 39096], [39096, 39097], [39098, 39099], [39099, 39106], [39106, 39107], [39107, 39108], [39108, 39109], [39110, 39115], [39116, 39117], [39117, 39119], [39119, 39120], [39120, 39122], [39122, 39123], [39124, 39130], [39130, 39131], [39132, 39133], [39133, 39140], [39140, 39141], [39141, 39142], [39143, 39146], [39147, 39156], [39157, 39158], [39158, 39160], [39160, 39161], [39162, 39168], [39168, 39169], [39170, 39171], [39171, 39179], [39179, 39180], [39180, 39181], [39181, 39182]]}) 
answer: set([u'ketchup', u'pronunciation', u'&#39853;', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])
candidate Sentence: (0.096354469656944275, {u'tokens': [u'Later', u'United', u'States', u'soft', u'influences', u'gave', u'rise', u'to', u'\u8fea\u65af\u79d1', u'-LRB-', u'd\xeds\u012bk\xe8', u',', u'``', u'disco', u"''", u'-RRB-', u',', u'\u53ef\u4e50', u'-LRB-', u'k\u011bl\xe8', u',', u'``', u'cola', u"''", u'-RRB-', u'and', u'\u8ff7\u4f60', u'-LRB-', u'm\xedn\u01d0', u',', u'``', u'mini', u'-LRB-', u'skirt', u'-RRB-', u"''", u'-RRB-', u'.'], u'lemmas': [u'later', u'United', u'States', u'soft', u'influence', u'give', u'rise', u'to', u'\u8fea\u65af\u79d1', u'-lrb-', u'd\xeds\u012bk\xe8', u',', u'``', u'disco', u"''", u'-rrb-', u',', u'\u53ef\u4e50', u'-lrb-', u'k\u011bl\xe8', u',', u'``', u'cola', u"''", u'-rrb-', u'and', u'\u8ff7\u4f60', u'-lrb-', u'm\xedn\u01d0', u',', u'``', u'minus', u'-lrb-', u'skirt', u'-rrb-', u"''", u'-rrb-', u'.'], u'pos': [u'RB', u'NNP', u'NNPS', u'JJ', u'NNS', u'VBD', u'NN', u'TO', u'CD', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u',', u'NN', u'-LRB-', u'NN', u',', u'``', u'NN', u"''", u'-RRB-', u'CC', u'NN', u'-LRB-', u'NN', u',', u'``', u'NNS', u'-LRB-', u'NN', u'-RRB-', u"''", u'-RRB-', u'.'], u'char_offsets': [[36823, 36828], [36829, 36835], [36836, 36842], [36843, 36847], [36848, 36858], [36859, 36863], [36864, 36868], [36869, 36871], [36872, 36875], [36876, 36877], [36877, 36883], [36883, 36884], [36885, 36886], [36886, 36891], [36891, 36892], [36892, 36893], [36893, 36894], [36895, 36897], [36898, 36899], [36899, 36903], [36903, 36904], [36905, 36906], [36906, 36910], [36910, 36911], [36911, 36912], [36913, 36916], [36917, 36919], [36920, 36921], [36921, 36925], [36925, 36926], [36927, 36928], [36928, 36932], [36932, 36933], [36933, 36938], [36938, 36939], [36939, 36940], [36940, 36941], [36941, 36942]]}) 
answer: set([u'ketchup', u'pronunciation', u'&#39853;', u'&#27713;', u'come', u'minnan', u'koe-tsiap'])

Does "ketchup" come from the Minnan pronunciation of &#39853;&#27713; (koe-tsiap)?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cb758>.answer
_____________________________ test_yesno[param81] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb950>, (<src.tfidf.TF_IDF object at 0x10e16f890>, set(['cougar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('A cougar is also known as a mountain lion.') == True
E                +  where 'A cougar is also known as a mountain lion.' = <src.question_processing.Question_parser instance at 0x1114cb950>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.41352972388267517, {u'tokens': [u'The', u'cougar', u'-LRB-', u'Puma', u'concolor', u'-RRB-', u',', u'also', u'known', u'as', u'puma', u',', u'mountain', u'lion', u',', u'mountain', u'cat', u',', u'catamount', u'or', u'panther', u',', u'depending', u'on', u'the', u'region', u',', u'is', u'a', u'mammal', u'of', u'the', u'family', u'Felidae', u',', u'native', u'to', u'the', u'Americas', u'.'], u'lemmas': [u'the', u'cougar', u'-lrb-', u'puma', u'concolor', u'-rrb-', u',', u'also', u'know', u'as', u'puma', u',', u'mountain', u'lion', u',', u'mountain', u'cat', u',', u'catamount', u'or', u'panther', u',', u'depend', u'on', u'the', u'region', u',', u'be', u'a', u'mammal', u'of', u'the', u'family', u'Felidae', u',', u'native', u'to', u'the', u'Americas', u'.'], u'pos': [u'DT', u'NN', u'-LRB-', u'NN', u'NN', u'-RRB-', u',', u'RB', u'VBN', u'IN', u'NN', u',', u'NN', u'NN', u',', u'NN', u'NN', u',', u'NN', u'CC', u'NN', u',', u'VBG', u'IN', u'DT', u'NN', u',', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NN', u'NNP', u',', u'JJ', u'TO', u'DT', u'NNPS', u'.'], u'char_offsets': [[0, 3], [4, 10], [11, 12], [12, 16], [17, 25], [25, 26], [26, 27], [28, 32], [33, 38], [39, 41], [42, 46], [46, 47], [48, 56], [57, 61], [61, 62], [63, 71], [72, 75], [75, 76], [77, 86], [87, 89], [90, 97], [97, 98], [99, 108], [109, 111], [112, 115], [116, 122], [122, 123], [124, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 149], [150, 157], [157, 158], [159, 165], [166, 168], [169, 172], [173, 181], [181, 182]]}) 
answer: set([])
candidate Sentence: (0.27257603406906128, {u'tokens': [u'The', u'cougar', u'has', u'numerous', u'names', u'in', u'English', u',', u'of', u'which', u'puma', u'and', u'mountain', u'lion', u'are', u'popular', u'.'], u'lemmas': [u'the', u'cougar', u'have', u'numerous', u'name', u'in', u'English', u',', u'of', u'which', u'puma', u'and', u'mountain', u'lion', u'be', u'popular', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'JJ', u'NNS', u'IN', u'NNP', u',', u'IN', u'WDT', u'NN', u'CC', u'NN', u'NN', u'VBP', u'JJ', u'.'], u'char_offsets': [[2324, 2327], [2328, 2334], [2335, 2338], [2339, 2347], [2348, 2353], [2354, 2356], [2357, 2364], [2364, 2365], [2366, 2368], [2369, 2374], [2375, 2379], [2380, 2383], [2384, 2392], [2393, 2397], [2398, 2401], [2402, 2409], [2409, 2410]]}) 
answer: set([u'know'])
candidate Sentence: (0.17417183518409729, {u'tokens': [u'Search', u'continues', u'for', u'mountain', u'lion', u'that', u'killed', u'Pinos', u'Altos', u'man', u',', u'New', u'Mexico', u'Department', u'of', u'Game', u'and', u'Fish', u',', u'press', u'release', u'June', u'23', u',', u'2008', u'-RSB-', u';', u'Wounded', u'mountain', u'lion', u'captured', u',', u'killed', u'near', u'Pinos', u'Altos', u',', u'New', u'Mexico', u'Department', u'of', u'Game', u'and', u'Fish', u',', u'press', u'release', u'June', u'25', u',', u'2008', u'-RSB-', u';', u'Second', u'mountain', u'lion', u'captured', u'near', u'Pinos', u'Altos', u',', u'New', u'Mexico', u'Department', u'of', u'Game', u'and', u'Fish', u',', u'press', u'release', u'July', u'1', u',', u'2008', u'-RSB-', u'As', u'with', u'many', u'predators', u',', u'a', u'cougar', u'may', u'attack', u'if', u'cornered', u',', u'if', u'a', u'fleeing', u'human', u'stimulates', u'their', u'instinct', u'to', u'chase', u',', u'or', u'if', u'a', u'person', u'``', u'plays', u'dead', u'.', u"''"], u'lemmas': [u'search', u'continue', u'for', u'mountain', u'lion', u'that', u'kill', u'Pinos', u'Altos', u'man', u',', u'New', u'Mexico', u'Department', u'of', u'Game', u'and', u'fish', u',', u'press', u'release', u'June', u'23', u',', u'2008', u'-rsb-', u';', u'wound', u'mountain', u'lion', u'capture', u',', u'kill', u'near', u'Pinos', u'Altos', u',', u'New', u'Mexico', u'Department', u'of', u'Game', u'and', u'fish', u',', u'press', u'release', u'June', u'25', u',', u'2008', u'-rsb-', u';', u'second', u'mountain', u'lion', u'capture', u'near', u'Pinos', u'Altos', u',', u'New', u'Mexico', u'Department', u'of', u'Game', u'and', u'fish', u',', u'press', u'release', u'July', u'1', u',', u'2008', u'-rsb-', u'as', u'with', u'many', u'predator', u',', u'a', u'cougar', u'may', u'attack', u'if', u'corner', u',', u'if', u'a', u'flee', u'human', u'stimulate', u'they', u'instinct', u'to', u'chase', u',', u'or', u'if', u'a', u'person', u'``', u'play', u'dead', u'.', u"''"], u'pos': [u'VB', u'VBZ', u'IN', u'NN', u'NN', u'WDT', u'VBD', u'NNP', u'NNP', u'NN', u',', u'NNP', u'NNP', u'NNP', u'IN', u'NNP', u'CC', u'NN', u',', u'NN', u'NN', u'NNP', u'CD', u',', u'CD', u'-RRB-', u':', u'VBN', u'NN', u'NN', u'VBN', u',', u'VBN', u'IN', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'IN', u'NNP', u'CC', u'NN', u',', u'NN', u'NN', u'NNP', u'CD', u',', u'CD', u'-RRB-', u':', u'JJ', u'NN', u'NN', u'VBN', u'IN', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'IN', u'NNP', u'CC', u'NN', u',', u'NN', u'NN', u'NNP', u'CD', u',', u'CD', u'-RRB-', u'IN', u'IN', u'JJ', u'NNS', u',', u'DT', u'NN', u'MD', u'VB', u'IN', u'VBN', u',', u'IN', u'DT', u'VBG', u'JJ', u'VBZ', u'PRP$', u'NN', u'TO', u'VB', u',', u'CC', u'IN', u'DT', u'NN', u'``', u'VBZ', u'JJ', u'.', u"''"], u'char_offsets': [[31626, 31632], [31633, 31642], [31643, 31646], [31647, 31655], [31656, 31660], [31661, 31665], [31666, 31672], [31673, 31678], [31679, 31684], [31685, 31688], [31688, 31689], [31690, 31693], [31694, 31700], [31701, 31711], [31712, 31714], [31715, 31719], [31720, 31723], [31724, 31728], [31728, 31729], [31730, 31735], [31736, 31743], [31744, 31748], [31749, 31751], [31751, 31752], [31753, 31757], [31757, 31758], [31758, 31759], [31761, 31768], [31769, 31777], [31778, 31782], [31783, 31791], [31791, 31792], [31793, 31799], [31800, 31804], [31805, 31810], [31811, 31816], [31816, 31817], [31818, 31821], [31822, 31828], [31829, 31839], [31840, 31842], [31843, 31847], [31848, 31851], [31852, 31856], [31856, 31857], [31858, 31863], [31864, 31871], [31872, 31876], [31877, 31879], [31879, 31880], [31881, 31885], [31885, 31886], [31886, 31887], [31889, 31895], [31896, 31904], [31905, 31909], [31910, 31918], [31919, 31923], [31924, 31929], [31930, 31935], [31935, 31936], [31937, 31940], [31941, 31947], [31948, 31958], [31959, 31961], [31962, 31966], [31967, 31970], [31971, 31975], [31975, 31976], [31977, 31982], [31983, 31990], [31991, 31995], [31996, 31997], [31997, 31998], [31999, 32003], [32003, 32004], [32005, 32007], [32008, 32012], [32013, 32017], [32018, 32027], [32027, 32028], [32029, 32030], [32031, 32037], [32038, 32041], [32042, 32048], [32049, 32051], [32052, 32060], [32060, 32061], [32062, 32064], [32065, 32066], [32067, 32074], [32075, 32080], [32081, 32091], [32092, 32097], [32098, 32106], [32107, 32109], [32110, 32115], [32115, 32116], [32117, 32119], [32120, 32122], [32123, 32124], [32125, 32131], [32132, 32133], [32133, 32138], [32139, 32143], [32143, 32144], [32144, 32145]]}) 
answer: set([u'know'])
candidate Sentence: (0.16133955121040344, {u'tokens': [u'*', u'Description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'No', u'Place', u'for', u'Predators', u'?'], u'lemmas': [u'*', u'description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'no', u'place', u'for', u'predator', u'?'], u'pos': [u'SYM', u'NN', u'IN', u'DT', u'NNP', u'NN', u'SYM', u'NNP', u'NNP', u'CC', u'NNP', u':', u'NNP', u'NNP', u'SYM', u'DT', u'NN', u'IN', u'NNS', u'.'], u'char_offsets': [[33435, 33436], [33438, 33449], [33450, 33452], [33453, 33454], [33455, 33461], [33462, 33468], [33469, 33470], [33472, 33478], [33479, 33484], [33485, 33488], [33489, 33495], [33496, 33497], [33498, 33511], [33512, 33519], [33520, 33521], [33523, 33525], [33526, 33531], [33532, 33535], [33536, 33545], [33545, 33546]]}) 
answer: set([u'mountain', u'lion', u'know'])
candidate Sentence: (0.15083388984203339, {u'tokens': [u'The', u'Quebec', u'wildlife', u'services', u'-LRB-', u'known', u'locally', u'as', u'MRNF', u'-RRB-', u'also', u'considers', u'Cougar', u'to', u'be', u'present', u'in', u'the', u'province', u'as', u'a', u'threatened', u'species', u'after', u'multiple', u'DNA', u'tests', u'confirmed', u'cougar', u'hair', u'in', u'Lynx', u'mating', u'sites', u'.'], u'lemmas': [u'the', u'Quebec', u'wildlife', u'service', u'-lrb-', u'know', u'locally', u'as', u'mrnf', u'-rrb-', u'also', u'consider', u'Cougar', u'to', u'be', u'present', u'in', u'the', u'province', u'as', u'a', u'threaten', u'species', u'after', u'multiple', u'dna', u'test', u'confirm', u'cougar', u'hair', u'in', u'Lynx', u'mate', u'site', u'.'], u'pos': [u'DT', u'NNP', u'NN', u'NNS', u'-LRB-', u'VBN', u'RB', u'IN', u'NN', u'-RRB-', u'RB', u'VBZ', u'NNP', u'TO', u'VB', u'JJ', u'IN', u'DT', u'NN', u'IN', u'DT', u'VBN', u'NNS', u'IN', u'JJ', u'NN', u'NNS', u'VBD', u'NN', u'NN', u'IN', u'NNP', u'VBG', u'NNS', u'.'], u'char_offsets': [[18964, 18967], [18968, 18974], [18975, 18983], [18984, 18992], [18993, 18994], [18994, 18999], [19000, 19007], [19008, 19010], [19011, 19015], [19015, 19016], [19017, 19021], [19022, 19031], [19032, 19038], [19039, 19041], [19042, 19044], [19045, 19052], [19053, 19055], [19056, 19059], [19060, 19068], [19069, 19071], [19072, 19073], [19074, 19084], [19085, 19092], [19093, 19098], [19099, 19107], [19108, 19111], [19112, 19117], [19118, 19127], [19128, 19134], [19135, 19139], [19140, 19142], [19143, 19147], [19148, 19154], [19155, 19160], [19160, 19161]]}) 
answer: set([u'mountain', u'lion'])
candidate Sentence: (0.14330804347991943, {u'tokens': [u'It', u'will', u'also', u'hunt', u'species', u'as', u'small', u'as', u'insects', u'and', u'rodents', u'.'], u'lemmas': [u'it', u'will', u'also', u'hunt', u'species', u'as', u'small', u'as', u'insect', u'and', u'rodent', u'.'], u'pos': [u'PRP', u'MD', u'RB', u'NN', u'NNS', u'IN', u'JJ', u'IN', u'NNS', u'CC', u'NNS', u'.'], u'char_offsets': [[931, 933], [934, 938], [939, 943], [944, 948], [949, 956], [957, 959], [960, 965], [966, 968], [969, 976], [977, 980], [981, 988], [988, 989]]}) 
answer: set([u'mountain', u'lion', u'know'])
candidate Sentence: (0.12736435234546661, {u'tokens': [u'Other', u'names', u'include', u'catamount', u',', u'panther', u',', u'mountain', u'screamer', u'and', u'painter', u'.'], u'lemmas': [u'other', u'name', u'include', u'catamount', u',', u'panther', u',', u'mountain', u'screamer', u'and', u'painter', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'NN', u',', u'NN', u',', u'NN', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[2411, 2416], [2417, 2422], [2423, 2430], [2431, 2440], [2440, 2441], [2442, 2449], [2449, 2450], [2451, 2459], [2460, 2468], [2469, 2472], [2473, 2480], [2480, 2481]]}) 
answer: set([u'lion', u'know'])
candidate Sentence: (0.11915060132741928, {u'tokens': [u'A', u'pumapard', u'is', u'a', u'hybrid', u'animal', u'resulting', u'from', u'a', u'union', u'between', u'a', u'cougar', u'and', u'a', u'leopard', u'.'], u'lemmas': [u'a', u'pumapard', u'be', u'a', u'hybrid', u'animal', u'result', u'from', u'a', u'union', u'between', u'a', u'cougar', u'and', u'a', u'leopard', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'DT', u'NN', u'NN', u'VBG', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'CC', u'DT', u'NN', u'.'], u'char_offsets': [[24067, 24068], [24069, 24077], [24078, 24080], [24081, 24082], [24083, 24089], [24090, 24096], [24097, 24106], [24107, 24111], [24112, 24113], [24114, 24119], [24120, 24127], [24128, 24129], [24130, 24136], [24137, 24140], [24141, 24142], [24143, 24150], [24150, 24151]]}) 
answer: set([u'mountain', u'lion', u'know'])
candidate Sentence: (0.11652307957410812, {u'tokens': [u'The', u'cougar', u'is', u'also', u'protected', u'across', u'much', u'of', u'the', u'rest', u'of', u'their', u'range', u'.'], u'lemmas': [u'the', u'cougar', u'be', u'also', u'protect', u'across', u'much', u'of', u'the', u'rest', u'of', u'they', u'range', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'IN', u'JJ', u'IN', u'DT', u'NN', u'IN', u'PRP$', u'NN', u'.'], u'char_offsets': [[26022, 26025], [26026, 26032], [26033, 26035], [26036, 26040], [26041, 26050], [26051, 26057], [26058, 26062], [26063, 26065], [26066, 26069], [26070, 26074], [26075, 26077], [26078, 26083], [26084, 26089], [26089, 26090]]}) 
answer: set([u'mountain', u'lion', u'know'])
candidate Sentence: (0.11180642247200012, {u'tokens': [u'The', u'only', u'unequivocally', u'known', u'eastern', u'population', u'is', u'the', u'Florida', u'panther', u',', u'which', u'is', u'critically', u'endangered', u'.'], u'lemmas': [u'the', u'only', u'unequivocally', u'know', u'eastern', u'population', u'be', u'the', u'Florida', u'panther', u',', u'which', u'be', u'critically', u'endanger', u'.'], u'pos': [u'DT', u'JJ', u'RB', u'VBN', u'JJ', u'NN', u'VBZ', u'DT', u'NNP', u'NN', u',', u'WDT', u'VBZ', u'RB', u'VBN', u'.'], u'char_offsets': [[19227, 19230], [19231, 19235], [19236, 19249], [19250, 19255], [19256, 19263], [19264, 19274], [19275, 19277], [19278, 19281], [19282, 19289], [19290, 19297], [19297, 19298], [19299, 19304], [19305, 19307], [19308, 19318], [19319, 19329], [19329, 19330]]}) 
answer: set([u'mountain', u'lion'])

Is a cougar also known as a mountain lion?
Validity= False
Question Type = NA
Answer Type = NA
Answer = A cougar is also known as a mountain lion.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('A cougar is also known as a mountain lion.') == True
 +  where 'A cougar is also known as a mountain lion.' = <src.question_processing.Question_parser instance at 0x1114cb950>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param83] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cb9e0>, (<src.tfidf.TF_IDF object at 0x10e16f890>, set(['cougar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Cougars are not larger than jaguars.') == True
E                +  where 'Cougars are not larger than jaguars.' = <src.question_processing.Question_parser instance at 0x1114cb9e0>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.3245537281036377, {u'tokens': [u'In', u'the', u'south', u',', u'the', u'cougar', u'must', u'compete', u'with', u'the', u'larger', u'jaguar', u'.'], u'lemmas': [u'in', u'the', u'south', u',', u'the', u'cougar', u'must', u'compete', u'with', u'the', u'larger', u'jaguar', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'DT', u'NN', u'MD', u'VB', u'IN', u'DT', u'JJR', u'NN', u'.'], u'char_offsets': [[21319, 21321], [21322, 21325], [21326, 21331], [21331, 21332], [21333, 21336], [21337, 21343], [21344, 21348], [21349, 21356], [21357, 21361], [21362, 21365], [21366, 21372], [21373, 21379], [21379, 21380]]}) 
answer: set([])
candidate Sentence: (0.28964966535568237, {u'tokens': [u'Competition', u'with', u'the', u'larger', u'jaguar', u'has', u'been', u'suggested', u'for', u'the', u'decline', u'in', u'the', u'size', u'of', u'prey', u'items', u'.'], u'lemmas': [u'competition', u'with', u'the', u'larger', u'jaguar', u'have', u'be', u'suggest', u'for', u'the', u'decline', u'in', u'the', u'size', u'of', u'prey', u'item', u'.'], u'pos': [u'NN', u'IN', u'DT', u'JJR', u'NN', u'VBZ', u'VBN', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'NNS', u'.'], u'char_offsets': [[11979, 11990], [11991, 11995], [11996, 11999], [12000, 12006], [12007, 12013], [12014, 12017], [12018, 12022], [12023, 12032], [12033, 12036], [12037, 12040], [12041, 12048], [12049, 12051], [12052, 12055], [12056, 12060], [12061, 12063], [12064, 12068], [12069, 12074], [12074, 12075]]}) 
answer: set([])
candidate Sentence: (0.26006105542182922, {u'tokens': [u'The', u'jaguar', u'tends', u'to', u'take', u'larger', u'prey', u'and', u'the', u'cougar', u'smaller', u'where', u'they', u'overlap', u',', u'reducing', u'the', u'cougar', u"'s", u'size', u'.'], u'lemmas': [u'the', u'jaguar', u'tend', u'to', u'take', u'larger', u'prey', u'and', u'the', u'cougar', u'smaller', u'where', u'they', u'overlap', u',', u'reduce', u'the', u'cougar', u"'s", u'size', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'TO', u'VB', u'JJR', u'NN', u'CC', u'DT', u'NN', u'JJR', u'WRB', u'PRP', u'VBP', u',', u'VBG', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[23120, 23123], [23124, 23130], [23131, 23136], [23137, 23139], [23140, 23144], [23145, 23151], [23152, 23156], [23157, 23160], [23161, 23164], [23165, 23171], [23172, 23179], [23180, 23185], [23186, 23190], [23191, 23198], [23198, 23199], [23200, 23208], [23209, 23212], [23213, 23219], [23219, 23221], [23222, 23226], [23226, 23227]]}) 
answer: set([])
candidate Sentence: (0.17801910638809204, {u'tokens': [u'Cougars', u'can', u'be', u'almost', u'as', u'large', u'as', u'jaguars', u',', u'but', u'are', u'less', u'muscular', u'and', u'not', u'as', u'powerful', u';', u'where', u'their', u'ranges', u'overlap', u',', u'the', u'cougar', u'tends', u'to', u'be', u'smaller', u'than', u'average', u'.'], u'lemmas': [u'Cougars', u'can', u'be', u'almost', u'as', u'large', u'as', u'jaguar', u',', u'but', u'be', u'less', u'muscular', u'and', u'not', u'as', u'powerful', u';', u'where', u'they', u'range', u'overlap', u',', u'the', u'cougar', u'tend', u'to', u'be', u'smaller', u'than', u'average', u'.'], u'pos': [u'NNPS', u'MD', u'VB', u'RB', u'RB', u'JJ', u'IN', u'NNS', u',', u'CC', u'VBP', u'RBR', u'JJ', u'CC', u'RB', u'IN', u'JJ', u':', u'WRB', u'PRP$', u'NNS', u'VBP', u',', u'DT', u'NN', u'VBZ', u'TO', u'VB', u'JJR', u'IN', u'NN', u'.'], u'char_offsets': [[8274, 8281], [8282, 8285], [8286, 8288], [8289, 8295], [8296, 8298], [8299, 8304], [8305, 8307], [8308, 8315], [8315, 8316], [8317, 8320], [8321, 8324], [8325, 8329], [8330, 8338], [8339, 8342], [8343, 8346], [8347, 8349], [8350, 8358], [8358, 8359], [8360, 8365], [8366, 8371], [8372, 8378], [8379, 8386], [8386, 8387], [8388, 8391], [8392, 8398], [8399, 8404], [8405, 8407], [8408, 8410], [8411, 8418], [8419, 8423], [8424, 8431], [8431, 8432]]}) 
answer: set([u'larger'])
candidate Sentence: (0.1747506707906723, {u'tokens': [u'*', u'Description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'No', u'Place', u'for', u'Predators', u'?'], u'lemmas': [u'*', u'description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'no', u'place', u'for', u'predator', u'?'], u'pos': [u'SYM', u'NN', u'IN', u'DT', u'NNP', u'NN', u'SYM', u'NNP', u'NNP', u'CC', u'NNP', u':', u'NNP', u'NNP', u'SYM', u'DT', u'NN', u'IN', u'NNS', u'.'], u'char_offsets': [[33435, 33436], [33438, 33449], [33450, 33452], [33453, 33454], [33455, 33461], [33462, 33468], [33469, 33470], [33472, 33478], [33479, 33484], [33485, 33488], [33489, 33495], [33496, 33497], [33498, 33511], [33512, 33519], [33520, 33521], [33523, 33525], [33526, 33531], [33532, 33535], [33536, 33545], [33545, 33546]]}) 
answer: set([u'larger', u'jaguar'])
candidate Sentence: (0.14501677453517914, {u'tokens': [u'It', u'is', u'the', u'second', u'heaviest', u'cat', u'in', u'the', u'American', u'continents', u'after', u'the', u'jaguar', u',', u'and', u'the', u'fourth', u'heaviest', u'in', u'the', u'world', u',', u'after', u'the', u'tiger', u',', u'lion', u',', u'and', u'jaguar', u'.'], u'lemmas': [u'it', u'be', u'the', u'second', u'heaviest', u'cat', u'in', u'the', u'american', u'continent', u'after', u'the', u'jaguar', u',', u'and', u'the', u'fourth', u'heaviest', u'in', u'the', u'world', u',', u'after', u'the', u'tiger', u',', u'lion', u',', u'and', u'jaguar', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'JJ', u'JJS', u'NN', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'NN', u',', u'CC', u'DT', u'JJ', u'JJS', u'IN', u'DT', u'NN', u',', u'IN', u'DT', u'NN', u',', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[459, 461], [462, 464], [465, 468], [469, 475], [476, 484], [485, 488], [489, 491], [492, 495], [496, 504], [505, 515], [516, 521], [522, 525], [526, 532], [532, 533], [534, 537], [538, 541], [542, 548], [549, 557], [558, 560], [561, 564], [565, 570], [570, 571], [572, 577], [578, 581], [582, 587], [587, 588], [589, 593], [593, 594], [595, 598], [599, 605], [605, 606]]}) 
answer: set([u'larger'])
candidate Sentence: (0.14410597085952759, {u'tokens': [u'In', u'the', u'southern', u'portion', u'of', u'its', u'range', u',', u'the', u'cougar', u'and', u'jaguar', u'share', u'overlapping', u'territory', u'.'], u'lemmas': [u'in', u'the', u'southern', u'portion', u'of', u'its', u'range', u',', u'the', u'cougar', u'and', u'jaguar', u'share', u'overlap', u'territory', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NN', u'IN', u'PRP$', u'NN', u',', u'DT', u'NN', u'CC', u'NN', u'NN', u'VBG', u'NN', u'.'], u'char_offsets': [[23028, 23030], [23031, 23034], [23035, 23043], [23044, 23051], [23052, 23054], [23055, 23058], [23059, 23064], [23064, 23065], [23066, 23069], [23070, 23076], [23077, 23080], [23081, 23087], [23088, 23093], [23094, 23105], [23106, 23115], [23115, 23116]]}) 
answer: set([u'larger'])
candidate Sentence: (0.13611210882663727, {u'tokens': [u'The', u'larger', u'front', u'feet', u'and', u'claws', u'are', u'adaptations', u'to', u'clutching', u'prey', u'.'], u'lemmas': [u'the', u'larger', u'front', u'foot', u'and', u'claw', u'be', u'adaptation', u'to', u'clutch', u'prey', u'.'], u'pos': [u'DT', u'JJR', u'JJ', u'NNS', u'CC', u'NNS', u'VBP', u'NNS', u'TO', u'VBG', u'NN', u'.'], u'char_offsets': [[8207, 8210], [8211, 8217], [8218, 8223], [8224, 8228], [8229, 8232], [8233, 8238], [8239, 8242], [8243, 8254], [8255, 8257], [8258, 8267], [8268, 8272], [8272, 8273]]}) 
answer: set([u'jaguar'])
candidate Sentence: (0.10517857223749161, {u'tokens': [u'Between', u'1890', u'and', u'1990', u',', u'in', u'North', u'America', u'there', u'were', u'53', u'reported', u',', u'confirmed', u'attacks', u'on', u'humans', u',', u'resulting', u'in', u'48', u'nonfatal', u'injuries', u'and', u'10', u'deaths', u'of', u'humans', u'-LRB-', u'the', u'total', u'is', u'greater', u'than', u'53', u'because', u'some', u'attacks', u'had', u'more', u'than', u'one', u'victim', u'-RRB-', u'.'], u'lemmas': [u'between', u'1890', u'and', u'1990', u',', u'in', u'North', u'America', u'there', u'be', u'53', u'report', u',', u'confirm', u'attack', u'on', u'human', u',', u'result', u'in', u'48', u'nonfatal', u'injury', u'and', u'10', u'death', u'of', u'human', u'-lrb-', u'the', u'total', u'be', u'greater', u'than', u'53', u'because', u'some', u'attack', u'have', u'more', u'than', u'one', u'victim', u'-rrb-', u'.'], u'pos': [u'IN', u'CD', u'CC', u'CD', u',', u'IN', u'NNP', u'NNP', u'EX', u'VBD', u'CD', u'VBN', u',', u'VBD', u'NNS', u'IN', u'NNS', u',', u'VBG', u'IN', u'CD', u'JJ', u'NNS', u'CC', u'CD', u'NNS', u'IN', u'NNS', u'-LRB-', u'DT', u'NN', u'VBZ', u'JJR', u'IN', u'CD', u'IN', u'DT', u'NNS', u'VBD', u'RBR', u'IN', u'CD', u'NN', u'-RRB-', u'.'], u'char_offsets': [[31037, 31044], [31045, 31049], [31050, 31053], [31054, 31058], [31058, 31059], [31060, 31062], [31063, 31068], [31069, 31076], [31077, 31082], [31083, 31087], [31088, 31090], [31091, 31099], [31099, 31100], [31101, 31110], [31111, 31118], [31119, 31121], [31122, 31128], [31128, 31129], [31130, 31139], [31140, 31142], [31143, 31145], [31146, 31154], [31155, 31163], [31164, 31167], [31168, 31170], [31171, 31177], [31178, 31180], [31181, 31187], [31188, 31189], [31189, 31192], [31193, 31198], [31199, 31201], [31202, 31209], [31210, 31214], [31215, 31217], [31218, 31225], [31226, 31230], [31231, 31238], [31239, 31242], [31243, 31247], [31248, 31252], [31253, 31256], [31257, 31263], [31263, 31264], [31264, 31265]]}) 
answer: set([u'larger', u'jaguar'])
candidate Sentence: (0.09393002837896347, {u'tokens': [u'The', u'term', u'``', u'black', u'panther', u"''", u'is', u'used', u'colloquially', u'to', u'refer', u'to', u'melanistic', u'individuals', u'of', u'other', u'species', u',', u'particularly', u'jaguars', u'and', u'leopards', u'.'], u'lemmas': [u'the', u'term', u'``', u'black', u'panther', u"''", u'be', u'use', u'colloquially', u'to', u'refer', u'to', u'melanistic', u'individual', u'of', u'other', u'species', u',', u'particularly', u'jaguar', u'and', u'leopard', u'.'], u'pos': [u'DT', u'NN', u'``', u'JJ', u'NN', u"''", u'VBZ', u'VBN', u'RB', u'TO', u'VB', u'TO', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u',', u'RB', u'NNS', u'CC', u'NNS', u'.'], u'char_offsets': [[9437, 9440], [9441, 9445], [9446, 9447], [9447, 9452], [9453, 9460], [9460, 9461], [9462, 9464], [9465, 9469], [9470, 9482], [9483, 9485], [9486, 9491], [9492, 9494], [9495, 9505], [9506, 9517], [9518, 9520], [9521, 9526], [9527, 9534], [9534, 9535], [9536, 9548], [9549, 9556], [9557, 9560], [9561, 9569], [9569, 9570]]}) 
answer: set([u'larger'])

Are cougars larger than jaguars?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Cougars are not larger than jaguars.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Cougars are not larger than jaguars.') == True
 +  where 'Cougars are not larger than jaguars.' = <src.question_processing.Question_parser instance at 0x1114cb9e0>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param84] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cba28>, (<src.tfidf.TF_IDF object at 0x10e16f890>, set(['cougar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('no') == True
E                +  where 'no' = <src.question_processing.Question_parser instance at 0x1114cba28>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.3245537281036377, {u'tokens': [u'In', u'the', u'south', u',', u'the', u'cougar', u'must', u'compete', u'with', u'the', u'larger', u'jaguar', u'.'], u'lemmas': [u'in', u'the', u'south', u',', u'the', u'cougar', u'must', u'compete', u'with', u'the', u'larger', u'jaguar', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'DT', u'NN', u'MD', u'VB', u'IN', u'DT', u'JJR', u'NN', u'.'], u'char_offsets': [[21319, 21321], [21322, 21325], [21326, 21331], [21331, 21332], [21333, 21336], [21337, 21343], [21344, 21348], [21349, 21356], [21357, 21361], [21362, 21365], [21366, 21372], [21373, 21379], [21379, 21380]]}) 
answer: set([])
candidate Sentence: (0.28964966535568237, {u'tokens': [u'Competition', u'with', u'the', u'larger', u'jaguar', u'has', u'been', u'suggested', u'for', u'the', u'decline', u'in', u'the', u'size', u'of', u'prey', u'items', u'.'], u'lemmas': [u'competition', u'with', u'the', u'larger', u'jaguar', u'have', u'be', u'suggest', u'for', u'the', u'decline', u'in', u'the', u'size', u'of', u'prey', u'item', u'.'], u'pos': [u'NN', u'IN', u'DT', u'JJR', u'NN', u'VBZ', u'VBN', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'NNS', u'.'], u'char_offsets': [[11979, 11990], [11991, 11995], [11996, 11999], [12000, 12006], [12007, 12013], [12014, 12017], [12018, 12022], [12023, 12032], [12033, 12036], [12037, 12040], [12041, 12048], [12049, 12051], [12052, 12055], [12056, 12060], [12061, 12063], [12064, 12068], [12069, 12074], [12074, 12075]]}) 
answer: set([])
candidate Sentence: (0.26006105542182922, {u'tokens': [u'The', u'jaguar', u'tends', u'to', u'take', u'larger', u'prey', u'and', u'the', u'cougar', u'smaller', u'where', u'they', u'overlap', u',', u'reducing', u'the', u'cougar', u"'s", u'size', u'.'], u'lemmas': [u'the', u'jaguar', u'tend', u'to', u'take', u'larger', u'prey', u'and', u'the', u'cougar', u'smaller', u'where', u'they', u'overlap', u',', u'reduce', u'the', u'cougar', u"'s", u'size', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'TO', u'VB', u'JJR', u'NN', u'CC', u'DT', u'NN', u'JJR', u'WRB', u'PRP', u'VBP', u',', u'VBG', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[23120, 23123], [23124, 23130], [23131, 23136], [23137, 23139], [23140, 23144], [23145, 23151], [23152, 23156], [23157, 23160], [23161, 23164], [23165, 23171], [23172, 23179], [23180, 23185], [23186, 23190], [23191, 23198], [23198, 23199], [23200, 23208], [23209, 23212], [23213, 23219], [23219, 23221], [23222, 23226], [23226, 23227]]}) 
answer: set([])
candidate Sentence: (0.17801910638809204, {u'tokens': [u'Cougars', u'can', u'be', u'almost', u'as', u'large', u'as', u'jaguars', u',', u'but', u'are', u'less', u'muscular', u'and', u'not', u'as', u'powerful', u';', u'where', u'their', u'ranges', u'overlap', u',', u'the', u'cougar', u'tends', u'to', u'be', u'smaller', u'than', u'average', u'.'], u'lemmas': [u'Cougars', u'can', u'be', u'almost', u'as', u'large', u'as', u'jaguar', u',', u'but', u'be', u'less', u'muscular', u'and', u'not', u'as', u'powerful', u';', u'where', u'they', u'range', u'overlap', u',', u'the', u'cougar', u'tend', u'to', u'be', u'smaller', u'than', u'average', u'.'], u'pos': [u'NNPS', u'MD', u'VB', u'RB', u'RB', u'JJ', u'IN', u'NNS', u',', u'CC', u'VBP', u'RBR', u'JJ', u'CC', u'RB', u'IN', u'JJ', u':', u'WRB', u'PRP$', u'NNS', u'VBP', u',', u'DT', u'NN', u'VBZ', u'TO', u'VB', u'JJR', u'IN', u'NN', u'.'], u'char_offsets': [[8274, 8281], [8282, 8285], [8286, 8288], [8289, 8295], [8296, 8298], [8299, 8304], [8305, 8307], [8308, 8315], [8315, 8316], [8317, 8320], [8321, 8324], [8325, 8329], [8330, 8338], [8339, 8342], [8343, 8346], [8347, 8349], [8350, 8358], [8358, 8359], [8360, 8365], [8366, 8371], [8372, 8378], [8379, 8386], [8386, 8387], [8388, 8391], [8392, 8398], [8399, 8404], [8405, 8407], [8408, 8410], [8411, 8418], [8419, 8423], [8424, 8431], [8431, 8432]]}) 
answer: set([u'larger'])
candidate Sentence: (0.1747506707906723, {u'tokens': [u'*', u'Description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'No', u'Place', u'for', u'Predators', u'?'], u'lemmas': [u'*', u'description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'no', u'place', u'for', u'predator', u'?'], u'pos': [u'SYM', u'NN', u'IN', u'DT', u'NNP', u'NN', u'SYM', u'NNP', u'NNP', u'CC', u'NNP', u':', u'NNP', u'NNP', u'SYM', u'DT', u'NN', u'IN', u'NNS', u'.'], u'char_offsets': [[33435, 33436], [33438, 33449], [33450, 33452], [33453, 33454], [33455, 33461], [33462, 33468], [33469, 33470], [33472, 33478], [33479, 33484], [33485, 33488], [33489, 33495], [33496, 33497], [33498, 33511], [33512, 33519], [33520, 33521], [33523, 33525], [33526, 33531], [33532, 33535], [33536, 33545], [33545, 33546]]}) 
answer: set([u'larger', u'jaguar'])
candidate Sentence: (0.14501677453517914, {u'tokens': [u'It', u'is', u'the', u'second', u'heaviest', u'cat', u'in', u'the', u'American', u'continents', u'after', u'the', u'jaguar', u',', u'and', u'the', u'fourth', u'heaviest', u'in', u'the', u'world', u',', u'after', u'the', u'tiger', u',', u'lion', u',', u'and', u'jaguar', u'.'], u'lemmas': [u'it', u'be', u'the', u'second', u'heaviest', u'cat', u'in', u'the', u'american', u'continent', u'after', u'the', u'jaguar', u',', u'and', u'the', u'fourth', u'heaviest', u'in', u'the', u'world', u',', u'after', u'the', u'tiger', u',', u'lion', u',', u'and', u'jaguar', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'JJ', u'JJS', u'NN', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'NN', u',', u'CC', u'DT', u'JJ', u'JJS', u'IN', u'DT', u'NN', u',', u'IN', u'DT', u'NN', u',', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[459, 461], [462, 464], [465, 468], [469, 475], [476, 484], [485, 488], [489, 491], [492, 495], [496, 504], [505, 515], [516, 521], [522, 525], [526, 532], [532, 533], [534, 537], [538, 541], [542, 548], [549, 557], [558, 560], [561, 564], [565, 570], [570, 571], [572, 577], [578, 581], [582, 587], [587, 588], [589, 593], [593, 594], [595, 598], [599, 605], [605, 606]]}) 
answer: set([u'larger'])
candidate Sentence: (0.14410597085952759, {u'tokens': [u'In', u'the', u'southern', u'portion', u'of', u'its', u'range', u',', u'the', u'cougar', u'and', u'jaguar', u'share', u'overlapping', u'territory', u'.'], u'lemmas': [u'in', u'the', u'southern', u'portion', u'of', u'its', u'range', u',', u'the', u'cougar', u'and', u'jaguar', u'share', u'overlap', u'territory', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NN', u'IN', u'PRP$', u'NN', u',', u'DT', u'NN', u'CC', u'NN', u'NN', u'VBG', u'NN', u'.'], u'char_offsets': [[23028, 23030], [23031, 23034], [23035, 23043], [23044, 23051], [23052, 23054], [23055, 23058], [23059, 23064], [23064, 23065], [23066, 23069], [23070, 23076], [23077, 23080], [23081, 23087], [23088, 23093], [23094, 23105], [23106, 23115], [23115, 23116]]}) 
answer: set([u'larger'])
candidate Sentence: (0.13611210882663727, {u'tokens': [u'The', u'larger', u'front', u'feet', u'and', u'claws', u'are', u'adaptations', u'to', u'clutching', u'prey', u'.'], u'lemmas': [u'the', u'larger', u'front', u'foot', u'and', u'claw', u'be', u'adaptation', u'to', u'clutch', u'prey', u'.'], u'pos': [u'DT', u'JJR', u'JJ', u'NNS', u'CC', u'NNS', u'VBP', u'NNS', u'TO', u'VBG', u'NN', u'.'], u'char_offsets': [[8207, 8210], [8211, 8217], [8218, 8223], [8224, 8228], [8229, 8232], [8233, 8238], [8239, 8242], [8243, 8254], [8255, 8257], [8258, 8267], [8268, 8272], [8272, 8273]]}) 
answer: set([u'jaguar'])
candidate Sentence: (0.10517857223749161, {u'tokens': [u'Between', u'1890', u'and', u'1990', u',', u'in', u'North', u'America', u'there', u'were', u'53', u'reported', u',', u'confirmed', u'attacks', u'on', u'humans', u',', u'resulting', u'in', u'48', u'nonfatal', u'injuries', u'and', u'10', u'deaths', u'of', u'humans', u'-LRB-', u'the', u'total', u'is', u'greater', u'than', u'53', u'because', u'some', u'attacks', u'had', u'more', u'than', u'one', u'victim', u'-RRB-', u'.'], u'lemmas': [u'between', u'1890', u'and', u'1990', u',', u'in', u'North', u'America', u'there', u'be', u'53', u'report', u',', u'confirm', u'attack', u'on', u'human', u',', u'result', u'in', u'48', u'nonfatal', u'injury', u'and', u'10', u'death', u'of', u'human', u'-lrb-', u'the', u'total', u'be', u'greater', u'than', u'53', u'because', u'some', u'attack', u'have', u'more', u'than', u'one', u'victim', u'-rrb-', u'.'], u'pos': [u'IN', u'CD', u'CC', u'CD', u',', u'IN', u'NNP', u'NNP', u'EX', u'VBD', u'CD', u'VBN', u',', u'VBD', u'NNS', u'IN', u'NNS', u',', u'VBG', u'IN', u'CD', u'JJ', u'NNS', u'CC', u'CD', u'NNS', u'IN', u'NNS', u'-LRB-', u'DT', u'NN', u'VBZ', u'JJR', u'IN', u'CD', u'IN', u'DT', u'NNS', u'VBD', u'RBR', u'IN', u'CD', u'NN', u'-RRB-', u'.'], u'char_offsets': [[31037, 31044], [31045, 31049], [31050, 31053], [31054, 31058], [31058, 31059], [31060, 31062], [31063, 31068], [31069, 31076], [31077, 31082], [31083, 31087], [31088, 31090], [31091, 31099], [31099, 31100], [31101, 31110], [31111, 31118], [31119, 31121], [31122, 31128], [31128, 31129], [31130, 31139], [31140, 31142], [31143, 31145], [31146, 31154], [31155, 31163], [31164, 31167], [31168, 31170], [31171, 31177], [31178, 31180], [31181, 31187], [31188, 31189], [31189, 31192], [31193, 31198], [31199, 31201], [31202, 31209], [31210, 31214], [31215, 31217], [31218, 31225], [31226, 31230], [31231, 31238], [31239, 31242], [31243, 31247], [31248, 31252], [31253, 31256], [31257, 31263], [31263, 31264], [31264, 31265]]}) 
answer: set([u'larger', u'jaguar'])
candidate Sentence: (0.09393002837896347, {u'tokens': [u'The', u'term', u'``', u'black', u'panther', u"''", u'is', u'used', u'colloquially', u'to', u'refer', u'to', u'melanistic', u'individuals', u'of', u'other', u'species', u',', u'particularly', u'jaguars', u'and', u'leopards', u'.'], u'lemmas': [u'the', u'term', u'``', u'black', u'panther', u"''", u'be', u'use', u'colloquially', u'to', u'refer', u'to', u'melanistic', u'individual', u'of', u'other', u'species', u',', u'particularly', u'jaguar', u'and', u'leopard', u'.'], u'pos': [u'DT', u'NN', u'``', u'JJ', u'NN', u"''", u'VBZ', u'VBN', u'RB', u'TO', u'VB', u'TO', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u',', u'RB', u'NNS', u'CC', u'NNS', u'.'], u'char_offsets': [[9437, 9440], [9441, 9445], [9446, 9447], [9447, 9452], [9453, 9460], [9460, 9461], [9462, 9464], [9465, 9469], [9470, 9482], [9483, 9485], [9486, 9491], [9492, 9494], [9495, 9505], [9506, 9517], [9518, 9520], [9521, 9526], [9527, 9534], [9534, 9535], [9536, 9548], [9549, 9556], [9557, 9560], [9561, 9569], [9569, 9570]]}) 
answer: set([u'larger'])

Are cougars larger than jaguars?
Validity= False
Question Type = NA
Answer Type = NA
Answer = no
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('no') == True
 +  where 'no' = <src.question_processing.Question_parser instance at 0x1114cba28>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param86] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cbab8>, (<src.tfidf.TF_IDF object at 0x10e16f890>, set(['cougar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbab8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.65966939926147461, {u'tokens': [u'The', u'World', u'Conservation', u'Union', u'-LRB-', u'IUCN', u'-RRB-', u'currently', u'lists', u'the', u'cougar', u'as', u'a', u'``', u'least', u'concern', u"''", u'species', u'.'], u'lemmas': [u'the', u'World', u'Conservation', u'Union', u'-lrb-', u'IUCN', u'-rrb-', u'currently', u'list', u'the', u'cougar', u'as', u'a', u'``', u'least', u'concern', u"''", u'species', u'.'], u'pos': [u'DT', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u'RB', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'``', u'JJS', u'NN', u"''", u'NNS', u'.'], u'char_offsets': [[25026, 25029], [25030, 25035], [25036, 25048], [25049, 25054], [25055, 25056], [25056, 25060], [25060, 25061], [25062, 25071], [25072, 25077], [25078, 25081], [25082, 25088], [25089, 25091], [25092, 25093], [25094, 25095], [25095, 25100], [25101, 25108], [25108, 25109], [25110, 25117], [25117, 25118]]}) 
answer: set([u'consider'])
candidate Sentence: (0.13396963477134705, {u'tokens': [u'South', u'of', u'the', u'Rio', u'Grande', u',', u'the', u'International', u'Union', u'for', u'the', u'Conservation', u'of', u'Nature', u'and', u'Natural', u'Resources', u'-LRB-', u'IUCN', u'-RRB-', u'lists', u'the', u'cat', u'in', u'every', u'Central', u'and', u'South', u'American', u'country', u'except', u'Costa', u'Rica', u'and', u'Panama', u'.'], u'lemmas': [u'South', u'of', u'the', u'Rio', u'Grande', u',', u'the', u'International', u'Union', u'for', u'the', u'Conservation', u'of', u'Nature', u'and', u'Natural', u'Resources', u'-lrb-', u'IUCN', u'-rrb-', u'list', u'the', u'cat', u'in', u'every', u'Central', u'and', u'South', u'American', u'country', u'except', u'Costa', u'Rica', u'and', u'Panama', u'.'], u'pos': [u'NNP', u'IN', u'DT', u'NNP', u'NNP', u',', u'DT', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'IN', u'NNP', u'CC', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NNP', u'CC', u'NNP', u'NNP', u'NN', u'IN', u'NNP', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[20293, 20298], [20299, 20301], [20302, 20305], [20306, 20309], [20310, 20316], [20316, 20317], [20318, 20321], [20322, 20335], [20336, 20341], [20342, 20345], [20346, 20349], [20350, 20362], [20363, 20365], [20366, 20372], [20373, 20376], [20377, 20384], [20385, 20394], [20395, 20396], [20396, 20400], [20400, 20401], [20402, 20407], [20408, 20411], [20412, 20415], [20416, 20418], [20419, 20424], [20425, 20432], [20433, 20436], [20437, 20442], [20443, 20451], [20452, 20459], [20460, 20466], [20467, 20472], [20473, 20477], [20478, 20481], [20482, 20488], [20488, 20489]]}) 
answer: set([u'world', u'concern', u'consider', u'least', u'species'])
candidate Sentence: (0.13258689641952515, {u'tokens': [u'Most', u'did', u'not', u'reach', u'adulthood', u'.'], u'lemmas': [u'most', u'do', u'not', u'reach', u'adulthood', u'.'], u'pos': [u'JJS', u'VBD', u'RB', u'VB', u'NN', u'.'], u'char_offsets': [[24282, 24286], [24287, 24290], [24291, 24294], [24295, 24300], [24301, 24310], [24310, 24311]]}) 
answer: set([u'consider', u'union', u'least', u'conservation', u'world', u'species', u'concern'])
candidate Sentence: (0.12796863913536072, {u'tokens': [u'During', u'the', u'early', u'years', u'of', u'ranching', u',', u'cougars', u'were', u'considered', u'on', u'par', u'with', u'wolves', u'in', u'destructiveness', u'.'], u'lemmas': [u'during', u'the', u'early', u'year', u'of', u'ranching', u',', u'cougar', u'be', u'consider', u'on', u'par', u'with', u'wolf', u'in', u'destructiveness', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NNS', u'IN', u'NN', u',', u'NNS', u'VBD', u'VBN', u'IN', u'NN', u'IN', u'NNS', u'IN', u'NN', u'.'], u'char_offsets': [[29542, 29548], [29549, 29552], [29553, 29558], [29559, 29564], [29565, 29567], [29568, 29576], [29576, 29577], [29578, 29585], [29586, 29590], [29591, 29601], [29602, 29604], [29605, 29608], [29609, 29613], [29614, 29620], [29621, 29623], [29624, 29639], [29639, 29640]]}) 
answer: set([u'union', u'least', u'conservation', u'world', u'species', u'concern'])
candidate Sentence: (0.11037647724151611, {u'tokens': [u'The', u'term', u'``', u'black', u'panther', u"''", u'is', u'used', u'colloquially', u'to', u'refer', u'to', u'melanistic', u'individuals', u'of', u'other', u'species', u',', u'particularly', u'jaguars', u'and', u'leopards', u'.'], u'lemmas': [u'the', u'term', u'``', u'black', u'panther', u"''", u'be', u'use', u'colloquially', u'to', u'refer', u'to', u'melanistic', u'individual', u'of', u'other', u'species', u',', u'particularly', u'jaguar', u'and', u'leopard', u'.'], u'pos': [u'DT', u'NN', u'``', u'JJ', u'NN', u"''", u'VBZ', u'VBN', u'RB', u'TO', u'VB', u'TO', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u',', u'RB', u'NNS', u'CC', u'NNS', u'.'], u'char_offsets': [[9437, 9440], [9441, 9445], [9446, 9447], [9447, 9452], [9453, 9460], [9460, 9461], [9462, 9464], [9465, 9469], [9470, 9482], [9483, 9485], [9486, 9491], [9492, 9494], [9495, 9505], [9506, 9517], [9518, 9520], [9521, 9526], [9527, 9534], [9534, 9535], [9536, 9548], [9549, 9556], [9557, 9560], [9561, 9569], [9569, 9570]]}) 
answer: set([u'consider', u'union', u'least', u'conservation', u'world', u'concern'])
candidate Sentence: (0.11007314920425415, {u'tokens': [u'In', u'North', u'America', u',', u'mythological', u'descriptions', u'of', u'the', u'cougar', u'have', u'appeared', u'in', u'the', u'stories', u'of', u'the', u'Hoc\u0105k', u'language', u'-LRB-', u'``', u'Ho-Chunk', u"''", u'or', u'``', u'Winnebago', u"''", u'-RRB-', u'of', u'Wisconsin', u'and', u'Illinois', u'Cougars', u',', u'The', u'Encyclopedia', u'of', u'Ho\u010d\u0105k', u'-LRB-', u'Winnebago', u'-RRB-', u'Mythology', u'.'], u'lemmas': [u'in', u'North', u'America', u',', u'mythological', u'description', u'of', u'the', u'cougar', u'have', u'appear', u'in', u'the', u'story', u'of', u'the', u'Hoc\u0105k', u'language', u'-lrb-', u'``', u'ho-chunk', u"''", u'or', u'``', u'Winnebago', u"''", u'-rrb-', u'of', u'Wisconsin', u'and', u'Illinois', u'Cougars', u',', u'the', u'encyclopedia', u'of', u'Ho\u010d\u0105k', u'-lrb-', u'Winnebago', u'-rrb-', u'Mythology', u'.'], u'pos': [u'IN', u'NNP', u'NNP', u',', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'VBP', u'VBN', u'IN', u'DT', u'NNS', u'IN', u'DT', u'NNP', u'NN', u'-LRB-', u'``', u'JJ', u"''", u'CC', u'``', u'NNP', u"''", u'-RRB-', u'IN', u'NNP', u'CC', u'NNP', u'NNPS', u',', u'DT', u'NN', u'IN', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u'NNP', u'.'], u'char_offsets': [[29172, 29174], [29175, 29180], [29181, 29188], [29188, 29189], [29190, 29202], [29203, 29215], [29216, 29218], [29219, 29222], [29223, 29229], [29230, 29234], [29235, 29243], [29244, 29246], [29247, 29250], [29251, 29258], [29259, 29261], [29262, 29265], [29266, 29271], [29272, 29280], [29281, 29282], [29282, 29283], [29283, 29291], [29291, 29292], [29293, 29295], [29296, 29297], [29297, 29306], [29306, 29307], [29307, 29308], [29309, 29311], [29312, 29321], [29322, 29325], [29326, 29334], [29338, 29345], [29345, 29346], [29347, 29350], [29351, 29363], [29364, 29366], [29367, 29372], [29373, 29374], [29374, 29383], [29383, 29384], [29385, 29394], [29394, 29395]]}) 
answer: set([u'consider', u'union', u'least', u'conservation', u'world', u'species', u'concern'])
candidate Sentence: (0.10577604174613953, {u'tokens': [u'*', u'Description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'No', u'Place', u'for', u'Predators', u'?'], u'lemmas': [u'*', u'description', u'of', u'a', u'Cougar', u'attack', u'*', u'Cougar', u'Facts', u'and', u'Photos', u'--', u'NatureMapping', u'Program', u'*', u'no', u'place', u'for', u'predator', u'?'], u'pos': [u'SYM', u'NN', u'IN', u'DT', u'NNP', u'NN', u'SYM', u'NNP', u'NNP', u'CC', u'NNP', u':', u'NNP', u'NNP', u'SYM', u'DT', u'NN', u'IN', u'NNS', u'.'], u'char_offsets': [[33435, 33436], [33438, 33449], [33450, 33452], [33453, 33454], [33455, 33461], [33462, 33468], [33469, 33470], [33472, 33478], [33479, 33484], [33485, 33488], [33489, 33495], [33496, 33497], [33498, 33511], [33512, 33519], [33520, 33521], [33523, 33525], [33526, 33531], [33532, 33535], [33536, 33545], [33545, 33546]]}) 
answer: set([u'consider', u'union', u'least', u'conservation', u'world', u'species', u'concern'])
candidate Sentence: (0.10467731952667236, {u'tokens': [u'The', u'Quebec', u'wildlife', u'services', u'-LRB-', u'known', u'locally', u'as', u'MRNF', u'-RRB-', u'also', u'considers', u'Cougar', u'to', u'be', u'present', u'in', u'the', u'province', u'as', u'a', u'threatened', u'species', u'after', u'multiple', u'DNA', u'tests', u'confirmed', u'cougar', u'hair', u'in', u'Lynx', u'mating', u'sites', u'.'], u'lemmas': [u'the', u'Quebec', u'wildlife', u'service', u'-lrb-', u'know', u'locally', u'as', u'mrnf', u'-rrb-', u'also', u'consider', u'Cougar', u'to', u'be', u'present', u'in', u'the', u'province', u'as', u'a', u'threaten', u'species', u'after', u'multiple', u'dna', u'test', u'confirm', u'cougar', u'hair', u'in', u'Lynx', u'mate', u'site', u'.'], u'pos': [u'DT', u'NNP', u'NN', u'NNS', u'-LRB-', u'VBN', u'RB', u'IN', u'NN', u'-RRB-', u'RB', u'VBZ', u'NNP', u'TO', u'VB', u'JJ', u'IN', u'DT', u'NN', u'IN', u'DT', u'VBN', u'NNS', u'IN', u'JJ', u'NN', u'NNS', u'VBD', u'NN', u'NN', u'IN', u'NNP', u'VBG', u'NNS', u'.'], u'char_offsets': [[18964, 18967], [18968, 18974], [18975, 18983], [18984, 18992], [18993, 18994], [18994, 18999], [19000, 19007], [19008, 19010], [19011, 19015], [19015, 19016], [19017, 19021], [19022, 19031], [19032, 19038], [19039, 19041], [19042, 19044], [19045, 19052], [19053, 19055], [19056, 19059], [19060, 19068], [19069, 19071], [19072, 19073], [19074, 19084], [19085, 19092], [19093, 19098], [19099, 19107], [19108, 19111], [19112, 19117], [19118, 19127], [19128, 19134], [19135, 19139], [19140, 19142], [19143, 19147], [19148, 19154], [19155, 19160], [19160, 19161]]}) 
answer: set([u'union', u'world', u'conservation', u'least', u'concern'])
candidate Sentence: (0.10351049900054932, {u'tokens': [u'Conservation', u'work', u'in', u'Texas', u'is', u'the', u'effort', u'of', u'a', u'non', u'profit', u'organization', u',', u'Balanced', u'Ecology', u'Inc.', u'-LRB-', u'BEI', u'-RRB-', u',', u'as', u'part', u'of', u'their', u'Texas', u'Mountain', u'Lion', u'Conservation', u'Project', u'.'], u'lemmas': [u'Conservation', u'work', u'in', u'Texas', u'be', u'the', u'effort', u'of', u'a', u'non', u'profit', u'organization', u',', u'balanced', u'Ecology', u'Inc.', u'-lrb-', u'BEI', u'-rrb-', u',', u'as', u'part', u'of', u'they', u'Texas', u'Mountain', u'Lion', u'Conservation', u'Project', u'.'], u'pos': [u'NNP', u'NN', u'IN', u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u',', u'JJ', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u',', u'IN', u'NN', u'IN', u'PRP$', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[27122, 27134], [27135, 27139], [27140, 27142], [27143, 27148], [27149, 27151], [27152, 27155], [27156, 27162], [27163, 27165], [27166, 27167], [27168, 27171], [27172, 27178], [27179, 27191], [27191, 27192], [27193, 27201], [27202, 27209], [27210, 27214], [27215, 27216], [27216, 27219], [27219, 27220], [27220, 27221], [27222, 27224], [27225, 27229], [27230, 27232], [27233, 27238], [27239, 27244], [27245, 27253], [27254, 27258], [27259, 27271], [27272, 27279], [27280, 27281]]}) 
answer: set([u'consider', u'union', u'least', u'world', u'species', u'concern'])
candidate Sentence: (0.10274501144886017, {u'tokens': [u'Conservation', u'threats', u'to', u'the', u'species', u'include', u'persecution', u'as', u'a', u'pest', u'animal', u',', u'degradation', u'and', u'fragmentation', u'of', u'their', u'habitat', u',', u'and', u'depletion', u'of', u'their', u'prey', u'base', u'.'], u'lemmas': [u'Conservation', u'threat', u'to', u'the', u'species', u'include', u'persecution', u'as', u'a', u'pest', u'animal', u',', u'degradation', u'and', u'fragmentation', u'of', u'they', u'habitat', u',', u'and', u'depletion', u'of', u'they', u'prey', u'base', u'.'], u'pos': [u'NNP', u'NNS', u'TO', u'DT', u'NNS', u'VBP', u'NN', u'IN', u'DT', u'NN', u'NN', u',', u'NN', u'CC', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'NN', u'IN', u'PRP$', u'NN', u'NN', u'.'], u'char_offsets': [[28034, 28046], [28047, 28054], [28055, 28057], [28058, 28061], [28062, 28069], [28070, 28077], [28078, 28089], [28090, 28092], [28093, 28094], [28095, 28099], [28100, 28106], [28106, 28107], [28108, 28119], [28120, 28123], [28124, 28137], [28138, 28140], [28141, 28146], [28147, 28154], [28154, 28155], [28156, 28159], [28160, 28169], [28170, 28172], [28173, 28178], [28179, 28183], [28184, 28188], [28188, 28189]]}) 
answer: set([u'union', u'world', u'consider', u'least', u'concern'])

Does the World Conservation Union consider the cougar a "least concern" species?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbab8>.answer
_____________________________ test_yesno[param92] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cbc68>, (<src.tfidf.TF_IDF object at 0x10a4d48d0>, set(['drum'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbc68>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.86695915460586548, {u'tokens': [u'Each', u'type', u'of', u'drumhead', u'serves', u'its', u'own', u'musical', u'purpose', u'and', u'has', u'its', u'own', u'unique', u'sound', u'.'], u'lemmas': [u'each', u'type', u'of', u'drumhead', u'serve', u'its', u'own', u'musical', u'purpose', u'and', u'have', u'its', u'own', u'unique', u'sound', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'VBZ', u'PRP$', u'JJ', u'JJ', u'NN', u'CC', u'VBZ', u'PRP$', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[3780, 3784], [3785, 3789], [3790, 3792], [3793, 3801], [3802, 3808], [3809, 3812], [3813, 3816], [3817, 3824], [3825, 3832], [3833, 3836], [3837, 3840], [3841, 3844], [3845, 3848], [3849, 3855], [3856, 3861], [3861, 3862]]}) 
answer: set([u'head'])
candidate Sentence: (0.15374471247196198, {u'tokens': [u'Drums', u'with', u'two', u'heads', u'can', u'also', u'have', u'a', u'set', u'of', u'wires', u',', u'called', u'snares', u',', u'held', u'across', u'the', u'bottom', u'head', u',', u'top', u'head', u',', u'or', u'both', u'heads', u',', u'hence', u'the', u'name', u'snare', u'drum', u'.'], u'lemmas': [u'drum', u'with', u'two', u'head', u'can', u'also', u'have', u'a', u'set', u'of', u'wire', u',', u'call', u'snare', u',', u'hold', u'across', u'the', u'bottom', u'head', u',', u'top', u'head', u',', u'or', u'both', u'head', u',', u'hence', u'the', u'name', u'snare', u'drum', u'.'], u'pos': [u'NNS', u'IN', u'CD', u'NNS', u'MD', u'RB', u'VB', u'DT', u'NN', u'IN', u'NNS', u',', u'VBN', u'NNS', u',', u'VBN', u'IN', u'DT', u'JJ', u'NN', u',', u'JJ', u'NN', u',', u'CC', u'DT', u'NNS', u',', u'RB', u'DT', u'NN', u'VB', u'VB', u'.'], u'char_offsets': [[1995, 2000], [2001, 2005], [2006, 2009], [2010, 2015], [2016, 2019], [2020, 2024], [2025, 2029], [2030, 2031], [2032, 2035], [2036, 2038], [2039, 2044], [2044, 2045], [2046, 2052], [2053, 2059], [2059, 2060], [2061, 2065], [2066, 2072], [2073, 2076], [2077, 2083], [2084, 2088], [2088, 2089], [2090, 2093], [2094, 2098], [2098, 2099], [2100, 2102], [2103, 2107], [2108, 2113], [2113, 2114], [2115, 2120], [2121, 2124], [2125, 2129], [2130, 2135], [2136, 2140], [2141, 2142]]}) 
answer: set([u'serve', u'type', u'purpose', u'musical'])
candidate Sentence: (0.12231619656085968, {u'tokens': [u'The', u'type', u'of', u'shell', u'also', u'affects', u'the', u'sound', u'of', u'a', u'drum', u'.'], u'lemmas': [u'the', u'type', u'of', u'shell', u'also', u'affect', u'the', u'sound', u'of', u'a', u'drum', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'RB', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'VBP', u'.'], u'char_offsets': [[4803, 4806], [4807, 4811], [4812, 4814], [4815, 4820], [4821, 4825], [4826, 4833], [4834, 4837], [4838, 4843], [4844, 4846], [4847, 4848], [4849, 4853], [4853, 4854]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.096087656915187836, {u'tokens': [u'The', u'sound', u'of', u'a', u'drum', u'depends', u'on', u'several', u'variables', u',', u'including', u'shape', u',', u'size', u'and', u'thickness', u'of', u'its', u'shell', u',', u'materials', u'from', u'which', u'the', u'shell', u'was', u'made', u',', u'counterhoop', u'material', u',', u'type', u'of', u'drumhead', u'used', u'and', u'tension', u'applied', u'to', u'it', u',', u'position', u'of', u'the', u'drum', u',', u'location', u',', u'and', u'the', u'velocity', u'and', u'angle', u'in', u'which', u'it', u'is', u'struck', u'.'], u'lemmas': [u'the', u'sound', u'of', u'a', u'drum', u'depend', u'on', u'several', u'variable', u',', u'include', u'shape', u',', u'size', u'and', u'thickness', u'of', u'its', u'shell', u',', u'material', u'from', u'which', u'the', u'shell', u'be', u'make', u',', u'counterhoop', u'material', u',', u'type', u'of', u'drumhead', u'use', u'and', u'tension', u'apply', u'to', u'it', u',', u'position', u'of', u'the', u'drum', u',', u'location', u',', u'and', u'the', u'velocity', u'and', u'angle', u'in', u'which', u'it', u'be', u'strike', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'VBP', u'VBZ', u'IN', u'JJ', u'NNS', u',', u'VBG', u'NN', u',', u'NN', u'CC', u'NN', u'IN', u'PRP$', u'NN', u',', u'NNS', u'IN', u'WDT', u'DT', u'NN', u'VBD', u'VBN', u',', u'NN', u'NN', u',', u'NN', u'IN', u'NN', u'VBN', u'CC', u'NN', u'VBD', u'TO', u'PRP', u',', u'NN', u'IN', u'DT', u'VBP', u',', u'NN', u',', u'CC', u'DT', u'NN', u'CC', u'NN', u'IN', u'WDT', u'PRP', u'VBZ', u'VBN', u'.'], u'char_offsets': [[2564, 2567], [2568, 2573], [2574, 2576], [2577, 2578], [2579, 2583], [2584, 2591], [2592, 2594], [2595, 2602], [2603, 2612], [2612, 2613], [2614, 2623], [2624, 2629], [2629, 2630], [2631, 2635], [2636, 2639], [2640, 2649], [2650, 2652], [2653, 2656], [2657, 2662], [2662, 2663], [2664, 2673], [2674, 2678], [2679, 2684], [2685, 2688], [2689, 2694], [2695, 2698], [2699, 2703], [2703, 2704], [2705, 2716], [2717, 2725], [2725, 2726], [2727, 2731], [2732, 2734], [2735, 2743], [2744, 2748], [2749, 2752], [2753, 2760], [2761, 2768], [2769, 2771], [2772, 2774], [2774, 2775], [2776, 2784], [2785, 2787], [2788, 2791], [2792, 2796], [2796, 2797], [2798, 2806], [2806, 2807], [2808, 2811], [2812, 2815], [2816, 2824], [2825, 2828], [2829, 2834], [2835, 2837], [2838, 2843], [2844, 2846], [2847, 2849], [2850, 2856], [2856, 2857]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.082161940634250641, {u'tokens': [u'The', u'type', u'of', u'wood', u'is', u'important', u'as', u'well', u'.'], u'lemmas': [u'the', u'type', u'of', u'wood', u'be', u'important', u'as', u'well', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'VBZ', u'JJ', u'RB', u'RB', u'.'], u'char_offsets': [[5084, 5087], [5088, 5092], [5093, 5095], [5096, 5100], [5101, 5103], [5104, 5113], [5114, 5116], [5117, 5121], [5121, 5122]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.081024825572967529, {u'tokens': [u'Drums', u'with', u'two', u'heads', u'covering', u'both', u'ends', u'of', u'a', u'cylindrical', u'shell', u'often', u'have', u'a', u'small', u'hole', u'somewhat', u'halfway', u'between', u'the', u'two', u'heads', u';', u'the', u'shell', u'forms', u'a', u'resonating', u'chamber', u'for', u'the', u'resulting', u'sound', u'.'], u'lemmas': [u'drum', u'with', u'two', u'head', u'cover', u'both', u'end', u'of', u'a', u'cylindrical', u'shell', u'often', u'have', u'a', u'small', u'hole', u'somewhat', u'halfway', u'between', u'the', u'two', u'head', u';', u'the', u'shell', u'form', u'a', u'resonate', u'chamber', u'for', u'the', u'result', u'sound', u'.'], u'pos': [u'NNS', u'IN', u'CD', u'NNS', u'VBG', u'CC', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'RB', u'VBP', u'DT', u'JJ', u'NN', u'RB', u'RB', u'IN', u'DT', u'CD', u'NNS', u':', u'DT', u'NN', u'VBZ', u'DT', u'VBG', u'NN', u'IN', u'DT', u'VBG', u'NN', u'.'], u'char_offsets': [[1671, 1676], [1677, 1681], [1682, 1685], [1686, 1691], [1692, 1700], [1701, 1705], [1706, 1710], [1711, 1713], [1714, 1715], [1716, 1727], [1728, 1733], [1734, 1739], [1740, 1744], [1745, 1746], [1747, 1752], [1753, 1757], [1758, 1766], [1767, 1774], [1775, 1782], [1783, 1786], [1787, 1790], [1791, 1796], [1796, 1797], [1798, 1801], [1802, 1807], [1808, 1813], [1814, 1815], [1816, 1826], [1827, 1834], [1835, 1838], [1839, 1842], [1843, 1852], [1853, 1858], [1858, 1859]]}) 
answer: set([u'serve', u'type', u'purpose', u'musical'])
candidate Sentence: (0.074329674243927002, {u'tokens': [u'The', u'head', u"'s", u'tension', u'can', u'be', u'adjusted', u'by', u'loosening', u'or', u'tightening', u'the', u'rods', u'.'], u'lemmas': [u'the', u'head', u"'s", u'tension', u'can', u'be', u'adjust', u'by', u'loosen', u'or', u'tighten', u'the', u'rod', u'.'], u'pos': [u'DT', u'NN', u'POS', u'NN', u'MD', u'VB', u'VBN', u'IN', u'VBG', u'CC', u'VBG', u'DT', u'NNS', u'.'], u'char_offsets': [[2446, 2449], [2450, 2454], [2454, 2456], [2457, 2464], [2465, 2468], [2469, 2471], [2472, 2480], [2481, 2483], [2484, 2493], [2494, 2496], [2497, 2507], [2508, 2511], [2512, 2516], [2516, 2517]]}) 
answer: set([u'serve', u'type', u'purpose', u'musical'])
candidate Sentence: (0.062839537858963013, {u'tokens': [u'Drum', u'carried', u'by', u'John', u'Unger', u',', u'Company', u'B', u',', u'40th', u'Regiment', u'New', u'York', u'Veteran', u'Volunteer', u'Infantry', u'Mozart', u'Regiment', u',', u'December', u'20', u',', u'1863', u'Several', u'factors', u'determine', u'the', u'sound', u'a', u'drum', u'produces', u',', u'including', u'the', u'type', u'of', u'shell', u'the', u'drum', u'has', u',', u'the', u'type', u'of', u'drumheads', u'it', u'has', u',', u'and', u'the', u'tension', u'of', u'the', u'drumheads', u'.'], u'lemmas': [u'drum', u'carry', u'by', u'John', u'Unger', u',', u'Company', u'B', u',', u'40th', u'Regiment', u'New', u'York', u'Veteran', u'Volunteer', u'Infantry', u'Mozart', u'Regiment', u',', u'December', u'20', u',', u'1863', u'several', u'factor', u'determine', u'the', u'sound', u'a', u'drum', u'produce', u',', u'include', u'the', u'type', u'of', u'shell', u'the', u'drum', u'have', u',', u'the', u'type', u'of', u'drumhead', u'it', u'have', u',', u'and', u'the', u'tension', u'of', u'the', u'drumhead', u'.'], u'pos': [u'VB', u'VBN', u'IN', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'JJ', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'CD', u',', u'CD', u'JJ', u'NNS', u'VBP', u'DT', u'NN', u'DT', u'VB', u'VBZ', u',', u'VBG', u'DT', u'NN', u'IN', u'NN', u'DT', u'VB', u'VBZ', u',', u'DT', u'NN', u'IN', u'NNS', u'PRP', u'VBZ', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[3124, 3128], [3129, 3136], [3137, 3139], [3140, 3144], [3145, 3150], [3150, 3151], [3152, 3159], [3160, 3161], [3161, 3162], [3163, 3167], [3168, 3176], [3177, 3180], [3181, 3185], [3186, 3193], [3194, 3203], [3204, 3212], [3213, 3219], [3220, 3228], [3228, 3229], [3230, 3238], [3239, 3241], [3241, 3242], [3243, 3247], [3248, 3255], [3256, 3263], [3264, 3273], [3274, 3277], [3278, 3283], [3284, 3285], [3286, 3290], [3291, 3299], [3299, 3300], [3301, 3310], [3311, 3314], [3315, 3319], [3320, 3322], [3323, 3328], [3329, 3332], [3333, 3337], [3338, 3341], [3341, 3342], [3343, 3346], [3347, 3351], [3352, 3354], [3355, 3364], [3365, 3367], [3368, 3371], [3371, 3372], [3373, 3376], [3377, 3380], [3381, 3388], [3389, 3391], [3392, 3395], [3396, 3405], [3405, 3406]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.06026337668299675, {u'tokens': [u'In', u'the', u'western', u'musical', u'tradition', u',', u'the', u'most', u'usual', u'shape', u'is', u'a', u'cylinder', u',', u'although', u'timpani', u',', u'for', u'example', u',', u'use', u'bowl-shaped', u'shells', u'.'], u'lemmas': [u'in', u'the', u'western', u'musical', u'tradition', u',', u'the', u'most', u'usual', u'shape', u'be', u'a', u'cylinder', u',', u'although', u'timpani', u',', u'for', u'example', u',', u'use', u'bowl-shaped', u'shell', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'JJ', u'NN', u',', u'DT', u'RBS', u'JJ', u'NN', u'VBZ', u'DT', u'NN', u',', u'IN', u'NNS', u',', u'IN', u'NN', u',', u'NN', u'JJ', u'NNS', u'.'], u'char_offsets': [[1140, 1142], [1143, 1146], [1147, 1154], [1155, 1162], [1163, 1172], [1172, 1173], [1174, 1177], [1178, 1182], [1183, 1188], [1189, 1194], [1195, 1197], [1198, 1199], [1200, 1208], [1208, 1209], [1210, 1218], [1219, 1226], [1226, 1227], [1228, 1231], [1232, 1239], [1239, 1240], [1241, 1244], [1245, 1256], [1257, 1263], [1264, 1265]]}) 
answer: set([u'serve', u'head', u'type', u'purpose'])
candidate Sentence: (0.060087621212005615, {u'tokens': [u'Lima-Peru', u'In', u'the', u'past', u'drums', u'have', u'been', u'used', u'not', u'only', u'for', u'their', u'musical', u'qualities', u',', u'but', u'also', u'as', u'a', u'means', u'of', u'communication', u',', u'especially', u'through', u'signals', u'.'], u'lemmas': [u'Lima-Peru', u'in', u'the', u'past', u'drum', u'have', u'be', u'use', u'not', u'only', u'for', u'they', u'musical', u'quality', u',', u'but', u'also', u'as', u'a', u'means', u'of', u'communication', u',', u'especially', u'through', u'signal', u'.'], u'pos': [u'NNP', u'IN', u'DT', u'JJ', u'NNS', u'VBP', u'VBN', u'VBN', u'RB', u'RB', u'IN', u'PRP$', u'JJ', u'NNS', u',', u'CC', u'RB', u'IN', u'DT', u'NN', u'IN', u'NN', u',', u'RB', u'IN', u'NNS', u'.'], u'char_offsets': [[6143, 6152], [6154, 6156], [6157, 6160], [6161, 6165], [6166, 6171], [6172, 6176], [6177, 6181], [6182, 6186], [6187, 6190], [6191, 6195], [6196, 6199], [6200, 6205], [6206, 6213], [6214, 6223], [6223, 6224], [6225, 6228], [6229, 6233], [6234, 6236], [6237, 6238], [6239, 6244], [6245, 6247], [6248, 6261], [6261, 6262], [6263, 6273], [6274, 6281], [6282, 6289], [6289, 6290]]}) 
answer: set([u'serve', u'head', u'type', u'purpose'])

Does each type of drum head serve its own musical purpose?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbc68>.answer
_____________________________ test_yesno[param93] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cbcb0>, (<src.tfidf.TF_IDF object at 0x10a4d48d0>, set(['drum'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbcb0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.86695915460586548, {u'tokens': [u'Each', u'type', u'of', u'drumhead', u'serves', u'its', u'own', u'musical', u'purpose', u'and', u'has', u'its', u'own', u'unique', u'sound', u'.'], u'lemmas': [u'each', u'type', u'of', u'drumhead', u'serve', u'its', u'own', u'musical', u'purpose', u'and', u'have', u'its', u'own', u'unique', u'sound', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'VBZ', u'PRP$', u'JJ', u'JJ', u'NN', u'CC', u'VBZ', u'PRP$', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[3780, 3784], [3785, 3789], [3790, 3792], [3793, 3801], [3802, 3808], [3809, 3812], [3813, 3816], [3817, 3824], [3825, 3832], [3833, 3836], [3837, 3840], [3841, 3844], [3845, 3848], [3849, 3855], [3856, 3861], [3861, 3862]]}) 
answer: set([u'head'])
candidate Sentence: (0.15374471247196198, {u'tokens': [u'Drums', u'with', u'two', u'heads', u'can', u'also', u'have', u'a', u'set', u'of', u'wires', u',', u'called', u'snares', u',', u'held', u'across', u'the', u'bottom', u'head', u',', u'top', u'head', u',', u'or', u'both', u'heads', u',', u'hence', u'the', u'name', u'snare', u'drum', u'.'], u'lemmas': [u'drum', u'with', u'two', u'head', u'can', u'also', u'have', u'a', u'set', u'of', u'wire', u',', u'call', u'snare', u',', u'hold', u'across', u'the', u'bottom', u'head', u',', u'top', u'head', u',', u'or', u'both', u'head', u',', u'hence', u'the', u'name', u'snare', u'drum', u'.'], u'pos': [u'NNS', u'IN', u'CD', u'NNS', u'MD', u'RB', u'VB', u'DT', u'NN', u'IN', u'NNS', u',', u'VBN', u'NNS', u',', u'VBN', u'IN', u'DT', u'JJ', u'NN', u',', u'JJ', u'NN', u',', u'CC', u'DT', u'NNS', u',', u'RB', u'DT', u'NN', u'VB', u'VB', u'.'], u'char_offsets': [[1995, 2000], [2001, 2005], [2006, 2009], [2010, 2015], [2016, 2019], [2020, 2024], [2025, 2029], [2030, 2031], [2032, 2035], [2036, 2038], [2039, 2044], [2044, 2045], [2046, 2052], [2053, 2059], [2059, 2060], [2061, 2065], [2066, 2072], [2073, 2076], [2077, 2083], [2084, 2088], [2088, 2089], [2090, 2093], [2094, 2098], [2098, 2099], [2100, 2102], [2103, 2107], [2108, 2113], [2113, 2114], [2115, 2120], [2121, 2124], [2125, 2129], [2130, 2135], [2136, 2140], [2141, 2142]]}) 
answer: set([u'serve', u'type', u'purpose', u'musical'])
candidate Sentence: (0.12231619656085968, {u'tokens': [u'The', u'type', u'of', u'shell', u'also', u'affects', u'the', u'sound', u'of', u'a', u'drum', u'.'], u'lemmas': [u'the', u'type', u'of', u'shell', u'also', u'affect', u'the', u'sound', u'of', u'a', u'drum', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'RB', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'VBP', u'.'], u'char_offsets': [[4803, 4806], [4807, 4811], [4812, 4814], [4815, 4820], [4821, 4825], [4826, 4833], [4834, 4837], [4838, 4843], [4844, 4846], [4847, 4848], [4849, 4853], [4853, 4854]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.096087656915187836, {u'tokens': [u'The', u'sound', u'of', u'a', u'drum', u'depends', u'on', u'several', u'variables', u',', u'including', u'shape', u',', u'size', u'and', u'thickness', u'of', u'its', u'shell', u',', u'materials', u'from', u'which', u'the', u'shell', u'was', u'made', u',', u'counterhoop', u'material', u',', u'type', u'of', u'drumhead', u'used', u'and', u'tension', u'applied', u'to', u'it', u',', u'position', u'of', u'the', u'drum', u',', u'location', u',', u'and', u'the', u'velocity', u'and', u'angle', u'in', u'which', u'it', u'is', u'struck', u'.'], u'lemmas': [u'the', u'sound', u'of', u'a', u'drum', u'depend', u'on', u'several', u'variable', u',', u'include', u'shape', u',', u'size', u'and', u'thickness', u'of', u'its', u'shell', u',', u'material', u'from', u'which', u'the', u'shell', u'be', u'make', u',', u'counterhoop', u'material', u',', u'type', u'of', u'drumhead', u'use', u'and', u'tension', u'apply', u'to', u'it', u',', u'position', u'of', u'the', u'drum', u',', u'location', u',', u'and', u'the', u'velocity', u'and', u'angle', u'in', u'which', u'it', u'be', u'strike', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'VBP', u'VBZ', u'IN', u'JJ', u'NNS', u',', u'VBG', u'NN', u',', u'NN', u'CC', u'NN', u'IN', u'PRP$', u'NN', u',', u'NNS', u'IN', u'WDT', u'DT', u'NN', u'VBD', u'VBN', u',', u'NN', u'NN', u',', u'NN', u'IN', u'NN', u'VBN', u'CC', u'NN', u'VBD', u'TO', u'PRP', u',', u'NN', u'IN', u'DT', u'VBP', u',', u'NN', u',', u'CC', u'DT', u'NN', u'CC', u'NN', u'IN', u'WDT', u'PRP', u'VBZ', u'VBN', u'.'], u'char_offsets': [[2564, 2567], [2568, 2573], [2574, 2576], [2577, 2578], [2579, 2583], [2584, 2591], [2592, 2594], [2595, 2602], [2603, 2612], [2612, 2613], [2614, 2623], [2624, 2629], [2629, 2630], [2631, 2635], [2636, 2639], [2640, 2649], [2650, 2652], [2653, 2656], [2657, 2662], [2662, 2663], [2664, 2673], [2674, 2678], [2679, 2684], [2685, 2688], [2689, 2694], [2695, 2698], [2699, 2703], [2703, 2704], [2705, 2716], [2717, 2725], [2725, 2726], [2727, 2731], [2732, 2734], [2735, 2743], [2744, 2748], [2749, 2752], [2753, 2760], [2761, 2768], [2769, 2771], [2772, 2774], [2774, 2775], [2776, 2784], [2785, 2787], [2788, 2791], [2792, 2796], [2796, 2797], [2798, 2806], [2806, 2807], [2808, 2811], [2812, 2815], [2816, 2824], [2825, 2828], [2829, 2834], [2835, 2837], [2838, 2843], [2844, 2846], [2847, 2849], [2850, 2856], [2856, 2857]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.082161940634250641, {u'tokens': [u'The', u'type', u'of', u'wood', u'is', u'important', u'as', u'well', u'.'], u'lemmas': [u'the', u'type', u'of', u'wood', u'be', u'important', u'as', u'well', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'VBZ', u'JJ', u'RB', u'RB', u'.'], u'char_offsets': [[5084, 5087], [5088, 5092], [5093, 5095], [5096, 5100], [5101, 5103], [5104, 5113], [5114, 5116], [5117, 5121], [5121, 5122]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.081024825572967529, {u'tokens': [u'Drums', u'with', u'two', u'heads', u'covering', u'both', u'ends', u'of', u'a', u'cylindrical', u'shell', u'often', u'have', u'a', u'small', u'hole', u'somewhat', u'halfway', u'between', u'the', u'two', u'heads', u';', u'the', u'shell', u'forms', u'a', u'resonating', u'chamber', u'for', u'the', u'resulting', u'sound', u'.'], u'lemmas': [u'drum', u'with', u'two', u'head', u'cover', u'both', u'end', u'of', u'a', u'cylindrical', u'shell', u'often', u'have', u'a', u'small', u'hole', u'somewhat', u'halfway', u'between', u'the', u'two', u'head', u';', u'the', u'shell', u'form', u'a', u'resonate', u'chamber', u'for', u'the', u'result', u'sound', u'.'], u'pos': [u'NNS', u'IN', u'CD', u'NNS', u'VBG', u'CC', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'RB', u'VBP', u'DT', u'JJ', u'NN', u'RB', u'RB', u'IN', u'DT', u'CD', u'NNS', u':', u'DT', u'NN', u'VBZ', u'DT', u'VBG', u'NN', u'IN', u'DT', u'VBG', u'NN', u'.'], u'char_offsets': [[1671, 1676], [1677, 1681], [1682, 1685], [1686, 1691], [1692, 1700], [1701, 1705], [1706, 1710], [1711, 1713], [1714, 1715], [1716, 1727], [1728, 1733], [1734, 1739], [1740, 1744], [1745, 1746], [1747, 1752], [1753, 1757], [1758, 1766], [1767, 1774], [1775, 1782], [1783, 1786], [1787, 1790], [1791, 1796], [1796, 1797], [1798, 1801], [1802, 1807], [1808, 1813], [1814, 1815], [1816, 1826], [1827, 1834], [1835, 1838], [1839, 1842], [1843, 1852], [1853, 1858], [1858, 1859]]}) 
answer: set([u'serve', u'type', u'purpose', u'musical'])
candidate Sentence: (0.074329674243927002, {u'tokens': [u'The', u'head', u"'s", u'tension', u'can', u'be', u'adjusted', u'by', u'loosening', u'or', u'tightening', u'the', u'rods', u'.'], u'lemmas': [u'the', u'head', u"'s", u'tension', u'can', u'be', u'adjust', u'by', u'loosen', u'or', u'tighten', u'the', u'rod', u'.'], u'pos': [u'DT', u'NN', u'POS', u'NN', u'MD', u'VB', u'VBN', u'IN', u'VBG', u'CC', u'VBG', u'DT', u'NNS', u'.'], u'char_offsets': [[2446, 2449], [2450, 2454], [2454, 2456], [2457, 2464], [2465, 2468], [2469, 2471], [2472, 2480], [2481, 2483], [2484, 2493], [2494, 2496], [2497, 2507], [2508, 2511], [2512, 2516], [2516, 2517]]}) 
answer: set([u'serve', u'type', u'purpose', u'musical'])
candidate Sentence: (0.062839537858963013, {u'tokens': [u'Drum', u'carried', u'by', u'John', u'Unger', u',', u'Company', u'B', u',', u'40th', u'Regiment', u'New', u'York', u'Veteran', u'Volunteer', u'Infantry', u'Mozart', u'Regiment', u',', u'December', u'20', u',', u'1863', u'Several', u'factors', u'determine', u'the', u'sound', u'a', u'drum', u'produces', u',', u'including', u'the', u'type', u'of', u'shell', u'the', u'drum', u'has', u',', u'the', u'type', u'of', u'drumheads', u'it', u'has', u',', u'and', u'the', u'tension', u'of', u'the', u'drumheads', u'.'], u'lemmas': [u'drum', u'carry', u'by', u'John', u'Unger', u',', u'Company', u'B', u',', u'40th', u'Regiment', u'New', u'York', u'Veteran', u'Volunteer', u'Infantry', u'Mozart', u'Regiment', u',', u'December', u'20', u',', u'1863', u'several', u'factor', u'determine', u'the', u'sound', u'a', u'drum', u'produce', u',', u'include', u'the', u'type', u'of', u'shell', u'the', u'drum', u'have', u',', u'the', u'type', u'of', u'drumhead', u'it', u'have', u',', u'and', u'the', u'tension', u'of', u'the', u'drumhead', u'.'], u'pos': [u'VB', u'VBN', u'IN', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'JJ', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'CD', u',', u'CD', u'JJ', u'NNS', u'VBP', u'DT', u'NN', u'DT', u'VB', u'VBZ', u',', u'VBG', u'DT', u'NN', u'IN', u'NN', u'DT', u'VB', u'VBZ', u',', u'DT', u'NN', u'IN', u'NNS', u'PRP', u'VBZ', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[3124, 3128], [3129, 3136], [3137, 3139], [3140, 3144], [3145, 3150], [3150, 3151], [3152, 3159], [3160, 3161], [3161, 3162], [3163, 3167], [3168, 3176], [3177, 3180], [3181, 3185], [3186, 3193], [3194, 3203], [3204, 3212], [3213, 3219], [3220, 3228], [3228, 3229], [3230, 3238], [3239, 3241], [3241, 3242], [3243, 3247], [3248, 3255], [3256, 3263], [3264, 3273], [3274, 3277], [3278, 3283], [3284, 3285], [3286, 3290], [3291, 3299], [3299, 3300], [3301, 3310], [3311, 3314], [3315, 3319], [3320, 3322], [3323, 3328], [3329, 3332], [3333, 3337], [3338, 3341], [3341, 3342], [3343, 3346], [3347, 3351], [3352, 3354], [3355, 3364], [3365, 3367], [3368, 3371], [3371, 3372], [3373, 3376], [3377, 3380], [3381, 3388], [3389, 3391], [3392, 3395], [3396, 3405], [3405, 3406]]}) 
answer: set([u'head', u'serve', u'purpose', u'musical'])
candidate Sentence: (0.06026337668299675, {u'tokens': [u'In', u'the', u'western', u'musical', u'tradition', u',', u'the', u'most', u'usual', u'shape', u'is', u'a', u'cylinder', u',', u'although', u'timpani', u',', u'for', u'example', u',', u'use', u'bowl-shaped', u'shells', u'.'], u'lemmas': [u'in', u'the', u'western', u'musical', u'tradition', u',', u'the', u'most', u'usual', u'shape', u'be', u'a', u'cylinder', u',', u'although', u'timpani', u',', u'for', u'example', u',', u'use', u'bowl-shaped', u'shell', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'JJ', u'NN', u',', u'DT', u'RBS', u'JJ', u'NN', u'VBZ', u'DT', u'NN', u',', u'IN', u'NNS', u',', u'IN', u'NN', u',', u'NN', u'JJ', u'NNS', u'.'], u'char_offsets': [[1140, 1142], [1143, 1146], [1147, 1154], [1155, 1162], [1163, 1172], [1172, 1173], [1174, 1177], [1178, 1182], [1183, 1188], [1189, 1194], [1195, 1197], [1198, 1199], [1200, 1208], [1208, 1209], [1210, 1218], [1219, 1226], [1226, 1227], [1228, 1231], [1232, 1239], [1239, 1240], [1241, 1244], [1245, 1256], [1257, 1263], [1264, 1265]]}) 
answer: set([u'serve', u'head', u'type', u'purpose'])
candidate Sentence: (0.060087621212005615, {u'tokens': [u'Lima-Peru', u'In', u'the', u'past', u'drums', u'have', u'been', u'used', u'not', u'only', u'for', u'their', u'musical', u'qualities', u',', u'but', u'also', u'as', u'a', u'means', u'of', u'communication', u',', u'especially', u'through', u'signals', u'.'], u'lemmas': [u'Lima-Peru', u'in', u'the', u'past', u'drum', u'have', u'be', u'use', u'not', u'only', u'for', u'they', u'musical', u'quality', u',', u'but', u'also', u'as', u'a', u'means', u'of', u'communication', u',', u'especially', u'through', u'signal', u'.'], u'pos': [u'NNP', u'IN', u'DT', u'JJ', u'NNS', u'VBP', u'VBN', u'VBN', u'RB', u'RB', u'IN', u'PRP$', u'JJ', u'NNS', u',', u'CC', u'RB', u'IN', u'DT', u'NN', u'IN', u'NN', u',', u'RB', u'IN', u'NNS', u'.'], u'char_offsets': [[6143, 6152], [6154, 6156], [6157, 6160], [6161, 6165], [6166, 6171], [6172, 6176], [6177, 6181], [6182, 6186], [6187, 6190], [6191, 6195], [6196, 6199], [6200, 6205], [6206, 6213], [6214, 6223], [6223, 6224], [6225, 6228], [6229, 6233], [6234, 6236], [6237, 6238], [6239, 6244], [6245, 6247], [6248, 6261], [6261, 6262], [6263, 6273], [6274, 6281], [6282, 6289], [6289, 6290]]}) 
answer: set([u'serve', u'head', u'type', u'purpose'])

Does each type of drum head serve its own musical purpose?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbcb0>.answer
_____________________________ test_yesno[param94] ______________________________

param = (<src.question_processing.Question_parser instance at 0x1114cbcf8>, (<src.tfidf.TF_IDF object at 0x10a4d48d0>, set(['drum'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbcf8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.51137542724609375, {u'tokens': [u'The', u'type', u'of', u'shell', u'also', u'affects', u'the', u'sound', u'of', u'a', u'drum', u'.'], u'lemmas': [u'the', u'type', u'of', u'shell', u'also', u'affect', u'the', u'sound', u'of', u'a', u'drum', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'RB', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'VBP', u'.'], u'char_offsets': [[4803, 4806], [4807, 4811], [4812, 4814], [4815, 4820], [4821, 4825], [4826, 4833], [4834, 4837], [4838, 4843], [4844, 4846], [4847, 4848], [4849, 4853], [4853, 4854]]}) 
answer: set([u'aburukuwa'])
candidate Sentence: (0.34035110473632812, {u'tokens': [u'The', u'type', u'of', u'wood', u'is', u'important', u'as', u'well', u'.'], u'lemmas': [u'the', u'type', u'of', u'wood', u'be', u'important', u'as', u'well', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'VBZ', u'JJ', u'RB', u'RB', u'.'], u'char_offsets': [[5084, 5087], [5088, 5092], [5093, 5095], [5096, 5100], [5101, 5103], [5104, 5113], [5114, 5116], [5117, 5121], [5121, 5122]]}) 
answer: set([u'aburukuwa'])
candidate Sentence: (0.29343646764755249, {u'tokens': [u'Because', u'the', u'vibrations', u'resonate', u'in', u'the', u'shell', u'of', u'the', u'drum', u',', u'the', u'shell', u'can', u'be', u'used', u'to', u'increase', u'the', u'volume', u'and', u'to', u'manipulate', u'the', u'type', u'of', u'sound', u'produced', u'.'], u'lemmas': [u'because', u'the', u'vibration', u'resonate', u'in', u'the', u'shell', u'of', u'the', u'drum', u',', u'the', u'shell', u'can', u'be', u'use', u'to', u'increase', u'the', u'volume', u'and', u'to', u'manipulate', u'the', u'type', u'of', u'sound', u'produce', u'.'], u'pos': [u'IN', u'DT', u'NNS', u'VBP', u'IN', u'DT', u'NN', u'IN', u'DT', u'VBP', u',', u'DT', u'NN', u'MD', u'VB', u'VBN', u'TO', u'VB', u'DT', u'NN', u'CC', u'TO', u'VB', u'DT', u'NN', u'IN', u'NN', u'VBD', u'.'], u'char_offsets': [[4855, 4862], [4863, 4866], [4867, 4877], [4878, 4886], [4887, 4889], [4890, 4893], [4894, 4899], [4900, 4902], [4903, 4906], [4907, 4911], [4911, 4912], [4913, 4916], [4917, 4922], [4923, 4926], [4927, 4929], [4930, 4934], [4935, 4937], [4938, 4946], [4947, 4950], [4951, 4957], [4958, 4961], [4962, 4964], [4965, 4975], [4976, 4979], [4980, 4984], [4985, 4987], [4988, 4993], [4994, 5002], [5002, 5003]]}) 
answer: set([u'aburukuwa'])
candidate Sentence: (0.26812058687210083, {u'tokens': [u'Drum', u'carried', u'by', u'John', u'Unger', u',', u'Company', u'B', u',', u'40th', u'Regiment', u'New', u'York', u'Veteran', u'Volunteer', u'Infantry', u'Mozart', u'Regiment', u',', u'December', u'20', u',', u'1863', u'Several', u'factors', u'determine', u'the', u'sound', u'a', u'drum', u'produces', u',', u'including', u'the', u'type', u'of', u'shell', u'the', u'drum', u'has', u',', u'the', u'type', u'of', u'drumheads', u'it', u'has', u',', u'and', u'the', u'tension', u'of', u'the', u'drumheads', u'.'], u'lemmas': [u'drum', u'carry', u'by', u'John', u'Unger', u',', u'Company', u'B', u',', u'40th', u'Regiment', u'New', u'York', u'Veteran', u'Volunteer', u'Infantry', u'Mozart', u'Regiment', u',', u'December', u'20', u',', u'1863', u'several', u'factor', u'determine', u'the', u'sound', u'a', u'drum', u'produce', u',', u'include', u'the', u'type', u'of', u'shell', u'the', u'drum', u'have', u',', u'the', u'type', u'of', u'drumhead', u'it', u'have', u',', u'and', u'the', u'tension', u'of', u'the', u'drumhead', u'.'], u'pos': [u'VB', u'VBN', u'IN', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'JJ', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'CD', u',', u'CD', u'JJ', u'NNS', u'VBP', u'DT', u'NN', u'DT', u'VB', u'VBZ', u',', u'VBG', u'DT', u'NN', u'IN', u'NN', u'DT', u'VB', u'VBZ', u',', u'DT', u'NN', u'IN', u'NNS', u'PRP', u'VBZ', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[3124, 3128], [3129, 3136], [3137, 3139], [3140, 3144], [3145, 3150], [3150, 3151], [3152, 3159], [3160, 3161], [3161, 3162], [3163, 3167], [3168, 3176], [3177, 3180], [3181, 3185], [3186, 3193], [3194, 3203], [3204, 3212], [3213, 3219], [3220, 3228], [3228, 3229], [3230, 3238], [3239, 3241], [3241, 3242], [3243, 3247], [3248, 3255], [3256, 3263], [3264, 3273], [3274, 3277], [3278, 3283], [3284, 3285], [3286, 3290], [3291, 3299], [3299, 3300], [3301, 3310], [3311, 3314], [3315, 3319], [3320, 3322], [3323, 3328], [3329, 3332], [3333, 3337], [3338, 3341], [3341, 3342], [3343, 3346], [3347, 3351], [3352, 3354], [3355, 3364], [3365, 3367], [3368, 3371], [3371, 3372], [3373, 3376], [3377, 3380], [3381, 3388], [3389, 3391], [3392, 3395], [3396, 3405], [3405, 3406]]}) 
answer: set([u'aburukuwa'])
candidate Sentence: (0.19107162952423096, {u'tokens': [u'The', u'sound', u'of', u'a', u'drum', u'depends', u'on', u'several', u'variables', u',', u'including', u'shape', u',', u'size', u'and', u'thickness', u'of', u'its', u'shell', u',', u'materials', u'from', u'which', u'the', u'shell', u'was', u'made', u',', u'counterhoop', u'material', u',', u'type', u'of', u'drumhead', u'used', u'and', u'tension', u'applied', u'to', u'it', u',', u'position', u'of', u'the', u'drum', u',', u'location', u',', u'and', u'the', u'velocity', u'and', u'angle', u'in', u'which', u'it', u'is', u'struck', u'.'], u'lemmas': [u'the', u'sound', u'of', u'a', u'drum', u'depend', u'on', u'several', u'variable', u',', u'include', u'shape', u',', u'size', u'and', u'thickness', u'of', u'its', u'shell', u',', u'material', u'from', u'which', u'the', u'shell', u'be', u'make', u',', u'counterhoop', u'material', u',', u'type', u'of', u'drumhead', u'use', u'and', u'tension', u'apply', u'to', u'it', u',', u'position', u'of', u'the', u'drum', u',', u'location', u',', u'and', u'the', u'velocity', u'and', u'angle', u'in', u'which', u'it', u'be', u'strike', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'VBP', u'VBZ', u'IN', u'JJ', u'NNS', u',', u'VBG', u'NN', u',', u'NN', u'CC', u'NN', u'IN', u'PRP$', u'NN', u',', u'NNS', u'IN', u'WDT', u'DT', u'NN', u'VBD', u'VBN', u',', u'NN', u'NN', u',', u'NN', u'IN', u'NN', u'VBN', u'CC', u'NN', u'VBD', u'TO', u'PRP', u',', u'NN', u'IN', u'DT', u'VBP', u',', u'NN', u',', u'CC', u'DT', u'NN', u'CC', u'NN', u'IN', u'WDT', u'PRP', u'VBZ', u'VBN', u'.'], u'char_offsets': [[2564, 2567], [2568, 2573], [2574, 2576], [2577, 2578], [2579, 2583], [2584, 2591], [2592, 2594], [2595, 2602], [2603, 2612], [2612, 2613], [2614, 2623], [2624, 2629], [2629, 2630], [2631, 2635], [2636, 2639], [2640, 2649], [2650, 2652], [2653, 2656], [2657, 2662], [2662, 2663], [2664, 2673], [2674, 2678], [2679, 2684], [2685, 2688], [2689, 2694], [2695, 2698], [2699, 2703], [2703, 2704], [2705, 2716], [2717, 2725], [2725, 2726], [2727, 2731], [2732, 2734], [2735, 2743], [2744, 2748], [2749, 2752], [2753, 2760], [2761, 2768], [2769, 2771], [2772, 2774], [2774, 2775], [2776, 2784], [2785, 2787], [2788, 2791], [2792, 2796], [2796, 2797], [2798, 2806], [2806, 2807], [2808, 2811], [2812, 2815], [2816, 2824], [2825, 2828], [2829, 2834], [2835, 2837], [2838, 2843], [2844, 2846], [2847, 2849], [2850, 2856], [2856, 2857]]}) 
answer: set([u'aburukuwa'])
candidate Sentence: (0.15839624404907227, {u'tokens': [u'The', u'larger', u'the', u'diameter', u'of', u'the', u'shell', u',', u'the', u'lower', u'the', u'pitch', u'of', u'the', u'drum', u'will', u'be', u'.'], u'lemmas': [u'the', u'larger', u'the', u'diameter', u'of', u'the', u'shell', u',', u'the', u'lower', u'the', u'pitch', u'of', u'the', u'drum', u'will', u'be', u'.'], u'pos': [u'DT', u'JJR', u'DT', u'NN', u'IN', u'DT', u'NN', u',', u'DT', u'JJR', u'DT', u'NN', u'IN', u'DT', u'VBP', u'MD', u'VB', u'.'], u'char_offsets': [[5004, 5007], [5008, 5014], [5015, 5018], [5019, 5027], [5028, 5030], [5031, 5034], [5035, 5040], [5040, 5041], [5042, 5045], [5046, 5051], [5052, 5055], [5056, 5061], [5062, 5064], [5065, 5068], [5069, 5073], [5074, 5078], [5079, 5081], [5081, 5082]]}) 
answer: set([u'aburukuwa', u'type'])
candidate Sentence: (0.15780381858348846, {u'tokens': [u'Each', u'type', u'of', u'drumhead', u'serves', u'its', u'own', u'musical', u'purpose', u'and', u'has', u'its', u'own', u'unique', u'sound', u'.'], u'lemmas': [u'each', u'type', u'of', u'drumhead', u'serve', u'its', u'own', u'musical', u'purpose', u'and', u'have', u'its', u'own', u'unique', u'sound', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'VBZ', u'PRP$', u'JJ', u'JJ', u'NN', u'CC', u'VBZ', u'PRP$', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[3780, 3784], [3785, 3789], [3790, 3792], [3793, 3801], [3802, 3808], [3809, 3812], [3813, 3816], [3817, 3824], [3825, 3832], [3833, 3836], [3837, 3840], [3841, 3844], [3845, 3848], [3849, 3855], [3856, 3861], [3861, 3862]]}) 
answer: set([u'aburukuwa'])
candidate Sentence: (0.14037114381790161, {u'tokens': [u'The', u'second', u'biggest', u'factor', u'affecting', u'the', u'sound', u'produced', u'by', u'a', u'drum', u'is', u'the', u'tension', u'at', u'which', u'the', u'drumhead', u'is', u'held', u'against', u'the', u'shell', u'of', u'the', u'drum', u'.'], u'lemmas': [u'the', u'second', u'biggest', u'factor', u'affect', u'the', u'sound', u'produce', u'by', u'a', u'drum', u'be', u'the', u'tension', u'at', u'which', u'the', u'drumhead', u'be', u'hold', u'against', u'the', u'shell', u'of', u'the', u'drum', u'.'], u'pos': [u'DT', u'JJ', u'JJS', u'NN', u'VBG', u'DT', u'NN', u'VBN', u'IN', u'DT', u'VBP', u'VBZ', u'DT', u'NN', u'IN', u'WDT', u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'VBP', u'.'], u'char_offsets': [[4387, 4390], [4391, 4397], [4398, 4405], [4406, 4412], [4413, 4422], [4423, 4426], [4427, 4432], [4433, 4441], [4442, 4444], [4445, 4446], [4447, 4451], [4452, 4454], [4455, 4458], [4459, 4466], [4467, 4469], [4470, 4475], [4476, 4479], [4480, 4488], [4489, 4491], [4492, 4496], [4497, 4504], [4505, 4508], [4509, 4514], [4515, 4517], [4518, 4521], [4522, 4526], [4526, 4527]]}) 
answer: set([u'aburukuwa', u'type'])
candidate Sentence: (0.11374986171722412, {u'tokens': [u'When', u'the', u'tension', u'is', u'increased', u',', u'the', u'amplitude', u'of', u'the', u'sound', u'is', u'reduced', u'and', u'the', u'frequency', u'is', u'increased', u',', u'making', u'the', u'pitch', u'higher', u'and', u'the', u'volume', u'lower', u'.'], u'lemmas': [u'when', u'the', u'tension', u'be', u'increase', u',', u'the', u'amplitude', u'of', u'the', u'sound', u'be', u'reduce', u'and', u'the', u'frequency', u'be', u'increase', u',', u'make', u'the', u'pitch', u'higher', u'and', u'the', u'volume', u'lower', u'.'], u'pos': [u'WRB', u'DT', u'NN', u'VBZ', u'VBN', u',', u'DT', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'CC', u'DT', u'NN', u'VBZ', u'VBN', u',', u'VBG', u'DT', u'NN', u'JJR', u'CC', u'DT', u'NN', u'JJR', u'.'], u'char_offsets': [[4655, 4659], [4660, 4663], [4664, 4671], [4672, 4674], [4675, 4684], [4684, 4685], [4686, 4689], [4690, 4699], [4700, 4702], [4703, 4706], [4707, 4712], [4713, 4715], [4716, 4723], [4725, 4728], [4729, 4732], [4733, 4742], [4743, 4745], [4746, 4755], [4755, 4756], [4757, 4763], [4764, 4767], [4768, 4773], [4774, 4780], [4781, 4784], [4785, 4788], [4789, 4795], [4796, 4801], [4801, 4802]]}) 
answer: set([u'type', u'aburukuwa'])
candidate Sentence: (0.10552647709846497, {u'tokens': [u'Single-headed', u'drums', u'normally', u'consist', u'of', u'a', u'skin', u'which', u'is', u'stretched', u'over', u'an', u'enclosed', u'space', u',', u'or', u'over', u'one', u'of', u'the', u'ends', u'of', u'a', u'hollow', u'vessel', u'.'], u'lemmas': [u'single-headed', u'drum', u'normally', u'consist', u'of', u'a', u'skin', u'which', u'be', u'stretch', u'over', u'a', u'enclosed', u'space', u',', u'or', u'over', u'one', u'of', u'the', u'end', u'of', u'a', u'hollow', u'vessel', u'.'], u'pos': [u'JJ', u'NNS', u'RB', u'VBP', u'IN', u'DT', u'NN', u'WDT', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u',', u'CC', u'IN', u'CD', u'IN', u'DT', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[1537, 1550], [1551, 1556], [1557, 1565], [1566, 1573], [1574, 1576], [1577, 1578], [1579, 1583], [1584, 1589], [1590, 1592], [1593, 1602], [1603, 1607], [1608, 1610], [1611, 1619], [1620, 1625], [1625, 1626], [1627, 1629], [1630, 1634], [1635, 1638], [1639, 1641], [1642, 1645], [1646, 1650], [1651, 1653], [1654, 1655], [1656, 1662], [1663, 1669], [1669, 1670]]}) 
answer: set([u'aburukuwa', u'type'])

Is the Aburukuwa a type of drum?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cbcf8>.answer
_____________________________ test_yesno[param128] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ce6c8>, (<src.tfidf.TF_IDF object at 0x10a4b0710>, set(['giant', 'giant_panda', 'panda'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114ce6c8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39236637949943542, {u'tokens': [u'A', u'Giant', u'Panda', u'cub', u'.'], u'lemmas': [u'a', u'giant', u'panda', u'cub', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[1794, 1795], [1796, 1801], [1802, 1807], [1808, 1811], [1811, 1812]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.26237842440605164, {u'tokens': [u'The', u'Giant', u'Panda', u'-LRB-', u'Ailuropoda', u'melanoleuca', u',', u'literally', u'meaning', u'``', u'cat-foot', u'black-and-white', u"''", u'-RRB-', u'is', u'a', u'mammal', u'native', u'to', u'central-western', u'and', u'south', u'western', u'China', u'.'], u'lemmas': [u'the', u'Giant', u'Panda', u'-lrb-', u'Ailuropoda', u'melanoleuca', u',', u'literally', u'mean', u'``', u'cat-foot', u'black-and-white', u"''", u'-rrb-', u'be', u'a', u'mammal', u'native', u'to', u'central-western', u'and', u'south', u'western', u'China', u'.'], u'pos': [u'DT', u'NNP', u'NNP', u'-LRB-', u'NNP', u'NN', u',', u'RB', u'VBG', u'``', u'JJ', u'JJ', u"''", u'-RRB-', u'VBZ', u'DT', u'NN', u'JJ', u'TO', u'JJ', u'CC', u'JJ', u'JJ', u'NNP', u'.'], u'char_offsets': [[0, 3], [4, 9], [10, 15], [16, 17], [17, 27], [28, 39], [39, 40], [41, 50], [51, 58], [59, 60], [60, 68], [69, 84], [84, 85], [85, 86], [87, 89], [90, 91], [92, 98], [99, 105], [106, 108], [109, 124], [125, 128], [129, 134], [135, 142], [143, 148], [148, 149]]}) 
answer: set([])
candidate Sentence: (0.23611243069171906, {u'tokens': [u'For', u'this', u'reason', u',', u'pandas', u'do', u'not', u'hibernate', u',', u'which', u'is', u'similar', u'to', u'other', u'subtropical', u'mammals', u',', u'and', u'will', u'instead', u'move', u'to', u'elevations', u'with', u'warmer', u'temperatures', u'.'], u'lemmas': [u'for', u'this', u'reason', u',', u'panda', u'do', u'not', u'hibernate', u',', u'which', u'be', u'similar', u'to', u'other', u'subtropical', u'mammal', u',', u'and', u'will', u'instead', u'move', u'to', u'elevation', u'with', u'warmer', u'temperature', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'NNS', u'VBP', u'RB', u'VB', u',', u'WDT', u'VBZ', u'JJ', u'TO', u'JJ', u'JJ', u'NNS', u',', u'CC', u'MD', u'RB', u'VB', u'TO', u'NNS', u'IN', u'JJR', u'NNS', u'.'], u'char_offsets': [[3839, 3842], [3843, 3847], [3848, 3854], [3854, 3855], [3856, 3862], [3863, 3865], [3866, 3869], [3870, 3879], [3879, 3880], [3881, 3886], [3887, 3889], [3890, 3897], [3898, 3900], [3901, 3906], [3907, 3918], [3919, 3926], [3926, 3927], [3928, 3931], [3932, 3936], [3937, 3944], [3945, 3949], [3950, 3952], [3953, 3963], [3964, 3968], [3969, 3975], [3976, 3988], [3988, 3989]]}) 
answer: set([])
candidate Sentence: (0.13539925217628479, {u'tokens': [u'Was', u'the', u'first', u'giant', u'panda', u'that', u'was', u'born', u'and', u'survived', u'in', u'captivity', u'outside', u'China', u'.'], u'lemmas': [u'be', u'the', u'first', u'giant', u'panda', u'that', u'be', u'bear', u'and', u'survive', u'in', u'captivity', u'outside', u'China', u'.'], u'pos': [u'VBD', u'DT', u'JJ', u'JJ', u'NN', u'WDT', u'VBD', u'VBN', u'CC', u'VBN', u'IN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[25307, 25310], [25311, 25314], [25315, 25320], [25321, 25326], [25327, 25332], [25333, 25337], [25338, 25341], [25342, 25346], [25347, 25350], [25351, 25359], [25360, 25362], [25363, 25372], [25373, 25380], [25381, 25386], [25386, 25387]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.11068816483020782, {u'tokens': [u'The', u'giant', u'panda', u'genome', u'was', u'sequenced', u'in', u'2009', u'using', u'a', u'next-generation', u'sequencing', u'technology', u'.'], u'lemmas': [u'the', u'giant', u'panda', u'genome', u'be', u'sequence', u'in', u'2009', u'use', u'a', u'next-generation', u'sequencing', u'technology', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBD', u'VBN', u'IN', u'CD', u'VBG', u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[6481, 6484], [6485, 6490], [6491, 6496], [6497, 6503], [6504, 6507], [6508, 6517], [6518, 6520], [6521, 6525], [6526, 6531], [6532, 6533], [6534, 6549], [6550, 6560], [6561, 6571], [6571, 6572]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.10233046859502792, {u'tokens': [u'They', u'are', u'expected', u'to', u'stay', u'for', u'a', u'minimum', u'of', u'10', u'years', u',', u'and', u'will', u'be', u'the', u'only', u'Giant', u'Pandas', u'living', u'in', u'the', u'Southern', u'Hemisphere', u'.'], u'lemmas': [u'they', u'be', u'expect', u'to', u'stay', u'for', u'a', u'minimum', u'of', u'10', u'year', u',', u'and', u'will', u'be', u'the', u'only', u'giant', u'panda', u'living', u'in', u'the', u'Southern', u'Hemisphere', u'.'], u'pos': [u'PRP', u'VBP', u'VBN', u'TO', u'VB', u'IN', u'DT', u'NN', u'IN', u'CD', u'NNS', u',', u'CC', u'MD', u'VB', u'DT', u'JJ', u'NN', u'NN', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'.'], u'char_offsets': [[23298, 23302], [23303, 23306], [23307, 23315], [23316, 23318], [23319, 23323], [23324, 23327], [23328, 23329], [23330, 23337], [23338, 23340], [23341, 23343], [23344, 23349], [23349, 23350], [23351, 23354], [23355, 23359], [23360, 23362], [23363, 23366], [23367, 23371], [23372, 23377], [23378, 23384], [23385, 23391], [23392, 23394], [23395, 23398], [23399, 23407], [23408, 23418], [23418, 23419]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.10210540890693665, {u'tokens': [u'A', u'Giant', u'Panda', u'cub', u'is', u'also', u'extremely', u'small', u',', u'and', u'it', u'is', u'difficult', u'for', u'the', u'mother', u'to', u'protect', u'it', u'because', u'of', u'the', u'baby', u"'s", u'size', u'.'], u'lemmas': [u'a', u'giant', u'panda', u'cub', u'be', u'also', u'extremely', u'small', u',', u'and', u'it', u'be', u'difficult', u'for', u'the', u'mother', u'to', u'protect', u'it', u'because', u'of', u'the', u'baby', u"'s", u'size', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'RB', u'RB', u'JJ', u',', u'CC', u'PRP', u'VBZ', u'JJ', u'IN', u'DT', u'NN', u'TO', u'VB', u'PRP', u'IN', u'IN', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[17518, 17519], [17520, 17525], [17526, 17531], [17532, 17535], [17536, 17538], [17539, 17543], [17544, 17553], [17554, 17559], [17559, 17560], [17561, 17564], [17565, 17567], [17568, 17570], [17571, 17580], [17581, 17584], [17585, 17588], [17589, 17595], [17596, 17598], [17599, 17606], [17607, 17609], [17610, 17617], [17618, 17620], [17621, 17624], [17625, 17629], [17629, 17631], [17632, 17636], [17636, 17637]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.098710060119628906, {u'tokens': [u'The', u'first', u'Westerner', u'known', u'to', u'have', u'seen', u'a', u'living', u'Giant', u'Panda', u'is', u'the', u'German', u'zoologist', u'Hugo', u'Weigold', u',', u'who', u'purchased', u'a', u'cub', u'in', u'1916', u'.'], u'lemmas': [u'the', u'first', u'Westerner', u'know', u'to', u'have', u'see', u'a', u'living', u'giant', u'panda', u'be', u'the', u'german', u'zoologist', u'Hugo', u'Weigold', u',', u'who', u'purchase', u'a', u'cub', u'in', u'1916', u'.'], u'pos': [u'DT', u'JJ', u'NNP', u'VBN', u'TO', u'VB', u'VBN', u'DT', u'NN', u'NN', u'NN', u'VBZ', u'DT', u'JJ', u'NN', u'NNP', u'NNP', u',', u'WP', u'VBD', u'DT', u'NN', u'IN', u'CD', u'.'], u'char_offsets': [[9102, 9105], [9106, 9111], [9112, 9121], [9122, 9127], [9128, 9130], [9131, 9135], [9136, 9140], [9141, 9142], [9143, 9149], [9150, 9155], [9156, 9161], [9162, 9164], [9165, 9168], [9169, 9175], [9176, 9185], [9186, 9190], [9191, 9198], [9198, 9199], [9200, 9203], [9204, 9213], [9214, 9215], [9216, 9219], [9220, 9222], [9223, 9227], [9227, 9228]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.089725479483604431, {u'tokens': [u'Chris', u'Packham', u':', u'`', u'Giant', u'pandas', u'should', u'be', u'allowed', u'to', u'die', u'out', u"'", u'.'], u'lemmas': [u'Chris', u'Packham', u':', u'`', u'giant', u'panda', u'should', u'be', u'allow', u'to', u'die', u'out', u"'", u'.'], u'pos': [u'NNP', u'NNP', u':', u'``', u'JJ', u'NNS', u'MD', u'VB', u'VBN', u'TO', u'VB', u'RP', u"''", u'.'], u'char_offsets': [[14796, 14801], [14802, 14809], [14809, 14810], [14811, 14812], [14812, 14817], [14818, 14824], [14825, 14831], [14832, 14834], [14835, 14842], [14843, 14845], [14846, 14849], [14850, 14853], [14853, 14854], [14854, 14855]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.088594093918800354, {u'tokens': [u'A', u'2007', u'report', u'shows', u'239', u'Giant', u'Pandas', u'living', u'in', u'captivity', u'inside', u'China', u'and', u'another', u'27', u'outside', u'the', u'country', u'.'], u'lemmas': [u'a', u'2007', u'report', u'show', u'239', u'giant', u'panda', u'living', u'in', u'captivity', u'inside', u'China', u'and', u'another', u'27', u'outside', u'the', u'country', u'.'], u'pos': [u'DT', u'CD', u'NN', u'VBZ', u'CD', u'JJ', u'NN', u'NN', u'IN', u'NN', u'IN', u'NNP', u'CC', u'DT', u'CD', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[858, 859], [860, 864], [865, 871], [872, 877], [878, 881], [882, 887], [888, 894], [895, 901], [902, 904], [905, 914], [915, 921], [922, 927], [928, 931], [932, 939], [940, 942], [943, 950], [951, 954], [955, 962], [962, 963]]}) 
answer: set([u'mammal'])

Is the Giant Panda a mammal?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114ce6c8>.answer
_____________________________ test_yesno[param129] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ce710>, (<src.tfidf.TF_IDF object at 0x10a4b0710>, set(['giant', 'giant_panda', 'panda'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114ce710>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39236637949943542, {u'tokens': [u'A', u'Giant', u'Panda', u'cub', u'.'], u'lemmas': [u'a', u'giant', u'panda', u'cub', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[1794, 1795], [1796, 1801], [1802, 1807], [1808, 1811], [1811, 1812]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.26237842440605164, {u'tokens': [u'The', u'Giant', u'Panda', u'-LRB-', u'Ailuropoda', u'melanoleuca', u',', u'literally', u'meaning', u'``', u'cat-foot', u'black-and-white', u"''", u'-RRB-', u'is', u'a', u'mammal', u'native', u'to', u'central-western', u'and', u'south', u'western', u'China', u'.'], u'lemmas': [u'the', u'Giant', u'Panda', u'-lrb-', u'Ailuropoda', u'melanoleuca', u',', u'literally', u'mean', u'``', u'cat-foot', u'black-and-white', u"''", u'-rrb-', u'be', u'a', u'mammal', u'native', u'to', u'central-western', u'and', u'south', u'western', u'China', u'.'], u'pos': [u'DT', u'NNP', u'NNP', u'-LRB-', u'NNP', u'NN', u',', u'RB', u'VBG', u'``', u'JJ', u'JJ', u"''", u'-RRB-', u'VBZ', u'DT', u'NN', u'JJ', u'TO', u'JJ', u'CC', u'JJ', u'JJ', u'NNP', u'.'], u'char_offsets': [[0, 3], [4, 9], [10, 15], [16, 17], [17, 27], [28, 39], [39, 40], [41, 50], [51, 58], [59, 60], [60, 68], [69, 84], [84, 85], [85, 86], [87, 89], [90, 91], [92, 98], [99, 105], [106, 108], [109, 124], [125, 128], [129, 134], [135, 142], [143, 148], [148, 149]]}) 
answer: set([])
candidate Sentence: (0.23611243069171906, {u'tokens': [u'For', u'this', u'reason', u',', u'pandas', u'do', u'not', u'hibernate', u',', u'which', u'is', u'similar', u'to', u'other', u'subtropical', u'mammals', u',', u'and', u'will', u'instead', u'move', u'to', u'elevations', u'with', u'warmer', u'temperatures', u'.'], u'lemmas': [u'for', u'this', u'reason', u',', u'panda', u'do', u'not', u'hibernate', u',', u'which', u'be', u'similar', u'to', u'other', u'subtropical', u'mammal', u',', u'and', u'will', u'instead', u'move', u'to', u'elevation', u'with', u'warmer', u'temperature', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'NNS', u'VBP', u'RB', u'VB', u',', u'WDT', u'VBZ', u'JJ', u'TO', u'JJ', u'JJ', u'NNS', u',', u'CC', u'MD', u'RB', u'VB', u'TO', u'NNS', u'IN', u'JJR', u'NNS', u'.'], u'char_offsets': [[3839, 3842], [3843, 3847], [3848, 3854], [3854, 3855], [3856, 3862], [3863, 3865], [3866, 3869], [3870, 3879], [3879, 3880], [3881, 3886], [3887, 3889], [3890, 3897], [3898, 3900], [3901, 3906], [3907, 3918], [3919, 3926], [3926, 3927], [3928, 3931], [3932, 3936], [3937, 3944], [3945, 3949], [3950, 3952], [3953, 3963], [3964, 3968], [3969, 3975], [3976, 3988], [3988, 3989]]}) 
answer: set([])
candidate Sentence: (0.13539925217628479, {u'tokens': [u'Was', u'the', u'first', u'giant', u'panda', u'that', u'was', u'born', u'and', u'survived', u'in', u'captivity', u'outside', u'China', u'.'], u'lemmas': [u'be', u'the', u'first', u'giant', u'panda', u'that', u'be', u'bear', u'and', u'survive', u'in', u'captivity', u'outside', u'China', u'.'], u'pos': [u'VBD', u'DT', u'JJ', u'JJ', u'NN', u'WDT', u'VBD', u'VBN', u'CC', u'VBN', u'IN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[25307, 25310], [25311, 25314], [25315, 25320], [25321, 25326], [25327, 25332], [25333, 25337], [25338, 25341], [25342, 25346], [25347, 25350], [25351, 25359], [25360, 25362], [25363, 25372], [25373, 25380], [25381, 25386], [25386, 25387]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.11068816483020782, {u'tokens': [u'The', u'giant', u'panda', u'genome', u'was', u'sequenced', u'in', u'2009', u'using', u'a', u'next-generation', u'sequencing', u'technology', u'.'], u'lemmas': [u'the', u'giant', u'panda', u'genome', u'be', u'sequence', u'in', u'2009', u'use', u'a', u'next-generation', u'sequencing', u'technology', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBD', u'VBN', u'IN', u'CD', u'VBG', u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[6481, 6484], [6485, 6490], [6491, 6496], [6497, 6503], [6504, 6507], [6508, 6517], [6518, 6520], [6521, 6525], [6526, 6531], [6532, 6533], [6534, 6549], [6550, 6560], [6561, 6571], [6571, 6572]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.10233046859502792, {u'tokens': [u'They', u'are', u'expected', u'to', u'stay', u'for', u'a', u'minimum', u'of', u'10', u'years', u',', u'and', u'will', u'be', u'the', u'only', u'Giant', u'Pandas', u'living', u'in', u'the', u'Southern', u'Hemisphere', u'.'], u'lemmas': [u'they', u'be', u'expect', u'to', u'stay', u'for', u'a', u'minimum', u'of', u'10', u'year', u',', u'and', u'will', u'be', u'the', u'only', u'giant', u'panda', u'living', u'in', u'the', u'Southern', u'Hemisphere', u'.'], u'pos': [u'PRP', u'VBP', u'VBN', u'TO', u'VB', u'IN', u'DT', u'NN', u'IN', u'CD', u'NNS', u',', u'CC', u'MD', u'VB', u'DT', u'JJ', u'NN', u'NN', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'.'], u'char_offsets': [[23298, 23302], [23303, 23306], [23307, 23315], [23316, 23318], [23319, 23323], [23324, 23327], [23328, 23329], [23330, 23337], [23338, 23340], [23341, 23343], [23344, 23349], [23349, 23350], [23351, 23354], [23355, 23359], [23360, 23362], [23363, 23366], [23367, 23371], [23372, 23377], [23378, 23384], [23385, 23391], [23392, 23394], [23395, 23398], [23399, 23407], [23408, 23418], [23418, 23419]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.10210540890693665, {u'tokens': [u'A', u'Giant', u'Panda', u'cub', u'is', u'also', u'extremely', u'small', u',', u'and', u'it', u'is', u'difficult', u'for', u'the', u'mother', u'to', u'protect', u'it', u'because', u'of', u'the', u'baby', u"'s", u'size', u'.'], u'lemmas': [u'a', u'giant', u'panda', u'cub', u'be', u'also', u'extremely', u'small', u',', u'and', u'it', u'be', u'difficult', u'for', u'the', u'mother', u'to', u'protect', u'it', u'because', u'of', u'the', u'baby', u"'s", u'size', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'RB', u'RB', u'JJ', u',', u'CC', u'PRP', u'VBZ', u'JJ', u'IN', u'DT', u'NN', u'TO', u'VB', u'PRP', u'IN', u'IN', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[17518, 17519], [17520, 17525], [17526, 17531], [17532, 17535], [17536, 17538], [17539, 17543], [17544, 17553], [17554, 17559], [17559, 17560], [17561, 17564], [17565, 17567], [17568, 17570], [17571, 17580], [17581, 17584], [17585, 17588], [17589, 17595], [17596, 17598], [17599, 17606], [17607, 17609], [17610, 17617], [17618, 17620], [17621, 17624], [17625, 17629], [17629, 17631], [17632, 17636], [17636, 17637]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.098710060119628906, {u'tokens': [u'The', u'first', u'Westerner', u'known', u'to', u'have', u'seen', u'a', u'living', u'Giant', u'Panda', u'is', u'the', u'German', u'zoologist', u'Hugo', u'Weigold', u',', u'who', u'purchased', u'a', u'cub', u'in', u'1916', u'.'], u'lemmas': [u'the', u'first', u'Westerner', u'know', u'to', u'have', u'see', u'a', u'living', u'giant', u'panda', u'be', u'the', u'german', u'zoologist', u'Hugo', u'Weigold', u',', u'who', u'purchase', u'a', u'cub', u'in', u'1916', u'.'], u'pos': [u'DT', u'JJ', u'NNP', u'VBN', u'TO', u'VB', u'VBN', u'DT', u'NN', u'NN', u'NN', u'VBZ', u'DT', u'JJ', u'NN', u'NNP', u'NNP', u',', u'WP', u'VBD', u'DT', u'NN', u'IN', u'CD', u'.'], u'char_offsets': [[9102, 9105], [9106, 9111], [9112, 9121], [9122, 9127], [9128, 9130], [9131, 9135], [9136, 9140], [9141, 9142], [9143, 9149], [9150, 9155], [9156, 9161], [9162, 9164], [9165, 9168], [9169, 9175], [9176, 9185], [9186, 9190], [9191, 9198], [9198, 9199], [9200, 9203], [9204, 9213], [9214, 9215], [9216, 9219], [9220, 9222], [9223, 9227], [9227, 9228]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.089725479483604431, {u'tokens': [u'Chris', u'Packham', u':', u'`', u'Giant', u'pandas', u'should', u'be', u'allowed', u'to', u'die', u'out', u"'", u'.'], u'lemmas': [u'Chris', u'Packham', u':', u'`', u'giant', u'panda', u'should', u'be', u'allow', u'to', u'die', u'out', u"'", u'.'], u'pos': [u'NNP', u'NNP', u':', u'``', u'JJ', u'NNS', u'MD', u'VB', u'VBN', u'TO', u'VB', u'RP', u"''", u'.'], u'char_offsets': [[14796, 14801], [14802, 14809], [14809, 14810], [14811, 14812], [14812, 14817], [14818, 14824], [14825, 14831], [14832, 14834], [14835, 14842], [14843, 14845], [14846, 14849], [14850, 14853], [14853, 14854], [14854, 14855]]}) 
answer: set([u'mammal'])
candidate Sentence: (0.088594093918800354, {u'tokens': [u'A', u'2007', u'report', u'shows', u'239', u'Giant', u'Pandas', u'living', u'in', u'captivity', u'inside', u'China', u'and', u'another', u'27', u'outside', u'the', u'country', u'.'], u'lemmas': [u'a', u'2007', u'report', u'show', u'239', u'giant', u'panda', u'living', u'in', u'captivity', u'inside', u'China', u'and', u'another', u'27', u'outside', u'the', u'country', u'.'], u'pos': [u'DT', u'CD', u'NN', u'VBZ', u'CD', u'JJ', u'NN', u'NN', u'IN', u'NN', u'IN', u'NNP', u'CC', u'DT', u'CD', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[858, 859], [860, 864], [865, 871], [872, 877], [878, 881], [882, 887], [888, 894], [895, 901], [902, 904], [905, 914], [915, 921], [922, 927], [928, 931], [932, 939], [940, 942], [943, 950], [951, 954], [955, 962], [962, 963]]}) 
answer: set([u'mammal'])

Is the Giant Panda a mammal?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114ce710>.answer
_____________________________ test_yesno[param138] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ce998>, (<src.tfidf.TF_IDF object at 0x10a4b0850>, set(['guitar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114ce998>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.33611646294593811, {u'tokens': [u'*', u'Flamenco', u'!'], u'lemmas': [u'*', u'flamenco', u'!'], u'pos': [u'SYM', u'NN', u'.'], u'char_offsets': [[49046, 49047], [49048, 49056], [49056, 49057]]}) 
answer: set([u'similar', u'classical'])
candidate Sentence: (0.24625295400619507, {u'tokens': [u'There', u'are', u'several', u'notable', u'subcategories', u'within', u'the', u'acoustic', u'guitar', u'group', u':', u'classical', u'and', u'flamenco', u'guitars', u';', u'steel', u'string', u'guitars', u',', u'which', u'include', u'the', u'flat', u'top', u'or', u'``', u'folk', u"''", u'guitar', u';', u'twelve', u'string', u'guitars', u'and', u'the', u'arch', u'top', u'guitar', u'.'], u'lemmas': [u'there', u'be', u'several', u'notable', u'subcategory', u'within', u'the', u'acoustic', u'guitar', u'group', u':', u'classical', u'and', u'flamenco', u'guitar', u';', u'steel', u'string', u'guitar', u',', u'which', u'include', u'the', u'flat', u'top', u'or', u'``', u'folk', u"''", u'guitar', u';', u'twelve', u'string', u'guitar', u'and', u'the', u'arch', u'top', u'guitar', u'.'], u'pos': [u'EX', u'VBP', u'JJ', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'NN', u':', u'JJ', u'CC', u'JJ', u'NNS', u':', u'NN', u'NN', u'NNS', u',', u'WDT', u'VBP', u'DT', u'JJ', u'NN', u'CC', u'``', u'NN', u"''", u'NN', u':', u'CD', u'NN', u'NNS', u'CC', u'DT', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[6005, 6010], [6011, 6014], [6015, 6022], [6023, 6030], [6031, 6044], [6045, 6051], [6052, 6055], [6056, 6064], [6065, 6071], [6072, 6077], [6077, 6078], [6079, 6088], [6089, 6092], [6093, 6101], [6102, 6109], [6109, 6110], [6111, 6116], [6117, 6123], [6124, 6131], [6131, 6132], [6133, 6138], [6139, 6146], [6147, 6150], [6151, 6155], [6156, 6159], [6160, 6162], [6163, 6164], [6164, 6168], [6168, 6169], [6170, 6176], [6176, 6177], [6178, 6184], [6185, 6191], [6192, 6199], [6200, 6203], [6204, 6207], [6208, 6212], [6213, 6216], [6217, 6223], [6223, 6224]]}) 
answer: set([u'similar'])
candidate Sentence: (0.23842421174049377, {u'tokens': [u'Classical', u'and', u'flamenco', u'instruments', u'historically', u'used', u'gut', u'strings', u',', u'but', u'these', u'have', u'been', u'superseded', u'by', u'polymer', u'materials', u',', u'such', u'as', u'nylon', u'and', u'fluorocarbon', u'materials', u'.'], u'lemmas': [u'classical', u'and', u'flamenco', u'instrument', u'historically', u'use', u'gut', u'string', u',', u'but', u'these', u'have', u'be', u'supersede', u'by', u'polymer', u'material', u',', u'such', u'as', u'nylon', u'and', u'fluorocarbon', u'material', u'.'], u'pos': [u'JJ', u'CC', u'NN', u'NNS', u'RB', u'VBN', u'NN', u'NNS', u',', u'CC', u'DT', u'VBP', u'VBN', u'VBN', u'IN', u'NN', u'NNS', u',', u'JJ', u'IN', u'NN', u'CC', u'NN', u'NNS', u'.'], u'char_offsets': [[29330, 29339], [29340, 29343], [29344, 29352], [29353, 29364], [29365, 29377], [29378, 29382], [29383, 29386], [29387, 29394], [29394, 29395], [29396, 29399], [29400, 29405], [29406, 29410], [29411, 29415], [29416, 29426], [29427, 29429], [29430, 29437], [29438, 29447], [29447, 29448], [29449, 29453], [29454, 29456], [29457, 29462], [29463, 29466], [29467, 29479], [29480, 29489], [29489, 29490]]}) 
answer: set([u'similar'])
candidate Sentence: (0.21534419059753418, {u'tokens': [u';', u'Flat-top', u'-LRB-', u'steel-string', u'-RRB-', u'guitars', u':', u'Similar', u'to', u'the', u'classical', u'guitar', u',', u'however', u',', u'within', u'the', u'varied', u'sizes', u'of', u'the', u'steel-stringed', u'guitar', u'the', u'body', u'size', u'is', u'usually', u'significantly', u'larger', u'than', u'a', u'classical', u'guitar', u'and', u'it', u'has', u'a', u'narrower', u',', u'reinforced', u'neck', u'and', u'stronger', u'structural', u'design', u'.'], u'lemmas': [u';', u'flat-top', u'-lrb-', u'steel-string', u'-rrb-', u'guitar', u':', u'similar', u'to', u'the', u'classical', u'guitar', u',', u'however', u',', u'within', u'the', u'varied', u'size', u'of', u'the', u'steel-stringed', u'guitar', u'the', u'body', u'size', u'be', u'usually', u'significantly', u'larger', u'than', u'a', u'classical', u'guitar', u'and', u'it', u'have', u'a', u'narrower', u',', u'reinforce', u'neck', u'and', u'stronger', u'structural', u'design', u'.'], u'pos': [u':', u'NN', u'-LRB-', u'JJ', u'-RRB-', u'NNS', u':', u'JJ', u'TO', u'DT', u'JJ', u'NN', u',', u'RB', u',', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'DT', u'NN', u'NN', u'VBZ', u'RB', u'RB', u'JJR', u'IN', u'DT', u'JJ', u'NN', u'CC', u'PRP', u'VBZ', u'DT', u'JJR', u',', u'VBN', u'NN', u'CC', u'JJR', u'JJ', u'NN', u'.'], u'char_offsets': [[9603, 9604], [9604, 9612], [9613, 9614], [9614, 9626], [9626, 9627], [9628, 9635], [9635, 9636], [9637, 9644], [9645, 9647], [9648, 9651], [9652, 9661], [9662, 9668], [9668, 9669], [9670, 9677], [9677, 9678], [9679, 9685], [9686, 9689], [9690, 9696], [9697, 9702], [9703, 9705], [9706, 9709], [9710, 9724], [9725, 9731], [9732, 9735], [9736, 9740], [9741, 9745], [9746, 9748], [9749, 9756], [9757, 9770], [9771, 9777], [9778, 9782], [9783, 9784], [9785, 9794], [9795, 9801], [9802, 9805], [9806, 9808], [9809, 9812], [9813, 9814], [9815, 9823], [9823, 9824], [9825, 9835], [9836, 9840], [9841, 9844], [9845, 9853], [9854, 9864], [9865, 9871], [9871, 9872]]}) 
answer: set([u'flamenco'])
candidate Sentence: (0.2147291898727417, {u'tokens': [u'The', u'physical', u'principle', u'of', u'the', u'guitar', u'is', u'therefore', u'similar', u'to', u'the', u'banjo', u'.'], u'lemmas': [u'the', u'physical', u'principle', u'of', u'the', u'guitar', u'be', u'therefore', u'similar', u'to', u'the', u'banjo', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'JJ', u'TO', u'DT', u'NN', u'.'], u'char_offsets': [[11151, 11154], [11155, 11163], [11164, 11173], [11174, 11176], [11177, 11180], [11181, 11187], [11188, 11190], [11191, 11200], [11201, 11208], [11209, 11211], [11212, 11215], [11216, 11221], [11221, 11222]]}) 
answer: set([u'flamenco', u'classical'])
candidate Sentence: (0.21090118587017059, {u'tokens': [u'Guitars', u'are', u'recognized', u'as', u'one', u'of', u'the', u'primary', u'instruments', u'in', u'blues', u',', u'country', u',', u'flamenco', u',', u'rock', u'music', u',', u'and', u'many', u'forms', u'of', u'pop', u'.'], u'lemmas': [u'guitar', u'be', u'recognize', u'as', u'one', u'of', u'the', u'primary', u'instrument', u'in', u'blues', u',', u'country', u',', u'flamenco', u',', u'rock', u'music', u',', u'and', u'many', u'form', u'of', u'pop', u'.'], u'pos': [u'NNS', u'VBP', u'VBN', u'IN', u'CD', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'NNS', u',', u'NN', u',', u'NN', u',', u'NN', u'NN', u',', u'CC', u'JJ', u'NNS', u'IN', u'NN', u'.'], u'char_offsets': [[201, 208], [209, 212], [213, 223], [224, 226], [227, 230], [231, 233], [234, 237], [238, 245], [246, 257], [258, 260], [261, 266], [266, 267], [268, 275], [275, 276], [277, 285], [285, 286], [287, 291], [292, 297], [297, 298], [299, 302], [303, 307], [308, 313], [314, 316], [317, 320], [320, 321]]}) 
answer: set([u'similar', u'classical'])
candidate Sentence: (0.19169627130031586, {u'tokens': [u'Vigorous', u'performance', u'styles', u'such', u'as', u'flamenco', u',', u'which', u'can', u'involve', u'the', u'use', u'of', u'the', u'guitar', u'as', u'a', u'percussion', u'instrument', u',', u'call', u'for', u'a', u'scratchplate', u'to', u'be', u'fitted', u'to', u'nylon-string', u'instruments', u'.'], u'lemmas': [u'vigorous', u'performance', u'style', u'such', u'as', u'flamenco', u',', u'which', u'can', u'involve', u'the', u'use', u'of', u'the', u'guitar', u'as', u'a', u'percussion', u'instrument', u',', u'call', u'for', u'a', u'scratchplate', u'to', u'be', u'fit', u'to', u'nylon-string', u'instrument', u'.'], u'pos': [u'JJ', u'NN', u'NNS', u'JJ', u'IN', u'NN', u',', u'WDT', u'MD', u'VB', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'NN', u',', u'NN', u'IN', u'DT', u'NN', u'TO', u'VB', u'VBN', u'TO', u'JJ', u'NNS', u'.'], u'char_offsets': [[40468, 40476], [40477, 40488], [40489, 40495], [40496, 40500], [40501, 40503], [40504, 40512], [40512, 40513], [40514, 40519], [40520, 40523], [40524, 40531], [40532, 40535], [40536, 40539], [40540, 40542], [40543, 40546], [40547, 40553], [40554, 40556], [40557, 40558], [40559, 40569], [40570, 40580], [40580, 40581], [40582, 40586], [40587, 40590], [40591, 40592], [40593, 40605], [40606, 40608], [40609, 40611], [40612, 40618], [40619, 40621], [40622, 40634], [40635, 40646], [40646, 40647]]}) 
answer: set([u'similar', u'classical'])
candidate Sentence: (0.18934209644794464, {u'tokens': [u'The', u'electric', u'bass', u'guitar', u'is', u'similar', u'in', u'tuning', u'to', u'the', u'traditional', u'double', u'bass', u'viol', u'.'], u'lemmas': [u'the', u'electric', u'bass', u'guitar', u'be', u'similar', u'in', u'tuning', u'to', u'the', u'traditional', u'double', u'bass', u'viol', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'JJ', u'IN', u'NN', u'TO', u'DT', u'JJ', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[17267, 17270], [17271, 17279], [17280, 17284], [17285, 17291], [17292, 17294], [17295, 17302], [17303, 17305], [17306, 17312], [17313, 17315], [17316, 17319], [17320, 17331], [17332, 17338], [17339, 17343], [17344, 17348], [17348, 17349]]}) 
answer: set([u'flamenco', u'classical'])
candidate Sentence: (0.18087916076183319, {u'tokens': [u'Many', u'open', u'tunings', u',', u'where', u'all', u'of', u'the', u'strings', u'are', u'tuned', u'to', u'a', u'similar', u'note', u'or', u'chord', u',', u'are', u'popular', u'for', u'slide', u'guitar', u'playing', u'.'], u'lemmas': [u'many', u'open', u'tuning', u',', u'where', u'all', u'of', u'the', u'string', u'be', u'tune', u'to', u'a', u'similar', u'note', u'or', u'chord', u',', u'be', u'popular', u'for', u'slide', u'guitar', u'playing', u'.'], u'pos': [u'JJ', u'JJ', u'NNS', u',', u'WRB', u'DT', u'IN', u'DT', u'NNS', u'VBP', u'VBN', u'TO', u'DT', u'JJ', u'NN', u'CC', u'NN', u',', u'VBP', u'JJ', u'IN', u'NN', u'NN', u'NN', u'.'], u'char_offsets': [[44183, 44187], [44188, 44192], [44193, 44200], [44200, 44201], [44202, 44207], [44208, 44211], [44212, 44214], [44215, 44218], [44219, 44226], [44227, 44230], [44231, 44236], [44237, 44239], [44240, 44241], [44242, 44249], [44250, 44254], [44255, 44257], [44258, 44263], [44263, 44264], [44265, 44268], [44269, 44276], [44277, 44280], [44281, 44286], [44287, 44293], [44294, 44301], [44301, 44302]]}) 
answer: set([u'flamenco', u'classical'])
candidate Sentence: (0.17828387022018433, {u'tokens': [u'The', u'acoustic', u'guitar', u'group', u'also', u'includes', u'unamplified', u'guitars', u'designed', u'to', u'play', u'in', u'different', u'registers', u'such', u'as', u'the', u'acoustic', u'bass', u'guitar', u'which', u'has', u'a', u'similar', u'tuning', u'to', u'that', u'of', u'the', u'electric', u'bass', u'guitar', u'.'], u'lemmas': [u'the', u'acoustic', u'guitar', u'group', u'also', u'include', u'unamplified', u'guitar', u'design', u'to', u'play', u'in', u'different', u'register', u'such', u'as', u'the', u'acoustic', u'bass', u'guitar', u'which', u'have', u'a', u'similar', u'tuning', u'to', u'that', u'of', u'the', u'electric', u'bass', u'guitar', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'RB', u'VBZ', u'JJ', u'NNS', u'VBN', u'TO', u'VB', u'IN', u'JJ', u'VBZ', u'JJ', u'IN', u'DT', u'JJ', u'NN', u'NN', u'WDT', u'VBZ', u'DT', u'JJ', u'NN', u'TO', u'DT', u'IN', u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[6225, 6228], [6229, 6237], [6238, 6244], [6245, 6250], [6251, 6255], [6256, 6264], [6265, 6276], [6277, 6284], [6285, 6293], [6294, 6296], [6297, 6301], [6302, 6304], [6305, 6314], [6315, 6324], [6325, 6329], [6330, 6332], [6333, 6336], [6337, 6345], [6346, 6350], [6351, 6357], [6358, 6363], [6364, 6367], [6368, 6369], [6370, 6377], [6378, 6384], [6385, 6387], [6388, 6392], [6393, 6395], [6396, 6399], [6400, 6408], [6409, 6413], [6414, 6420], [6420, 6421]]}) 
answer: set([u'flamenco', u'classical'])

Is the flamenco guitar similar to the classical guitar?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114ce998>.answer
_____________________________ test_yesno[param139] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ce9e0>, (<src.tfidf.TF_IDF object at 0x10a4b0850>, set(['guitar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114ce9e0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.33611646294593811, {u'tokens': [u'*', u'Flamenco', u'!'], u'lemmas': [u'*', u'flamenco', u'!'], u'pos': [u'SYM', u'NN', u'.'], u'char_offsets': [[49046, 49047], [49048, 49056], [49056, 49057]]}) 
answer: set([u'similar', u'classical'])
candidate Sentence: (0.24625295400619507, {u'tokens': [u'There', u'are', u'several', u'notable', u'subcategories', u'within', u'the', u'acoustic', u'guitar', u'group', u':', u'classical', u'and', u'flamenco', u'guitars', u';', u'steel', u'string', u'guitars', u',', u'which', u'include', u'the', u'flat', u'top', u'or', u'``', u'folk', u"''", u'guitar', u';', u'twelve', u'string', u'guitars', u'and', u'the', u'arch', u'top', u'guitar', u'.'], u'lemmas': [u'there', u'be', u'several', u'notable', u'subcategory', u'within', u'the', u'acoustic', u'guitar', u'group', u':', u'classical', u'and', u'flamenco', u'guitar', u';', u'steel', u'string', u'guitar', u',', u'which', u'include', u'the', u'flat', u'top', u'or', u'``', u'folk', u"''", u'guitar', u';', u'twelve', u'string', u'guitar', u'and', u'the', u'arch', u'top', u'guitar', u'.'], u'pos': [u'EX', u'VBP', u'JJ', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'NN', u':', u'JJ', u'CC', u'JJ', u'NNS', u':', u'NN', u'NN', u'NNS', u',', u'WDT', u'VBP', u'DT', u'JJ', u'NN', u'CC', u'``', u'NN', u"''", u'NN', u':', u'CD', u'NN', u'NNS', u'CC', u'DT', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[6005, 6010], [6011, 6014], [6015, 6022], [6023, 6030], [6031, 6044], [6045, 6051], [6052, 6055], [6056, 6064], [6065, 6071], [6072, 6077], [6077, 6078], [6079, 6088], [6089, 6092], [6093, 6101], [6102, 6109], [6109, 6110], [6111, 6116], [6117, 6123], [6124, 6131], [6131, 6132], [6133, 6138], [6139, 6146], [6147, 6150], [6151, 6155], [6156, 6159], [6160, 6162], [6163, 6164], [6164, 6168], [6168, 6169], [6170, 6176], [6176, 6177], [6178, 6184], [6185, 6191], [6192, 6199], [6200, 6203], [6204, 6207], [6208, 6212], [6213, 6216], [6217, 6223], [6223, 6224]]}) 
answer: set([u'similar'])
candidate Sentence: (0.23842421174049377, {u'tokens': [u'Classical', u'and', u'flamenco', u'instruments', u'historically', u'used', u'gut', u'strings', u',', u'but', u'these', u'have', u'been', u'superseded', u'by', u'polymer', u'materials', u',', u'such', u'as', u'nylon', u'and', u'fluorocarbon', u'materials', u'.'], u'lemmas': [u'classical', u'and', u'flamenco', u'instrument', u'historically', u'use', u'gut', u'string', u',', u'but', u'these', u'have', u'be', u'supersede', u'by', u'polymer', u'material', u',', u'such', u'as', u'nylon', u'and', u'fluorocarbon', u'material', u'.'], u'pos': [u'JJ', u'CC', u'NN', u'NNS', u'RB', u'VBN', u'NN', u'NNS', u',', u'CC', u'DT', u'VBP', u'VBN', u'VBN', u'IN', u'NN', u'NNS', u',', u'JJ', u'IN', u'NN', u'CC', u'NN', u'NNS', u'.'], u'char_offsets': [[29330, 29339], [29340, 29343], [29344, 29352], [29353, 29364], [29365, 29377], [29378, 29382], [29383, 29386], [29387, 29394], [29394, 29395], [29396, 29399], [29400, 29405], [29406, 29410], [29411, 29415], [29416, 29426], [29427, 29429], [29430, 29437], [29438, 29447], [29447, 29448], [29449, 29453], [29454, 29456], [29457, 29462], [29463, 29466], [29467, 29479], [29480, 29489], [29489, 29490]]}) 
answer: set([u'similar'])
candidate Sentence: (0.21534419059753418, {u'tokens': [u';', u'Flat-top', u'-LRB-', u'steel-string', u'-RRB-', u'guitars', u':', u'Similar', u'to', u'the', u'classical', u'guitar', u',', u'however', u',', u'within', u'the', u'varied', u'sizes', u'of', u'the', u'steel-stringed', u'guitar', u'the', u'body', u'size', u'is', u'usually', u'significantly', u'larger', u'than', u'a', u'classical', u'guitar', u'and', u'it', u'has', u'a', u'narrower', u',', u'reinforced', u'neck', u'and', u'stronger', u'structural', u'design', u'.'], u'lemmas': [u';', u'flat-top', u'-lrb-', u'steel-string', u'-rrb-', u'guitar', u':', u'similar', u'to', u'the', u'classical', u'guitar', u',', u'however', u',', u'within', u'the', u'varied', u'size', u'of', u'the', u'steel-stringed', u'guitar', u'the', u'body', u'size', u'be', u'usually', u'significantly', u'larger', u'than', u'a', u'classical', u'guitar', u'and', u'it', u'have', u'a', u'narrower', u',', u'reinforce', u'neck', u'and', u'stronger', u'structural', u'design', u'.'], u'pos': [u':', u'NN', u'-LRB-', u'JJ', u'-RRB-', u'NNS', u':', u'JJ', u'TO', u'DT', u'JJ', u'NN', u',', u'RB', u',', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'DT', u'NN', u'NN', u'VBZ', u'RB', u'RB', u'JJR', u'IN', u'DT', u'JJ', u'NN', u'CC', u'PRP', u'VBZ', u'DT', u'JJR', u',', u'VBN', u'NN', u'CC', u'JJR', u'JJ', u'NN', u'.'], u'char_offsets': [[9603, 9604], [9604, 9612], [9613, 9614], [9614, 9626], [9626, 9627], [9628, 9635], [9635, 9636], [9637, 9644], [9645, 9647], [9648, 9651], [9652, 9661], [9662, 9668], [9668, 9669], [9670, 9677], [9677, 9678], [9679, 9685], [9686, 9689], [9690, 9696], [9697, 9702], [9703, 9705], [9706, 9709], [9710, 9724], [9725, 9731], [9732, 9735], [9736, 9740], [9741, 9745], [9746, 9748], [9749, 9756], [9757, 9770], [9771, 9777], [9778, 9782], [9783, 9784], [9785, 9794], [9795, 9801], [9802, 9805], [9806, 9808], [9809, 9812], [9813, 9814], [9815, 9823], [9823, 9824], [9825, 9835], [9836, 9840], [9841, 9844], [9845, 9853], [9854, 9864], [9865, 9871], [9871, 9872]]}) 
answer: set([u'flamenco'])
candidate Sentence: (0.2147291898727417, {u'tokens': [u'The', u'physical', u'principle', u'of', u'the', u'guitar', u'is', u'therefore', u'similar', u'to', u'the', u'banjo', u'.'], u'lemmas': [u'the', u'physical', u'principle', u'of', u'the', u'guitar', u'be', u'therefore', u'similar', u'to', u'the', u'banjo', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'JJ', u'TO', u'DT', u'NN', u'.'], u'char_offsets': [[11151, 11154], [11155, 11163], [11164, 11173], [11174, 11176], [11177, 11180], [11181, 11187], [11188, 11190], [11191, 11200], [11201, 11208], [11209, 11211], [11212, 11215], [11216, 11221], [11221, 11222]]}) 
answer: set([u'flamenco', u'classical'])
candidate Sentence: (0.21090118587017059, {u'tokens': [u'Guitars', u'are', u'recognized', u'as', u'one', u'of', u'the', u'primary', u'instruments', u'in', u'blues', u',', u'country', u',', u'flamenco', u',', u'rock', u'music', u',', u'and', u'many', u'forms', u'of', u'pop', u'.'], u'lemmas': [u'guitar', u'be', u'recognize', u'as', u'one', u'of', u'the', u'primary', u'instrument', u'in', u'blues', u',', u'country', u',', u'flamenco', u',', u'rock', u'music', u',', u'and', u'many', u'form', u'of', u'pop', u'.'], u'pos': [u'NNS', u'VBP', u'VBN', u'IN', u'CD', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'NNS', u',', u'NN', u',', u'NN', u',', u'NN', u'NN', u',', u'CC', u'JJ', u'NNS', u'IN', u'NN', u'.'], u'char_offsets': [[201, 208], [209, 212], [213, 223], [224, 226], [227, 230], [231, 233], [234, 237], [238, 245], [246, 257], [258, 260], [261, 266], [266, 267], [268, 275], [275, 276], [277, 285], [285, 286], [287, 291], [292, 297], [297, 298], [299, 302], [303, 307], [308, 313], [314, 316], [317, 320], [320, 321]]}) 
answer: set([u'similar', u'classical'])
candidate Sentence: (0.19169627130031586, {u'tokens': [u'Vigorous', u'performance', u'styles', u'such', u'as', u'flamenco', u',', u'which', u'can', u'involve', u'the', u'use', u'of', u'the', u'guitar', u'as', u'a', u'percussion', u'instrument', u',', u'call', u'for', u'a', u'scratchplate', u'to', u'be', u'fitted', u'to', u'nylon-string', u'instruments', u'.'], u'lemmas': [u'vigorous', u'performance', u'style', u'such', u'as', u'flamenco', u',', u'which', u'can', u'involve', u'the', u'use', u'of', u'the', u'guitar', u'as', u'a', u'percussion', u'instrument', u',', u'call', u'for', u'a', u'scratchplate', u'to', u'be', u'fit', u'to', u'nylon-string', u'instrument', u'.'], u'pos': [u'JJ', u'NN', u'NNS', u'JJ', u'IN', u'NN', u',', u'WDT', u'MD', u'VB', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'NN', u',', u'NN', u'IN', u'DT', u'NN', u'TO', u'VB', u'VBN', u'TO', u'JJ', u'NNS', u'.'], u'char_offsets': [[40468, 40476], [40477, 40488], [40489, 40495], [40496, 40500], [40501, 40503], [40504, 40512], [40512, 40513], [40514, 40519], [40520, 40523], [40524, 40531], [40532, 40535], [40536, 40539], [40540, 40542], [40543, 40546], [40547, 40553], [40554, 40556], [40557, 40558], [40559, 40569], [40570, 40580], [40580, 40581], [40582, 40586], [40587, 40590], [40591, 40592], [40593, 40605], [40606, 40608], [40609, 40611], [40612, 40618], [40619, 40621], [40622, 40634], [40635, 40646], [40646, 40647]]}) 
answer: set([u'similar', u'classical'])
candidate Sentence: (0.18934209644794464, {u'tokens': [u'The', u'electric', u'bass', u'guitar', u'is', u'similar', u'in', u'tuning', u'to', u'the', u'traditional', u'double', u'bass', u'viol', u'.'], u'lemmas': [u'the', u'electric', u'bass', u'guitar', u'be', u'similar', u'in', u'tuning', u'to', u'the', u'traditional', u'double', u'bass', u'viol', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'JJ', u'IN', u'NN', u'TO', u'DT', u'JJ', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[17267, 17270], [17271, 17279], [17280, 17284], [17285, 17291], [17292, 17294], [17295, 17302], [17303, 17305], [17306, 17312], [17313, 17315], [17316, 17319], [17320, 17331], [17332, 17338], [17339, 17343], [17344, 17348], [17348, 17349]]}) 
answer: set([u'flamenco', u'classical'])
candidate Sentence: (0.18087916076183319, {u'tokens': [u'Many', u'open', u'tunings', u',', u'where', u'all', u'of', u'the', u'strings', u'are', u'tuned', u'to', u'a', u'similar', u'note', u'or', u'chord', u',', u'are', u'popular', u'for', u'slide', u'guitar', u'playing', u'.'], u'lemmas': [u'many', u'open', u'tuning', u',', u'where', u'all', u'of', u'the', u'string', u'be', u'tune', u'to', u'a', u'similar', u'note', u'or', u'chord', u',', u'be', u'popular', u'for', u'slide', u'guitar', u'playing', u'.'], u'pos': [u'JJ', u'JJ', u'NNS', u',', u'WRB', u'DT', u'IN', u'DT', u'NNS', u'VBP', u'VBN', u'TO', u'DT', u'JJ', u'NN', u'CC', u'NN', u',', u'VBP', u'JJ', u'IN', u'NN', u'NN', u'NN', u'.'], u'char_offsets': [[44183, 44187], [44188, 44192], [44193, 44200], [44200, 44201], [44202, 44207], [44208, 44211], [44212, 44214], [44215, 44218], [44219, 44226], [44227, 44230], [44231, 44236], [44237, 44239], [44240, 44241], [44242, 44249], [44250, 44254], [44255, 44257], [44258, 44263], [44263, 44264], [44265, 44268], [44269, 44276], [44277, 44280], [44281, 44286], [44287, 44293], [44294, 44301], [44301, 44302]]}) 
answer: set([u'flamenco', u'classical'])
candidate Sentence: (0.17828387022018433, {u'tokens': [u'The', u'acoustic', u'guitar', u'group', u'also', u'includes', u'unamplified', u'guitars', u'designed', u'to', u'play', u'in', u'different', u'registers', u'such', u'as', u'the', u'acoustic', u'bass', u'guitar', u'which', u'has', u'a', u'similar', u'tuning', u'to', u'that', u'of', u'the', u'electric', u'bass', u'guitar', u'.'], u'lemmas': [u'the', u'acoustic', u'guitar', u'group', u'also', u'include', u'unamplified', u'guitar', u'design', u'to', u'play', u'in', u'different', u'register', u'such', u'as', u'the', u'acoustic', u'bass', u'guitar', u'which', u'have', u'a', u'similar', u'tuning', u'to', u'that', u'of', u'the', u'electric', u'bass', u'guitar', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'RB', u'VBZ', u'JJ', u'NNS', u'VBN', u'TO', u'VB', u'IN', u'JJ', u'VBZ', u'JJ', u'IN', u'DT', u'JJ', u'NN', u'NN', u'WDT', u'VBZ', u'DT', u'JJ', u'NN', u'TO', u'DT', u'IN', u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[6225, 6228], [6229, 6237], [6238, 6244], [6245, 6250], [6251, 6255], [6256, 6264], [6265, 6276], [6277, 6284], [6285, 6293], [6294, 6296], [6297, 6301], [6302, 6304], [6305, 6314], [6315, 6324], [6325, 6329], [6330, 6332], [6333, 6336], [6337, 6345], [6346, 6350], [6351, 6357], [6358, 6363], [6364, 6367], [6368, 6369], [6370, 6377], [6378, 6384], [6385, 6387], [6388, 6392], [6393, 6395], [6396, 6399], [6400, 6408], [6409, 6413], [6414, 6420], [6420, 6421]]}) 
answer: set([u'flamenco', u'classical'])

Is the flamenco guitar similar to the classical guitar?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114ce9e0>.answer
_____________________________ test_yesno[param142] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ceab8>, (<src.tfidf.TF_IDF object at 0x10a4b0850>, set(['guitar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114ceab8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.43902823328971863, {u'tokens': [u'The', u'guitar', u'player', u'-LRB-', u'c.', u'1672', u'-RRB-', u',', u'by', u'Johannes', u'Vermeer', u'Guitars', u'can', u'be', u'divided', u'into', u'two', u'broad', u'categories', u',', u'acoustic', u'and', u'electric', u':', u'An', u'acoustic', u'guitar', u'is', u'one', u'not', u'dependent', u'on', u'an', u'external', u'device', u'to', u'be', u'heard', u'but', u'uses', u'a', u'soundboard', u'which', u'is', u'a', u'wooden', u'piece', u'mounted', u'on', u'the', u'front', u'of', u'the', u'guitar', u"'s", u'body', u'.'], u'lemmas': [u'the', u'guitar', u'player', u'-lrb-', u'c.', u'1672', u'-rrb-', u',', u'by', u'Johannes', u'Vermeer', u'Guitars', u'can', u'be', u'divide', u'into', u'two', u'broad', u'category', u',', u'acoustic', u'and', u'electric', u':', u'a', u'acoustic', u'guitar', u'be', u'one', u'not', u'dependent', u'on', u'a', u'external', u'device', u'to', u'be', u'hear', u'but', u'use', u'a', u'soundboard', u'which', u'be', u'a', u'wooden', u'piece', u'mount', u'on', u'the', u'front', u'of', u'the', u'guitar', u"'s", u'body', u'.'], u'pos': [u'DT', u'NN', u'NN', u'-LRB-', u'NN', u'CD', u'-RRB-', u',', u'IN', u'NNP', u'NNP', u'NNP', u'MD', u'VB', u'VBN', u'IN', u'CD', u'JJ', u'NNS', u',', u'JJ', u'CC', u'JJ', u':', u'DT', u'JJ', u'NN', u'VBZ', u'CD', u'RB', u'JJ', u'IN', u'DT', u'JJ', u'NN', u'TO', u'VB', u'VBN', u'CC', u'VBZ', u'DT', u'NN', u'WDT', u'VBZ', u'DT', u'JJ', u'NN', u'VBD', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[5423, 5426], [5427, 5433], [5434, 5440], [5441, 5442], [5442, 5444], [5445, 5449], [5449, 5450], [5450, 5451], [5452, 5454], [5455, 5463], [5464, 5471], [5472, 5479], [5480, 5483], [5484, 5486], [5487, 5494], [5495, 5499], [5500, 5503], [5504, 5509], [5510, 5520], [5520, 5521], [5522, 5530], [5531, 5534], [5535, 5543], [5543, 5544], [5545, 5547], [5548, 5556], [5557, 5563], [5564, 5566], [5567, 5570], [5571, 5574], [5575, 5584], [5585, 5587], [5588, 5590], [5591, 5599], [5600, 5606], [5607, 5609], [5610, 5612], [5613, 5618], [5619, 5622], [5623, 5627], [5628, 5629], [5630, 5640], [5641, 5646], [5647, 5649], [5650, 5651], [5652, 5658], [5659, 5664], [5665, 5672], [5673, 5675], [5676, 5679], [5680, 5685], [5686, 5688], [5689, 5692], [5693, 5699], [5699, 5701], [5702, 5706], [5706, 5707]]}) 
answer: set([])
candidate Sentence: (0.18585856258869171, {u'tokens': [u'The', u'twelfth', u'fret', u'divides', u'the', u'scale', u'length', u'in', u'two', u'exact', u'halves', u'and', u'the', u'24th', u'fret', u'position', u'divides', u'the', u'scale', u'length', u'in', u'half', u'yet', u'again', u'.'], u'lemmas': [u'the', u'twelfth', u'fret', u'divide', u'the', u'scale', u'length', u'in', u'two', u'exact', u'half', u'and', u'the', u'24th', u'fret', u'position', u'divide', u'the', u'scale', u'length', u'in', u'half', u'yet', u'again', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'NN', u'NN', u'IN', u'CD', u'JJ', u'NNS', u'CC', u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'DT', u'NN', u'NN', u'IN', u'NN', u'RB', u'RB', u'.'], u'char_offsets': [[21707, 21710], [21711, 21718], [21719, 21723], [21724, 21731], [21732, 21735], [21736, 21741], [21742, 21748], [21749, 21751], [21752, 21755], [21756, 21761], [21762, 21768], [21769, 21772], [21773, 21776], [21777, 21781], [21782, 21786], [21787, 21795], [21796, 21803], [21804, 21807], [21808, 21813], [21814, 21820], [21821, 21823], [21824, 21828], [21829, 21832], [21833, 21838], [21838, 21839]]}) 
answer: set([u'category', u'broad'])
candidate Sentence: (0.1324327290058136, {u'tokens': [u'That', u'distance', u'is', u'subtracted', u'from', u'the', u'scale', u'length', u'and', u'the', u'result', u'is', u'divided', u'in', u'two', u'sections', u'by', u'the', u'constant', u'to', u'yield', u'the', u'distance', u'from', u'the', u'first', u'fret', u'to', u'the', u'second', u'fret', u'.'], u'lemmas': [u'that', u'distance', u'be', u'subtract', u'from', u'the', u'scale', u'length', u'and', u'the', u'result', u'be', u'divide', u'in', u'two', u'section', u'by', u'the', u'constant', u'to', u'yield', u'the', u'distance', u'from', u'the', u'first', u'fret', u'to', u'the', u'second', u'fret', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'NN', u'CC', u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'CD', u'NNS', u'IN', u'DT', u'JJ', u'TO', u'VB', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'TO', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[22094, 22098], [22099, 22107], [22108, 22110], [22111, 22121], [22122, 22126], [22127, 22130], [22131, 22136], [22137, 22143], [22144, 22147], [22148, 22151], [22152, 22158], [22159, 22161], [22162, 22169], [22170, 22172], [22173, 22176], [22177, 22185], [22186, 22188], [22189, 22192], [22193, 22201], [22202, 22204], [22205, 22210], [22211, 22214], [22215, 22223], [22224, 22228], [22229, 22232], [22233, 22238], [22239, 22243], [22244, 22246], [22247, 22250], [22251, 22257], [22258, 22262], [22262, 22263]]}) 
answer: set([u'category', u'broad'])
candidate Sentence: (0.12797744572162628, {u'tokens': [u'The', u'scale', u'length', u'divided', u'by', u'this', u'value', u'yields', u'the', u'distance', u'from', u'the', u'nut', u'to', u'the', u'first', u'fret', u'.'], u'lemmas': [u'the', u'scale', u'length', u'divide', u'by', u'this', u'value', u'yield', u'the', u'distance', u'from', u'the', u'nut', u'to', u'the', u'first', u'fret', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBN', u'IN', u'DT', u'NN', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NN', u'TO', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[22003, 22006], [22007, 22012], [22013, 22019], [22020, 22027], [22028, 22030], [22031, 22035], [22036, 22041], [22042, 22048], [22049, 22052], [22053, 22061], [22062, 22066], [22067, 22070], [22071, 22074], [22075, 22077], [22078, 22081], [22082, 22087], [22088, 22092], [22092, 22093]]}) 
answer: set([u'category', u'broad', u'two'])
candidate Sentence: (0.11718807369470596, {u'tokens': [u'The', u'ratio', u'of', u'the', u'spacing', u'of', u'two', u'consecutive', u'frets', u'is', u'the', u'twelfth', u'root', u'of', u'two', u'.'], u'lemmas': [u'the', u'ratio', u'of', u'the', u'spacing', u'of', u'two', u'consecutive', u'fret', u'be', u'the', u'twelfth', u'root', u'of', u'two', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'CD', u'JJ', u'VBZ', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'CD', u'.'], u'char_offsets': [[21629, 21632], [21633, 21638], [21639, 21641], [21642, 21645], [21646, 21653], [21654, 21656], [21657, 21660], [21661, 21672], [21673, 21678], [21679, 21681], [21682, 21685], [21686, 21693], [21694, 21698], [21699, 21701], [21702, 21705], [21705, 21706]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.097049862146377563, {u'tokens': [u'Alternate', u'tunings', u'are', u'used', u'for', u'two', u'main', u'reasons', u':', u'the', u'ease', u'of', u'playing', u'and', u'the', u'variation', u'in', u'tone', u'that', u'can', u'be', u'achieved', u'.'], u'lemmas': [u'alternate', u'tuning', u'be', u'use', u'for', u'two', u'main', u'reason', u':', u'the', u'ease', u'of', u'playing', u'and', u'the', u'variation', u'in', u'tone', u'that', u'can', u'be', u'achieve', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'VBN', u'IN', u'CD', u'JJ', u'NNS', u':', u'DT', u'NN', u'IN', u'NN', u'CC', u'DT', u'NN', u'IN', u'NN', u'WDT', u'MD', u'VB', u'VBN', u'.'], u'char_offsets': [[44303, 44312], [44313, 44320], [44321, 44324], [44325, 44329], [44330, 44333], [44334, 44337], [44338, 44342], [44343, 44350], [44350, 44351], [44352, 44355], [44356, 44360], [44361, 44363], [44364, 44371], [44372, 44375], [44376, 44379], [44380, 44389], [44390, 44392], [44393, 44397], [44398, 44402], [44403, 44406], [44407, 44409], [44410, 44418], [44418, 44419]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.095963791012763977, {u'tokens': [u'There', u'are', u'two', u'main', u'types', u'of', u'pickup', u',', u'single', u'and', u'double', u'coil', u'-LRB-', u'or', u'humbucker', u'-RRB-', u',', u'each', u'of', u'which', u'can', u'be', u'passive', u'or', u'active', u'.'], u'lemmas': [u'there', u'be', u'two', u'main', u'type', u'of', u'pickup', u',', u'single', u'and', u'double', u'coil', u'-lrb-', u'or', u'humbucker', u'-rrb-', u',', u'each', u'of', u'which', u'can', u'be', u'passive', u'or', u'active', u'.'], u'pos': [u'EX', u'VBP', u'CD', u'JJ', u'NNS', u'IN', u'NN', u',', u'JJ', u'CC', u'JJ', u'NN', u'-LRB-', u'CC', u'NN', u'-RRB-', u',', u'DT', u'IN', u'WDT', u'MD', u'VB', u'JJ', u'CC', u'JJ', u'.'], u'char_offsets': [[16087, 16092], [16093, 16096], [16097, 16100], [16101, 16105], [16106, 16111], [16112, 16114], [16115, 16121], [16121, 16122], [16123, 16129], [16130, 16133], [16134, 16140], [16141, 16145], [16146, 16147], [16147, 16149], [16150, 16159], [16159, 16160], [16160, 16161], [16162, 16166], [16167, 16169], [16170, 16175], [16176, 16179], [16180, 16182], [16183, 16190], [16191, 16193], [16194, 16200], [16200, 16201]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.094398520886898041, {u'tokens': [u'The', u'manufacturer', u"'s", u'logo', u'or', u'a', u'small', u'design', u'is', u'often', u'inlaid', u'into', u'the', u'headstock', u'.'], u'lemmas': [u'the', u'manufacturer', u"'s", u'logo', u'or', u'a', u'small', u'design', u'be', u'often', u'inlay', u'into', u'the', u'headstock', u'.'], u'pos': [u'DT', u'NN', u'POS', u'NN', u'CC', u'DT', u'JJ', u'NN', u'VBZ', u'RB', u'VBN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[25754, 25757], [25758, 25770], [25770, 25772], [25773, 25777], [25778, 25780], [25781, 25782], [25783, 25788], [25789, 25795], [25796, 25798], [25799, 25804], [25805, 25811], [25812, 25816], [25817, 25820], [25821, 25830], [25830, 25831]]}) 
answer: set([u'category', u'broad', u'divide', u'two'])
candidate Sentence: (0.092643000185489655, {u'tokens': [u'Purfling', u'can', u'also', u'appear', u'on', u'the', u'back', u'of', u'an', u'acoustic', u'guitar', u',', u'marking', u'the', u'edge', u'joints', u'of', u'the', u'two', u'or', u'three', u'sections', u'of', u'the', u'back', u'.'], u'lemmas': [u'purfle', u'can', u'also', u'appear', u'on', u'the', u'back', u'of', u'a', u'acoustic', u'guitar', u',', u'mark', u'the', u'edge', u'joint', u'of', u'the', u'two', u'or', u'three', u'section', u'of', u'the', u'back', u'.'], u'pos': [u'VBG', u'MD', u'RB', u'VB', u'IN', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u',', u'VBG', u'DT', u'NN', u'NNS', u'IN', u'DT', u'CD', u'CC', u'CD', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[38200, 38208], [38209, 38212], [38213, 38217], [38218, 38224], [38225, 38227], [38228, 38231], [38232, 38236], [38237, 38239], [38240, 38242], [38243, 38251], [38252, 38258], [38258, 38259], [38260, 38267], [38268, 38271], [38272, 38276], [38277, 38283], [38284, 38286], [38287, 38290], [38291, 38294], [38295, 38297], [38298, 38303], [38304, 38312], [38313, 38315], [38316, 38319], [38320, 38324], [38324, 38325]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.090025641024112701, {u'tokens': [u'They', u'can', u'also', u'be', u'a', u'solo', u'classical', u'instrument', u'.'], u'lemmas': [u'they', u'can', u'also', u'be', u'a', u'solo', u'classical', u'instrument', u'.'], u'pos': [u'PRP', u'MD', u'RB', u'VB', u'DT', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[322, 326], [327, 330], [331, 335], [336, 338], [339, 340], [341, 345], [346, 355], [356, 366], [366, 367]]}) 
answer: set([u'category', u'broad', u'divide', u'two'])

Can guitars be divided into two broad categories?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114ceab8>.answer
_____________________________ test_yesno[param143] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ceb00>, (<src.tfidf.TF_IDF object at 0x10a4b0850>, set(['guitar'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114ceb00>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.43902823328971863, {u'tokens': [u'The', u'guitar', u'player', u'-LRB-', u'c.', u'1672', u'-RRB-', u',', u'by', u'Johannes', u'Vermeer', u'Guitars', u'can', u'be', u'divided', u'into', u'two', u'broad', u'categories', u',', u'acoustic', u'and', u'electric', u':', u'An', u'acoustic', u'guitar', u'is', u'one', u'not', u'dependent', u'on', u'an', u'external', u'device', u'to', u'be', u'heard', u'but', u'uses', u'a', u'soundboard', u'which', u'is', u'a', u'wooden', u'piece', u'mounted', u'on', u'the', u'front', u'of', u'the', u'guitar', u"'s", u'body', u'.'], u'lemmas': [u'the', u'guitar', u'player', u'-lrb-', u'c.', u'1672', u'-rrb-', u',', u'by', u'Johannes', u'Vermeer', u'Guitars', u'can', u'be', u'divide', u'into', u'two', u'broad', u'category', u',', u'acoustic', u'and', u'electric', u':', u'a', u'acoustic', u'guitar', u'be', u'one', u'not', u'dependent', u'on', u'a', u'external', u'device', u'to', u'be', u'hear', u'but', u'use', u'a', u'soundboard', u'which', u'be', u'a', u'wooden', u'piece', u'mount', u'on', u'the', u'front', u'of', u'the', u'guitar', u"'s", u'body', u'.'], u'pos': [u'DT', u'NN', u'NN', u'-LRB-', u'NN', u'CD', u'-RRB-', u',', u'IN', u'NNP', u'NNP', u'NNP', u'MD', u'VB', u'VBN', u'IN', u'CD', u'JJ', u'NNS', u',', u'JJ', u'CC', u'JJ', u':', u'DT', u'JJ', u'NN', u'VBZ', u'CD', u'RB', u'JJ', u'IN', u'DT', u'JJ', u'NN', u'TO', u'VB', u'VBN', u'CC', u'VBZ', u'DT', u'NN', u'WDT', u'VBZ', u'DT', u'JJ', u'NN', u'VBD', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[5423, 5426], [5427, 5433], [5434, 5440], [5441, 5442], [5442, 5444], [5445, 5449], [5449, 5450], [5450, 5451], [5452, 5454], [5455, 5463], [5464, 5471], [5472, 5479], [5480, 5483], [5484, 5486], [5487, 5494], [5495, 5499], [5500, 5503], [5504, 5509], [5510, 5520], [5520, 5521], [5522, 5530], [5531, 5534], [5535, 5543], [5543, 5544], [5545, 5547], [5548, 5556], [5557, 5563], [5564, 5566], [5567, 5570], [5571, 5574], [5575, 5584], [5585, 5587], [5588, 5590], [5591, 5599], [5600, 5606], [5607, 5609], [5610, 5612], [5613, 5618], [5619, 5622], [5623, 5627], [5628, 5629], [5630, 5640], [5641, 5646], [5647, 5649], [5650, 5651], [5652, 5658], [5659, 5664], [5665, 5672], [5673, 5675], [5676, 5679], [5680, 5685], [5686, 5688], [5689, 5692], [5693, 5699], [5699, 5701], [5702, 5706], [5706, 5707]]}) 
answer: set([])
candidate Sentence: (0.18585856258869171, {u'tokens': [u'The', u'twelfth', u'fret', u'divides', u'the', u'scale', u'length', u'in', u'two', u'exact', u'halves', u'and', u'the', u'24th', u'fret', u'position', u'divides', u'the', u'scale', u'length', u'in', u'half', u'yet', u'again', u'.'], u'lemmas': [u'the', u'twelfth', u'fret', u'divide', u'the', u'scale', u'length', u'in', u'two', u'exact', u'half', u'and', u'the', u'24th', u'fret', u'position', u'divide', u'the', u'scale', u'length', u'in', u'half', u'yet', u'again', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'NN', u'NN', u'IN', u'CD', u'JJ', u'NNS', u'CC', u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'DT', u'NN', u'NN', u'IN', u'NN', u'RB', u'RB', u'.'], u'char_offsets': [[21707, 21710], [21711, 21718], [21719, 21723], [21724, 21731], [21732, 21735], [21736, 21741], [21742, 21748], [21749, 21751], [21752, 21755], [21756, 21761], [21762, 21768], [21769, 21772], [21773, 21776], [21777, 21781], [21782, 21786], [21787, 21795], [21796, 21803], [21804, 21807], [21808, 21813], [21814, 21820], [21821, 21823], [21824, 21828], [21829, 21832], [21833, 21838], [21838, 21839]]}) 
answer: set([u'category', u'broad'])
candidate Sentence: (0.1324327290058136, {u'tokens': [u'That', u'distance', u'is', u'subtracted', u'from', u'the', u'scale', u'length', u'and', u'the', u'result', u'is', u'divided', u'in', u'two', u'sections', u'by', u'the', u'constant', u'to', u'yield', u'the', u'distance', u'from', u'the', u'first', u'fret', u'to', u'the', u'second', u'fret', u'.'], u'lemmas': [u'that', u'distance', u'be', u'subtract', u'from', u'the', u'scale', u'length', u'and', u'the', u'result', u'be', u'divide', u'in', u'two', u'section', u'by', u'the', u'constant', u'to', u'yield', u'the', u'distance', u'from', u'the', u'first', u'fret', u'to', u'the', u'second', u'fret', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'NN', u'CC', u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'CD', u'NNS', u'IN', u'DT', u'JJ', u'TO', u'VB', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'TO', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[22094, 22098], [22099, 22107], [22108, 22110], [22111, 22121], [22122, 22126], [22127, 22130], [22131, 22136], [22137, 22143], [22144, 22147], [22148, 22151], [22152, 22158], [22159, 22161], [22162, 22169], [22170, 22172], [22173, 22176], [22177, 22185], [22186, 22188], [22189, 22192], [22193, 22201], [22202, 22204], [22205, 22210], [22211, 22214], [22215, 22223], [22224, 22228], [22229, 22232], [22233, 22238], [22239, 22243], [22244, 22246], [22247, 22250], [22251, 22257], [22258, 22262], [22262, 22263]]}) 
answer: set([u'category', u'broad'])
candidate Sentence: (0.12797744572162628, {u'tokens': [u'The', u'scale', u'length', u'divided', u'by', u'this', u'value', u'yields', u'the', u'distance', u'from', u'the', u'nut', u'to', u'the', u'first', u'fret', u'.'], u'lemmas': [u'the', u'scale', u'length', u'divide', u'by', u'this', u'value', u'yield', u'the', u'distance', u'from', u'the', u'nut', u'to', u'the', u'first', u'fret', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBN', u'IN', u'DT', u'NN', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NN', u'TO', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[22003, 22006], [22007, 22012], [22013, 22019], [22020, 22027], [22028, 22030], [22031, 22035], [22036, 22041], [22042, 22048], [22049, 22052], [22053, 22061], [22062, 22066], [22067, 22070], [22071, 22074], [22075, 22077], [22078, 22081], [22082, 22087], [22088, 22092], [22092, 22093]]}) 
answer: set([u'category', u'broad', u'two'])
candidate Sentence: (0.11718807369470596, {u'tokens': [u'The', u'ratio', u'of', u'the', u'spacing', u'of', u'two', u'consecutive', u'frets', u'is', u'the', u'twelfth', u'root', u'of', u'two', u'.'], u'lemmas': [u'the', u'ratio', u'of', u'the', u'spacing', u'of', u'two', u'consecutive', u'fret', u'be', u'the', u'twelfth', u'root', u'of', u'two', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'CD', u'JJ', u'VBZ', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'CD', u'.'], u'char_offsets': [[21629, 21632], [21633, 21638], [21639, 21641], [21642, 21645], [21646, 21653], [21654, 21656], [21657, 21660], [21661, 21672], [21673, 21678], [21679, 21681], [21682, 21685], [21686, 21693], [21694, 21698], [21699, 21701], [21702, 21705], [21705, 21706]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.097049862146377563, {u'tokens': [u'Alternate', u'tunings', u'are', u'used', u'for', u'two', u'main', u'reasons', u':', u'the', u'ease', u'of', u'playing', u'and', u'the', u'variation', u'in', u'tone', u'that', u'can', u'be', u'achieved', u'.'], u'lemmas': [u'alternate', u'tuning', u'be', u'use', u'for', u'two', u'main', u'reason', u':', u'the', u'ease', u'of', u'playing', u'and', u'the', u'variation', u'in', u'tone', u'that', u'can', u'be', u'achieve', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'VBN', u'IN', u'CD', u'JJ', u'NNS', u':', u'DT', u'NN', u'IN', u'NN', u'CC', u'DT', u'NN', u'IN', u'NN', u'WDT', u'MD', u'VB', u'VBN', u'.'], u'char_offsets': [[44303, 44312], [44313, 44320], [44321, 44324], [44325, 44329], [44330, 44333], [44334, 44337], [44338, 44342], [44343, 44350], [44350, 44351], [44352, 44355], [44356, 44360], [44361, 44363], [44364, 44371], [44372, 44375], [44376, 44379], [44380, 44389], [44390, 44392], [44393, 44397], [44398, 44402], [44403, 44406], [44407, 44409], [44410, 44418], [44418, 44419]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.095963791012763977, {u'tokens': [u'There', u'are', u'two', u'main', u'types', u'of', u'pickup', u',', u'single', u'and', u'double', u'coil', u'-LRB-', u'or', u'humbucker', u'-RRB-', u',', u'each', u'of', u'which', u'can', u'be', u'passive', u'or', u'active', u'.'], u'lemmas': [u'there', u'be', u'two', u'main', u'type', u'of', u'pickup', u',', u'single', u'and', u'double', u'coil', u'-lrb-', u'or', u'humbucker', u'-rrb-', u',', u'each', u'of', u'which', u'can', u'be', u'passive', u'or', u'active', u'.'], u'pos': [u'EX', u'VBP', u'CD', u'JJ', u'NNS', u'IN', u'NN', u',', u'JJ', u'CC', u'JJ', u'NN', u'-LRB-', u'CC', u'NN', u'-RRB-', u',', u'DT', u'IN', u'WDT', u'MD', u'VB', u'JJ', u'CC', u'JJ', u'.'], u'char_offsets': [[16087, 16092], [16093, 16096], [16097, 16100], [16101, 16105], [16106, 16111], [16112, 16114], [16115, 16121], [16121, 16122], [16123, 16129], [16130, 16133], [16134, 16140], [16141, 16145], [16146, 16147], [16147, 16149], [16150, 16159], [16159, 16160], [16160, 16161], [16162, 16166], [16167, 16169], [16170, 16175], [16176, 16179], [16180, 16182], [16183, 16190], [16191, 16193], [16194, 16200], [16200, 16201]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.094398520886898041, {u'tokens': [u'The', u'manufacturer', u"'s", u'logo', u'or', u'a', u'small', u'design', u'is', u'often', u'inlaid', u'into', u'the', u'headstock', u'.'], u'lemmas': [u'the', u'manufacturer', u"'s", u'logo', u'or', u'a', u'small', u'design', u'be', u'often', u'inlay', u'into', u'the', u'headstock', u'.'], u'pos': [u'DT', u'NN', u'POS', u'NN', u'CC', u'DT', u'JJ', u'NN', u'VBZ', u'RB', u'VBN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[25754, 25757], [25758, 25770], [25770, 25772], [25773, 25777], [25778, 25780], [25781, 25782], [25783, 25788], [25789, 25795], [25796, 25798], [25799, 25804], [25805, 25811], [25812, 25816], [25817, 25820], [25821, 25830], [25830, 25831]]}) 
answer: set([u'category', u'broad', u'divide', u'two'])
candidate Sentence: (0.092643000185489655, {u'tokens': [u'Purfling', u'can', u'also', u'appear', u'on', u'the', u'back', u'of', u'an', u'acoustic', u'guitar', u',', u'marking', u'the', u'edge', u'joints', u'of', u'the', u'two', u'or', u'three', u'sections', u'of', u'the', u'back', u'.'], u'lemmas': [u'purfle', u'can', u'also', u'appear', u'on', u'the', u'back', u'of', u'a', u'acoustic', u'guitar', u',', u'mark', u'the', u'edge', u'joint', u'of', u'the', u'two', u'or', u'three', u'section', u'of', u'the', u'back', u'.'], u'pos': [u'VBG', u'MD', u'RB', u'VB', u'IN', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u',', u'VBG', u'DT', u'NN', u'NNS', u'IN', u'DT', u'CD', u'CC', u'CD', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[38200, 38208], [38209, 38212], [38213, 38217], [38218, 38224], [38225, 38227], [38228, 38231], [38232, 38236], [38237, 38239], [38240, 38242], [38243, 38251], [38252, 38258], [38258, 38259], [38260, 38267], [38268, 38271], [38272, 38276], [38277, 38283], [38284, 38286], [38287, 38290], [38291, 38294], [38295, 38297], [38298, 38303], [38304, 38312], [38313, 38315], [38316, 38319], [38320, 38324], [38324, 38325]]}) 
answer: set([u'category', u'broad', u'divide'])
candidate Sentence: (0.090025641024112701, {u'tokens': [u'They', u'can', u'also', u'be', u'a', u'solo', u'classical', u'instrument', u'.'], u'lemmas': [u'they', u'can', u'also', u'be', u'a', u'solo', u'classical', u'instrument', u'.'], u'pos': [u'PRP', u'MD', u'RB', u'VB', u'DT', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[322, 326], [327, 330], [331, 335], [336, 338], [339, 340], [341, 345], [346, 355], [356, 366], [366, 367]]}) 
answer: set([u'category', u'broad', u'divide', u'two'])

Can guitars be divided into two broad categories?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114ceb00>.answer
_____________________________ test_yesno[param146] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114cebd8>, (<src.tfidf.TF_IDF object at 0x10a4d4990>, set(['becquerel', 'henri', 'henri_becquerel'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114cebd8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.53987157344818115, {u'tokens': [u'He', u'studied', u'science', u'at', u'the', u'\xc9cole', u'Polytechnique', u'and', u'engineering', u'at', u'the', u'\xc9cole', u'des', u'Ponts', u'et', u'Chauss\xe9es', u'.'], u'lemmas': [u'he', u'study', u'science', u'at', u'the', u'\xc9cole', u'Polytechnique', u'and', u'engineering', u'at', u'the', u'\xc9cole', u'des', u'Ponts', u'et', u'chauss\xe9es', u'.'], u'pos': [u'PRP', u'VBD', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'CC', u'NN', u'IN', u'DT', u'NNP', u'FW', u'NNP', u'FW', u'FW', u'.'], u'char_offsets': [[400, 402], [403, 410], [411, 418], [419, 421], [422, 425], [426, 431], [432, 445], [446, 449], [450, 461], [462, 464], [465, 468], [469, 474], [475, 478], [479, 484], [485, 487], [488, 497], [497, 498]]}) 
answer: set([u'cole', u'chausses'])
candidate Sentence: (0.10870081186294556, {u'tokens': [u'In', u'1908', u',', u'the', u'year', u'of', u'his', u'death', u',', u'Becquerel', u'was', u'elected', u'Permanent', u'Secretary', u'of', u'the', u'Acad\xe9mie', u'des', u'Sciences', u'.'], u'lemmas': [u'in', u'1908', u',', u'the', u'year', u'of', u'he', u'death', u',', u'Becquerel', u'be', u'elect', u'Permanent', u'Secretary', u'of', u'the', u'Acad\xe9mie', u'des', u'Sciences', u'.'], u'pos': [u'IN', u'CD', u',', u'DT', u'NN', u'IN', u'PRP$', u'NN', u',', u'NNP', u'VBD', u'VBN', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNPS', u'.'], u'char_offsets': [[2726, 2728], [2729, 2733], [2733, 2734], [2735, 2738], [2739, 2743], [2744, 2746], [2747, 2750], [2751, 2756], [2756, 2757], [2758, 2767], [2768, 2771], [2772, 2779], [2780, 2789], [2790, 2799], [2800, 2802], [2803, 2806], [2807, 2815], [2816, 2819], [2820, 2828], [2828, 2829]]}) 
answer: set([u'science', u'study', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.084758460521697998, {u'tokens': [u'Describing', u'his', u'method', u'to', u'the', u'French', u'Academy', u'of', u'Sciences', u'on', u'24', u'January', u'1896', u',', u'he', u'said', u':', u'One', u'wraps', u'a', u'Lumi\xe8re', u'photographic', u'plate', u'with', u'a', u'bromide', u'emulsion', u'in', u'two', u'sheets', u'of', u'very', u'thick', u'black', u'paper', u',', u'such', u'that', u'the', u'plate', u'does', u'not', u'become', u'clouded', u'upon', u'being', u'exposed', u'to', u'the', u'sun', u'for', u'a', u'day', u'.'], u'lemmas': [u'describe', u'he', u'method', u'to', u'the', u'french', u'academy', u'of', u'Sciences', u'on', u'24', u'January', u'1896', u',', u'he', u'say', u':', u'one', u'wrap', u'a', u'lumi\xe8re', u'photographic', u'plate', u'with', u'a', u'bromide', u'emulsion', u'in', u'two', u'sheet', u'of', u'very', u'thick', u'black', u'paper', u',', u'such', u'that', u'the', u'plate', u'do', u'not', u'become', u'clouded', u'upon', u'be', u'expose', u'to', u'the', u'sun', u'for', u'a', u'day', u'.'], u'pos': [u'VBG', u'PRP$', u'NN', u'TO', u'DT', u'JJ', u'NN', u'IN', u'NNPS', u'IN', u'CD', u'NNP', u'CD', u',', u'PRP', u'VBD', u':', u'CD', u'VBZ', u'DT', u'JJ', u'JJ', u'NN', u'IN', u'DT', u'NN', u'NN', u'IN', u'CD', u'NNS', u'IN', u'RB', u'JJ', u'JJ', u'NN', u',', u'JJ', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'VB', u'JJ', u'IN', u'VBG', u'VBN', u'TO', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[1316, 1326], [1327, 1330], [1331, 1337], [1338, 1340], [1341, 1344], [1345, 1351], [1352, 1359], [1360, 1362], [1363, 1371], [1372, 1374], [1375, 1377], [1378, 1385], [1386, 1390], [1390, 1391], [1392, 1394], [1395, 1399], [1399, 1400], [1402, 1405], [1406, 1411], [1412, 1413], [1414, 1421], [1422, 1434], [1435, 1440], [1441, 1445], [1446, 1447], [1448, 1455], [1456, 1464], [1465, 1467], [1468, 1471], [1472, 1478], [1479, 1481], [1482, 1486], [1487, 1492], [1493, 1498], [1499, 1504], [1504, 1505], [1506, 1510], [1511, 1515], [1516, 1519], [1520, 1525], [1526, 1530], [1531, 1534], [1535, 1541], [1542, 1549], [1550, 1554], [1555, 1560], [1561, 1568], [1569, 1571], [1572, 1575], [1576, 1579], [1580, 1583], [1584, 1585], [1586, 1589], [1589, 1590]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.082553312182426453, {u'tokens': [u'He', u'died', u'at', u'the', u'age', u'of', u'55', u'in', u'Le', u'Croisic', u'.'], u'lemmas': [u'he', u'die', u'at', u'the', u'age', u'of', u'55', u'in', u'Le', u'Croisic', u'.'], u'pos': [u'PRP', u'VBD', u'IN', u'DT', u'NN', u'IN', u'CD', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[2830, 2832], [2833, 2837], [2838, 2840], [2841, 2844], [2845, 2848], [2849, 2851], [2852, 2854], [2855, 2857], [2858, 2860], [2861, 2868], [2868, 2869]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.062086045742034912, {u'tokens': [u'In', u'1892', u',', u'he', u'became', u'the', u'third', u'in', u'his', u'family', u'to', u'occupy', u'the', u'physics', u'chair', u'at', u'the', u'Mus\xe9um', u'National', u"d'Histoire", u'Naturelle', u'.'], u'lemmas': [u'in', u'1892', u',', u'he', u'become', u'the', u'third', u'in', u'he', u'family', u'to', u'occupy', u'the', u'physics', u'chair', u'at', u'the', u'Mus\xe9um', u'National', u"d'Histoire", u'Naturelle', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP', u'VBD', u'DT', u'JJ', u'IN', u'PRP$', u'NN', u'TO', u'VB', u'DT', u'NN', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[542, 544], [545, 549], [549, 550], [551, 553], [554, 560], [561, 564], [565, 570], [571, 573], [574, 577], [578, 584], [585, 587], [588, 594], [595, 598], [599, 606], [607, 612], [613, 615], [616, 619], [620, 626], [627, 635], [636, 646], [647, 656], [656, 657]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.024634828791022301, {u'tokens': [u'He', u'also', u'received', u'the', u'following', u'awards', u'besides', u'the', u'Nobel', u'Prize', u'for', u'Physics', u'-LRB-', u'1903', u'-RRB-', u':', u'*', u'Antoine', u'C\xe9sar', u'Becquerel', u'-LRB-', u'his', u'grandfather', u'-RRB-', u'*', u'A.', u'E.', u'Becquerel', u'-LRB-', u'his', u'father', u'-RRB-', u'*', u'Jean', u'Becquerel', u'-LRB-', u'his', u'son', u'-RRB-', u'*', u'Henri', u'Becquerel', u'-', u'Biography', u'*', u'Becquerel', u'short', u'biography', u'and', u'the', u'use', u'of', u'his', u'name', u'as', u'a', u'unit', u'of', u'measure', u'in', u'the', u'SI', u'*', u'Annotated', u'bibliography', u'for', u'Henri', u'Becquerel', u'from', u'the', u'Alsos', u'Digital', u'Library', u'for', u'Nuclear', u'Issues'], u'lemmas': [u'he', u'also', u'receive', u'the', u'follow', u'award', u'besides', u'the', u'Nobel', u'Prize', u'for', u'physics', u'-lrb-', u'1903', u'-rrb-', u':', u'*', u'Antoine', u'C\xe9sar', u'Becquerel', u'-lrb-', u'he', u'grandfather', u'-rrb-', u'*', u'a.', u'E.', u'Becquerel', u'-lrb-', u'he', u'father', u'-rrb-', u'*', u'Jean', u'Becquerel', u'-lrb-', u'he', u'son', u'-rrb-', u'*', u'Henri', u'Becquerel', u'-', u'biography', u'*', u'Becquerel', u'short', u'biography', u'and', u'the', u'use', u'of', u'he', u'name', u'as', u'a', u'unit', u'of', u'measure', u'in', u'the', u'SI', u'*', u'annotated', u'bibliography', u'for', u'Henri', u'Becquerel', u'from', u'the', u'Alsos', u'Digital', u'Library', u'for', u'Nuclear', u'issue'], u'pos': [u'PRP', u'RB', u'VBD', u'DT', u'VBG', u'NNS', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'NN', u'-LRB-', u'CD', u'-RRB-', u':', u'SYM', u'NNP', u'NNP', u'NNP', u'-LRB-', u'PRP$', u'NN', u'-RRB-', u'SYM', u'NN', u'NNP', u'NNP', u'-LRB-', u'PRP$', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'-LRB-', u'PRP$', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u':', u'NN', u'SYM', u'NNP', u'JJ', u'NN', u'CC', u'DT', u'NN', u'IN', u'PRP$', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'IN', u'DT', u'NNP', u'SYM', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u'IN', u'NNP', u'NNS'], u'char_offsets': [[3032, 3034], [3035, 3039], [3040, 3048], [3049, 3052], [3053, 3062], [3063, 3069], [3070, 3077], [3078, 3081], [3082, 3087], [3088, 3093], [3094, 3097], [3098, 3105], [3106, 3107], [3107, 3111], [3111, 3112], [3112, 3113], [3114, 3115], [3116, 3123], [3124, 3129], [3130, 3139], [3140, 3141], [3141, 3144], [3145, 3156], [3156, 3157], [3158, 3159], [3160, 3162], [3163, 3165], [3166, 3175], [3176, 3177], [3177, 3180], [3181, 3187], [3187, 3188], [3189, 3190], [3191, 3195], [3196, 3205], [3206, 3207], [3207, 3210], [3211, 3214], [3214, 3215], [3216, 3217], [3219, 3224], [3225, 3234], [3235, 3236], [3237, 3246], [3247, 3248], [3250, 3259], [3260, 3265], [3266, 3275], [3276, 3279], [3280, 3283], [3284, 3287], [3288, 3290], [3291, 3294], [3295, 3299], [3300, 3302], [3303, 3304], [3305, 3309], [3310, 3312], [3313, 3320], [3321, 3323], [3324, 3327], [3328, 3330], [3331, 3332], [3334, 3343], [3344, 3356], [3357, 3360], [3361, 3366], [3367, 3376], [3377, 3381], [3382, 3385], [3386, 3391], [3392, 3399], [3400, 3407], [3408, 3411], [3412, 3419], [3420, 3426]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.020379679277539253, {u'tokens': [u'There', u'is', u'a', u'crater', u'called', u'Becquerel', u'on', u'the', u'Moon', u'and', u'also', u'a', u'crater', u'called', u'Becquerel', u'on', u'Mars', u'.'], u'lemmas': [u'there', u'be', u'a', u'crater', u'call', u'Becquerel', u'on', u'the', u'Moon', u'and', u'also', u'a', u'crater', u'call', u'Becquerel', u'on', u'Mars', u'.'], u'pos': [u'EX', u'VBZ', u'DT', u'NN', u'VBN', u'NNP', u'IN', u'DT', u'NNP', u'CC', u'RB', u'DT', u'NN', u'VBN', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[2941, 2946], [2947, 2949], [2950, 2951], [2952, 2958], [2959, 2965], [2966, 2975], [2976, 2978], [2979, 2982], [2983, 2987], [2988, 2991], [2992, 2996], [2997, 2998], [2999, 3005], [3006, 3012], [3013, 3022], [3023, 3025], [3026, 3030], [3030, 3031]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.020328933373093605, {u'tokens': [u'Becquerel', u'was', u'born', u'in', u'Paris', u'into', u'a', u'family', u'which', u'produced', u'four', u'generations', u'of', u'scientists', u',', u'including', u'Becquerel', u"'s", u'own', u'son', u'Jean', u'.'], u'lemmas': [u'Becquerel', u'be', u'bear', u'in', u'Paris', u'into', u'a', u'family', u'which', u'produce', u'four', u'generation', u'of', u'scientist', u',', u'include', u'Becquerel', u"'s", u'own', u'son', u'Jean', u'.'], u'pos': [u'NNP', u'VBD', u'VBN', u'IN', u'NNP', u'IN', u'DT', u'NN', u'WDT', u'VBD', u'CD', u'NNS', u'IN', u'NNS', u',', u'VBG', u'NNP', u'POS', u'JJ', u'NN', u'NNP', u'.'], u'char_offsets': [[275, 284], [285, 288], [289, 293], [294, 296], [297, 302], [303, 307], [308, 309], [310, 316], [317, 322], [323, 331], [332, 336], [337, 348], [349, 351], [352, 362], [362, 363], [364, 373], [374, 383], [383, 385], [386, 389], [390, 393], [394, 398], [398, 399]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.015657473355531693, {u'tokens': [u'However', u',', u'prior', u'to', u'actually', u'performing', u'the', u'experiment', u',', u'Becquerel', u'found', u'that', u'the', u'photographic', u'plates', u'were', u'already', u'exposed', u',', u'showing', u'the', u'image', u'of', u'the', u'substance', u'.'], u'lemmas': [u'however', u',', u'prior', u'to', u'actually', u'perform', u'the', u'experiment', u',', u'Becquerel', u'find', u'that', u'the', u'photographic', u'plate', u'be', u'already', u'expose', u',', u'show', u'the', u'image', u'of', u'the', u'substance', u'.'], u'pos': [u'RB', u',', u'RB', u'TO', u'RB', u'VBG', u'DT', u'NN', u',', u'NNP', u'VBD', u'IN', u'DT', u'JJ', u'NNS', u'VBD', u'RB', u'VBN', u',', u'VBG', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[1068, 1075], [1075, 1076], [1077, 1082], [1083, 1085], [1086, 1094], [1095, 1105], [1106, 1109], [1110, 1120], [1120, 1121], [1122, 1131], [1132, 1137], [1138, 1142], [1143, 1146], [1147, 1159], [1160, 1166], [1167, 1171], [1172, 1179], [1180, 1187], [1187, 1188], [1189, 1196], [1197, 1200], [1201, 1206], [1207, 1209], [1210, 1213], [1214, 1223], [1223, 1224]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])
candidate Sentence: (0.015180650167167187, {u'tokens': [u'This', u'discovery', u'led', u'Becquerel', u'to', u'investigate', u'the', u'spontaneous', u'emission', u'of', u'nuclear', u'radiation', u'.'], u'lemmas': [u'this', u'discovery', u'lead', u'Becquerel', u'to', u'investigate', u'the', u'spontaneous', u'emission', u'of', u'nuclear', u'radiation', u'.'], u'pos': [u'DT', u'NN', u'VBD', u'NNP', u'TO', u'VB', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[1225, 1229], [1230, 1239], [1240, 1243], [1244, 1253], [1254, 1256], [1257, 1268], [1269, 1272], [1273, 1284], [1285, 1293], [1294, 1296], [1297, 1304], [1305, 1314], [1314, 1315]]}) 
answer: set([u'science', u'study', u'des', u'ponts', u'et', u'cole', u'chausses'])

Did Becquerel study science at the cole des Ponts et Chausses?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114cebd8>.answer
_____________________________ test_yesno[param148] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114cec68>, (<src.tfidf.TF_IDF object at 0x10a4d4990>, set(['becquerel', 'henri', 'henri_becquerel'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cec68>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.79266440868377686, {u'tokens': [u'In', u'1894', u',', u'he', u'became', u'chief', u'engineer', u'in', u'the', u'Department', u'of', u'Bridges', u'and', u'Highways', u'.'], u'lemmas': [u'in', u'1894', u',', u'he', u'become', u'chief', u'engineer', u'in', u'the', u'Department', u'of', u'Bridges', u'and', u'highway', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP', u'VBD', u'JJ', u'NN', u'IN', u'DT', u'NNP', u'IN', u'NNPS', u'CC', u'NNS', u'.'], u'char_offsets': [[658, 660], [661, 665], [665, 666], [667, 669], [670, 676], [677, 682], [683, 691], [692, 694], [695, 698], [699, 709], [710, 712], [713, 720], [721, 724], [725, 733], [733, 734]]}) 
answer: set([u'1892'])
candidate Sentence: (0.19068318605422974, {u'tokens': [u'In', u'1892', u',', u'he', u'became', u'the', u'third', u'in', u'his', u'family', u'to', u'occupy', u'the', u'physics', u'chair', u'at', u'the', u'Mus\xe9um', u'National', u"d'Histoire", u'Naturelle', u'.'], u'lemmas': [u'in', u'1892', u',', u'he', u'become', u'the', u'third', u'in', u'he', u'family', u'to', u'occupy', u'the', u'physics', u'chair', u'at', u'the', u'Mus\xe9um', u'National', u"d'Histoire", u'Naturelle', u'.'], u'pos': [u'IN', u'CD', u',', u'PRP', u'VBD', u'DT', u'JJ', u'IN', u'PRP$', u'NN', u'TO', u'VB', u'DT', u'NN', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[542, 544], [545, 549], [549, 550], [551, 553], [554, 560], [561, 564], [565, 570], [571, 573], [574, 577], [578, 584], [585, 587], [588, 594], [595, 598], [599, 606], [607, 612], [613, 615], [616, 619], [620, 626], [627, 635], [636, 646], [647, 656], [656, 657]]}) 
answer: set([u'department', u'bridges', u'chief', u'highway', u'engineer'])
candidate Sentence: (0.1143018901348114, {u'tokens': [u'Describing', u'his', u'method', u'to', u'the', u'French', u'Academy', u'of', u'Sciences', u'on', u'24', u'January', u'1896', u',', u'he', u'said', u':', u'One', u'wraps', u'a', u'Lumi\xe8re', u'photographic', u'plate', u'with', u'a', u'bromide', u'emulsion', u'in', u'two', u'sheets', u'of', u'very', u'thick', u'black', u'paper', u',', u'such', u'that', u'the', u'plate', u'does', u'not', u'become', u'clouded', u'upon', u'being', u'exposed', u'to', u'the', u'sun', u'for', u'a', u'day', u'.'], u'lemmas': [u'describe', u'he', u'method', u'to', u'the', u'french', u'academy', u'of', u'Sciences', u'on', u'24', u'January', u'1896', u',', u'he', u'say', u':', u'one', u'wrap', u'a', u'lumi\xe8re', u'photographic', u'plate', u'with', u'a', u'bromide', u'emulsion', u'in', u'two', u'sheet', u'of', u'very', u'thick', u'black', u'paper', u',', u'such', u'that', u'the', u'plate', u'do', u'not', u'become', u'clouded', u'upon', u'be', u'expose', u'to', u'the', u'sun', u'for', u'a', u'day', u'.'], u'pos': [u'VBG', u'PRP$', u'NN', u'TO', u'DT', u'JJ', u'NN', u'IN', u'NNPS', u'IN', u'CD', u'NNP', u'CD', u',', u'PRP', u'VBD', u':', u'CD', u'VBZ', u'DT', u'JJ', u'JJ', u'NN', u'IN', u'DT', u'NN', u'NN', u'IN', u'CD', u'NNS', u'IN', u'RB', u'JJ', u'JJ', u'NN', u',', u'JJ', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'VB', u'JJ', u'IN', u'VBG', u'VBN', u'TO', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[1316, 1326], [1327, 1330], [1331, 1337], [1338, 1340], [1341, 1344], [1345, 1351], [1352, 1359], [1360, 1362], [1363, 1371], [1372, 1374], [1375, 1377], [1378, 1385], [1386, 1390], [1390, 1391], [1392, 1394], [1395, 1399], [1399, 1400], [1402, 1405], [1406, 1411], [1412, 1413], [1414, 1421], [1422, 1434], [1435, 1440], [1441, 1445], [1446, 1447], [1448, 1455], [1456, 1464], [1465, 1467], [1468, 1471], [1472, 1478], [1479, 1481], [1482, 1486], [1487, 1492], [1493, 1498], [1499, 1504], [1504, 1505], [1506, 1510], [1511, 1515], [1516, 1519], [1520, 1525], [1526, 1530], [1531, 1534], [1535, 1541], [1542, 1549], [1550, 1554], [1555, 1560], [1561, 1568], [1569, 1571], [1572, 1575], [1576, 1579], [1580, 1583], [1584, 1585], [1586, 1589], [1589, 1590]]}) 
answer: set([u'bridges', u'chief', u'highway', u'department', u'1892', u'engineer'])
candidate Sentence: (0.048345927149057388, {u'tokens': [u'In', u'1903', u',', u'he', u'shared', u'the', u'Nobel', u'Prize', u'in', u'Physics', u'with', u'Pierre', u'and', u'Marie', u'Curie', u'``', u'in', u'recognition', u'of', u'the', u'extraordinary', u'services', u'he', u'has', u'rendered', u'by', u'his', u'discovery', u'of', u'spontaneous', u'radioactivity', u"''", u'.'], u'lemmas': [u'in', u'1903', u',', u'he', u'share', u'the', u'Nobel', u'Prize', u'in', u'physics', u'with', u'Pierre', u'and', u'Marie', u'Curie', u'``', u'in', u'recognition', u'of', u'the', u'extraordinary', u'service', u'he', u'have', u'render', u'by', u'he', u'discovery', u'of', u'spontaneous', u'radioactivity', u"''", u'.'], u'pos': [u'IN', u'CD', u',', u'PRP', u'VBD', u'DT', u'NNP', u'NNP', u'IN', u'NN', u'IN', u'NNP', u'CC', u'NNP', u'NNP', u'``', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NNS', u'PRP', u'VBZ', u'VBN', u'IN', u'PRP$', u'NN', u'IN', u'JJ', u'NN', u"''", u'.'], u'char_offsets': [[2332, 2334], [2335, 2339], [2339, 2340], [2341, 2343], [2344, 2350], [2351, 2354], [2355, 2360], [2361, 2366], [2367, 2369], [2370, 2377], [2378, 2382], [2383, 2389], [2390, 2393], [2394, 2399], [2400, 2405], [2406, 2407], [2407, 2409], [2410, 2421], [2422, 2424], [2425, 2428], [2429, 2442], [2443, 2451], [2452, 2454], [2455, 2458], [2459, 2467], [2468, 2470], [2471, 2474], [2475, 2484], [2485, 2487], [2488, 2499], [2500, 2513], [2513, 2514], [2514, 2515]]}) 
answer: set([u'bridges', u'chief', u'1892', u'department', u'become', u'highway', u'engineer'])
candidate Sentence: (0.023881666362285614, {u'tokens': [u'He', u'died', u'at', u'the', u'age', u'of', u'55', u'in', u'Le', u'Croisic', u'.'], u'lemmas': [u'he', u'die', u'at', u'the', u'age', u'of', u'55', u'in', u'Le', u'Croisic', u'.'], u'pos': [u'PRP', u'VBD', u'IN', u'DT', u'NN', u'IN', u'CD', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[2830, 2832], [2833, 2837], [2838, 2840], [2841, 2844], [2845, 2848], [2849, 2851], [2852, 2854], [2855, 2857], [2858, 2860], [2861, 2868], [2868, 2869]]}) 
answer: set([u'bridges', u'chief', u'1892', u'department', u'become', u'highway', u'engineer'])
candidate Sentence: (0.022806655615568161, {u'tokens': [u'In', u'1908', u',', u'the', u'year', u'of', u'his', u'death', u',', u'Becquerel', u'was', u'elected', u'Permanent', u'Secretary', u'of', u'the', u'Acad\xe9mie', u'des', u'Sciences', u'.'], u'lemmas': [u'in', u'1908', u',', u'the', u'year', u'of', u'he', u'death', u',', u'Becquerel', u'be', u'elect', u'Permanent', u'Secretary', u'of', u'the', u'Acad\xe9mie', u'des', u'Sciences', u'.'], u'pos': [u'IN', u'CD', u',', u'DT', u'NN', u'IN', u'PRP$', u'NN', u',', u'NNP', u'VBD', u'VBN', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNPS', u'.'], u'char_offsets': [[2726, 2728], [2729, 2733], [2733, 2734], [2735, 2738], [2739, 2743], [2744, 2746], [2747, 2750], [2751, 2756], [2756, 2757], [2758, 2767], [2768, 2771], [2772, 2779], [2780, 2789], [2790, 2799], [2800, 2802], [2803, 2806], [2807, 2815], [2816, 2819], [2820, 2828], [2828, 2829]]}) 
answer: set([u'bridges', u'chief', u'1892', u'department', u'become', u'highway', u'engineer'])
candidate Sentence: (0.020713824778795242, {u'tokens': [u'In', u'1890', u'he', u'married', u'Louise', u'D\xe9sir\xe9e', u'Lorieux', u'.'], u'lemmas': [u'in', u'1890', u'he', u'marry', u'Louise', u'D\xe9sir\xe9e', u'Lorieux', u'.'], u'pos': [u'IN', u'CD', u'PRP', u'VBD', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[499, 501], [502, 506], [507, 509], [510, 517], [518, 524], [525, 532], [533, 540], [540, 541]]}) 
answer: set([u'bridges', u'chief', u'highway', u'department', u'become', u'1892', u'engineer'])
candidate Sentence: (0.020383454859256744, {u'tokens': [u'He', u'also', u'received', u'the', u'following', u'awards', u'besides', u'the', u'Nobel', u'Prize', u'for', u'Physics', u'-LRB-', u'1903', u'-RRB-', u':', u'*', u'Antoine', u'C\xe9sar', u'Becquerel', u'-LRB-', u'his', u'grandfather', u'-RRB-', u'*', u'A.', u'E.', u'Becquerel', u'-LRB-', u'his', u'father', u'-RRB-', u'*', u'Jean', u'Becquerel', u'-LRB-', u'his', u'son', u'-RRB-', u'*', u'Henri', u'Becquerel', u'-', u'Biography', u'*', u'Becquerel', u'short', u'biography', u'and', u'the', u'use', u'of', u'his', u'name', u'as', u'a', u'unit', u'of', u'measure', u'in', u'the', u'SI', u'*', u'Annotated', u'bibliography', u'for', u'Henri', u'Becquerel', u'from', u'the', u'Alsos', u'Digital', u'Library', u'for', u'Nuclear', u'Issues'], u'lemmas': [u'he', u'also', u'receive', u'the', u'follow', u'award', u'besides', u'the', u'Nobel', u'Prize', u'for', u'physics', u'-lrb-', u'1903', u'-rrb-', u':', u'*', u'Antoine', u'C\xe9sar', u'Becquerel', u'-lrb-', u'he', u'grandfather', u'-rrb-', u'*', u'a.', u'E.', u'Becquerel', u'-lrb-', u'he', u'father', u'-rrb-', u'*', u'Jean', u'Becquerel', u'-lrb-', u'he', u'son', u'-rrb-', u'*', u'Henri', u'Becquerel', u'-', u'biography', u'*', u'Becquerel', u'short', u'biography', u'and', u'the', u'use', u'of', u'he', u'name', u'as', u'a', u'unit', u'of', u'measure', u'in', u'the', u'SI', u'*', u'annotated', u'bibliography', u'for', u'Henri', u'Becquerel', u'from', u'the', u'Alsos', u'Digital', u'Library', u'for', u'Nuclear', u'issue'], u'pos': [u'PRP', u'RB', u'VBD', u'DT', u'VBG', u'NNS', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'NN', u'-LRB-', u'CD', u'-RRB-', u':', u'SYM', u'NNP', u'NNP', u'NNP', u'-LRB-', u'PRP$', u'NN', u'-RRB-', u'SYM', u'NN', u'NNP', u'NNP', u'-LRB-', u'PRP$', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'-LRB-', u'PRP$', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u':', u'NN', u'SYM', u'NNP', u'JJ', u'NN', u'CC', u'DT', u'NN', u'IN', u'PRP$', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'IN', u'DT', u'NNP', u'SYM', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u'IN', u'NNP', u'NNS'], u'char_offsets': [[3032, 3034], [3035, 3039], [3040, 3048], [3049, 3052], [3053, 3062], [3063, 3069], [3070, 3077], [3078, 3081], [3082, 3087], [3088, 3093], [3094, 3097], [3098, 3105], [3106, 3107], [3107, 3111], [3111, 3112], [3112, 3113], [3114, 3115], [3116, 3123], [3124, 3129], [3130, 3139], [3140, 3141], [3141, 3144], [3145, 3156], [3156, 3157], [3158, 3159], [3160, 3162], [3163, 3165], [3166, 3175], [3176, 3177], [3177, 3180], [3181, 3187], [3187, 3188], [3189, 3190], [3191, 3195], [3196, 3205], [3206, 3207], [3207, 3210], [3211, 3214], [3214, 3215], [3216, 3217], [3219, 3224], [3225, 3234], [3235, 3236], [3237, 3246], [3247, 3248], [3250, 3259], [3260, 3265], [3266, 3275], [3276, 3279], [3280, 3283], [3284, 3287], [3288, 3290], [3291, 3294], [3295, 3299], [3300, 3302], [3303, 3304], [3305, 3309], [3310, 3312], [3313, 3320], [3321, 3323], [3324, 3327], [3328, 3330], [3331, 3332], [3334, 3343], [3344, 3356], [3357, 3360], [3361, 3366], [3367, 3376], [3377, 3381], [3382, 3385], [3386, 3391], [3392, 3399], [3400, 3407], [3408, 3411], [3412, 3419], [3420, 3426]]}) 
answer: set([u'bridges', u'chief', u'1892', u'department', u'become', u'highway', u'engineer'])
candidate Sentence: (0.019706860184669495, {u'tokens': [u'Antoine', u'Henri', u'Becquerel', u'-LRB-', u'15', u'December', u'1852', u'25', u'August', u'1908', u'-RRB-', u'was', u'a', u'French', u'physicist', u',', u'Nobel', u'laureate', u',', u'and', u'the', u'discoverer', u'of', u'radioactivity', u',', u'for', u'which', u'he', u'won', u'the', u'1903', u'Nobel', u'Prize', u'in', u'Physics', u'-LRB-', u'along', u'with', u'Marie', u'Curie', u'and', u'Pierre', u'Curie', u'who', u'had', u'found', u'additional', u'radioactive', u'elements', u'-RRB-', u'.'], u'lemmas': [u'Antoine', u'Henri', u'Becquerel', u'-lrb-', u'15', u'December', u'1852', u'25', u'August', u'1908', u'-rrb-', u'be', u'a', u'french', u'physicist', u',', u'Nobel', u'laureate', u',', u'and', u'the', u'discoverer', u'of', u'radioactivity', u',', u'for', u'which', u'he', u'win', u'the', u'1903', u'Nobel', u'Prize', u'in', u'physics', u'-lrb-', u'along', u'with', u'Marie', u'Curie', u'and', u'Pierre', u'Curie', u'who', u'have', u'find', u'additional', u'radioactive', u'element', u'-rrb-', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u'NNP', u'CD', u'CD', u'NNP', u'CD', u'-RRB-', u'VBD', u'DT', u'JJ', u'NN', u',', u'NNP', u'NN', u',', u'CC', u'DT', u'NN', u'IN', u'NN', u',', u'IN', u'WDT', u'PRP', u'VBD', u'DT', u'CD', u'NNP', u'NNP', u'IN', u'NN', u'-LRB-', u'IN', u'IN', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u'WP', u'VBD', u'VBN', u'JJ', u'JJ', u'NNS', u'-RRB-', u'.'], u'char_offsets': [[0, 7], [8, 13], [14, 23], [24, 25], [25, 27], [28, 36], [37, 41], [44, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 65], [66, 72], [73, 82], [82, 83], [84, 89], [90, 98], [98, 99], [100, 103], [104, 107], [108, 118], [119, 121], [122, 135], [135, 136], [137, 140], [141, 146], [147, 149], [150, 153], [154, 157], [158, 162], [163, 168], [169, 174], [175, 177], [178, 185], [186, 187], [187, 192], [193, 197], [198, 203], [204, 209], [210, 213], [214, 220], [221, 226], [227, 230], [231, 234], [235, 240], [241, 251], [252, 263], [264, 272], [272, 273], [273, 274]]}) 
answer: set([u'bridges', u'chief', u'1892', u'department', u'become', u'highway', u'engineer'])
candidate Sentence: (0.019545117393136024, {u'tokens': [u'Investigating', u'the', u'work', u'of', u'Wilhelm', u'Conrad', u'R\xf6ntgen', u',', u'Becquerel', u'wrapped', u'a', u'fluorescent', u'substance', u',', u'potassium', u'uranyl', u'sulfate', u',', u'in', u'photographic', u'plates', u'and', u'black', u'material', u'in', u'preparation', u'for', u'an', u'experiment', u'requiring', u'bright', u'sunlight', u'.'], u'lemmas': [u'investigate', u'the', u'work', u'of', u'Wilhelm', u'Conrad', u'R\xf6ntgen', u',', u'Becquerel', u'wrap', u'a', u'fluorescent', u'substance', u',', u'potassium', u'uranyl', u'sulfate', u',', u'in', u'photographic', u'plate', u'and', u'black', u'material', u'in', u'preparation', u'for', u'a', u'experiment', u'require', u'bright', u'sunlight', u'.'], u'pos': [u'VBG', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'VBD', u'DT', u'JJ', u'NN', u',', u'NN', u'NN', u'NN', u',', u'IN', u'JJ', u'NNS', u'CC', u'JJ', u'NN', u'IN', u'NN', u'IN', u'DT', u'NN', u'VBG', u'JJ', u'NN', u'.'], u'char_offsets': [[847, 860], [861, 864], [865, 869], [870, 872], [873, 880], [881, 887], [888, 895], [895, 896], [897, 906], [907, 914], [915, 916], [917, 928], [929, 938], [938, 939], [940, 949], [950, 956], [957, 964], [964, 965], [966, 968], [969, 981], [982, 988], [989, 992], [993, 998], [999, 1007], [1008, 1010], [1011, 1022], [1023, 1026], [1027, 1029], [1030, 1040], [1041, 1050], [1051, 1057], [1058, 1066], [1066, 1067]]}) 
answer: set([u'bridges', u'chief', u'highway', u'department', u'become', u'1892', u'engineer'])

Did he become chief engineer in the Department of Bridges and Highways in 1892?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cec68>.answer
_____________________________ test_yesno[param159] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114cef80>, (<src.tfidf.TF_IDF object at 0x10fd76290>, set(['isaac', 'isaac_newton', 'newton'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cef80>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.32071039080619812, {u'tokens': [u'NY', u':', u'Thomas', u'Y.', u'Crowell', u'&', u'Co.', u',', u'1889', u'-RRB-', u'From', u'the', u'age', u'of', u'about', u'twelve', u'until', u'he', u'was', u'seventeen', u',', u'Newton', u'was', u'educated', u'at', u'The', u'King', u"'s", u'School', u',', u'Grantham', u'-LRB-', u'where', u'his', u'signature', u'can', u'still', u'be', u'seen', u'upon', u'a', u'library', u'window', u'sill', u'-RRB-', u'.'], u'lemmas': [u'NY', u':', u'Thomas', u'Y.', u'Crowell', u'&', u'Co.', u',', u'1889', u'-rrb-', u'from', u'the', u'age', u'of', u'about', u'twelve', u'until', u'he', u'be', u'seventeen', u',', u'Newton', u'be', u'educate', u'at', u'the', u'King', u"'s", u'School', u',', u'Grantham', u'-lrb-', u'where', u'he', u'signature', u'can', u'still', u'be', u'see', u'upon', u'a', u'library', u'window', u'sill', u'-rrb-', u'.'], u'pos': [u'NNP', u':', u'NNP', u'NNP', u'NNP', u'CC', u'NNP', u',', u'CD', u'-RRB-', u'IN', u'DT', u'NN', u'IN', u'IN', u'CD', u'IN', u'PRP', u'VBD', u'CD', u',', u'NNP', u'VBD', u'VBN', u'IN', u'DT', u'NNP', u'POS', u'NNP', u',', u'NNP', u'-LRB-', u'WRB', u'PRP$', u'NN', u'MD', u'RB', u'VB', u'VBN', u'IN', u'DT', u'NN', u'NN', u'NN', u'-RRB-', u'.'], u'char_offsets': [[3294, 3296], [3296, 3297], [3298, 3304], [3305, 3307], [3308, 3315], [3316, 3317], [3318, 3321], [3321, 3322], [3323, 3327], [3327, 3328], [3329, 3333], [3334, 3337], [3338, 3341], [3342, 3344], [3345, 3350], [3351, 3357], [3358, 3363], [3364, 3366], [3367, 3370], [3371, 3380], [3380, 3381], [3382, 3388], [3389, 3392], [3393, 3401], [3402, 3404], [3405, 3408], [3409, 3413], [3413, 3415], [3416, 3422], [3422, 3423], [3424, 3432], [3433, 3434], [3434, 3439], [3440, 3443], [3444, 3453], [3454, 3457], [3458, 3463], [3464, 3466], [3467, 3471], [3472, 3476], [3477, 3478], [3479, 3486], [3487, 3493], [3494, 3498], [3498, 3499], [3499, 3500]]}) 
answer: set([u'schol'])
candidate Sentence: (0.25480198860168457, {u'tokens': [u'The', u'King', u"'s", u'School', u',', u'Grantham', u',', u'claims', u'that', u'the', u'tree', u'was', u'purchased', u'by', u'the', u'school', u',', u'uprooted', u'and', u'transported', u'to', u'the', u'headmaster', u"'s", u'garden', u'some', u'years', u'later', u'.'], u'lemmas': [u'the', u'King', u"'s", u'School', u',', u'Grantham', u',', u'claim', u'that', u'the', u'tree', u'be', u'purchase', u'by', u'the', u'school', u',', u'uproot', u'and', u'transport', u'to', u'the', u'headmaster', u"'s", u'garden', u'some', u'year', u'later', u'.'], u'pos': [u'DT', u'NNP', u'POS', u'NNP', u',', u'NNP', u',', u'VBZ', u'IN', u'DT', u'NN', u'VBD', u'VBN', u'IN', u'DT', u'NN', u',', u'VBN', u'CC', u'VBN', u'TO', u'DT', u'NN', u'POS', u'NN', u'DT', u'NNS', u'RB', u'.'], u'char_offsets': [[44724, 44727], [44728, 44732], [44732, 44734], [44735, 44741], [44741, 44742], [44743, 44751], [44751, 44752], [44753, 44759], [44760, 44764], [44765, 44768], [44769, 44773], [44774, 44777], [44778, 44787], [44788, 44790], [44791, 44794], [44795, 44801], [44801, 44802], [44803, 44811], [44812, 44815], [44816, 44827], [44828, 44830], [44831, 44834], [44835, 44845], [44845, 44847], [44848, 44854], [44855, 44859], [44860, 44865], [44866, 44871], [44871, 44872]]}) 
answer: set([u'educate', u'schol'])
candidate Sentence: (0.22604398429393768, {u'tokens': [u'in', u'JSTOR', u'*', u'Pfizenmaier', u',', u'Thomas', u'C.', u'``', u'Was', u'Isaac', u'Newton', u'an', u'Arian', u'?'], u'lemmas': [u'in', u'JSTOR', u'*', u'Pfizenmaier', u',', u'Thomas', u'C.', u'``', u'be', u'Isaac', u'Newton', u'a', u'Arian', u'?'], u'pos': [u'IN', u'NNP', u'SYM', u'NNP', u',', u'NNP', u'NNP', u'``', u'VBD', u'NNP', u'NNP', u'DT', u'NNP', u'.'], u'char_offsets': [[48600, 48602], [48603, 48608], [48609, 48610], [48611, 48622], [48622, 48623], [48624, 48630], [48631, 48633], [48634, 48635], [48635, 48638], [48639, 48644], [48645, 48651], [48652, 48654], [48655, 48660], [48660, 48661]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.15292468667030334, {u'tokens': [u'Westfall', u'2007', u',', u'p.', u'73', u'One', u'of', u'Newton', u"'s", u'cases', u'as', u'the', u'King', u"'s", u'attorney', u'was', u'against', u'William', u'Chaloner', u'.'], u'lemmas': [u'Westfall', u'2007', u',', u'p.', u'73', u'one', u'of', u'Newton', u"'s", u'case', u'as', u'the', u'King', u"'s", u'attorney', u'be', u'against', u'William', u'Chaloner', u'.'], u'pos': [u'NNP', u'CD', u',', u'NN', u'CD', u'CD', u'IN', u'NNP', u'POS', u'NNS', u'IN', u'DT', u'NNP', u'POS', u'NN', u'VBD', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[38589, 38597], [38598, 38602], [38602, 38603], [38604, 38606], [38606, 38608], [38609, 38612], [38613, 38615], [38616, 38622], [38622, 38624], [38625, 38630], [38631, 38633], [38634, 38637], [38638, 38642], [38642, 38644], [38645, 38653], [38654, 38657], [38658, 38665], [38666, 38673], [38674, 38682], [38682, 38683]]}) 
answer: set([u'educate', u'grantham', u'schol'])
candidate Sentence: (0.14731311798095703, {u'tokens': [u'*', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'*', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[49861, 49862], [49862, 49868], [49868, 49869], [49870, 49875], [49875, 49876]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.14731311798095703, {u'tokens': [u'*', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'*', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[49344, 49345], [49346, 49352], [49352, 49353], [49354, 49359], [49359, 49360]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.14731311798095703, {u'tokens': [u'*', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'*', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[47281, 47282], [47283, 47289], [47289, 47290], [47291, 47296], [47296, 47297]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.11861536651849747, {u'tokens': [u'Isaac', u'Newton', u"'s", u'Natural', u'Philosophy', u'.'], u'lemmas': [u'Isaac', u'Newton', u"'s", u'natural', u'philosophy', u'.'], u'pos': [u'NNP', u'NNP', u'POS', u'JJ', u'NN', u'.'], u'char_offsets': [[46591, 46596], [46597, 46603], [46603, 46605], [46606, 46613], [46614, 46624], [46624, 46625]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.11849664896726608, {u'tokens': [u'Westfall', u'1994', u',', u'pp', u'16-19', u'Henry', u'Stokes', u',', u'master', u'at', u'the', u'King', u"'s", u'School', u',', u'persuaded', u'his', u'mother', u'to', u'send', u'him', u'back', u'to', u'school', u'so', u'that', u'he', u'might', u'complete', u'his', u'education', u'.'], u'lemmas': [u'Westfall', u'1994', u',', u'pp', u'16-19', u'Henry', u'Stokes', u',', u'master', u'at', u'the', u'King', u"'s", u'School', u',', u'persuade', u'he', u'mother', u'to', u'send', u'he', u'back', u'to', u'school', u'so', u'that', u'he', u'might', u'complete', u'he', u'education', u'.'], u'pos': [u'NNP', u'CD', u',', u'NN', u'CD', u'NNP', u'NNP', u',', u'NN', u'IN', u'DT', u'NNP', u'POS', u'NNP', u',', u'VBD', u'PRP$', u'NN', u'TO', u'VB', u'PRP', u'RB', u'TO', u'NN', u'IN', u'IN', u'PRP', u'MD', u'VB', u'PRP$', u'NN', u'.'], u'char_offsets': [[3706, 3714], [3715, 3719], [3719, 3720], [3721, 3723], [3724, 3729], [3731, 3736], [3737, 3743], [3743, 3744], [3745, 3751], [3752, 3754], [3755, 3758], [3759, 3763], [3763, 3765], [3766, 3772], [3772, 3773], [3774, 3783], [3784, 3787], [3788, 3794], [3795, 3797], [3798, 3802], [3803, 3806], [3807, 3811], [3812, 3814], [3815, 3821], [3822, 3824], [3825, 3829], [3830, 3832], [3833, 3838], [3839, 3847], [3848, 3851], [3852, 3861], [3861, 3862]]}) 
answer: set([u'educate', u'grantham', u'schol'])
candidate Sentence: (0.099781617522239685, {u'tokens': [u'**', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'**', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[49472, 49474], [49475, 49481], [49481, 49482], [49483, 49488], [49488, 49489]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])

Was Isaac Newton educated at The King's Schol, Grantham?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cef80>.answer
_____________________________ test_yesno[param160] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114cefc8>, (<src.tfidf.TF_IDF object at 0x10fd76290>, set(['isaac', 'isaac_newton', 'newton'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cefc8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.32071039080619812, {u'tokens': [u'NY', u':', u'Thomas', u'Y.', u'Crowell', u'&', u'Co.', u',', u'1889', u'-RRB-', u'From', u'the', u'age', u'of', u'about', u'twelve', u'until', u'he', u'was', u'seventeen', u',', u'Newton', u'was', u'educated', u'at', u'The', u'King', u"'s", u'School', u',', u'Grantham', u'-LRB-', u'where', u'his', u'signature', u'can', u'still', u'be', u'seen', u'upon', u'a', u'library', u'window', u'sill', u'-RRB-', u'.'], u'lemmas': [u'NY', u':', u'Thomas', u'Y.', u'Crowell', u'&', u'Co.', u',', u'1889', u'-rrb-', u'from', u'the', u'age', u'of', u'about', u'twelve', u'until', u'he', u'be', u'seventeen', u',', u'Newton', u'be', u'educate', u'at', u'the', u'King', u"'s", u'School', u',', u'Grantham', u'-lrb-', u'where', u'he', u'signature', u'can', u'still', u'be', u'see', u'upon', u'a', u'library', u'window', u'sill', u'-rrb-', u'.'], u'pos': [u'NNP', u':', u'NNP', u'NNP', u'NNP', u'CC', u'NNP', u',', u'CD', u'-RRB-', u'IN', u'DT', u'NN', u'IN', u'IN', u'CD', u'IN', u'PRP', u'VBD', u'CD', u',', u'NNP', u'VBD', u'VBN', u'IN', u'DT', u'NNP', u'POS', u'NNP', u',', u'NNP', u'-LRB-', u'WRB', u'PRP$', u'NN', u'MD', u'RB', u'VB', u'VBN', u'IN', u'DT', u'NN', u'NN', u'NN', u'-RRB-', u'.'], u'char_offsets': [[3294, 3296], [3296, 3297], [3298, 3304], [3305, 3307], [3308, 3315], [3316, 3317], [3318, 3321], [3321, 3322], [3323, 3327], [3327, 3328], [3329, 3333], [3334, 3337], [3338, 3341], [3342, 3344], [3345, 3350], [3351, 3357], [3358, 3363], [3364, 3366], [3367, 3370], [3371, 3380], [3380, 3381], [3382, 3388], [3389, 3392], [3393, 3401], [3402, 3404], [3405, 3408], [3409, 3413], [3413, 3415], [3416, 3422], [3422, 3423], [3424, 3432], [3433, 3434], [3434, 3439], [3440, 3443], [3444, 3453], [3454, 3457], [3458, 3463], [3464, 3466], [3467, 3471], [3472, 3476], [3477, 3478], [3479, 3486], [3487, 3493], [3494, 3498], [3498, 3499], [3499, 3500]]}) 
answer: set([u'schol'])
candidate Sentence: (0.25480198860168457, {u'tokens': [u'The', u'King', u"'s", u'School', u',', u'Grantham', u',', u'claims', u'that', u'the', u'tree', u'was', u'purchased', u'by', u'the', u'school', u',', u'uprooted', u'and', u'transported', u'to', u'the', u'headmaster', u"'s", u'garden', u'some', u'years', u'later', u'.'], u'lemmas': [u'the', u'King', u"'s", u'School', u',', u'Grantham', u',', u'claim', u'that', u'the', u'tree', u'be', u'purchase', u'by', u'the', u'school', u',', u'uproot', u'and', u'transport', u'to', u'the', u'headmaster', u"'s", u'garden', u'some', u'year', u'later', u'.'], u'pos': [u'DT', u'NNP', u'POS', u'NNP', u',', u'NNP', u',', u'VBZ', u'IN', u'DT', u'NN', u'VBD', u'VBN', u'IN', u'DT', u'NN', u',', u'VBN', u'CC', u'VBN', u'TO', u'DT', u'NN', u'POS', u'NN', u'DT', u'NNS', u'RB', u'.'], u'char_offsets': [[44724, 44727], [44728, 44732], [44732, 44734], [44735, 44741], [44741, 44742], [44743, 44751], [44751, 44752], [44753, 44759], [44760, 44764], [44765, 44768], [44769, 44773], [44774, 44777], [44778, 44787], [44788, 44790], [44791, 44794], [44795, 44801], [44801, 44802], [44803, 44811], [44812, 44815], [44816, 44827], [44828, 44830], [44831, 44834], [44835, 44845], [44845, 44847], [44848, 44854], [44855, 44859], [44860, 44865], [44866, 44871], [44871, 44872]]}) 
answer: set([u'educate', u'schol'])
candidate Sentence: (0.22604398429393768, {u'tokens': [u'in', u'JSTOR', u'*', u'Pfizenmaier', u',', u'Thomas', u'C.', u'``', u'Was', u'Isaac', u'Newton', u'an', u'Arian', u'?'], u'lemmas': [u'in', u'JSTOR', u'*', u'Pfizenmaier', u',', u'Thomas', u'C.', u'``', u'be', u'Isaac', u'Newton', u'a', u'Arian', u'?'], u'pos': [u'IN', u'NNP', u'SYM', u'NNP', u',', u'NNP', u'NNP', u'``', u'VBD', u'NNP', u'NNP', u'DT', u'NNP', u'.'], u'char_offsets': [[48600, 48602], [48603, 48608], [48609, 48610], [48611, 48622], [48622, 48623], [48624, 48630], [48631, 48633], [48634, 48635], [48635, 48638], [48639, 48644], [48645, 48651], [48652, 48654], [48655, 48660], [48660, 48661]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.15292468667030334, {u'tokens': [u'Westfall', u'2007', u',', u'p.', u'73', u'One', u'of', u'Newton', u"'s", u'cases', u'as', u'the', u'King', u"'s", u'attorney', u'was', u'against', u'William', u'Chaloner', u'.'], u'lemmas': [u'Westfall', u'2007', u',', u'p.', u'73', u'one', u'of', u'Newton', u"'s", u'case', u'as', u'the', u'King', u"'s", u'attorney', u'be', u'against', u'William', u'Chaloner', u'.'], u'pos': [u'NNP', u'CD', u',', u'NN', u'CD', u'CD', u'IN', u'NNP', u'POS', u'NNS', u'IN', u'DT', u'NNP', u'POS', u'NN', u'VBD', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[38589, 38597], [38598, 38602], [38602, 38603], [38604, 38606], [38606, 38608], [38609, 38612], [38613, 38615], [38616, 38622], [38622, 38624], [38625, 38630], [38631, 38633], [38634, 38637], [38638, 38642], [38642, 38644], [38645, 38653], [38654, 38657], [38658, 38665], [38666, 38673], [38674, 38682], [38682, 38683]]}) 
answer: set([u'educate', u'grantham', u'schol'])
candidate Sentence: (0.14731311798095703, {u'tokens': [u'*', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'*', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[49861, 49862], [49862, 49868], [49868, 49869], [49870, 49875], [49875, 49876]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.14731311798095703, {u'tokens': [u'*', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'*', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[49344, 49345], [49346, 49352], [49352, 49353], [49354, 49359], [49359, 49360]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.14731311798095703, {u'tokens': [u'*', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'*', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[47281, 47282], [47283, 47289], [47289, 47290], [47291, 47296], [47296, 47297]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.11861536651849747, {u'tokens': [u'Isaac', u'Newton', u"'s", u'Natural', u'Philosophy', u'.'], u'lemmas': [u'Isaac', u'Newton', u"'s", u'natural', u'philosophy', u'.'], u'pos': [u'NNP', u'NNP', u'POS', u'JJ', u'NN', u'.'], u'char_offsets': [[46591, 46596], [46597, 46603], [46603, 46605], [46606, 46613], [46614, 46624], [46624, 46625]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])
candidate Sentence: (0.11849664896726608, {u'tokens': [u'Westfall', u'1994', u',', u'pp', u'16-19', u'Henry', u'Stokes', u',', u'master', u'at', u'the', u'King', u"'s", u'School', u',', u'persuaded', u'his', u'mother', u'to', u'send', u'him', u'back', u'to', u'school', u'so', u'that', u'he', u'might', u'complete', u'his', u'education', u'.'], u'lemmas': [u'Westfall', u'1994', u',', u'pp', u'16-19', u'Henry', u'Stokes', u',', u'master', u'at', u'the', u'King', u"'s", u'School', u',', u'persuade', u'he', u'mother', u'to', u'send', u'he', u'back', u'to', u'school', u'so', u'that', u'he', u'might', u'complete', u'he', u'education', u'.'], u'pos': [u'NNP', u'CD', u',', u'NN', u'CD', u'NNP', u'NNP', u',', u'NN', u'IN', u'DT', u'NNP', u'POS', u'NNP', u',', u'VBD', u'PRP$', u'NN', u'TO', u'VB', u'PRP', u'RB', u'TO', u'NN', u'IN', u'IN', u'PRP', u'MD', u'VB', u'PRP$', u'NN', u'.'], u'char_offsets': [[3706, 3714], [3715, 3719], [3719, 3720], [3721, 3723], [3724, 3729], [3731, 3736], [3737, 3743], [3743, 3744], [3745, 3751], [3752, 3754], [3755, 3758], [3759, 3763], [3763, 3765], [3766, 3772], [3772, 3773], [3774, 3783], [3784, 3787], [3788, 3794], [3795, 3797], [3798, 3802], [3803, 3806], [3807, 3811], [3812, 3814], [3815, 3821], [3822, 3824], [3825, 3829], [3830, 3832], [3833, 3838], [3839, 3847], [3848, 3851], [3852, 3861], [3861, 3862]]}) 
answer: set([u'educate', u'grantham', u'schol'])
candidate Sentence: (0.099781617522239685, {u'tokens': [u'**', u'Newton', u',', u'Isaac', u'.'], u'lemmas': [u'**', u'Newton', u',', u'Isaac', u'.'], u'pos': [u'SYM', u'NNP', u',', u'NNP', u'.'], u'char_offsets': [[49472, 49474], [49475, 49481], [49481, 49482], [49483, 49488], [49488, 49489]]}) 
answer: set([u'king', u'educate', u'grantham', u'schol'])

Was Isaac Newton educated at The King's Schol, Grantham?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114cefc8>.answer
_____________________________ test_yesno[param161] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3050>, (<src.tfidf.TF_IDF object at 0x10e16fad0>, set(['jakarta'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d3050>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.38293623924255371, {u'tokens': [u'Jakarta', u"'s", u'Central', u'Business', u'District', u'along', u'the', u'Jenderal', u'Sudirman', u'Road', u',', u'centered', u'at', u'the', u'Wisma', u'46', u'building', u',', u'currently', u'the', u'tallest', u'office', u'building', u'in', u'Indonesia', u'.'], u'lemmas': [u'Jakarta', u"'s", u'Central', u'Business', u'District', u'along', u'the', u'Jenderal', u'Sudirman', u'Road', u',', u'center', u'at', u'the', u'Wisma', u'46', u'building', u',', u'currently', u'the', u'tallest', u'office', u'building', u'in', u'Indonesia', u'.'], u'pos': [u'NNP', u'POS', u'NNP', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u',', u'VBN', u'IN', u'DT', u'NNP', u'CD', u'NN', u',', u'RB', u'DT', u'JJS', u'NN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[22559, 22566], [22566, 22568], [22569, 22576], [22577, 22585], [22586, 22594], [22595, 22600], [22601, 22604], [22605, 22613], [22614, 22622], [22623, 22627], [22627, 22628], [22629, 22637], [22638, 22640], [22641, 22644], [22645, 22650], [22651, 22653], [22654, 22662], [22662, 22663], [22664, 22673], [22674, 22677], [22678, 22685], [22686, 22692], [22693, 22701], [22702, 22704], [22705, 22714], [22714, 22715]]}) 
answer: set([u'build'])
candidate Sentence: (0.28426390886306763, {u'tokens': [u'The', u'Wisma', u'46', u'building', u'in', u'Central', u'Jakarta', u'is', u'currently', u'the', u'highest', u'building', u'in', u'Jakarta', u'and', u'Indonesia', u'.'], u'lemmas': [u'the', u'Wisma', u'46', u'building', u'in', u'Central', u'Jakarta', u'be', u'currently', u'the', u'highest', u'building', u'in', u'Jakarta', u'and', u'Indonesia', u'.'], u'pos': [u'DT', u'NNP', u'CD', u'NN', u'IN', u'NNP', u'NNP', u'VBZ', u'RB', u'DT', u'JJS', u'NN', u'IN', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[22957, 22960], [22961, 22966], [22967, 22969], [22970, 22978], [22979, 22981], [22982, 22989], [22990, 22997], [22998, 23000], [23001, 23010], [23011, 23014], [23015, 23022], [23023, 23031], [23032, 23034], [23035, 23042], [23043, 23046], [23047, 23056], [23056, 23057]]}) 
answer: set([u'tallest', u'build'])
candidate Sentence: (0.18283633887767792, {u'tokens': [u'The', u'area', u'includes', u'Jakarta', u"'s", u'Chinatown', u'and', u'landmarks', u'include', u'the', u'Chinese', u'Langgam', u'building', u'and', u'the', u'Toko', u'Merah', u'building', u'.'], u'lemmas': [u'the', u'area', u'include', u'Jakarta', u"'s", u'Chinatown', u'and', u'landmark', u'include', u'the', u'chinese', u'langgam', u'building', u'and', u'the', u'Toko', u'Merah', u'building', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'NNP', u'POS', u'NNP', u'CC', u'NNS', u'VBP', u'DT', u'JJ', u'NN', u'NN', u'CC', u'DT', u'NNP', u'NNP', u'NN', u'.'], u'char_offsets': [[9011, 9014], [9015, 9019], [9020, 9028], [9029, 9036], [9036, 9038], [9039, 9048], [9049, 9052], [9053, 9062], [9063, 9070], [9071, 9074], [9075, 9082], [9083, 9090], [9091, 9099], [9100, 9103], [9104, 9107], [9108, 9112], [9113, 9118], [9119, 9127], [9127, 9128]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.16602367162704468, {u'tokens': [u'Jayawikarta', u'is', u'thought', u'to', u'have', u'made', u'trading', u'connections', u'with', u'the', u'English', u'merchants', u',', u'rivals', u'of', u'the', u'Dutch', u',', u'by', u'allowing', u'them', u'to', u'build', u'houses', u'directly', u'across', u'from', u'the', u'Dutch', u'buildings', u'in', u'1615', u'.'], u'lemmas': [u'Jayawikarta', u'be', u'think', u'to', u'have', u'make', u'trading', u'connection', u'with', u'the', u'English', u'merchant', u',', u'rival', u'of', u'the', u'Dutch', u',', u'by', u'allow', u'they', u'to', u'build', u'house', u'directly', u'across', u'from', u'the', u'dutch', u'building', u'in', u'1615', u'.'], u'pos': [u'NNP', u'VBZ', u'VBN', u'TO', u'VB', u'VBN', u'NN', u'NNS', u'IN', u'DT', u'NNP', u'NNS', u',', u'NNS', u'IN', u'DT', u'NNP', u',', u'IN', u'VBG', u'PRP', u'TO', u'VB', u'NNS', u'RB', u'IN', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'CD', u'.'], u'char_offsets': [[3444, 3455], [3456, 3458], [3459, 3466], [3467, 3469], [3470, 3474], [3475, 3479], [3480, 3487], [3488, 3499], [3500, 3504], [3505, 3508], [3509, 3516], [3517, 3526], [3526, 3527], [3528, 3534], [3535, 3537], [3538, 3541], [3542, 3547], [3547, 3548], [3549, 3551], [3552, 3560], [3561, 3565], [3566, 3568], [3569, 3574], [3575, 3581], [3582, 3590], [3591, 3597], [3598, 3602], [3603, 3606], [3607, 3612], [3613, 3622], [3623, 3625], [3626, 3630], [3630, 3631]]}) 
answer: set([u'wisma', u'indonesia', u'tallest'])
candidate Sentence: (0.1545906662940979, {u'tokens': [u'The', u'park', u'is', u'surrounded', u'by', u'several', u'Dutch', u'colonial', u'buildings', u'.'], u'lemmas': [u'the', u'park', u'be', u'surround', u'by', u'several', u'dutch', u'colonial', u'building', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'JJ', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[23691, 23694], [23695, 23699], [23700, 23702], [23703, 23713], [23714, 23716], [23717, 23724], [23725, 23730], [23731, 23739], [23740, 23749], [23749, 23750]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.15046511590480804, {u'tokens': [u'The', u'Senayan', u'complex', u'was', u'built', u'in', u'1959', u'to', u'accommodate', u'the', u'Asian', u'Games', u'in', u'1962', u'.'], u'lemmas': [u'the', u'senayan', u'complex', u'be', u'build', u'in', u'1959', u'to', u'accommodate', u'the', u'asian', u'Games', u'in', u'1962', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBD', u'VBN', u'IN', u'CD', u'TO', u'VB', u'DT', u'JJ', u'NNPS', u'IN', u'CD', u'.'], u'char_offsets': [[30328, 30331], [30332, 30339], [30340, 30347], [30348, 30351], [30352, 30357], [30358, 30360], [30361, 30365], [30366, 30368], [30369, 30380], [30381, 30384], [30385, 30390], [30391, 30396], [30397, 30399], [30400, 30404], [30404, 30405]]}) 
answer: set([u'building', u'wisma', u'indonesia', u'tallest'])
candidate Sentence: (0.14198429882526398, {u'tokens': [u'It', u'is', u'characterized', u'by', u'large', u'parks', u'and', u'Dutch', u'colonial', u'buildings', u'.'], u'lemmas': [u'it', u'be', u'characterize', u'by', u'large', u'park', u'and', u'dutch', u'colonial', u'building', u'.'], u'pos': [u'PRP', u'VBZ', u'VBN', u'IN', u'JJ', u'NNS', u'CC', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[8761, 8763], [8764, 8766], [8767, 8780], [8781, 8783], [8784, 8789], [8790, 8795], [8796, 8799], [8800, 8805], [8806, 8814], [8815, 8824], [8824, 8825]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.12776245176792145, {u'tokens': [u'The', u'building', u'now', u'serves', u'as', u'Jakarta', u'History', u'Museum', u',', u'Jakarta', u'Old', u'Town', u'area', u'.'], u'lemmas': [u'the', u'building', u'now', u'serve', u'as', u'Jakarta', u'history', u'museum', u',', u'Jakarta', u'Old', u'Town', u'area', u'.'], u'pos': [u'DT', u'NN', u'RB', u'VBZ', u'IN', u'NNP', u'NN', u'NN', u',', u'NNP', u'NNP', u'NNP', u'NN', u'.'], u'char_offsets': [[1481, 1484], [1485, 1493], [1494, 1497], [1498, 1504], [1505, 1507], [1508, 1515], [1516, 1523], [1524, 1530], [1530, 1531], [1532, 1539], [1540, 1543], [1544, 1548], [1549, 1553], [1553, 1554]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.12362903356552124, {u'tokens': [u'Dutch', u'Batavia', u'in', u'the', u'17th', u'Century', u',', u'built', u'in', u'what', u'is', u'now', u'North', u'Jakarta', u'The', u'Jakarta', u'area', u'was', u'part', u'of', u'the', u'fourth', u'century', u'Indianized', u'kingdom', u'of', u'Tarumanagara', u'.'], u'lemmas': [u'dutch', u'Batavia', u'in', u'the', u'17th', u'Century', u',', u'build', u'in', u'what', u'be', u'now', u'north', u'Jakarta', u'the', u'Jakarta', u'area', u'be', u'part', u'of', u'the', u'fourth', u'century', u'indianize', u'kingdom', u'of', u'Tarumanagara', u'.'], u'pos': [u'JJ', u'NNP', u'IN', u'DT', u'JJ', u'NNP', u',', u'VBN', u'IN', u'WP', u'VBZ', u'RB', u'JJ', u'NNP', u'DT', u'NNP', u'NN', u'VBD', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[1555, 1560], [1561, 1568], [1569, 1571], [1572, 1575], [1576, 1580], [1581, 1588], [1588, 1589], [1590, 1595], [1596, 1598], [1599, 1603], [1604, 1606], [1607, 1610], [1611, 1616], [1617, 1624], [1625, 1628], [1629, 1636], [1637, 1641], [1642, 1645], [1646, 1650], [1651, 1653], [1654, 1657], [1658, 1664], [1665, 1672], [1673, 1683], [1684, 1691], [1692, 1694], [1695, 1707], [1707, 1708]]}) 
answer: set([u'building', u'wisma', u'indonesia', u'tallest'])
candidate Sentence: (0.11915851384401321, {u'tokens': [u'The', u'Jakarta', u'Old', u'Town', u'contains', u'museums', u'that', u'are', u'former', u'institution', u'buildings', u'of', u'Batavia', u'.'], u'lemmas': [u'the', u'Jakarta', u'Old', u'Town', u'contain', u'museum', u'that', u'be', u'former', u'institution', u'building', u'of', u'Batavia', u'.'], u'pos': [u'DT', u'NNP', u'NNP', u'NNP', u'VBZ', u'NNS', u'WDT', u'VBP', u'JJ', u'NN', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[17579, 17582], [17583, 17590], [17591, 17594], [17595, 17599], [17600, 17608], [17609, 17616], [17617, 17621], [17622, 17625], [17626, 17632], [17633, 17644], [17645, 17654], [17655, 17657], [17658, 17665], [17665, 17666]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])

Is the Wisma building the tallest building in Indonesia?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d3050>.answer
_____________________________ test_yesno[param162] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3098>, (<src.tfidf.TF_IDF object at 0x10e16fad0>, set(['jakarta'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes,')
E                +    where 'Yes,' = <src.question_processing.Question_parser instance at 0x1114d3098>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.38293623924255371, {u'tokens': [u'Jakarta', u"'s", u'Central', u'Business', u'District', u'along', u'the', u'Jenderal', u'Sudirman', u'Road', u',', u'centered', u'at', u'the', u'Wisma', u'46', u'building', u',', u'currently', u'the', u'tallest', u'office', u'building', u'in', u'Indonesia', u'.'], u'lemmas': [u'Jakarta', u"'s", u'Central', u'Business', u'District', u'along', u'the', u'Jenderal', u'Sudirman', u'Road', u',', u'center', u'at', u'the', u'Wisma', u'46', u'building', u',', u'currently', u'the', u'tallest', u'office', u'building', u'in', u'Indonesia', u'.'], u'pos': [u'NNP', u'POS', u'NNP', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u',', u'VBN', u'IN', u'DT', u'NNP', u'CD', u'NN', u',', u'RB', u'DT', u'JJS', u'NN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[22559, 22566], [22566, 22568], [22569, 22576], [22577, 22585], [22586, 22594], [22595, 22600], [22601, 22604], [22605, 22613], [22614, 22622], [22623, 22627], [22627, 22628], [22629, 22637], [22638, 22640], [22641, 22644], [22645, 22650], [22651, 22653], [22654, 22662], [22662, 22663], [22664, 22673], [22674, 22677], [22678, 22685], [22686, 22692], [22693, 22701], [22702, 22704], [22705, 22714], [22714, 22715]]}) 
answer: set([u'build'])
candidate Sentence: (0.28426390886306763, {u'tokens': [u'The', u'Wisma', u'46', u'building', u'in', u'Central', u'Jakarta', u'is', u'currently', u'the', u'highest', u'building', u'in', u'Jakarta', u'and', u'Indonesia', u'.'], u'lemmas': [u'the', u'Wisma', u'46', u'building', u'in', u'Central', u'Jakarta', u'be', u'currently', u'the', u'highest', u'building', u'in', u'Jakarta', u'and', u'Indonesia', u'.'], u'pos': [u'DT', u'NNP', u'CD', u'NN', u'IN', u'NNP', u'NNP', u'VBZ', u'RB', u'DT', u'JJS', u'NN', u'IN', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[22957, 22960], [22961, 22966], [22967, 22969], [22970, 22978], [22979, 22981], [22982, 22989], [22990, 22997], [22998, 23000], [23001, 23010], [23011, 23014], [23015, 23022], [23023, 23031], [23032, 23034], [23035, 23042], [23043, 23046], [23047, 23056], [23056, 23057]]}) 
answer: set([u'tallest', u'build'])
candidate Sentence: (0.18283633887767792, {u'tokens': [u'The', u'area', u'includes', u'Jakarta', u"'s", u'Chinatown', u'and', u'landmarks', u'include', u'the', u'Chinese', u'Langgam', u'building', u'and', u'the', u'Toko', u'Merah', u'building', u'.'], u'lemmas': [u'the', u'area', u'include', u'Jakarta', u"'s", u'Chinatown', u'and', u'landmark', u'include', u'the', u'chinese', u'langgam', u'building', u'and', u'the', u'Toko', u'Merah', u'building', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'NNP', u'POS', u'NNP', u'CC', u'NNS', u'VBP', u'DT', u'JJ', u'NN', u'NN', u'CC', u'DT', u'NNP', u'NNP', u'NN', u'.'], u'char_offsets': [[9011, 9014], [9015, 9019], [9020, 9028], [9029, 9036], [9036, 9038], [9039, 9048], [9049, 9052], [9053, 9062], [9063, 9070], [9071, 9074], [9075, 9082], [9083, 9090], [9091, 9099], [9100, 9103], [9104, 9107], [9108, 9112], [9113, 9118], [9119, 9127], [9127, 9128]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.16602367162704468, {u'tokens': [u'Jayawikarta', u'is', u'thought', u'to', u'have', u'made', u'trading', u'connections', u'with', u'the', u'English', u'merchants', u',', u'rivals', u'of', u'the', u'Dutch', u',', u'by', u'allowing', u'them', u'to', u'build', u'houses', u'directly', u'across', u'from', u'the', u'Dutch', u'buildings', u'in', u'1615', u'.'], u'lemmas': [u'Jayawikarta', u'be', u'think', u'to', u'have', u'make', u'trading', u'connection', u'with', u'the', u'English', u'merchant', u',', u'rival', u'of', u'the', u'Dutch', u',', u'by', u'allow', u'they', u'to', u'build', u'house', u'directly', u'across', u'from', u'the', u'dutch', u'building', u'in', u'1615', u'.'], u'pos': [u'NNP', u'VBZ', u'VBN', u'TO', u'VB', u'VBN', u'NN', u'NNS', u'IN', u'DT', u'NNP', u'NNS', u',', u'NNS', u'IN', u'DT', u'NNP', u',', u'IN', u'VBG', u'PRP', u'TO', u'VB', u'NNS', u'RB', u'IN', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'CD', u'.'], u'char_offsets': [[3444, 3455], [3456, 3458], [3459, 3466], [3467, 3469], [3470, 3474], [3475, 3479], [3480, 3487], [3488, 3499], [3500, 3504], [3505, 3508], [3509, 3516], [3517, 3526], [3526, 3527], [3528, 3534], [3535, 3537], [3538, 3541], [3542, 3547], [3547, 3548], [3549, 3551], [3552, 3560], [3561, 3565], [3566, 3568], [3569, 3574], [3575, 3581], [3582, 3590], [3591, 3597], [3598, 3602], [3603, 3606], [3607, 3612], [3613, 3622], [3623, 3625], [3626, 3630], [3630, 3631]]}) 
answer: set([u'wisma', u'indonesia', u'tallest'])
candidate Sentence: (0.1545906662940979, {u'tokens': [u'The', u'park', u'is', u'surrounded', u'by', u'several', u'Dutch', u'colonial', u'buildings', u'.'], u'lemmas': [u'the', u'park', u'be', u'surround', u'by', u'several', u'dutch', u'colonial', u'building', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'JJ', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[23691, 23694], [23695, 23699], [23700, 23702], [23703, 23713], [23714, 23716], [23717, 23724], [23725, 23730], [23731, 23739], [23740, 23749], [23749, 23750]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.15046511590480804, {u'tokens': [u'The', u'Senayan', u'complex', u'was', u'built', u'in', u'1959', u'to', u'accommodate', u'the', u'Asian', u'Games', u'in', u'1962', u'.'], u'lemmas': [u'the', u'senayan', u'complex', u'be', u'build', u'in', u'1959', u'to', u'accommodate', u'the', u'asian', u'Games', u'in', u'1962', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBD', u'VBN', u'IN', u'CD', u'TO', u'VB', u'DT', u'JJ', u'NNPS', u'IN', u'CD', u'.'], u'char_offsets': [[30328, 30331], [30332, 30339], [30340, 30347], [30348, 30351], [30352, 30357], [30358, 30360], [30361, 30365], [30366, 30368], [30369, 30380], [30381, 30384], [30385, 30390], [30391, 30396], [30397, 30399], [30400, 30404], [30404, 30405]]}) 
answer: set([u'building', u'wisma', u'indonesia', u'tallest'])
candidate Sentence: (0.14198429882526398, {u'tokens': [u'It', u'is', u'characterized', u'by', u'large', u'parks', u'and', u'Dutch', u'colonial', u'buildings', u'.'], u'lemmas': [u'it', u'be', u'characterize', u'by', u'large', u'park', u'and', u'dutch', u'colonial', u'building', u'.'], u'pos': [u'PRP', u'VBZ', u'VBN', u'IN', u'JJ', u'NNS', u'CC', u'JJ', u'NN', u'NNS', u'.'], u'char_offsets': [[8761, 8763], [8764, 8766], [8767, 8780], [8781, 8783], [8784, 8789], [8790, 8795], [8796, 8799], [8800, 8805], [8806, 8814], [8815, 8824], [8824, 8825]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.12776245176792145, {u'tokens': [u'The', u'building', u'now', u'serves', u'as', u'Jakarta', u'History', u'Museum', u',', u'Jakarta', u'Old', u'Town', u'area', u'.'], u'lemmas': [u'the', u'building', u'now', u'serve', u'as', u'Jakarta', u'history', u'museum', u',', u'Jakarta', u'Old', u'Town', u'area', u'.'], u'pos': [u'DT', u'NN', u'RB', u'VBZ', u'IN', u'NNP', u'NN', u'NN', u',', u'NNP', u'NNP', u'NNP', u'NN', u'.'], u'char_offsets': [[1481, 1484], [1485, 1493], [1494, 1497], [1498, 1504], [1505, 1507], [1508, 1515], [1516, 1523], [1524, 1530], [1530, 1531], [1532, 1539], [1540, 1543], [1544, 1548], [1549, 1553], [1553, 1554]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])
candidate Sentence: (0.12362903356552124, {u'tokens': [u'Dutch', u'Batavia', u'in', u'the', u'17th', u'Century', u',', u'built', u'in', u'what', u'is', u'now', u'North', u'Jakarta', u'The', u'Jakarta', u'area', u'was', u'part', u'of', u'the', u'fourth', u'century', u'Indianized', u'kingdom', u'of', u'Tarumanagara', u'.'], u'lemmas': [u'dutch', u'Batavia', u'in', u'the', u'17th', u'Century', u',', u'build', u'in', u'what', u'be', u'now', u'north', u'Jakarta', u'the', u'Jakarta', u'area', u'be', u'part', u'of', u'the', u'fourth', u'century', u'indianize', u'kingdom', u'of', u'Tarumanagara', u'.'], u'pos': [u'JJ', u'NNP', u'IN', u'DT', u'JJ', u'NNP', u',', u'VBN', u'IN', u'WP', u'VBZ', u'RB', u'JJ', u'NNP', u'DT', u'NNP', u'NN', u'VBD', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[1555, 1560], [1561, 1568], [1569, 1571], [1572, 1575], [1576, 1580], [1581, 1588], [1588, 1589], [1590, 1595], [1596, 1598], [1599, 1603], [1604, 1606], [1607, 1610], [1611, 1616], [1617, 1624], [1625, 1628], [1629, 1636], [1637, 1641], [1642, 1645], [1646, 1650], [1651, 1653], [1654, 1657], [1658, 1664], [1665, 1672], [1673, 1683], [1684, 1691], [1692, 1694], [1695, 1707], [1707, 1708]]}) 
answer: set([u'building', u'wisma', u'indonesia', u'tallest'])
candidate Sentence: (0.11915851384401321, {u'tokens': [u'The', u'Jakarta', u'Old', u'Town', u'contains', u'museums', u'that', u'are', u'former', u'institution', u'buildings', u'of', u'Batavia', u'.'], u'lemmas': [u'the', u'Jakarta', u'Old', u'Town', u'contain', u'museum', u'that', u'be', u'former', u'institution', u'building', u'of', u'Batavia', u'.'], u'pos': [u'DT', u'NNP', u'NNP', u'NNP', u'VBZ', u'NNS', u'WDT', u'VBP', u'JJ', u'NN', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[17579, 17582], [17583, 17590], [17591, 17594], [17595, 17599], [17600, 17608], [17609, 17616], [17617, 17621], [17622, 17625], [17626, 17632], [17633, 17644], [17645, 17654], [17655, 17657], [17658, 17665], [17665, 17666]]}) 
answer: set([u'tallest', u'indonesia', u'wisma', u'build'])

Is the Wisma building the tallest building in Indonesia?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes,
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes,')
 +    where 'Yes,' = <src.question_processing.Question_parser instance at 0x1114d3098>.answer
_____________________________ test_yesno[param165] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3170>, (<src.tfidf.TF_IDF object at 0x10e16fad0>, set(['jakarta'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d3170>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.46456235647201538, {u'tokens': [u'The', u'metropolitan', u'area', u',', u'Jabodetabek', u',', u'is', u'the', u'second', u'largest', u'in', u'the', u'world', u'.'], u'lemmas': [u'the', u'metropolitan', u'area', u',', u'jabodetabek', u',', u'be', u'the', u'second', u'largest', u'in', u'the', u'world', u'.'], u'pos': [u'DT', u'JJ', u'NN', u',', u'NN', u',', u'VBZ', u'DT', u'JJ', u'JJS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[339, 342], [343, 355], [356, 360], [360, 361], [362, 373], [373, 374], [375, 377], [378, 381], [382, 388], [389, 396], [397, 399], [400, 403], [404, 409], [409, 410]]}) 
answer: set([u'city', u'12th'])
candidate Sentence: (0.38391271233558655, {u'tokens': [u'Jakarta', u'-LRB-', u'also', u'DKI', u'Jakarta', u'-RRB-', u'is', u'the', u'capital', u'and', u'largest', u'city', u'of', u'Indonesia', u'.'], u'lemmas': [u'Jakarta', u'-lrb-', u'also', u'DKI', u'Jakarta', u'-rrb-', u'be', u'the', u'capital', u'and', u'largest', u'city', u'of', u'Indonesia', u'.'], u'pos': [u'NNP', u'-LRB-', u'RB', u'NNP', u'NNP', u'-RRB-', u'VBZ', u'DT', u'NN', u'CC', u'JJS', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[0, 7], [8, 9], [9, 13], [14, 17], [18, 25], [25, 26], [27, 29], [30, 33], [34, 41], [42, 45], [46, 53], [54, 58], [59, 61], [62, 71], [71, 72]]}) 
answer: set([u'12th', u'world'])
candidate Sentence: (0.35539999604225159, {u'tokens': [u'The', u'population', u'of', u'greater', u'Jakarta', u'is', u'estimated', u'at', u'23', u'million', u',', u'making', u'it', u'the', u'second', u'largest', u'urban', u'area', u'in', u'the', u'world', u'.'], u'lemmas': [u'the', u'population', u'of', u'greater', u'Jakarta', u'be', u'estimate', u'at', u'23', u'million', u',', u'make', u'it', u'the', u'second', u'largest', u'urban', u'area', u'in', u'the', u'world', u'.'], u'pos': [u'DT', u'NN', u'IN', u'JJR', u'NNP', u'VBZ', u'VBN', u'IN', u'CD', u'CD', u',', u'VBG', u'PRP', u'DT', u'JJ', u'JJS', u'JJ', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[22077, 22080], [22081, 22091], [22092, 22094], [22095, 22102], [22103, 22110], [22111, 22113], [22114, 22123], [22124, 22126], [22127, 22129], [22130, 22137], [22137, 22138], [22139, 22145], [22146, 22148], [22149, 22152], [22153, 22159], [22160, 22167], [22168, 22173], [22174, 22178], [22179, 22181], [22182, 22185], [22186, 22191], [22191, 22192]]}) 
answer: set([u'city', u'12th'])
candidate Sentence: (0.32038417458534241, {u'tokens': [u'It', u'is', u'the', u'most', u'populous', u'city', u'in', u'Indonesia', u'and', u'Southeast', u'Asia', u',', u'and', u'is', u'the', u'twelfth-largest', u'city', u'in', u'the', u'world', u'.'], u'lemmas': [u'it', u'be', u'the', u'most', u'populous', u'city', u'in', u'Indonesia', u'and', u'Southeast', u'Asia', u',', u'and', u'be', u'the', u'twelfth-largest', u'city', u'in', u'the', u'world', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'RBS', u'JJ', u'NN', u'IN', u'NNP', u'CC', u'NNP', u'NNP', u',', u'CC', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[231, 233], [234, 236], [237, 240], [241, 245], [246, 254], [255, 259], [260, 262], [263, 272], [273, 276], [277, 286], [287, 291], [291, 292], [293, 296], [297, 299], [300, 303], [304, 319], [320, 324], [325, 327], [328, 331], [332, 337], [337, 338]]}) 
answer: set([u'12th', u'largest'])
candidate Sentence: (0.23952849209308624, {u'tokens': [u'Financial', u'services', u',', u'trade', u'and', u'manufacturing', u'are', u'the', u'largest', u'sectors', u'of', u'the', u'city', u"'s", u'economy', u'.'], u'lemmas': [u'Financial', u'service', u',', u'trade', u'and', u'manufacturing', u'be', u'the', u'largest', u'sector', u'of', u'the', u'city', u"'s", u'economy', u'.'], u'pos': [u'NNP', u'NNS', u',', u'NN', u'CC', u'NN', u'VBP', u'DT', u'JJS', u'NNS', u'IN', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[19474, 19483], [19484, 19492], [19492, 19493], [19494, 19499], [19500, 19503], [19504, 19517], [19518, 19521], [19522, 19525], [19526, 19533], [19534, 19541], [19542, 19544], [19545, 19548], [19549, 19553], [19553, 19555], [19556, 19563], [19563, 19564]]}) 
answer: set([u'12th', u'world'])
candidate Sentence: (0.22970418632030487, {u'tokens': [u'Jalan', u'Thamrin', u',', u'the', u'main', u'avenue', u'in', u'Central', u'Jakarta', u'One', u'of', u'the', u'most', u'populous', u'cities', u'in', u'the', u'world', u',', u'Jakarta', u'is', u'strained', u'by', u'transportation', u'problems', u'.'], u'lemmas': [u'Jalan', u'Thamrin', u',', u'the', u'main', u'avenue', u'in', u'Central', u'Jakarta', u'one', u'of', u'the', u'most', u'populous', u'city', u'in', u'the', u'world', u',', u'Jakarta', u'be', u'strain', u'by', u'transportation', u'problem', u'.'], u'pos': [u'NNP', u'NNP', u',', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'CD', u'IN', u'DT', u'RBS', u'JJ', u'NNS', u'IN', u'DT', u'NN', u',', u'NNP', u'VBZ', u'VBN', u'IN', u'NN', u'NNS', u'.'], u'char_offsets': [[25074, 25079], [25080, 25087], [25087, 25088], [25089, 25092], [25093, 25097], [25098, 25104], [25105, 25107], [25108, 25115], [25116, 25123], [25124, 25127], [25128, 25130], [25131, 25134], [25135, 25139], [25140, 25148], [25149, 25155], [25156, 25158], [25159, 25162], [25163, 25168], [25168, 25169], [25170, 25177], [25178, 25180], [25181, 25189], [25190, 25192], [25193, 25207], [25208, 25216], [25216, 25217]]}) 
answer: set([u'12th', u'largest'])
candidate Sentence: (0.22298970818519592, {u'tokens': [u'Jakarta', u'is', u'listed', u'as', u'a', u'global', u'city', u'in', u'the', u'2008', u'Globalization', u'and', u'World', u'Cities', u'Study', u'Group', u'and', u'Network', u'-LRB-', u'GaWC', u'-RRB-', u'research', u'.'], u'lemmas': [u'Jakarta', u'be', u'list', u'as', u'a', u'global', u'city', u'in', u'the', u'2008', u'globalization', u'and', u'world', u'city', u'Study', u'Group', u'and', u'Network', u'-lrb-', u'GaWC', u'-rrb-', u'research', u'.'], u'pos': [u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'CD', u'NN', u'CC', u'NN', u'NNS', u'NNP', u'NNP', u'CC', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u'NN', u'.'], u'char_offsets': [[411, 418], [419, 421], [422, 428], [429, 431], [432, 433], [434, 440], [441, 445], [446, 448], [449, 452], [453, 457], [458, 471], [472, 475], [476, 481], [482, 488], [489, 494], [495, 500], [501, 504], [505, 512], [513, 514], [514, 518], [518, 519], [520, 528], [528, 529]]}) 
answer: set([u'12th', u'largest'])
candidate Sentence: (0.16407212615013123, {u'tokens': [u'As', u'the', u'largest', u'city', u'and', u'the', u'capital', u',', u'Jakarta', u'houses', u'a', u'large', u'number', u'of', u'students', u'from', u'various', u'parts', u'of', u'Indonesia', u',', u'many', u'of', u'whom', u'reside', u'in', u'dormitories', u'or', u'home-stay', u'residences', u'.'], u'lemmas': [u'as', u'the', u'largest', u'city', u'and', u'the', u'capital', u',', u'Jakarta', u'house', u'a', u'large', u'number', u'of', u'student', u'from', u'various', u'part', u'of', u'Indonesia', u',', u'many', u'of', u'whom', u'reside', u'in', u'dormitory', u'or', u'home-stay', u'residence', u'.'], u'pos': [u'IN', u'DT', u'JJS', u'NN', u'CC', u'DT', u'NN', u',', u'NNP', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'NNS', u'IN', u'JJ', u'NNS', u'IN', u'NNP', u',', u'JJ', u'IN', u'WP', u'VBP', u'IN', u'NNS', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[28975, 28977], [28978, 28981], [28982, 28989], [28990, 28994], [28995, 28998], [28999, 29002], [29003, 29010], [29010, 29011], [29012, 29019], [29020, 29026], [29027, 29028], [29029, 29034], [29035, 29041], [29042, 29044], [29045, 29053], [29054, 29058], [29059, 29066], [29067, 29072], [29073, 29075], [29076, 29085], [29085, 29086], [29087, 29091], [29092, 29094], [29095, 29099], [29100, 29106], [29107, 29109], [29110, 29121], [29122, 29124], [29125, 29134], [29135, 29145], [29145, 29146]]}) 
answer: set([u'world', u'12th'])
candidate Sentence: (0.1478235274553299, {u'tokens': [u'The', u'biggest', u'stadium', u'in', u'Jakarta', u'is', u'the', u'Bung', u'Karno', u'Stadium', u'with', u'a', u'capacity', u'of', u'100,000', u'seats', u'Football', u'stadiums', u'of', u'the', u'world', u'-', u'Stadiums', u'in', u'Indonesia', u'.'], u'lemmas': [u'the', u'biggest', u'stadium', u'in', u'Jakarta', u'be', u'the', u'Bung', u'Karno', u'Stadium', u'with', u'a', u'capacity', u'of', u'100,000', u'seat', u'football', u'stadium', u'of', u'the', u'world', u'-', u'stadium', u'in', u'Indonesia', u'.'], u'pos': [u'DT', u'JJS', u'NN', u'IN', u'NNP', u'VBZ', u'DT', u'NNP', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'CD', u'NNS', u'NN', u'NNS', u'IN', u'DT', u'NN', u':', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[29822, 29825], [29826, 29833], [29834, 29841], [29842, 29844], [29845, 29852], [29853, 29855], [29856, 29859], [29860, 29864], [29865, 29870], [29871, 29878], [29879, 29883], [29884, 29885], [29886, 29894], [29895, 29897], [29898, 29905], [29906, 29911], [29913, 29921], [29922, 29930], [29931, 29933], [29934, 29937], [29938, 29943], [29944, 29945], [29946, 29954], [29955, 29957], [29958, 29967], [29969, 29970]]}) 
answer: set([u'city', u'largest', u'12th'])
candidate Sentence: (0.13914389908313751, {u'tokens': [u'As', u'the', u'nation', u"'s", u'largest', u'city', u'and', u'capital', u',', u'Jakarta', u'has', u'lured', u'much', u'national', u'and', u'regional', u'talent', u'who', u'hope', u'to', u'find', u'a', u'greater', u'audience', u'and', u'more', u'opportunities', u'for', u'success', u'.'], u'lemmas': [u'as', u'the', u'nation', u"'s", u'largest', u'city', u'and', u'capital', u',', u'Jakarta', u'have', u'lure', u'much', u'national', u'and', u'regional', u'talent', u'who', u'hope', u'to', u'find', u'a', u'greater', u'audience', u'and', u'more', u'opportunity', u'for', u'success', u'.'], u'pos': [u'IN', u'DT', u'NN', u'POS', u'JJS', u'NN', u'CC', u'NN', u',', u'NNP', u'VBZ', u'VBN', u'JJ', u'JJ', u'CC', u'JJ', u'NN', u'WP', u'VBP', u'TO', u'VB', u'DT', u'JJR', u'NN', u'CC', u'JJR', u'NNS', u'IN', u'NN', u'.'], u'char_offsets': [[16114, 16116], [16117, 16120], [16121, 16127], [16127, 16129], [16130, 16137], [16138, 16142], [16143, 16146], [16147, 16154], [16154, 16155], [16156, 16163], [16164, 16167], [16168, 16173], [16174, 16178], [16179, 16187], [16188, 16191], [16192, 16200], [16201, 16207], [16208, 16211], [16212, 16216], [16217, 16219], [16220, 16224], [16225, 16226], [16227, 16234], [16235, 16243], [16244, 16247], [16248, 16252], [16253, 16266], [16267, 16270], [16271, 16278], [16278, 16279]]}) 
answer: set([u'12th', u'world'])

Is Jakarta the 12th largest city in the world?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d3170>.answer
_____________________________ test_yesno[param166] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d31b8>, (<src.tfidf.TF_IDF object at 0x10e16fad0>, set(['jakarta'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114d31b8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.46456235647201538, {u'tokens': [u'The', u'metropolitan', u'area', u',', u'Jabodetabek', u',', u'is', u'the', u'second', u'largest', u'in', u'the', u'world', u'.'], u'lemmas': [u'the', u'metropolitan', u'area', u',', u'jabodetabek', u',', u'be', u'the', u'second', u'largest', u'in', u'the', u'world', u'.'], u'pos': [u'DT', u'JJ', u'NN', u',', u'NN', u',', u'VBZ', u'DT', u'JJ', u'JJS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[339, 342], [343, 355], [356, 360], [360, 361], [362, 373], [373, 374], [375, 377], [378, 381], [382, 388], [389, 396], [397, 399], [400, 403], [404, 409], [409, 410]]}) 
answer: set([u'city', u'12th'])
candidate Sentence: (0.38391271233558655, {u'tokens': [u'Jakarta', u'-LRB-', u'also', u'DKI', u'Jakarta', u'-RRB-', u'is', u'the', u'capital', u'and', u'largest', u'city', u'of', u'Indonesia', u'.'], u'lemmas': [u'Jakarta', u'-lrb-', u'also', u'DKI', u'Jakarta', u'-rrb-', u'be', u'the', u'capital', u'and', u'largest', u'city', u'of', u'Indonesia', u'.'], u'pos': [u'NNP', u'-LRB-', u'RB', u'NNP', u'NNP', u'-RRB-', u'VBZ', u'DT', u'NN', u'CC', u'JJS', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[0, 7], [8, 9], [9, 13], [14, 17], [18, 25], [25, 26], [27, 29], [30, 33], [34, 41], [42, 45], [46, 53], [54, 58], [59, 61], [62, 71], [71, 72]]}) 
answer: set([u'12th', u'world'])
candidate Sentence: (0.35539999604225159, {u'tokens': [u'The', u'population', u'of', u'greater', u'Jakarta', u'is', u'estimated', u'at', u'23', u'million', u',', u'making', u'it', u'the', u'second', u'largest', u'urban', u'area', u'in', u'the', u'world', u'.'], u'lemmas': [u'the', u'population', u'of', u'greater', u'Jakarta', u'be', u'estimate', u'at', u'23', u'million', u',', u'make', u'it', u'the', u'second', u'largest', u'urban', u'area', u'in', u'the', u'world', u'.'], u'pos': [u'DT', u'NN', u'IN', u'JJR', u'NNP', u'VBZ', u'VBN', u'IN', u'CD', u'CD', u',', u'VBG', u'PRP', u'DT', u'JJ', u'JJS', u'JJ', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[22077, 22080], [22081, 22091], [22092, 22094], [22095, 22102], [22103, 22110], [22111, 22113], [22114, 22123], [22124, 22126], [22127, 22129], [22130, 22137], [22137, 22138], [22139, 22145], [22146, 22148], [22149, 22152], [22153, 22159], [22160, 22167], [22168, 22173], [22174, 22178], [22179, 22181], [22182, 22185], [22186, 22191], [22191, 22192]]}) 
answer: set([u'city', u'12th'])
candidate Sentence: (0.32038417458534241, {u'tokens': [u'It', u'is', u'the', u'most', u'populous', u'city', u'in', u'Indonesia', u'and', u'Southeast', u'Asia', u',', u'and', u'is', u'the', u'twelfth-largest', u'city', u'in', u'the', u'world', u'.'], u'lemmas': [u'it', u'be', u'the', u'most', u'populous', u'city', u'in', u'Indonesia', u'and', u'Southeast', u'Asia', u',', u'and', u'be', u'the', u'twelfth-largest', u'city', u'in', u'the', u'world', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'RBS', u'JJ', u'NN', u'IN', u'NNP', u'CC', u'NNP', u'NNP', u',', u'CC', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[231, 233], [234, 236], [237, 240], [241, 245], [246, 254], [255, 259], [260, 262], [263, 272], [273, 276], [277, 286], [287, 291], [291, 292], [293, 296], [297, 299], [300, 303], [304, 319], [320, 324], [325, 327], [328, 331], [332, 337], [337, 338]]}) 
answer: set([u'12th', u'largest'])
candidate Sentence: (0.23952849209308624, {u'tokens': [u'Financial', u'services', u',', u'trade', u'and', u'manufacturing', u'are', u'the', u'largest', u'sectors', u'of', u'the', u'city', u"'s", u'economy', u'.'], u'lemmas': [u'Financial', u'service', u',', u'trade', u'and', u'manufacturing', u'be', u'the', u'largest', u'sector', u'of', u'the', u'city', u"'s", u'economy', u'.'], u'pos': [u'NNP', u'NNS', u',', u'NN', u'CC', u'NN', u'VBP', u'DT', u'JJS', u'NNS', u'IN', u'DT', u'NN', u'POS', u'NN', u'.'], u'char_offsets': [[19474, 19483], [19484, 19492], [19492, 19493], [19494, 19499], [19500, 19503], [19504, 19517], [19518, 19521], [19522, 19525], [19526, 19533], [19534, 19541], [19542, 19544], [19545, 19548], [19549, 19553], [19553, 19555], [19556, 19563], [19563, 19564]]}) 
answer: set([u'12th', u'world'])
candidate Sentence: (0.22970418632030487, {u'tokens': [u'Jalan', u'Thamrin', u',', u'the', u'main', u'avenue', u'in', u'Central', u'Jakarta', u'One', u'of', u'the', u'most', u'populous', u'cities', u'in', u'the', u'world', u',', u'Jakarta', u'is', u'strained', u'by', u'transportation', u'problems', u'.'], u'lemmas': [u'Jalan', u'Thamrin', u',', u'the', u'main', u'avenue', u'in', u'Central', u'Jakarta', u'one', u'of', u'the', u'most', u'populous', u'city', u'in', u'the', u'world', u',', u'Jakarta', u'be', u'strain', u'by', u'transportation', u'problem', u'.'], u'pos': [u'NNP', u'NNP', u',', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'CD', u'IN', u'DT', u'RBS', u'JJ', u'NNS', u'IN', u'DT', u'NN', u',', u'NNP', u'VBZ', u'VBN', u'IN', u'NN', u'NNS', u'.'], u'char_offsets': [[25074, 25079], [25080, 25087], [25087, 25088], [25089, 25092], [25093, 25097], [25098, 25104], [25105, 25107], [25108, 25115], [25116, 25123], [25124, 25127], [25128, 25130], [25131, 25134], [25135, 25139], [25140, 25148], [25149, 25155], [25156, 25158], [25159, 25162], [25163, 25168], [25168, 25169], [25170, 25177], [25178, 25180], [25181, 25189], [25190, 25192], [25193, 25207], [25208, 25216], [25216, 25217]]}) 
answer: set([u'12th', u'largest'])
candidate Sentence: (0.22298970818519592, {u'tokens': [u'Jakarta', u'is', u'listed', u'as', u'a', u'global', u'city', u'in', u'the', u'2008', u'Globalization', u'and', u'World', u'Cities', u'Study', u'Group', u'and', u'Network', u'-LRB-', u'GaWC', u'-RRB-', u'research', u'.'], u'lemmas': [u'Jakarta', u'be', u'list', u'as', u'a', u'global', u'city', u'in', u'the', u'2008', u'globalization', u'and', u'world', u'city', u'Study', u'Group', u'and', u'Network', u'-lrb-', u'GaWC', u'-rrb-', u'research', u'.'], u'pos': [u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'CD', u'NN', u'CC', u'NN', u'NNS', u'NNP', u'NNP', u'CC', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u'NN', u'.'], u'char_offsets': [[411, 418], [419, 421], [422, 428], [429, 431], [432, 433], [434, 440], [441, 445], [446, 448], [449, 452], [453, 457], [458, 471], [472, 475], [476, 481], [482, 488], [489, 494], [495, 500], [501, 504], [505, 512], [513, 514], [514, 518], [518, 519], [520, 528], [528, 529]]}) 
answer: set([u'12th', u'largest'])
candidate Sentence: (0.16407212615013123, {u'tokens': [u'As', u'the', u'largest', u'city', u'and', u'the', u'capital', u',', u'Jakarta', u'houses', u'a', u'large', u'number', u'of', u'students', u'from', u'various', u'parts', u'of', u'Indonesia', u',', u'many', u'of', u'whom', u'reside', u'in', u'dormitories', u'or', u'home-stay', u'residences', u'.'], u'lemmas': [u'as', u'the', u'largest', u'city', u'and', u'the', u'capital', u',', u'Jakarta', u'house', u'a', u'large', u'number', u'of', u'student', u'from', u'various', u'part', u'of', u'Indonesia', u',', u'many', u'of', u'whom', u'reside', u'in', u'dormitory', u'or', u'home-stay', u'residence', u'.'], u'pos': [u'IN', u'DT', u'JJS', u'NN', u'CC', u'DT', u'NN', u',', u'NNP', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'NNS', u'IN', u'JJ', u'NNS', u'IN', u'NNP', u',', u'JJ', u'IN', u'WP', u'VBP', u'IN', u'NNS', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[28975, 28977], [28978, 28981], [28982, 28989], [28990, 28994], [28995, 28998], [28999, 29002], [29003, 29010], [29010, 29011], [29012, 29019], [29020, 29026], [29027, 29028], [29029, 29034], [29035, 29041], [29042, 29044], [29045, 29053], [29054, 29058], [29059, 29066], [29067, 29072], [29073, 29075], [29076, 29085], [29085, 29086], [29087, 29091], [29092, 29094], [29095, 29099], [29100, 29106], [29107, 29109], [29110, 29121], [29122, 29124], [29125, 29134], [29135, 29145], [29145, 29146]]}) 
answer: set([u'world', u'12th'])
candidate Sentence: (0.1478235274553299, {u'tokens': [u'The', u'biggest', u'stadium', u'in', u'Jakarta', u'is', u'the', u'Bung', u'Karno', u'Stadium', u'with', u'a', u'capacity', u'of', u'100,000', u'seats', u'Football', u'stadiums', u'of', u'the', u'world', u'-', u'Stadiums', u'in', u'Indonesia', u'.'], u'lemmas': [u'the', u'biggest', u'stadium', u'in', u'Jakarta', u'be', u'the', u'Bung', u'Karno', u'Stadium', u'with', u'a', u'capacity', u'of', u'100,000', u'seat', u'football', u'stadium', u'of', u'the', u'world', u'-', u'stadium', u'in', u'Indonesia', u'.'], u'pos': [u'DT', u'JJS', u'NN', u'IN', u'NNP', u'VBZ', u'DT', u'NNP', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'CD', u'NNS', u'NN', u'NNS', u'IN', u'DT', u'NN', u':', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[29822, 29825], [29826, 29833], [29834, 29841], [29842, 29844], [29845, 29852], [29853, 29855], [29856, 29859], [29860, 29864], [29865, 29870], [29871, 29878], [29879, 29883], [29884, 29885], [29886, 29894], [29895, 29897], [29898, 29905], [29906, 29911], [29913, 29921], [29922, 29930], [29931, 29933], [29934, 29937], [29938, 29943], [29944, 29945], [29946, 29954], [29955, 29957], [29958, 29967], [29969, 29970]]}) 
answer: set([u'city', u'largest', u'12th'])
candidate Sentence: (0.13914389908313751, {u'tokens': [u'As', u'the', u'nation', u"'s", u'largest', u'city', u'and', u'capital', u',', u'Jakarta', u'has', u'lured', u'much', u'national', u'and', u'regional', u'talent', u'who', u'hope', u'to', u'find', u'a', u'greater', u'audience', u'and', u'more', u'opportunities', u'for', u'success', u'.'], u'lemmas': [u'as', u'the', u'nation', u"'s", u'largest', u'city', u'and', u'capital', u',', u'Jakarta', u'have', u'lure', u'much', u'national', u'and', u'regional', u'talent', u'who', u'hope', u'to', u'find', u'a', u'greater', u'audience', u'and', u'more', u'opportunity', u'for', u'success', u'.'], u'pos': [u'IN', u'DT', u'NN', u'POS', u'JJS', u'NN', u'CC', u'NN', u',', u'NNP', u'VBZ', u'VBN', u'JJ', u'JJ', u'CC', u'JJ', u'NN', u'WP', u'VBP', u'TO', u'VB', u'DT', u'JJR', u'NN', u'CC', u'JJR', u'NNS', u'IN', u'NN', u'.'], u'char_offsets': [[16114, 16116], [16117, 16120], [16121, 16127], [16127, 16129], [16130, 16137], [16138, 16142], [16143, 16146], [16147, 16154], [16154, 16155], [16156, 16163], [16164, 16167], [16168, 16173], [16174, 16178], [16179, 16187], [16188, 16191], [16192, 16200], [16201, 16207], [16208, 16211], [16212, 16216], [16217, 16219], [16220, 16224], [16225, 16226], [16227, 16234], [16235, 16243], [16244, 16247], [16248, 16252], [16253, 16266], [16267, 16270], [16271, 16278], [16278, 16279]]}) 
answer: set([u'12th', u'world'])

Is Jakarta the 12th largest city in the world?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114d31b8>.answer
_____________________________ test_yesno[param186] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3758>, (<src.tfidf.TF_IDF object at 0x10e16f150>, set(['kuala', 'kuala_lumpur', 'lumpur'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3758>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.36749625205993652, {u'tokens': [u'Kuala', u'Lumpur', u'is', u'home', u'to', u'the', u'Parliament', u'of', u'Malaysia', u'.'], u'lemmas': [u'Kuala', u'Lumpur', u'be', u'home', u'to', u'the', u'Parliament', u'of', u'Malaysia', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'NN', u'TO', u'DT', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[12855, 12860], [12861, 12867], [12868, 12870], [12871, 12875], [12876, 12878], [12879, 12882], [12883, 12893], [12894, 12896], [12897, 12905], [12905, 12906]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.36584106087684631, {u'tokens': [u'Kuala', u'Lumpur', u'is', u'the', u'seat', u'of', u'the', u'Parliament', u'of', u'Malaysia', u'.'], u'lemmas': [u'Kuala', u'Lumpur', u'be', u'the', u'seat', u'of', u'the', u'Parliament', u'of', u'Malaysia', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'DT', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[583, 588], [589, 595], [596, 598], [599, 602], [603, 607], [608, 610], [611, 614], [615, 625], [626, 628], [629, 637], [637, 638]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.25351014733314514, {u'tokens': [u'As', u'capital', u'of', u'Malaysia', u',', u'Kuala', u'Lumpur', u'has', u'a', u'comprehensive', u'road', u'network', u'that', u'leads', u'to', u'the', u'rest', u'of', u'Peninsular', u'Malaysia', u'.'], u'lemmas': [u'as', u'capital', u'of', u'Malaysia', u',', u'Kuala', u'Lumpur', u'have', u'a', u'comprehensive', u'road', u'network', u'that', u'lead', u'to', u'the', u'rest', u'of', u'Peninsular', u'Malaysia', u'.'], u'pos': [u'IN', u'NN', u'IN', u'NNP', u',', u'NNP', u'NNP', u'VBZ', u'DT', u'JJ', u'NN', u'NN', u'WDT', u'VBZ', u'TO', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[35719, 35721], [35722, 35729], [35730, 35732], [35733, 35741], [35741, 35742], [35743, 35748], [35749, 35755], [35756, 35759], [35760, 35761], [35762, 35775], [35776, 35780], [35781, 35788], [35789, 35793], [35794, 35799], [35800, 35802], [35803, 35806], [35807, 35811], [35812, 35814], [35815, 35825], [35826, 35834], [35834, 35835]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.21190264821052551, {u'tokens': [u'Bursa', u'Malaysia', u'or', u'the', u'Malaysia', u'Exchange', u'is', u'based', u'in', u'the', u'city', u'and', u'forms', u'one', u'of', u'its', u'core', u'economic', u'activities', u'.'], u'lemmas': [u'Bursa', u'Malaysia', u'or', u'the', u'Malaysia', u'Exchange', u'be', u'base', u'in', u'the', u'city', u'and', u'form', u'one', u'of', u'its', u'core', u'economic', u'activity', u'.'], u'pos': [u'NNP', u'NNP', u'CC', u'DT', u'NNP', u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'CC', u'VBZ', u'CD', u'IN', u'PRP$', u'JJ', u'JJ', u'NNS', u'.'], u'char_offsets': [[14635, 14640], [14641, 14649], [14650, 14652], [14653, 14656], [14657, 14665], [14666, 14674], [14675, 14677], [14678, 14683], [14684, 14686], [14687, 14690], [14691, 14695], [14696, 14699], [14700, 14705], [14706, 14709], [14710, 14712], [14713, 14716], [14717, 14721], [14722, 14730], [14731, 14741], [14741, 14742]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.19721844792366028, {u'tokens': [u'TM', u'Tower', u'is', u'the', u'headquarters', u'of', u'Malaysia', u"'s", u'principal', u'telecommunication', u'service', u'provider', u',', u'Telekom', u'Malaysia', u'.'], u'lemmas': [u'TM', u'Tower', u'be', u'the', u'headquarters', u'of', u'Malaysia', u"'s", u'principal', u'telecommunication', u'service', u'provider', u',', u'Telekom', u'Malaysia', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'NNP', u'POS', u'JJ', u'NN', u'NN', u'NN', u',', u'NNP', u'NNP', u'.'], u'char_offsets': [[33211, 33213], [33214, 33219], [33220, 33222], [33223, 33226], [33227, 33239], [33240, 33242], [33243, 33251], [33251, 33253], [33254, 33263], [33264, 33281], [33282, 33289], [33290, 33298], [33298, 33299], [33300, 33307], [33308, 33316], [33316, 33317]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.19366438686847687, {u'tokens': [u'Since', u'2000', u',', u'the', u'Ministry', u'of', u'Tourism', u'of', u'Malaysia', u'has', u'kick-started', u'the', u'mega', u'sale', u'event', u'for', u'all', u'shopping', u'in', u'Malaysia', u'.'], u'lemmas': [u'since', u'2000', u',', u'the', u'Ministry', u'of', u'Tourism', u'of', u'Malaysia', u'have', u'kick-start', u'the', u'mega', u'sale', u'event', u'for', u'all', u'shopping', u'in', u'Malaysia', u'.'], u'pos': [u'IN', u'CD', u',', u'DT', u'NNP', u'IN', u'NNP', u'IN', u'NNP', u'VBZ', u'VBN', u'DT', u'JJ', u'NN', u'NN', u'IN', u'DT', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[22736, 22741], [22742, 22746], [22746, 22747], [22748, 22751], [22752, 22760], [22761, 22763], [22764, 22771], [22772, 22774], [22775, 22783], [22784, 22787], [22788, 22800], [22801, 22804], [22805, 22809], [22810, 22814], [22815, 22820], [22821, 22824], [22825, 22828], [22829, 22837], [22838, 22840], [22841, 22849], [22849, 22850]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.18492060899734497, {u'tokens': [u'Kuala', u'Lumpur', u'City', u'Centre', u'Park', u'Kuala', u'Lumpur', u'also', u'has', u'a', u'mix', u'of', u'different', u'cultures', u'which', u'include', u'Malays', u',', u'Chinese', u',', u'Indians', u',', u'Eurasians', u',', u'as', u'well', u'as', u'Kadazans', u',', u'Ibans', u'and', u'other', u'indigenous', u'races', u'from', u'East', u'Malaysia', u'and', u'Peninsula', u'Malaysia', u'.'], u'lemmas': [u'Kuala', u'Lumpur', u'City', u'Centre', u'Park', u'Kuala', u'Lumpur', u'also', u'have', u'a', u'mix', u'of', u'different', u'culture', u'which', u'include', u'Malays', u',', u'Chinese', u',', u'Indians', u',', u'Eurasians', u',', u'as', u'well', u'as', u'Kadazans', u',', u'Ibans', u'and', u'other', u'indigenous', u'race', u'from', u'East', u'Malaysia', u'and', u'Peninsula', u'Malaysia', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'RB', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'WDT', u'VBP', u'NNP', u',', u'NNP', u',', u'NNPS', u',', u'NNPS', u',', u'RB', u'RB', u'IN', u'NNP', u',', u'NNP', u'CC', u'JJ', u'JJ', u'NNS', u'IN', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u'.'], u'char_offsets': [[9023, 9028], [9029, 9035], [9036, 9040], [9041, 9047], [9048, 9052], [9053, 9058], [9059, 9065], [9066, 9070], [9071, 9074], [9075, 9076], [9077, 9080], [9081, 9083], [9084, 9093], [9094, 9102], [9103, 9108], [9109, 9116], [9117, 9123], [9123, 9124], [9125, 9132], [9132, 9133], [9134, 9141], [9141, 9142], [9143, 9152], [9152, 9153], [9154, 9156], [9157, 9161], [9162, 9164], [9165, 9173], [9173, 9174], [9175, 9180], [9181, 9184], [9185, 9190], [9191, 9201], [9202, 9207], [9208, 9212], [9213, 9217], [9218, 9226], [9227, 9230], [9231, 9240], [9241, 9249], [9249, 9250]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.17992788553237915, {u'tokens': [u'Such', u'public', u'institutions', u'include', u'the', u'International', u'Islamic', u'University', u'Malaysia', u',', u'University', u'of', u'Malaya', u',', u'the', u'Universiti', u'Teknologi', u'Malaysia', u',', u'International', u'Medical', u'University', u'and', u'the', u'Medical', u'Faculty', u'of', u'the', u'Universiti', u'Kebangsaan', u'Malaysia', u'.'], u'lemmas': [u'such', u'public', u'institution', u'include', u'the', u'International', u'Islamic', u'University', u'Malaysia', u',', u'University', u'of', u'Malaya', u',', u'the', u'Universiti', u'Teknologi', u'Malaysia', u',', u'International', u'Medical', u'University', u'and', u'the', u'Medical', u'Faculty', u'of', u'the', u'Universiti', u'Kebangsaan', u'Malaysia', u'.'], u'pos': [u'JJ', u'JJ', u'NNS', u'VBP', u'DT', u'NNP', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'IN', u'NNP', u',', u'DT', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'CC', u'DT', u'NNP', u'NNP', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[16904, 16908], [16909, 16915], [16916, 16928], [16929, 16936], [16937, 16940], [16941, 16954], [16955, 16962], [16963, 16973], [16974, 16982], [16982, 16983], [16984, 16994], [16995, 16997], [16998, 17004], [17004, 17005], [17006, 17009], [17010, 17020], [17021, 17030], [17031, 17039], [17039, 17040], [17041, 17054], [17055, 17062], [17063, 17073], [17074, 17077], [17078, 17081], [17082, 17089], [17090, 17097], [17098, 17100], [17101, 17104], [17105, 17115], [17116, 17126], [17127, 17135], [17135, 17136]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.17713727056980133, {u'tokens': [u'Other', u'universities', u'located', u'in', u'Kuala', u'Lumpur', u'include', u'UCSI', u'University', u',', u'International', u'Medical', u'University', u',', u'Open', u'University', u'Malaysia', u',', u'Universiti', u'Kuala', u'Lumpur', u',', u'Wawasan', u'Open', u'University', u'and', u'the', u'branch', u'campus', u'of', u'Universiti', u'Kebangsaan', u'Malaysia', u'and', u'Universiti', u'Teknologi', u'Malaysia', u'.'], u'lemmas': [u'other', u'university', u'locate', u'in', u'Kuala', u'Lumpur', u'include', u'UCSI', u'University', u',', u'International', u'Medical', u'University', u',', u'Open', u'University', u'Malaysia', u',', u'Universiti', u'Kuala', u'Lumpur', u',', u'Wawasan', u'Open', u'University', u'and', u'the', u'branch', u'campus', u'of', u'Universiti', u'Kebangsaan', u'Malaysia', u'and', u'Universiti', u'Teknologi', u'Malaysia', u'.'], u'pos': [u'JJ', u'NNS', u'VBN', u'IN', u'NNP', u'NNP', u'VBP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'NNP', u'CC', u'DT', u'NN', u'NN', u'IN', u'NNP', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[39920, 39925], [39926, 39938], [39939, 39946], [39947, 39949], [39950, 39955], [39956, 39962], [39963, 39970], [39971, 39975], [39976, 39986], [39986, 39987], [39988, 40001], [40002, 40009], [40010, 40020], [40020, 40021], [40022, 40026], [40027, 40037], [40038, 40046], [40046, 40047], [40048, 40058], [40059, 40064], [40065, 40071], [40071, 40072], [40073, 40080], [40081, 40085], [40086, 40096], [40097, 40100], [40101, 40104], [40105, 40111], [40112, 40118], [40119, 40121], [40122, 40132], [40133, 40143], [40144, 40152], [40153, 40156], [40157, 40167], [40168, 40177], [40178, 40186], [40186, 40187]]}) 
answer: set([u'capitol'])
candidate Sentence: (0.17711366713047028, {u'tokens': [u'The', u'main', u'airport', u',', u'Kuala', u'Lumpur', u'International', u'Airport', u'-LRB-', u'KLIA', u'-RRB-', u',', u'which', u'is', u'also', u'the', u'aviation', u'hub', u'of', u'Malaysia', u',', u'is', u'located', u'about', u'south', u'of', u'city', u'.'], u'lemmas': [u'the', u'main', u'airport', u',', u'Kuala', u'Lumpur', u'International', u'Airport', u'-lrb-', u'KLIA', u'-rrb-', u',', u'which', u'be', u'also', u'the', u'aviation', u'hub', u'of', u'Malaysia', u',', u'be', u'located', u'about', u'south', u'of', u'city', u'.'], u'pos': [u'DT', u'JJ', u'NN', u',', u'NNP', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u',', u'WDT', u'VBZ', u'RB', u'DT', u'NN', u'NN', u'IN', u'NNP', u',', u'VBZ', u'JJ', u'IN', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[35906, 35909], [35910, 35914], [35915, 35922], [35922, 35923], [35924, 35929], [35930, 35936], [35937, 35950], [35951, 35958], [35959, 35960], [35960, 35964], [35964, 35965], [35965, 35966], [35967, 35972], [35973, 35975], [35976, 35980], [35981, 35984], [35985, 35993], [35994, 35997], [35998, 36000], [36001, 36009], [36009, 36010], [36011, 36013], [36014, 36021], [36022, 36027], [36030, 36035], [36036, 36038], [36039, 36043], [36043, 36044]]}) 
answer: set([u'capitol'])

Is Kuala Lumpur the capitol of Malaysia? disfluent
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3758>.answer
_____________________________ test_yesno[param191] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d38c0>, (<src.tfidf.TF_IDF object at 0x10e16f150>, set(['kuala', 'kuala_lumpur', 'lumpur'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d38c0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.32441753149032593, {u'tokens': [u'Kuala', u'Lumpur', u'is', u'home', u'to', u'the', u'Parliament', u'of', u'Malaysia', u'.'], u'lemmas': [u'Kuala', u'Lumpur', u'be', u'home', u'to', u'the', u'Parliament', u'of', u'Malaysia', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'NN', u'TO', u'DT', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[12855, 12860], [12861, 12867], [12868, 12870], [12871, 12875], [12876, 12878], [12879, 12882], [12883, 12893], [12894, 12896], [12897, 12905], [12905, 12906]]}) 
answer: set([u'malaysium'])
candidate Sentence: (0.28168633580207825, {u'tokens': [u'Kuala', u'Lumpur', u'is', u'home', u'to', u'the', u'University', u'of', u'Malaya', u'.'], u'lemmas': [u'Kuala', u'Lumpur', u'be', u'home', u'to', u'the', u'University', u'of', u'Malaya', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'NN', u'TO', u'DT', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[39433, 39438], [39439, 39445], [39446, 39448], [39449, 39453], [39454, 39456], [39457, 39460], [39461, 39471], [39472, 39474], [39475, 39481], [39481, 39482]]}) 
answer: set([u'parliament', u'malaysium'])
candidate Sentence: (0.22694194316864014, {u'tokens': [u'The', u'parliament', u'is', u'composed', u'of', u'a', u'lower', u'House', u'of', u'Representatives', u'-LRB-', u'Dewan', u'Rakyat', u'-RRB-', u'and', u'an', u'upper', u'House', u'of', u'Senate', u'-LRB-', u'Dewan', u'Negara', u'-RRB-', u'.'], u'lemmas': [u'the', u'parliament', u'be', u'compose', u'of', u'a', u'lower', u'House', u'of', u'Representatives', u'-lrb-', u'Dewan', u'Rakyat', u'-rrb-', u'and', u'a', u'upper', u'House', u'of', u'Senate', u'-lrb-', u'Dewan', u'Negara', u'-rrb-', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'VBN', u'IN', u'DT', u'JJR', u'NNP', u'IN', u'NNP', u'-LRB-', u'NNP', u'NNP', u'-RRB-', u'CC', u'DT', u'JJ', u'NNP', u'IN', u'NNP', u'-LRB-', u'NNP', u'NNP', u'-RRB-', u'.'], u'char_offsets': [[12907, 12910], [12911, 12921], [12922, 12924], [12925, 12933], [12934, 12936], [12937, 12938], [12939, 12944], [12945, 12950], [12951, 12953], [12954, 12969], [12970, 12971], [12971, 12976], [12977, 12983], [12983, 12984], [12985, 12988], [12989, 12991], [12992, 12997], [12998, 13003], [13004, 13006], [13007, 13013], [13014, 13015], [13015, 13020], [13021, 13027], [13027, 13028], [13028, 13029]]}) 
answer: set([u'home', u'malaysium'])
candidate Sentence: (0.14327001571655273, {u'tokens': [u'In', u'addition', u',', u'Kuala', u'Lumpur', u'is', u'home', u'to', u'the', u'tallest', u'twin', u'buildings', u'in', u'the', u'world', u',', u'the', u'Petronas', u'Twin', u'Towers', u'.'], u'lemmas': [u'in', u'addition', u',', u'Kuala', u'Lumpur', u'be', u'home', u'to', u'the', u'tallest', u'twin', u'building', u'in', u'the', u'world', u',', u'the', u'Petronas', u'Twin', u'Towers', u'.'], u'pos': [u'IN', u'NN', u',', u'NNP', u'NNP', u'VBZ', u'NN', u'TO', u'DT', u'JJS', u'JJ', u'NNS', u'IN', u'DT', u'NN', u',', u'DT', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[1709, 1711], [1712, 1720], [1720, 1721], [1722, 1727], [1728, 1734], [1735, 1737], [1738, 1742], [1743, 1745], [1746, 1749], [1750, 1757], [1758, 1762], [1763, 1772], [1773, 1775], [1776, 1779], [1780, 1785], [1785, 1786], [1787, 1790], [1791, 1799], [1800, 1804], [1805, 1811], [1811, 1812]]}) 
answer: set([u'parliament', u'malaysium'])
candidate Sentence: (0.12373147904872894, {u'tokens': [u'The', u'city', u'was', u'once', u'home', u'to', u'the', u'executive', u'and', u'judicial', u'branches', u'of', u'the', u'federal', u'government', u',', u'but', u'they', u'have', u'since', u'moved', u'to', u'Putrajaya', u'starting', u'in', u'1999', u'.'], u'lemmas': [u'the', u'city', u'be', u'once', u'home', u'to', u'the', u'executive', u'and', u'judicial', u'branch', u'of', u'the', u'federal', u'government', u',', u'but', u'they', u'have', u'since', u'move', u'to', u'Putrajaya', u'start', u'in', u'1999', u'.'], u'pos': [u'DT', u'NN', u'VBD', u'RB', u'NN', u'TO', u'DT', u'NN', u'CC', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'CC', u'PRP', u'VBP', u'IN', u'VBN', u'TO', u'NNP', u'VBG', u'IN', u'CD', u'.'], u'char_offsets': [[639, 642], [643, 647], [648, 651], [652, 656], [657, 661], [662, 664], [665, 668], [669, 678], [679, 682], [683, 691], [692, 700], [701, 703], [704, 707], [708, 715], [716, 726], [726, 727], [728, 731], [732, 736], [737, 741], [742, 747], [748, 753], [754, 756], [757, 766], [767, 775], [776, 778], [779, 783], [783, 784]]}) 
answer: set([u'parliament', u'malaysium'])
candidate Sentence: (0.10456109046936035, {u'tokens': [u'It', u'is', u'also', u'known', u'as', u'Pasar', u'Seni', u'in', u'Malay', u'.'], u'lemmas': [u'it', u'be', u'also', u'know', u'as', u'Pasar', u'Seni', u'in', u'Malay', u'.'], u'pos': [u'PRP', u'VBZ', u'RB', u'VBN', u'IN', u'NNP', u'NNP', u'IN', u'NNP', u'.'], u'char_offsets': [[22695, 22697], [22698, 22700], [22701, 22705], [22706, 22711], [22712, 22714], [22715, 22720], [22721, 22725], [22726, 22728], [22729, 22734], [22734, 22735]]}) 
answer: set([u'home', u'parliament', u'malaysium'])
candidate Sentence: (0.10194607079029083, {u'tokens': [u'These', u'residual', u'forest', u'areas', u'are', u'home', u'to', u'a', u'number', u'of', u'fauna', u'species', u'particularly', u'monkeys', u',', u'tree', u'shrews', u',', u'squirrels', u'and', u'birds', u'.'], u'lemmas': [u'these', u'residual', u'forest', u'area', u'be', u'home', u'to', u'a', u'number', u'of', u'fauna', u'species', u'particularly', u'monkey', u',', u'tree', u'shrew', u',', u'squirrel', u'and', u'bird', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NNS', u'VBP', u'NN', u'TO', u'DT', u'NN', u'IN', u'NNS', u'NNS', u'RB', u'NNS', u',', u'NN', u'NNS', u',', u'NNS', u'CC', u'NNS', u'.'], u'char_offsets': [[26871, 26876], [26877, 26885], [26886, 26892], [26893, 26898], [26899, 26902], [26903, 26907], [26908, 26910], [26911, 26912], [26913, 26919], [26920, 26922], [26923, 26928], [26929, 26936], [26937, 26949], [26950, 26957], [26957, 26958], [26959, 26963], [26964, 26970], [26970, 26971], [26972, 26981], [26982, 26985], [26986, 26991], [26991, 26992]]}) 
answer: set([u'parliament', u'malaysium'])
candidate Sentence: (0.10138731449842453, {u'tokens': [u'It', u'is', u'located', u'at', u'Jalan', u'Lembah', u'Perdana', u'next', u'to', u'the', u'National', u'Mosque', u'.'], u'lemmas': [u'it', u'be', u'located', u'at', u'Jalan', u'Lembah', u'Perdana', u'next', u'to', u'the', u'National', u'Mosque', u'.'], u'pos': [u'PRP', u'VBZ', u'JJ', u'IN', u'NNP', u'NNP', u'NNP', u'IN', u'TO', u'DT', u'NNP', u'NNP', u'.'], u'char_offsets': [[27738, 27740], [27741, 27743], [27744, 27751], [27752, 27754], [27755, 27760], [27761, 27767], [27768, 27775], [27776, 27780], [27781, 27783], [27784, 27787], [27788, 27796], [27797, 27803], [27803, 27804]]}) 
answer: set([u'home', u'parliament', u'malaysium'])
candidate Sentence: (0.096881181001663208, {u'tokens': [u'It', u'was', u'established', u'to', u'be', u'a', u'major', u'centre', u'for', u'military', u'and', u'defence', u'technology', u'studies', u'.'], u'lemmas': [u'it', u'be', u'establish', u'to', u'be', u'a', u'major', u'centre', u'for', u'military', u'and', u'defence', u'technology', u'study', u'.'], u'pos': [u'PRP', u'VBD', u'VBN', u'TO', u'VB', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'CC', u'NN', u'NN', u'NNS', u'.'], u'char_offsets': [[40315, 40317], [40318, 40321], [40322, 40333], [40334, 40336], [40337, 40339], [40340, 40341], [40342, 40347], [40348, 40354], [40355, 40358], [40359, 40367], [40368, 40371], [40372, 40379], [40380, 40390], [40391, 40398], [40398, 40399]]}) 
answer: set([u'home', u'parliament', u'malaysium'])
candidate Sentence: (0.095385372638702393, {u'tokens': [u'Kuala', u'Lumpur', u'City', u'Centre', u'Park', u'as', u'seen', u'from', u'the', u'Traders', u'Hotel', u'The', u'Perdana', u'Lake', u'Gardens', u',', u'a', u'manicured', u'garden', u'near', u'the', u'Malaysian', u'Parliament', u'building', u',', u'was', u'once', u'home', u'to', u'a', u'British', u'colonial', u'official', u'.'], u'lemmas': [u'Kuala', u'Lumpur', u'City', u'Centre', u'Park', u'as', u'see', u'from', u'the', u'trader', u'hotel', u'the', u'Perdana', u'Lake', u'Gardens', u',', u'a', u'manicure', u'garden', u'near', u'the', u'malaysian', u'Parliament', u'building', u',', u'be', u'once', u'home', u'to', u'a', u'british', u'colonial', u'official', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u'NNP', u'NNP', u'IN', u'VBN', u'IN', u'DT', u'NNS', u'NN', u'DT', u'NNP', u'NNP', u'NNP', u',', u'DT', u'VBN', u'NN', u'IN', u'DT', u'JJ', u'NNP', u'NN', u',', u'VBD', u'RB', u'NN', u'TO', u'DT', u'JJ', u'NN', u'NN', u'.'], u'char_offsets': [[25829, 25834], [25835, 25841], [25842, 25846], [25847, 25853], [25854, 25858], [25859, 25861], [25862, 25866], [25867, 25871], [25872, 25875], [25876, 25883], [25884, 25889], [25890, 25893], [25894, 25901], [25902, 25906], [25907, 25914], [25914, 25915], [25916, 25917], [25920, 25929], [25930, 25936], [25937, 25941], [25942, 25945], [25946, 25955], [25956, 25966], [25967, 25975], [25975, 25976], [25977, 25980], [25981, 25985], [25986, 25990], [25991, 25993], [25994, 25995], [25996, 26003], [26004, 26012], [26013, 26021], [26021, 26022]]}) 
answer: set([u'malaysium'])

is it home to the parliament of malaysia?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d38c0>.answer
_____________________________ test_yesno[param192] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3908>, (<src.tfidf.TF_IDF object at 0x10e16ff50>, set(['lobster'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3908>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.28565219044685364, {u'tokens': [u'They', u'are', u'invertebrates', u',', u'with', u'a', u'hard', u'protective', u'exoskeleton', u'.'], u'lemmas': [u'they', u'be', u'invertebrate', u',', u'with', u'a', u'hard', u'protective', u'exoskeleton', u'.'], u'pos': [u'PRP', u'VBP', u'NNS', u',', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[959, 963], [964, 967], [968, 981], [981, 982], [983, 987], [988, 989], [990, 994], [995, 1005], [1006, 1017], [1017, 1018]]}) 
answer: set([])
candidate Sentence: (0.17952127754688263, {u'tokens': [u'These', u'findings', u'have', u'been', u'replicated', u'for', u'other', u'invertebrate', u'species', u',', u'but', u'similar', u'data', u'is', u'not', u'yet', u'available', u'for', u'lobsters', u'.'], u'lemmas': [u'these', u'finding', u'have', u'be', u'replicate', u'for', u'other', u'invertebrate', u'species', u',', u'but', u'similar', u'datum', u'be', u'not', u'yet', u'available', u'for', u'lobster', u'.'], u'pos': [u'DT', u'NNS', u'VBP', u'VBN', u'VBN', u'IN', u'JJ', u'JJ', u'NNS', u',', u'CC', u'JJ', u'NNS', u'VBZ', u'RB', u'RB', u'JJ', u'IN', u'NNS', u'.'], u'char_offsets': [[10875, 10880], [10881, 10889], [10890, 10894], [10895, 10899], [10900, 10910], [10911, 10914], [10915, 10920], [10921, 10933], [10934, 10941], [10941, 10942], [10944, 10947], [10948, 10955], [10956, 10960], [10961, 10963], [10964, 10967], [10968, 10971], [10972, 10981], [10982, 10985], [10986, 10994], [10994, 10995]]}) 
answer: set([])
candidate Sentence: (0.099935524165630341, {u'tokens': [u'It', u'and', u'the', u'related', u'lobster', u'poems', u'can', u'be', u'read', u'here', u':', u'``', u'Will', u'you', u',', u'wo', u"n't", u'you', u',', u'will', u'you', u',', u'wo', u"n't", u'you', u',', u'wo', u"n't", u'you', u'join', u'the', u'dance', u'?', u"''"], u'lemmas': [u'it', u'and', u'the', u'related', u'lobster', u'poem', u'can', u'be', u'read', u'here', u':', u'``', u'will', u'you', u',', u'will', u'not', u'you', u',', u'will', u'you', u',', u'will', u'not', u'you', u',', u'will', u'not', u'you', u'join', u'the', u'dance', u'?', u"''"], u'pos': [u'PRP', u'CC', u'DT', u'JJ', u'NN', u'NNS', u'MD', u'VB', u'VBN', u'RB', u':', u'``', u'MD', u'PRP', u',', u'MD', u'RB', u'PRP', u',', u'MD', u'PRP', u',', u'MD', u'RB', u'PRP', u',', u'MD', u'RB', u'PRP', u'VB', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[12535, 12537], [12538, 12541], [12542, 12545], [12546, 12553], [12554, 12561], [12562, 12567], [12568, 12571], [12572, 12574], [12575, 12579], [12581, 12585], [12585, 12586], [12587, 12588], [12588, 12592], [12593, 12596], [12596, 12597], [12598, 12600], [12600, 12603], [12604, 12607], [12607, 12608], [12609, 12613], [12614, 12617], [12617, 12618], [12619, 12621], [12621, 12624], [12625, 12628], [12628, 12629], [12630, 12632], [12632, 12635], [12636, 12639], [12640, 12644], [12645, 12648], [12649, 12654], [12654, 12655], [12655, 12656]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.013469373807311058, {u'tokens': [u'Though', u'several', u'groups', u'of', u'crustaceans', u'are', u'known', u'as', u'``', u'lobsters', u',', u"''", u'the', u'clawed', u'lobsters', u'are', u'most', u'often', u'associated', u'with', u'the', u'name', u'.'], u'lemmas': [u'though', u'several', u'group', u'of', u'crustacean', u'be', u'know', u'as', u'``', u'lobster', u',', u"''", u'the', u'clawed', u'lobster', u'be', u'most', u'often', u'associate', u'with', u'the', u'name', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u'IN', u'NNS', u'VBP', u'VBN', u'IN', u'``', u'NNS', u',', u"''", u'DT', u'JJ', u'NNS', u'VBP', u'RBS', u'RB', u'VBN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[233, 239], [240, 247], [248, 254], [255, 257], [258, 269], [270, 273], [274, 279], [280, 282], [283, 284], [284, 292], [292, 293], [293, 294], [295, 298], [299, 305], [306, 314], [315, 318], [319, 323], [324, 329], [330, 340], [341, 345], [346, 349], [350, 354], [354, 355]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.013387018814682961, {u'tokens': [u'Although', u'lobster', u'skin', u'has', u'been', u'found', u'in', u'lobster', u'stomachs', u',', u'this', u'is', u'because', u'lobsters', u'eat', u'their', u'shed', u'skin', u'after', u'molting', u'.'], u'lemmas': [u'although', u'lobster', u'skin', u'have', u'be', u'find', u'in', u'lobster', u'stomach', u',', u'this', u'be', u'because', u'lobster', u'eat', u'they', u'shed', u'skin', u'after', u'molt', u'.'], u'pos': [u'IN', u'NN', u'NN', u'VBZ', u'VBN', u'VBN', u'IN', u'NN', u'NNS', u',', u'DT', u'VBZ', u'IN', u'NNS', u'VBP', u'PRP$', u'NN', u'NN', u'IN', u'VBG', u'.'], u'char_offsets': [[1967, 1975], [1976, 1983], [1984, 1988], [1989, 1992], [1993, 1997], [1998, 2003], [2004, 2006], [2007, 2014], [2015, 2023], [2023, 2024], [2025, 2029], [2030, 2032], [2033, 2040], [2041, 2049], [2050, 2053], [2054, 2059], [2060, 2064], [2065, 2069], [2070, 2075], [2076, 2083], [2083, 2084]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.012895837426185608, {u'tokens': [u'Lobsters', u'are', u'found', u'in', u'all', u'oceans', u'.'], u'lemmas': [u'lobster', u'be', u'find', u'in', u'all', u'ocean', u'.'], u'pos': [u'NNS', u'VBP', u'VBN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[751, 759], [760, 763], [764, 769], [770, 772], [773, 776], [777, 783], [783, 784]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.012847550213336945, {u'tokens': [u'Lobster', u'is', u'fished', u'in', u'water', u'between', u',', u'although', u'some', u'lobsters', u'live', u'at', u'.'], u'lemmas': [u'lobster', u'be', u'fish', u'in', u'water', u'between', u',', u'although', u'some', u'lobster', u'live', u'at', u'.'], u'pos': [u'NN', u'VBZ', u'VBN', u'IN', u'NN', u'IN', u',', u'IN', u'DT', u'NNS', u'VBP', u'IN', u'.'], u'char_offsets': [[11980, 11987], [11988, 11990], [11991, 11997], [11998, 12000], [12001, 12006], [12007, 12014], [12016, 12017], [12018, 12026], [12027, 12031], [12032, 12040], [12041, 12045], [12046, 12048], [12050, 12051]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.012279829010367393, {u'tokens': [u'Clawed', u'lobsters', u'are', u'not', u'closely', u'related', u'to', u'spiny', u'lobsters', u'or', u'slipper', u'lobsters', u',', u'which', u'have', u'no', u'claws', u'-LRB-', u'chelae', u'-RRB-', u',', u'or', u'squat', u'lobsters', u'.'], u'lemmas': [u'claw', u'lobster', u'be', u'not', u'closely', u'related', u'to', u'spiny', u'lobster', u'or', u'slipper', u'lobster', u',', u'which', u'have', u'no', u'claw', u'-lrb-', u'chela', u'-rrb-', u',', u'or', u'squat', u'lobster', u'.'], u'pos': [u'VBN', u'NNS', u'VBP', u'RB', u'RB', u'JJ', u'TO', u'JJ', u'NNS', u'CC', u'NN', u'NNS', u',', u'WDT', u'VBP', u'DT', u'NNS', u'-LRB-', u'NNS', u'-RRB-', u',', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[408, 414], [415, 423], [424, 427], [428, 431], [432, 439], [440, 447], [448, 450], [451, 456], [457, 465], [466, 468], [469, 476], [477, 485], [485, 486], [487, 492], [493, 497], [498, 500], [501, 506], [507, 508], [508, 514], [514, 515], [515, 516], [517, 519], [520, 525], [526, 534], [534, 535]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.011324957013130188, {u'tokens': [u'In', u'fact', u',', u'older', u'lobsters', u'are', u'more', u'fertile', u'than', u'younger', u'lobsters', u'.'], u'lemmas': [u'in', u'fact', u',', u'older', u'lobster', u'be', u'more', u'fertile', u'than', u'younger', u'lobster', u'.'], u'pos': [u'IN', u'NN', u',', u'JJR', u'NNS', u'VBP', u'RBR', u'JJ', u'IN', u'JJR', u'NNS', u'.'], u'char_offsets': [[3969, 3971], [3972, 3976], [3976, 3977], [3978, 3983], [3984, 3992], [3993, 3996], [3997, 4001], [4002, 4009], [4010, 4014], [4015, 4022], [4023, 4031], [4031, 4032]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.011264082044363022, {u'tokens': [u'Due', u'to', u'the', u'ambiguous', u'nature', u'of', u'suffering', u',', u'the', u'issue', u'of', u'lobster', u'pain', u'may', u'be', u'argued', u'by', u'analogy', u'that', u'lobster', u'biology', u'is', u'similar', u'to', u'human', u'biology', u'or', u'that', u'lobster', u'behavior', u'warrants', u'assumptions', u'that', u'lobsters', u'can', u'feel', u'pain', u'.'], u'lemmas': [u'due', u'to', u'the', u'ambiguous', u'nature', u'of', u'suffering', u',', u'the', u'issue', u'of', u'lobster', u'pain', u'may', u'be', u'argue', u'by', u'analogy', u'that', u'lobster', u'biology', u'be', u'similar', u'to', u'human', u'biology', u'or', u'that', u'lobster', u'behavior', u'warrant', u'assumption', u'that', u'lobster', u'can', u'feel', u'pain', u'.'], u'pos': [u'JJ', u'TO', u'DT', u'JJ', u'NN', u'IN', u'NN', u',', u'DT', u'NN', u'IN', u'NN', u'NN', u'MD', u'VB', u'VBN', u'IN', u'NN', u'WDT', u'NN', u'NN', u'VBZ', u'JJ', u'TO', u'JJ', u'NN', u'CC', u'IN', u'NN', u'NN', u'NNS', u'NNS', u'WDT', u'NNS', u'MD', u'VB', u'NN', u'.'], u'char_offsets': [[7372, 7375], [7376, 7378], [7379, 7382], [7383, 7392], [7393, 7399], [7400, 7402], [7403, 7412], [7412, 7413], [7414, 7417], [7418, 7423], [7424, 7426], [7427, 7434], [7435, 7439], [7440, 7443], [7444, 7446], [7447, 7453], [7454, 7456], [7457, 7464], [7465, 7469], [7470, 7477], [7478, 7485], [7486, 7488], [7489, 7496], [7497, 7499], [7500, 7505], [7506, 7513], [7514, 7516], [7517, 7521], [7522, 7529], [7530, 7538], [7539, 7547], [7548, 7559], [7560, 7564], [7565, 7573], [7574, 7577], [7578, 7582], [7583, 7587], [7587, 7588]]}) 
answer: set([u'invertebrate'])

Are lobsters invertebrates?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3908>.answer
_____________________________ test_yesno[param193] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3950>, (<src.tfidf.TF_IDF object at 0x10e16ff50>, set(['lobster'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3950>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.28565219044685364, {u'tokens': [u'They', u'are', u'invertebrates', u',', u'with', u'a', u'hard', u'protective', u'exoskeleton', u'.'], u'lemmas': [u'they', u'be', u'invertebrate', u',', u'with', u'a', u'hard', u'protective', u'exoskeleton', u'.'], u'pos': [u'PRP', u'VBP', u'NNS', u',', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[959, 963], [964, 967], [968, 981], [981, 982], [983, 987], [988, 989], [990, 994], [995, 1005], [1006, 1017], [1017, 1018]]}) 
answer: set([])
candidate Sentence: (0.17952127754688263, {u'tokens': [u'These', u'findings', u'have', u'been', u'replicated', u'for', u'other', u'invertebrate', u'species', u',', u'but', u'similar', u'data', u'is', u'not', u'yet', u'available', u'for', u'lobsters', u'.'], u'lemmas': [u'these', u'finding', u'have', u'be', u'replicate', u'for', u'other', u'invertebrate', u'species', u',', u'but', u'similar', u'datum', u'be', u'not', u'yet', u'available', u'for', u'lobster', u'.'], u'pos': [u'DT', u'NNS', u'VBP', u'VBN', u'VBN', u'IN', u'JJ', u'JJ', u'NNS', u',', u'CC', u'JJ', u'NNS', u'VBZ', u'RB', u'RB', u'JJ', u'IN', u'NNS', u'.'], u'char_offsets': [[10875, 10880], [10881, 10889], [10890, 10894], [10895, 10899], [10900, 10910], [10911, 10914], [10915, 10920], [10921, 10933], [10934, 10941], [10941, 10942], [10944, 10947], [10948, 10955], [10956, 10960], [10961, 10963], [10964, 10967], [10968, 10971], [10972, 10981], [10982, 10985], [10986, 10994], [10994, 10995]]}) 
answer: set([])
candidate Sentence: (0.099935524165630341, {u'tokens': [u'It', u'and', u'the', u'related', u'lobster', u'poems', u'can', u'be', u'read', u'here', u':', u'``', u'Will', u'you', u',', u'wo', u"n't", u'you', u',', u'will', u'you', u',', u'wo', u"n't", u'you', u',', u'wo', u"n't", u'you', u'join', u'the', u'dance', u'?', u"''"], u'lemmas': [u'it', u'and', u'the', u'related', u'lobster', u'poem', u'can', u'be', u'read', u'here', u':', u'``', u'will', u'you', u',', u'will', u'not', u'you', u',', u'will', u'you', u',', u'will', u'not', u'you', u',', u'will', u'not', u'you', u'join', u'the', u'dance', u'?', u"''"], u'pos': [u'PRP', u'CC', u'DT', u'JJ', u'NN', u'NNS', u'MD', u'VB', u'VBN', u'RB', u':', u'``', u'MD', u'PRP', u',', u'MD', u'RB', u'PRP', u',', u'MD', u'PRP', u',', u'MD', u'RB', u'PRP', u',', u'MD', u'RB', u'PRP', u'VB', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[12535, 12537], [12538, 12541], [12542, 12545], [12546, 12553], [12554, 12561], [12562, 12567], [12568, 12571], [12572, 12574], [12575, 12579], [12581, 12585], [12585, 12586], [12587, 12588], [12588, 12592], [12593, 12596], [12596, 12597], [12598, 12600], [12600, 12603], [12604, 12607], [12607, 12608], [12609, 12613], [12614, 12617], [12617, 12618], [12619, 12621], [12621, 12624], [12625, 12628], [12628, 12629], [12630, 12632], [12632, 12635], [12636, 12639], [12640, 12644], [12645, 12648], [12649, 12654], [12654, 12655], [12655, 12656]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.013469373807311058, {u'tokens': [u'Though', u'several', u'groups', u'of', u'crustaceans', u'are', u'known', u'as', u'``', u'lobsters', u',', u"''", u'the', u'clawed', u'lobsters', u'are', u'most', u'often', u'associated', u'with', u'the', u'name', u'.'], u'lemmas': [u'though', u'several', u'group', u'of', u'crustacean', u'be', u'know', u'as', u'``', u'lobster', u',', u"''", u'the', u'clawed', u'lobster', u'be', u'most', u'often', u'associate', u'with', u'the', u'name', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u'IN', u'NNS', u'VBP', u'VBN', u'IN', u'``', u'NNS', u',', u"''", u'DT', u'JJ', u'NNS', u'VBP', u'RBS', u'RB', u'VBN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[233, 239], [240, 247], [248, 254], [255, 257], [258, 269], [270, 273], [274, 279], [280, 282], [283, 284], [284, 292], [292, 293], [293, 294], [295, 298], [299, 305], [306, 314], [315, 318], [319, 323], [324, 329], [330, 340], [341, 345], [346, 349], [350, 354], [354, 355]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.013387018814682961, {u'tokens': [u'Although', u'lobster', u'skin', u'has', u'been', u'found', u'in', u'lobster', u'stomachs', u',', u'this', u'is', u'because', u'lobsters', u'eat', u'their', u'shed', u'skin', u'after', u'molting', u'.'], u'lemmas': [u'although', u'lobster', u'skin', u'have', u'be', u'find', u'in', u'lobster', u'stomach', u',', u'this', u'be', u'because', u'lobster', u'eat', u'they', u'shed', u'skin', u'after', u'molt', u'.'], u'pos': [u'IN', u'NN', u'NN', u'VBZ', u'VBN', u'VBN', u'IN', u'NN', u'NNS', u',', u'DT', u'VBZ', u'IN', u'NNS', u'VBP', u'PRP$', u'NN', u'NN', u'IN', u'VBG', u'.'], u'char_offsets': [[1967, 1975], [1976, 1983], [1984, 1988], [1989, 1992], [1993, 1997], [1998, 2003], [2004, 2006], [2007, 2014], [2015, 2023], [2023, 2024], [2025, 2029], [2030, 2032], [2033, 2040], [2041, 2049], [2050, 2053], [2054, 2059], [2060, 2064], [2065, 2069], [2070, 2075], [2076, 2083], [2083, 2084]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.012895837426185608, {u'tokens': [u'Lobsters', u'are', u'found', u'in', u'all', u'oceans', u'.'], u'lemmas': [u'lobster', u'be', u'find', u'in', u'all', u'ocean', u'.'], u'pos': [u'NNS', u'VBP', u'VBN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[751, 759], [760, 763], [764, 769], [770, 772], [773, 776], [777, 783], [783, 784]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.012847550213336945, {u'tokens': [u'Lobster', u'is', u'fished', u'in', u'water', u'between', u',', u'although', u'some', u'lobsters', u'live', u'at', u'.'], u'lemmas': [u'lobster', u'be', u'fish', u'in', u'water', u'between', u',', u'although', u'some', u'lobster', u'live', u'at', u'.'], u'pos': [u'NN', u'VBZ', u'VBN', u'IN', u'NN', u'IN', u',', u'IN', u'DT', u'NNS', u'VBP', u'IN', u'.'], u'char_offsets': [[11980, 11987], [11988, 11990], [11991, 11997], [11998, 12000], [12001, 12006], [12007, 12014], [12016, 12017], [12018, 12026], [12027, 12031], [12032, 12040], [12041, 12045], [12046, 12048], [12050, 12051]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.012279829010367393, {u'tokens': [u'Clawed', u'lobsters', u'are', u'not', u'closely', u'related', u'to', u'spiny', u'lobsters', u'or', u'slipper', u'lobsters', u',', u'which', u'have', u'no', u'claws', u'-LRB-', u'chelae', u'-RRB-', u',', u'or', u'squat', u'lobsters', u'.'], u'lemmas': [u'claw', u'lobster', u'be', u'not', u'closely', u'related', u'to', u'spiny', u'lobster', u'or', u'slipper', u'lobster', u',', u'which', u'have', u'no', u'claw', u'-lrb-', u'chela', u'-rrb-', u',', u'or', u'squat', u'lobster', u'.'], u'pos': [u'VBN', u'NNS', u'VBP', u'RB', u'RB', u'JJ', u'TO', u'JJ', u'NNS', u'CC', u'NN', u'NNS', u',', u'WDT', u'VBP', u'DT', u'NNS', u'-LRB-', u'NNS', u'-RRB-', u',', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[408, 414], [415, 423], [424, 427], [428, 431], [432, 439], [440, 447], [448, 450], [451, 456], [457, 465], [466, 468], [469, 476], [477, 485], [485, 486], [487, 492], [493, 497], [498, 500], [501, 506], [507, 508], [508, 514], [514, 515], [515, 516], [517, 519], [520, 525], [526, 534], [534, 535]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.011324957013130188, {u'tokens': [u'In', u'fact', u',', u'older', u'lobsters', u'are', u'more', u'fertile', u'than', u'younger', u'lobsters', u'.'], u'lemmas': [u'in', u'fact', u',', u'older', u'lobster', u'be', u'more', u'fertile', u'than', u'younger', u'lobster', u'.'], u'pos': [u'IN', u'NN', u',', u'JJR', u'NNS', u'VBP', u'RBR', u'JJ', u'IN', u'JJR', u'NNS', u'.'], u'char_offsets': [[3969, 3971], [3972, 3976], [3976, 3977], [3978, 3983], [3984, 3992], [3993, 3996], [3997, 4001], [4002, 4009], [4010, 4014], [4015, 4022], [4023, 4031], [4031, 4032]]}) 
answer: set([u'invertebrate'])
candidate Sentence: (0.011264082044363022, {u'tokens': [u'Due', u'to', u'the', u'ambiguous', u'nature', u'of', u'suffering', u',', u'the', u'issue', u'of', u'lobster', u'pain', u'may', u'be', u'argued', u'by', u'analogy', u'that', u'lobster', u'biology', u'is', u'similar', u'to', u'human', u'biology', u'or', u'that', u'lobster', u'behavior', u'warrants', u'assumptions', u'that', u'lobsters', u'can', u'feel', u'pain', u'.'], u'lemmas': [u'due', u'to', u'the', u'ambiguous', u'nature', u'of', u'suffering', u',', u'the', u'issue', u'of', u'lobster', u'pain', u'may', u'be', u'argue', u'by', u'analogy', u'that', u'lobster', u'biology', u'be', u'similar', u'to', u'human', u'biology', u'or', u'that', u'lobster', u'behavior', u'warrant', u'assumption', u'that', u'lobster', u'can', u'feel', u'pain', u'.'], u'pos': [u'JJ', u'TO', u'DT', u'JJ', u'NN', u'IN', u'NN', u',', u'DT', u'NN', u'IN', u'NN', u'NN', u'MD', u'VB', u'VBN', u'IN', u'NN', u'WDT', u'NN', u'NN', u'VBZ', u'JJ', u'TO', u'JJ', u'NN', u'CC', u'IN', u'NN', u'NN', u'NNS', u'NNS', u'WDT', u'NNS', u'MD', u'VB', u'NN', u'.'], u'char_offsets': [[7372, 7375], [7376, 7378], [7379, 7382], [7383, 7392], [7393, 7399], [7400, 7402], [7403, 7412], [7412, 7413], [7414, 7417], [7418, 7423], [7424, 7426], [7427, 7434], [7435, 7439], [7440, 7443], [7444, 7446], [7447, 7453], [7454, 7456], [7457, 7464], [7465, 7469], [7470, 7477], [7478, 7485], [7486, 7488], [7489, 7496], [7497, 7499], [7500, 7505], [7506, 7513], [7514, 7516], [7517, 7521], [7522, 7529], [7530, 7538], [7539, 7547], [7548, 7559], [7560, 7564], [7565, 7573], [7574, 7577], [7578, 7582], [7583, 7587], [7587, 7588]]}) 
answer: set([u'invertebrate'])

Are lobsters invertebrates?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3950>.answer
_____________________________ test_yesno[param200] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3b48>, (<src.tfidf.TF_IDF object at 0x10a4b0d50>, set(['lyre'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3b48>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.45988816022872925, {u'tokens': [u'The', u'lyre', u'is', u'a', u'stringed', u'musical', u'instrument', u'well', u'known', u'for', u'its', u'use', u'in', u'classical', u'antiquity', u'and', u'later', u'.'], u'lemmas': [u'the', u'lyre', u'be', u'a', u'stringed', u'musical', u'instrument', u'well', u'know', u'for', u'its', u'use', u'in', u'classical', u'antiquity', u'and', u'later', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'DT', u'JJ', u'JJ', u'NN', u'RB', u'VBN', u'IN', u'PRP$', u'NN', u'IN', u'JJ', u'NN', u'CC', u'RB', u'.'], u'char_offsets': [[0, 3], [5, 9], [10, 12], [13, 14], [15, 23], [24, 31], [32, 42], [43, 47], [48, 53], [54, 57], [58, 61], [62, 65], [66, 68], [69, 78], [79, 88], [89, 92], [93, 98], [98, 99]]}) 
answer: set([])
candidate Sentence: (0.28501662611961365, {u'tokens': [u'Lyres', u'from', u'various', u'times', u'and', u'places', u'are', u'regarded', u'by', u'some', u'organologists', u'-LRB-', u'specialists', u'in', u'the', u'history', u'of', u'musical', u'instruments', u'-RRB-', u'as', u'a', u'branch', u'of', u'the', u'zither', u'family', u',', u'a', u'general', u'category', u'which', u'includes', u'many', u'different', u'stringed', u'instruments', u',', u'such', u'as', u'lutes', u',', u'guitars', u',', u'kantele', u',', u'and', u'psalteries', u',', u'not', u'just', u'zithers', u'.'], u'lemmas': [u'lyre', u'from', u'various', u'time', u'and', u'place', u'be', u'regard', u'by', u'some', u'organologist', u'-lrb-', u'specialist', u'in', u'the', u'history', u'of', u'musical', u'instrument', u'-rrb-', u'as', u'a', u'branch', u'of', u'the', u'zither', u'family', u',', u'a', u'general', u'category', u'which', u'include', u'many', u'different', u'stringed', u'instrument', u',', u'such', u'as', u'lute', u',', u'guitar', u',', u'kantele', u',', u'and', u'psaltery', u',', u'not', u'just', u'zither', u'.'], u'pos': [u'NNS', u'IN', u'JJ', u'NNS', u'CC', u'NNS', u'VBP', u'VBN', u'IN', u'DT', u'NNS', u'-LRB-', u'NNS', u'IN', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'-RRB-', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'NN', u',', u'DT', u'JJ', u'NN', u'WDT', u'VBZ', u'JJ', u'JJ', u'JJ', u'NNS', u',', u'JJ', u'IN', u'NNS', u',', u'NNS', u',', u'NN', u',', u'CC', u'NNS', u',', u'RB', u'RB', u'NNS', u'.'], u'char_offsets': [[401, 406], [407, 411], [412, 419], [420, 425], [426, 429], [430, 436], [437, 440], [441, 449], [450, 452], [453, 457], [458, 471], [472, 473], [473, 484], [485, 487], [488, 491], [492, 499], [500, 502], [503, 510], [511, 522], [522, 523], [524, 526], [527, 528], [529, 535], [536, 538], [539, 542], [543, 549], [550, 556], [556, 557], [558, 559], [560, 567], [568, 576], [577, 582], [583, 591], [592, 596], [597, 606], [607, 615], [616, 627], [627, 628], [629, 633], [634, 636], [637, 642], [642, 643], [644, 651], [651, 652], [653, 660], [660, 661], [662, 665], [666, 676], [676, 677], [678, 681], [682, 686], [687, 694], [694, 695]]}) 
answer: set([])
candidate Sentence: (0.21319462358951569, {u'tokens': [u'The', u'History', u'of', u'Musical', u'Instruments', u'-LRB-', u'New', u'York', u':', u'W.W.', u'Norton', u',', u'1940', u'-RRB-', u'.'], u'lemmas': [u'the', u'history', u'of', u'musical', u'Instruments', u'-lrb-', u'New', u'York', u':', u'W.W.', u'Norton', u',', u'1940', u'-rrb-', u'.'], u'pos': [u'DT', u'NN', u'IN', u'JJ', u'NNP', u'-LRB-', u'NNP', u'NNP', u':', u'NNP', u'NNP', u',', u'CD', u'-RRB-', u'.'], u'char_offsets': [[11795, 11798], [11799, 11806], [11807, 11809], [11810, 11817], [11818, 11829], [11830, 11831], [11831, 11834], [11835, 11839], [11839, 11840], [11841, 11845], [11846, 11852], [11852, 11853], [11854, 11858], [11858, 11859], [11859, 11860]]}) 
answer: set([u'stringed', u'instrument'])
candidate Sentence: (0.18262876570224762, {u'tokens': [u'This', u'group', u'they', u'usually', u'refer', u'to', u'as', u'the', u'lute', u'class', u',', u'after', u'the', u'instrument', u'of', u'that', u'name', u',', u'and', u'include', u'within', u'it', u'the', u'guitar', u',', u'the', u'violin', u',', u'the', u'banjo', u',', u'and', u'similar', u'stringed', u'instruments', u'with', u'fingerboards', u'.'], u'lemmas': [u'this', u'group', u'they', u'usually', u'refer', u'to', u'as', u'the', u'lute', u'class', u',', u'after', u'the', u'instrument', u'of', u'that', u'name', u',', u'and', u'include', u'within', u'it', u'the', u'guitar', u',', u'the', u'violin', u',', u'the', u'banjo', u',', u'and', u'similar', u'stringed', u'instrument', u'with', u'fingerboard', u'.'], u'pos': [u'DT', u'NN', u'PRP', u'RB', u'VBP', u'TO', u'IN', u'DT', u'NN', u'NN', u',', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u',', u'CC', u'VBP', u'IN', u'PRP', u'DT', u'NN', u',', u'DT', u'NN', u',', u'DT', u'NN', u',', u'CC', u'JJ', u'JJ', u'NNS', u'IN', u'NNS', u'.'], u'char_offsets': [[1402, 1406], [1407, 1412], [1413, 1417], [1418, 1425], [1426, 1431], [1432, 1434], [1435, 1437], [1438, 1441], [1442, 1446], [1447, 1452], [1452, 1453], [1454, 1459], [1460, 1463], [1464, 1474], [1475, 1477], [1478, 1482], [1483, 1487], [1487, 1488], [1489, 1492], [1493, 1500], [1501, 1507], [1508, 1510], [1511, 1514], [1515, 1521], [1521, 1522], [1523, 1526], [1527, 1533], [1533, 1534], [1535, 1538], [1539, 1544], [1544, 1545], [1546, 1549], [1550, 1557], [1558, 1566], [1567, 1578], [1579, 1583], [1584, 1596], [1596, 1597]]}) 
answer: set([u'musical'])
candidate Sentence: (0.13711260259151459, {u'tokens': [u'Reproduction', u'of', u'the', u'lyre', u'from', u'the', u'royal', u'burial', u'at', u'Sutton', u'Hoo', u',', u'late', u'6th/early', u'7th', u'century', u'AD', u'Other', u'instruments', u'known', u'as', u'lyres', u'have', u'been', u'fashioned', u'and', u'used', u'in', u'Europe', u'outside', u'the', u'Greco-Roman', u'world', u'since', u'at', u'least', u'the', u'early', u'Middle', u'Ages', u',', u'and', u'one', u'view', u'holds', u'that', u'many', u'modern', u'stringed', u'instruments', u'are', u'late-emerging', u'examples', u'of', u'the', u'lyre', u'class', u'.'], u'lemmas': [u'Reproduction', u'of', u'the', u'lyre', u'from', u'the', u'royal', u'burial', u'at', u'Sutton', u'Hoo', u',', u'late', u'6th/early', u'7th', u'century', u'ad', u'other', u'instrument', u'know', u'as', u'lyre', u'have', u'be', u'fashion', u'and', u'use', u'in', u'Europe', u'outside', u'the', u'Greco-Roman', u'world', u'since', u'at', u'least', u'the', u'early', u'middle', u'Ages', u',', u'and', u'one', u'view', u'hold', u'that', u'many', u'modern', u'stringed', u'instrument', u'be', u'late-emerging', u'example', u'of', u'the', u'lyre', u'class', u'.'], u'pos': [u'NNP', u'IN', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u',', u'JJ', u'RB', u'JJ', u'NN', u'NN', u'JJ', u'NNS', u'VBN', u'IN', u'NNS', u'VBP', u'VBN', u'VBN', u'CC', u'VBN', u'IN', u'NNP', u'IN', u'DT', u'NNP', u'NN', u'IN', u'IN', u'JJS', u'DT', u'JJ', u'NN', u'NNPS', u',', u'CC', u'CD', u'NN', u'VBZ', u'IN', u'JJ', u'JJ', u'JJ', u'NNS', u'VBP', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[8050, 8062], [8063, 8065], [8066, 8069], [8070, 8074], [8075, 8079], [8080, 8083], [8084, 8089], [8090, 8096], [8097, 8099], [8100, 8106], [8107, 8110], [8110, 8111], [8112, 8116], [8117, 8126], [8127, 8130], [8131, 8138], [8139, 8141], [8142, 8147], [8148, 8159], [8160, 8165], [8166, 8168], [8169, 8174], [8175, 8179], [8180, 8184], [8185, 8194], [8195, 8198], [8199, 8203], [8204, 8206], [8207, 8213], [8214, 8221], [8222, 8225], [8226, 8237], [8238, 8243], [8244, 8249], [8250, 8252], [8253, 8258], [8259, 8262], [8263, 8268], [8269, 8275], [8276, 8280], [8280, 8281], [8282, 8285], [8286, 8289], [8290, 8294], [8295, 8300], [8301, 8305], [8306, 8310], [8311, 8317], [8318, 8326], [8327, 8338], [8339, 8342], [8343, 8356], [8357, 8365], [8366, 8368], [8369, 8372], [8373, 8377], [8378, 8383], [8383, 8384]]}) 
answer: set([u'musical'])
candidate Sentence: (0.13288977742195129, {u'tokens': [u'While', u'the', u'dates', u'of', u'origin', u'and', u'other', u'evolutionary', u'details', u'of', u'the', u'European', u'bowed', u'yoke', u'lyres', u'continue', u'to', u'be', u'disputed', u'among', u'organologists', u',', u'there', u'is', u'general', u'agreement', u'that', u'none', u'of', u'them', u'were', u'the', u'ancestors', u'of', u'modern', u'orchestral', u'bowed', u'stringed', u'instruments', u',', u'as', u'once', u'was', u'thought', u'.'], u'lemmas': [u'while', u'the', u'date', u'of', u'origin', u'and', u'other', u'evolutionary', u'detail', u'of', u'the', u'european', u'bow', u'yoke', u'lyre', u'continue', u'to', u'be', u'dispute', u'among', u'organologist', u',', u'there', u'be', u'general', u'agreement', u'that', u'none', u'of', u'they', u'be', u'the', u'ancestor', u'of', u'modern', u'orchestral', u'bow', u'stringed', u'instrument', u',', u'as', u'once', u'be', u'think', u'.'], u'pos': [u'IN', u'DT', u'NNS', u'IN', u'NN', u'CC', u'JJ', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'VBD', u'NN', u'NNS', u'VBP', u'TO', u'VB', u'VBN', u'IN', u'NNS', u',', u'EX', u'VBZ', u'JJ', u'NN', u'WDT', u'NN', u'IN', u'PRP', u'VBD', u'DT', u'NNS', u'IN', u'JJ', u'JJ', u'VBD', u'JJ', u'NNS', u',', u'IN', u'RB', u'VBD', u'VBN', u'.'], u'char_offsets': [[10150, 10155], [10156, 10159], [10160, 10165], [10166, 10168], [10169, 10175], [10176, 10179], [10180, 10185], [10186, 10198], [10199, 10206], [10207, 10209], [10210, 10213], [10214, 10222], [10223, 10228], [10229, 10233], [10234, 10239], [10240, 10248], [10249, 10251], [10252, 10254], [10255, 10263], [10264, 10269], [10270, 10283], [10283, 10284], [10285, 10290], [10291, 10293], [10294, 10301], [10302, 10311], [10312, 10316], [10317, 10321], [10322, 10324], [10325, 10329], [10330, 10334], [10335, 10338], [10339, 10348], [10349, 10351], [10352, 10358], [10359, 10369], [10370, 10375], [10376, 10384], [10385, 10396], [10396, 10397], [10398, 10400], [10401, 10405], [10406, 10409], [10410, 10417], [10417, 10418]]}) 
answer: set([u'musical'])
candidate Sentence: (0.080507740378379822, {u'tokens': [u'A', u'music', u'holder', u'used', u'by', u'marching', u'bands', u'is', u'also', u'called', u'a', u'``', u'lyre', u"''", u'for', u'its', u'shape', u'similar', u'to', u'this', u'instrument', u'.'], u'lemmas': [u'a', u'music', u'holder', u'use', u'by', u'march', u'band', u'be', u'also', u'call', u'a', u'``', u'lyre', u"''", u'for', u'its', u'shape', u'similar', u'to', u'this', u'instrument', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBN', u'IN', u'VBG', u'NNS', u'VBZ', u'RB', u'VBN', u'DT', u'``', u'NN', u"''", u'IN', u'PRP$', u'NN', u'JJ', u'TO', u'DT', u'NN', u'.'], u'char_offsets': [[10617, 10618], [10619, 10624], [10625, 10631], [10632, 10636], [10637, 10639], [10640, 10648], [10649, 10654], [10655, 10657], [10658, 10662], [10663, 10669], [10670, 10671], [10672, 10673], [10673, 10677], [10677, 10678], [10679, 10682], [10683, 10686], [10687, 10692], [10693, 10700], [10701, 10703], [10704, 10708], [10709, 10719], [10719, 10720]]}) 
answer: set([u'stringed', u'musical'])
candidate Sentence: (0.077958539128303528, {u'tokens': [u'The', u'lyre', u'of', u'Classical', u'Antiquity', u'was', u'ordinarily', u'played', u'by', u'being', u'strummed', u'with', u'a', u'plectrum', u',', u'like', u'a', u'guitar', u'or', u'a', u'zither', u',', u'rather', u'than', u'being', u'plucked', u',', u'like', u'a', u'harp', u'.'], u'lemmas': [u'the', u'lyre', u'of', u'classical', u'antiquity', u'be', u'ordinarily', u'play', u'by', u'be', u'strum', u'with', u'a', u'plectrum', u',', u'like', u'a', u'guitar', u'or', u'a', u'zither', u',', u'rather', u'than', u'be', u'pluck', u',', u'like', u'a', u'harp', u'.'], u'pos': [u'DT', u'NN', u'IN', u'JJ', u'NN', u'VBD', u'RB', u'VBN', u'IN', u'VBG', u'VBN', u'IN', u'DT', u'NN', u',', u'IN', u'DT', u'NN', u'CC', u'DT', u'NN', u',', u'RB', u'IN', u'VBG', u'VBN', u',', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[172, 175], [176, 180], [181, 183], [184, 193], [194, 203], [204, 207], [208, 218], [219, 225], [226, 228], [229, 234], [235, 243], [244, 248], [249, 250], [251, 259], [259, 260], [261, 265], [266, 267], [268, 274], [275, 277], [278, 279], [280, 286], [286, 287], [288, 294], [295, 299], [300, 305], [306, 313], [313, 314], [315, 319], [320, 321], [322, 326], [326, 327]]}) 
answer: set([u'stringed', u'instrument', u'musical'])
candidate Sentence: (0.074648156762123108, {u'tokens': [u'Examples', u'of', u'that', u'difference', u'include', u'a', u'piano', u'-LRB-', u'a', u'keyed', u'zither', u'-RRB-', u'and', u'a', u'violin', u'-LRB-', u'referred', u'to', u'by', u'some', u'as', u'a', u'species', u'of', u'fingerboard', u'lyre', u'-RRB-', u'.'], u'lemmas': [u'example', u'of', u'that', u'difference', u'include', u'a', u'piano', u'-lrb-', u'a', u'key', u'zither', u'-rrb-', u'and', u'a', u'violin', u'-lrb-', u'refer', u'to', u'by', u'some', u'as', u'a', u'species', u'of', u'fingerboard', u'lyre', u'-rrb-', u'.'], u'pos': [u'NNS', u'IN', u'DT', u'NN', u'VBP', u'DT', u'NN', u'-LRB-', u'DT', u'VBN', u'NN', u'-RRB-', u'CC', u'DT', u'NN', u'-LRB-', u'VBN', u'TO', u'IN', u'DT', u'IN', u'DT', u'NNS', u'IN', u'NN', u'NN', u'-RRB-', u'.'], u'char_offsets': [[1069, 1077], [1078, 1080], [1081, 1085], [1086, 1096], [1097, 1104], [1105, 1106], [1107, 1112], [1113, 1114], [1114, 1115], [1116, 1121], [1122, 1128], [1128, 1129], [1130, 1133], [1134, 1135], [1136, 1142], [1143, 1144], [1144, 1152], [1153, 1155], [1156, 1158], [1159, 1163], [1164, 1166], [1167, 1168], [1169, 1176], [1177, 1179], [1180, 1191], [1192, 1196], [1196, 1197], [1197, 1198]]}) 
answer: set([u'stringed', u'instrument', u'musical'])
candidate Sentence: (0.062320858240127563, {u'tokens': [u'There', u'is', u'no', u'clear', u'evidence', u'that', u'non-Greco-Roman', u'lyres', u'were', u'played', u'exclusively', u'with', u'plectra', u',', u'and', u'numerous', u'instruments', u'regarded', u'by', u'some', u'as', u'modern', u'lyres', u'are', u'played', u'with', u'bows', u'.'], u'lemmas': [u'there', u'be', u'no', u'clear', u'evidence', u'that', u'non-greco-roman', u'lyre', u'be', u'play', u'exclusively', u'with', u'plectra', u',', u'and', u'numerous', u'instrument', u'regard', u'by', u'some', u'as', u'modern', u'lyre', u'be', u'play', u'with', u'bow', u'.'], u'pos': [u'EX', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u'VBD', u'VBN', u'RB', u'IN', u'NN', u',', u'CC', u'JJ', u'NNS', u'VBN', u'IN', u'DT', u'IN', u'JJ', u'NNS', u'VBP', u'VBN', u'IN', u'NNS', u'.'], u'char_offsets': [[8385, 8390], [8391, 8393], [8394, 8396], [8397, 8402], [8403, 8411], [8412, 8416], [8417, 8432], [8433, 8438], [8439, 8443], [8444, 8450], [8451, 8462], [8463, 8467], [8468, 8475], [8475, 8476], [8477, 8480], [8481, 8489], [8490, 8501], [8502, 8510], [8511, 8513], [8514, 8518], [8519, 8521], [8522, 8528], [8529, 8534], [8535, 8538], [8539, 8545], [8546, 8550], [8551, 8555], [8555, 8556]]}) 
answer: set([u'stringed', u'musical'])

Is the lyre a stringed musical instrument?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d3b48>.answer
_____________________________ test_yesno[param202] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d3bd8>, (<src.tfidf.TF_IDF object at 0x10a4d4ed0>, set(['language', 'malay', 'malay_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114d3bd8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.52360594272613525, {u'tokens': [u'One', u'of', u'these', u'is', u'that', u'it', u'came', u'from', u'Sumatra', u'island', u'.'], u'lemmas': [u'one', u'of', u'these', u'be', u'that', u'it', u'come', u'from', u'Sumatra', u'island', u'.'], u'pos': [u'CD', u'IN', u'DT', u'VBZ', u'IN', u'PRP', u'VBD', u'IN', u'NNP', u'NN', u'.'], u'char_offsets': [[1906, 1909], [1910, 1912], [1913, 1918], [1919, 1921], [1922, 1926], [1927, 1929], [1930, 1934], [1935, 1939], [1940, 1947], [1948, 1954], [1954, 1955]]}) 
answer: set([u'originate'])
candidate Sentence: (0.23928949236869812, {u'tokens': [u'-LSB-', u'1', u'-RSB-', u'There', u'are', u'many', u'hypotheses', u'as', u'to', u'where', u'the', u'Malay', u'language', u'originated', u'.'], u'lemmas': [u'-lsb-', u'1', u'-rsb-', u'there', u'be', u'many', u'hypothesis', u'as', u'to', u'where', u'the', u'Malay', u'language', u'originate', u'.'], u'pos': [u'-LRB-', u'CD', u'-RRB-', u'EX', u'VBP', u'JJ', u'NNS', u'IN', u'TO', u'WRB', u'DT', u'NNP', u'NN', u'VBD', u'.'], u'char_offsets': [[1833, 1834], [1834, 1835], [1835, 1836], [1837, 1842], [1843, 1846], [1847, 1851], [1852, 1862], [1863, 1865], [1866, 1868], [1869, 1874], [1875, 1878], [1879, 1884], [1885, 1893], [1894, 1904], [1904, 1905]]}) 
answer: set([u'island', u'sumatra'])
candidate Sentence: (0.16777566075325012, {u'tokens': [u'The', u'oldest', u'written', u'documents', u'in', u'Malay', u',', u'dated', u'from', u'the', u'end', u'of', u'the', u'7th', u'century', u'AD', u',', u'were', u'found', u'on', u'Bangka', u'Island', u',', u'off', u'the', u'southeastern', u'coast', u'of', u'Sumatra', u'and', u'in', u'Palembang', u'in', u'southern', u'Sumatra', u'.'], u'lemmas': [u'the', u'oldest', u'write', u'document', u'in', u'Malay', u',', u'date', u'from', u'the', u'end', u'of', u'the', u'7th', u'century', u'ad', u',', u'be', u'find', u'on', u'Bangka', u'Island', u',', u'off', u'the', u'southeastern', u'coast', u'of', u'Sumatra', u'and', u'in', u'Palembang', u'in', u'southern', u'Sumatra', u'.'], u'pos': [u'DT', u'JJS', u'VBN', u'NNS', u'IN', u'NNP', u',', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u',', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u',', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'CC', u'IN', u'NNP', u'IN', u'JJ', u'NNP', u'.'], u'char_offsets': [[1956, 1959], [1960, 1966], [1967, 1974], [1975, 1984], [1985, 1987], [1988, 1993], [1993, 1994], [1995, 2000], [2001, 2005], [2006, 2009], [2010, 2013], [2014, 2016], [2017, 2020], [2021, 2024], [2025, 2032], [2033, 2035], [2035, 2036], [2037, 2041], [2042, 2047], [2048, 2050], [2051, 2057], [2058, 2064], [2064, 2065], [2066, 2069], [2070, 2073], [2074, 2086], [2087, 2092], [2093, 2095], [2096, 2103], [2104, 2107], [2108, 2110], [2111, 2120], [2121, 2123], [2124, 2132], [2133, 2140], [2140, 2141]]}) 
answer: set([u'originate'])
candidate Sentence: (0.11002375930547714, {u'tokens': [u'In', u'several', u'parts', u'of', u'Indonesia', u',', u'in', u'Sumatra', u'and', u'Borneo', u'Islands', u',', u'Malay', u'is', u'spoken', u'as', u'local', u'dialect', u'of', u'ethnic', u'Malays', u'.'], u'lemmas': [u'in', u'several', u'part', u'of', u'Indonesia', u',', u'in', u'Sumatra', u'and', u'Borneo', u'Islands', u',', u'Malay', u'be', u'speak', u'as', u'local', u'dialect', u'of', u'ethnic', u'Malays', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u'IN', u'NNP', u',', u'IN', u'NNP', u'CC', u'NNP', u'NNPS', u',', u'NNP', u'VBZ', u'VBN', u'IN', u'JJ', u'NN', u'IN', u'JJ', u'NNP', u'.'], u'char_offsets': [[3110, 3112], [3113, 3120], [3121, 3126], [3127, 3129], [3130, 3139], [3139, 3140], [3141, 3143], [3144, 3151], [3152, 3155], [3156, 3162], [3163, 3170], [3170, 3171], [3172, 3177], [3178, 3180], [3181, 3187], [3188, 3190], [3191, 3196], [3197, 3204], [3205, 3207], [3208, 3214], [3215, 3221], [3221, 3222]]}) 
answer: set([u'island', u'originate'])
candidate Sentence: (0.09979606419801712, {u'tokens': [u'Many', u'roots', u'have', u'come', u'virtually', u'unchanged', u'from', u'their', u'common', u'Austronesian', u'ancestor', u'.'], u'lemmas': [u'many', u'root', u'have', u'come', u'virtually', u'unchanged', u'from', u'they', u'common', u'austronesian', u'ancestor', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'VBN', u'RB', u'JJ', u'IN', u'PRP$', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[6754, 6758], [6759, 6764], [6765, 6769], [6770, 6774], [6775, 6784], [6785, 6794], [6795, 6799], [6800, 6805], [6806, 6812], [6813, 6825], [6826, 6834], [6834, 6835]]}) 
answer: set([u'island', u'sumatra', u'originate'])
candidate Sentence: (0.097680531442165375, {u'tokens': [u'Historically', u',', u'Malay', u'has', u'been', u'written', u'using', u'various', u'scripts', u'.'], u'lemmas': [u'Historically', u',', u'Malay', u'have', u'be', u'write', u'use', u'various', u'script', u'.'], u'pos': [u'NNP', u',', u'NNP', u'VBZ', u'VBN', u'VBN', u'VBG', u'JJ', u'NNS', u'.'], u'char_offsets': [[7631, 7643], [7643, 7644], [7645, 7650], [7651, 7654], [7655, 7659], [7660, 7667], [7668, 7673], [7674, 7681], [7682, 7689], [7689, 7690]]}) 
answer: set([u'island', u'sumatra', u'originate'])
candidate Sentence: (0.095397040247917175, {u'tokens': [u'``', u'Malayu', u"''", u'was', u'the', u'name', u'of', u'an', u'old', u'kingdom', u'located', u'in', u'Jambi', u'province', u'in', u'eastern', u'Sumatra', u'.'], u'lemmas': [u'``', u'malayu', u"''", u'be', u'the', u'name', u'of', u'a', u'old', u'kingdom', u'located', u'in', u'Jambi', u'province', u'in', u'eastern', u'Sumatra', u'.'], u'pos': [u'``', u'FW', u"''", u'VBD', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'JJ', u'IN', u'NNP', u'NN', u'IN', u'JJ', u'NNP', u'.'], u'char_offsets': [[2142, 2143], [2143, 2149], [2149, 2150], [2151, 2154], [2155, 2158], [2159, 2163], [2164, 2166], [2167, 2169], [2170, 2173], [2174, 2181], [2182, 2189], [2190, 2192], [2193, 2198], [2199, 2207], [2208, 2210], [2211, 2218], [2219, 2226], [2226, 2227]]}) 
answer: set([u'island', u'originate'])
candidate Sentence: (0.087915360927581787, {u'tokens': [u'In', u'Malay', u',', u'there', u'are', u':', u'Adjective', u'affixes', u'are', u'attached', u'to', u'root', u'words', u'to', u'form', u'adjectives', u':', u'In', u'addition', u'to', u'these', u'affixes', u',', u'Malay', u'also', u'has', u'a', u'lot', u'of', u'borrowed', u'affixes', u'from', u'other', u'languages', u'such', u'as', u'Sanskrit', u',', u'Arabic', u'and', u'English', u'.'], u'lemmas': [u'in', u'Malay', u',', u'there', u'be', u':', u'Adjective', u'affix', u'be', u'attach', u'to', u'root', u'word', u'to', u'form', u'adjective', u':', u'in', u'addition', u'to', u'these', u'affix', u',', u'Malay', u'also', u'have', u'a', u'lot', u'of', u'borrow', u'affix', u'from', u'other', u'language', u'such', u'as', u'Sanskrit', u',', u'Arabic', u'and', u'English', u'.'], u'pos': [u'IN', u'NNP', u',', u'EX', u'VBP', u':', u'NNP', u'VBZ', u'VBP', u'VBN', u'TO', u'VB', u'NNS', u'TO', u'VB', u'NNS', u':', u'IN', u'NN', u'TO', u'DT', u'NNS', u',', u'NNP', u'RB', u'VBZ', u'DT', u'NN', u'IN', u'VBN', u'NNS', u'IN', u'JJ', u'NNS', u'JJ', u'IN', u'NNP', u',', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[11172, 11174], [11175, 11180], [11180, 11181], [11182, 11187], [11188, 11191], [11191, 11192], [11193, 11202], [11203, 11210], [11211, 11214], [11215, 11223], [11224, 11226], [11227, 11231], [11232, 11237], [11238, 11240], [11241, 11245], [11246, 11256], [11256, 11257], [11258, 11260], [11261, 11269], [11270, 11272], [11273, 11278], [11279, 11286], [11286, 11287], [11288, 11293], [11294, 11298], [11299, 11302], [11303, 11304], [11305, 11308], [11309, 11311], [11312, 11320], [11321, 11328], [11329, 11333], [11334, 11339], [11340, 11349], [11350, 11354], [11355, 11357], [11358, 11366], [11366, 11367], [11368, 11374], [11375, 11378], [11379, 11386], [11386, 11387]]}) 
answer: set([u'island', u'sumatra', u'originate'])
candidate Sentence: (0.085581511259078979, {u'tokens': [u'The', u'earliest', u'known', u'inscription', u'in', u'the', u'Old', u'Malay', u'language', u'was', u'found', u'in', u'Sumatra', u',', u'written', u'in', u'Pallava', u'variant', u'of', u'Grantha', u'script', u'/', u'ref', u'>', u'and', u'dates', u'back', u'to', u'7th', u'century', u'-', u'known', u'as', u'Kedukan', u'Bukit', u'Inscription', u',', u'it', u'was', u'discovered', u'by', u'the', u'Dutchman', u'M.', u'Batenburg', u'on', u'29', u'November', u'1920', u',', u'at', u'Kedukan', u'Bukit', u',', u'South', u'Sumatra', u',', u'on', u'the', u'banks', u'of', u'the', u'River', u'Tatang', u',', u'a', u'tributary', u'of', u'the', u'River', u'Musi', u'.'], u'lemmas': [u'the', u'earliest', u'known', u'inscription', u'in', u'the', u'Old', u'Malay', u'language', u'be', u'find', u'in', u'Sumatra', u',', u'write', u'in', u'pallava', u'variant', u'of', u'grantha', u'script', u'/', u'ref', u'>', u'and', u'date', u'back', u'to', u'7th', u'century', u'-', u'know', u'as', u'Kedukan', u'Bukit', u'Inscription', u',', u'it', u'be', u'discover', u'by', u'the', u'Dutchman', u'M.', u'Batenburg', u'on', u'29', u'November', u'1920', u',', u'at', u'Kedukan', u'Bukit', u',', u'South', u'Sumatra', u',', u'on', u'the', u'bank', u'of', u'the', u'river', u'Tatang', u',', u'a', u'tributary', u'of', u'the', u'River', u'Musi', u'.'], u'pos': [u'DT', u'JJS', u'JJ', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'NN', u'VBD', u'VBN', u'IN', u'NNP', u',', u'VBN', u'IN', u'NN', u'NN', u'IN', u'NN', u'NN', u':', u'NN', u'JJR', u'CC', u'VBZ', u'RB', u'TO', u'JJ', u'NN', u':', u'VBN', u'IN', u'NNP', u'NNP', u'NNP', u',', u'PRP', u'VBD', u'VBN', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u'IN', u'CD', u'NNP', u'CD', u',', u'IN', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'IN', u'DT', u'NNS', u'IN', u'DT', u'NN', u'NNP', u',', u'DT', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'.'], u'char_offsets': [[5187, 5190], [5191, 5199], [5200, 5205], [5206, 5217], [5218, 5220], [5221, 5224], [5225, 5228], [5229, 5234], [5235, 5243], [5244, 5247], [5248, 5253], [5254, 5256], [5257, 5264], [5264, 5265], [5266, 5273], [5274, 5276], [5277, 5284], [5285, 5292], [5293, 5295], [5296, 5303], [5304, 5310], [5313, 5314], [5314, 5317], [5317, 5318], [5319, 5322], [5323, 5328], [5329, 5333], [5334, 5336], [5337, 5340], [5341, 5348], [5349, 5350], [5351, 5356], [5357, 5359], [5360, 5367], [5368, 5373], [5374, 5385], [5385, 5386], [5387, 5389], [5390, 5393], [5394, 5404], [5405, 5407], [5408, 5411], [5412, 5420], [5421, 5423], [5424, 5433], [5434, 5436], [5437, 5439], [5440, 5448], [5449, 5453], [5453, 5454], [5455, 5457], [5458, 5465], [5466, 5471], [5471, 5472], [5473, 5478], [5479, 5486], [5486, 5487], [5488, 5490], [5491, 5494], [5495, 5500], [5501, 5503], [5504, 5507], [5508, 5513], [5514, 5520], [5520, 5521], [5522, 5523], [5524, 5533], [5534, 5536], [5537, 5540], [5541, 5546], [5547, 5551], [5551, 5552]]}) 
answer: set([u'island', u'originate'])
candidate Sentence: (0.063236705958843231, {u'tokens': [u'However', u',', u'reduplication', u'has', u'most', u'of', u'the', u'time', u'many', u'other', u'functions', u'and', u'meanings', u'.'], u'lemmas': [u'however', u',', u'reduplication', u'have', u'most', u'of', u'the', u'time', u'many', u'other', u'function', u'and', u'meaning', u'.'], u'pos': [u'RB', u',', u'NN', u'VBZ', u'JJS', u'IN', u'DT', u'NN', u'JJ', u'JJ', u'NNS', u'CC', u'NNS', u'.'], u'char_offsets': [[14059, 14066], [14066, 14067], [14068, 14081], [14082, 14085], [14086, 14090], [14091, 14093], [14094, 14097], [14098, 14102], [14103, 14107], [14108, 14113], [14114, 14123], [14124, 14127], [14128, 14136], [14136, 14137]]}) 
answer: set([u'island', u'sumatra', u'originate'])

Could Malay have originated from Sumatra island?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114d3bd8>.answer
_____________________________ test_yesno[param221] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8170>, (<src.tfidf.TF_IDF object at 0x10a4b08d0>, set(['faraday', 'michael', 'michael_faraday'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8170>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.63347971439361572, {u'tokens': [u'Faraday', u'also', u'was', u'active', u'in', u'what', u'would', u'now', u'be', u'called', u'environmental', u'science', u',', u'or', u'engineering', u'.'], u'lemmas': [u'Faraday', u'also', u'be', u'active', u'in', u'what', u'would', u'now', u'be', u'call', u'environmental', u'science', u',', u'or', u'engineering', u'.'], u'pos': [u'NNP', u'RB', u'VBD', u'JJ', u'IN', u'WP', u'MD', u'RB', u'VB', u'VBN', u'JJ', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[19377, 19384], [19385, 19389], [19390, 19393], [19394, 19400], [19401, 19403], [19404, 19408], [19409, 19414], [19415, 19418], [19419, 19421], [19422, 19428], [19429, 19442], [19443, 19450], [19450, 19451], [19452, 19454], [19455, 19466], [19466, 19467]]}) 
answer: set([u'area'])
candidate Sentence: (0.20785526931285858, {u'tokens': [u'*', u'Regarding', u'the', u'hereafter', u',', u'``', u'Speculations', u'?'], u'lemmas': [u'*', u'regard', u'the', u'hereafter', u',', u'``', u'speculation', u'?'], u'pos': [u'SYM', u'VBG', u'DT', u'RB', u',', u'``', u'NNS', u'.'], u'char_offsets': [[24894, 24895], [24896, 24905], [24906, 24909], [24910, 24919], [24919, 24920], [24921, 24922], [24922, 24934], [24934, 24935]]}) 
answer: set([u'area', u'science', u'environmental', u'call', u'active', u'now'])
candidate Sentence: (0.19536694884300232, {u'tokens': [u'Education', u'was', u'another', u'area', u'of', u'service', u'for', u'Faraday', u'.'], u'lemmas': [u'education', u'be', u'another', u'area', u'of', u'service', u'for', u'Faraday', u'.'], u'pos': [u'NN', u'VBD', u'DT', u'NN', u'IN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[20010, 20019], [20020, 20023], [20024, 20031], [20032, 20036], [20037, 20039], [20040, 20047], [20048, 20051], [20052, 20059], [20059, 20060]]}) 
answer: set([u'active', u'science', u'now', u'call', u'environmental'])
candidate Sentence: (0.16763134300708771, {u'tokens': [u'This', u'is', u'now', u'termed', u'the', u'Faraday', u'effect', u'.'], u'lemmas': [u'this', u'be', u'now', u'term', u'the', u'Faraday', u'effect', u'.'], u'pos': [u'DT', u'VBZ', u'RB', u'VBN', u'DT', u'NNP', u'NN', u'.'], u'char_offsets': [[16311, 16315], [16316, 16318], [16319, 16322], [16323, 16329], [16330, 16333], [16334, 16341], [16342, 16348], [16348, 16349]]}) 
answer: set([u'active', u'science', u'call', u'environmental', u'area'])
candidate Sentence: (0.14287599921226501, {u'tokens': [u'Some', u'historians', u'of', u'science', u'refer', u'to', u'him', u'as', u'the', u'best', u'experimentalist', u'in', u'the', u'history', u'of', u'science', u'.'], u'lemmas': [u'some', u'historian', u'of', u'science', u'refer', u'to', u'he', u'as', u'the', u'best', u'experimentalist', u'in', u'the', u'history', u'of', u'science', u'.'], u'pos': [u'DT', u'NNS', u'IN', u'NN', u'VBP', u'TO', u'PRP', u'IN', u'DT', u'JJS', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[1382, 1386], [1387, 1397], [1401, 1403], [1404, 1411], [1412, 1417], [1418, 1420], [1421, 1424], [1425, 1427], [1428, 1431], [1432, 1436], [1437, 1452], [1453, 1455], [1456, 1459], [1460, 1467], [1468, 1470], [1471, 1478], [1478, 1479]]}) 
answer: set([u'active', u'environmental', u'now', u'call', u'area'])
candidate Sentence: (0.1339237242937088, {u'tokens': [u'This', u'was', u'the', u'Master', u'Mason', u"'s", u'House', u',', u'later', u'called', u'Faraday', u'House', u',', u'and', u'now', u'No.', u'37', u'Hampton', u'Court', u'Road', u'.'], u'lemmas': [u'this', u'be', u'the', u'Master', u'Mason', u"'s", u'House', u',', u'later', u'call', u'Faraday', u'House', u',', u'and', u'now', u'no.', u'37', u'Hampton', u'Court', u'Road', u'.'], u'pos': [u'DT', u'VBD', u'DT', u'NNP', u'NNP', u'POS', u'NNP', u',', u'RB', u'VBN', u'NNP', u'NNP', u',', u'CC', u'RB', u'NN', u'CD', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[21361, 21365], [21366, 21369], [21370, 21373], [21374, 21380], [21381, 21386], [21386, 21388], [21389, 21394], [21394, 21395], [21396, 21401], [21402, 21408], [21409, 21416], [21417, 21422], [21422, 21423], [21424, 21427], [21428, 21431], [21432, 21435], [21435, 21437], [21438, 21445], [21446, 21451], [21452, 21456], [21456, 21457]]}) 
answer: set([u'active', u'science', u'area', u'environmental'])
candidate Sentence: (0.12861759960651398, {u'tokens': [u'History', u'of', u'Science', u'and', u'Technology', u'.'], u'lemmas': [u'history', u'of', u'science', u'and', u'technology', u'.'], u'pos': [u'NN', u'IN', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[3690, 3697], [3698, 3700], [3701, 3708], [3709, 3712], [3713, 3723], [3723, 3724]]}) 
answer: set([u'active', u'environmental', u'now', u'call', u'area'])
candidate Sentence: (0.11733967810869217, {u'tokens': [u'This', u'shielding', u'effect', u'is', u'used', u'in', u'what', u'is', u'now', u'known', u'as', u'a', u'Faraday', u'cage', u'.'], u'lemmas': [u'this', u'shield', u'effect', u'be', u'use', u'in', u'what', u'be', u'now', u'know', u'as', u'a', u'Faraday', u'cage', u'.'], u'pos': [u'DT', u'VBG', u'NN', u'VBZ', u'VBN', u'IN', u'WP', u'VBZ', u'RB', u'VBN', u'IN', u'DT', u'NNP', u'NN', u'.'], u'char_offsets': [[17387, 17391], [17392, 17401], [17402, 17408], [17409, 17411], [17412, 17416], [17417, 17419], [17420, 17424], [17425, 17427], [17428, 17431], [17432, 17437], [17438, 17440], [17441, 17442], [17443, 17450], [17451, 17455], [17455, 17456]]}) 
answer: set([u'active', u'science', u'call', u'environmental', u'area'])
candidate Sentence: (0.10605959594249725, {u'tokens': [u'Faraday', u'was', u'the', u'first', u'to', u'report', u'what', u'later', u'came', u'to', u'be', u'called', u'metallic', u'nanoparticles', u'.'], u'lemmas': [u'Faraday', u'be', u'the', u'first', u'to', u'report', u'what', u'later', u'come', u'to', u'be', u'call', u'metallic', u'nanoparticle', u'.'], u'pos': [u'NNP', u'VBD', u'DT', u'JJ', u'TO', u'VB', u'WP', u'RB', u'VBD', u'TO', u'VB', u'VBN', u'JJ', u'NNS', u'.'], u'char_offsets': [[9745, 9752], [9753, 9756], [9757, 9760], [9761, 9766], [9767, 9769], [9770, 9776], [9777, 9781], [9782, 9787], [9788, 9792], [9793, 9795], [9796, 9798], [9799, 9805], [9806, 9814], [9815, 9828], [9828, 9829]]}) 
answer: set([u'active', u'science', u'now', u'environmental', u'area'])
candidate Sentence: (0.10592009127140045, {u'tokens': [u'``', u'best', u'experimentalist', u'in', u'the', u'history', u'of', u'science', u'.', u"''"], u'lemmas': [u'``', u'best', u'experimentalist', u'in', u'the', u'history', u'of', u'science', u'.', u"''"], u'pos': [u'``', u'JJS', u'NN', u'IN', u'DT', u'NN', u'IN', u'NN', u'.', u"''"], u'char_offsets': [[1481, 1482], [1482, 1486], [1487, 1502], [1503, 1505], [1506, 1509], [1510, 1517], [1518, 1520], [1521, 1528], [1528, 1529], [1529, 1530]]}) 
answer: set([u'active', u'environmental', u'now', u'call', u'area'])

was he active in the area now called environmental science?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8170>.answer
_____________________________ test_yesno[param232] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8488>, (<src.tfidf.TF_IDF object at 0x10e16f950>, set(['nikola', 'nikola_tesla', 'tesla'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Nikola Tesla died alone.') == True
E                +  where 'Nikola Tesla died alone.' = <src.question_processing.Question_parser instance at 0x1114d8488>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.346649169921875, {u'tokens': [u'Did', u'Tesla', u'really', u'invent', u'the', u'loudspeaker', u'?', u"''"], u'lemmas': [u'do', u'Tesla', u'really', u'invent', u'the', u'loudspeaker', u'?', u"''"], u'pos': [u'VBD', u'NNP', u'RB', u'VB', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[7475, 7478], [7479, 7484], [7485, 7491], [7492, 7498], [7499, 7502], [7503, 7514], [7514, 7515], [7515, 7516]]}) 
answer: set([u'alone', u'die'])
candidate Sentence: (0.2918725311756134, {u'tokens': [u'Why', u'the', u'Name', u'``', u'Tesla', u"''", u'?'], u'lemmas': [u'why', u'the', u'name', u'``', u'Tesla', u"''", u'?'], u'pos': [u'WRB', u'DT', u'NN', u'``', u'NNP', u"''", u'.'], u'char_offsets': [[49416, 49419], [49420, 49423], [49424, 49428], [49429, 49430], [49430, 49435], [49435, 49436], [49436, 49437]]}) 
answer: set([u'alone', u'die'])
candidate Sentence: (0.26085346937179565, {u'tokens': [u'Prodigal', u'Genius', u':', u'The', u'Life', u'of', u'Nikola', u'Tesla', u'by', u'John', u'Jacob', u"O'Neill", u'ISBN', u'978-0914732334', u'Tesla', u'died', u'of', u'heart', u'failure', u'alone', u'in', u'room', u'3327', u'of', u'the', u'New', u'Yorker', u'Hotel', u',', u'on', u'7', u'January', u'1943', u'.'], u'lemmas': [u'prodigal', u'genius', u':', u'the', u'life', u'of', u'Nikola', u'Tesla', u'by', u'John', u'Jacob', u"O'Neill", u'ISBN', u'978-0914732334', u'Tesla', u'die', u'of', u'heart', u'failure', u'alone', u'in', u'room', u'3327', u'of', u'the', u'New', u'Yorker', u'Hotel', u',', u'on', u'7', u'January', u'1943', u'.'], u'pos': [u'JJ', u'NN', u':', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'NNP', u'CD', u'NNP', u'VBD', u'IN', u'NN', u'NN', u'RB', u'IN', u'NN', u'CD', u'IN', u'DT', u'NNP', u'NNP', u'NNP', u',', u'IN', u'CD', u'NNP', u'CD', u'.'], u'char_offsets': [[42568, 42576], [42577, 42583], [42583, 42584], [42585, 42588], [42589, 42593], [42594, 42596], [42597, 42603], [42604, 42609], [42610, 42612], [42613, 42617], [42618, 42623], [42624, 42631], [42632, 42636], [42637, 42651], [42652, 42657], [42658, 42662], [42663, 42665], [42666, 42671], [42672, 42679], [42680, 42685], [42686, 42688], [42689, 42693], [42694, 42698], [42699, 42701], [42702, 42705], [42706, 42709], [42710, 42716], [42717, 42722], [42722, 42723], [42724, 42726], [42727, 42728], [42729, 42736], [42737, 42741], [42741, 42742]]}) 
answer: set([])
candidate Sentence: (0.17754662036895752, {u'tokens': [u'ISBN', u'*', u'Valentinuzzi', u',', u'M.E.', u',', u'Nikola', u'Tesla', u':', u'why', u'was', u'he', u'so', u'much', u'resisted', u'and', u'forgotten', u'?'], u'lemmas': [u'ISBN', u'*', u'Valentinuzzi', u',', u'M.E.', u',', u'Nikola', u'Tesla', u':', u'why', u'be', u'he', u'so', u'much', u'resist', u'and', u'forget', u'?'], u'pos': [u'NNP', u'SYM', u'NNP', u',', u'NNP', u',', u'NNP', u'NNP', u':', u'WRB', u'VBD', u'PRP', u'RB', u'RB', u'VBN', u'CC', u'VBN', u'.'], u'char_offsets': [[56372, 56376], [56377, 56378], [56379, 56391], [56391, 56392], [56393, 56397], [56397, 56398], [56399, 56405], [56406, 56411], [56411, 56412], [56413, 56416], [56417, 56420], [56421, 56423], [56424, 56426], [56427, 56431], [56432, 56440], [56441, 56444], [56445, 56454], [56454, 56455]]}) 
answer: set([u'alone', u'die'])
candidate Sentence: (0.16273051500320435, {u'tokens': [u'Seifer', u',', u'``', u'Wizard', u"''", u'pp', u'378', u'--', u'380', u'Earlier', u',', u'Tesla', u'alone', u'was', u'rumored', u'to', u'have', u'been', u'nominated', u'for', u'the', u'Nobel', u'Prize', u'of', u'1912', u'.'], u'lemmas': [u'Seifer', u',', u'``', u'Wizard', u"''", u'pp', u'378', u'--', u'380', u'earlier', u',', u'Tesla', u'alone', u'be', u'rumor', u'to', u'have', u'be', u'nominate', u'for', u'the', u'Nobel', u'Prize', u'of', u'1912', u'.'], u'pos': [u'NNP', u',', u'``', u'NNP', u"''", u'NN', u'CD', u':', u'CD', u'JJR', u',', u'NNP', u'RB', u'VBD', u'VBN', u'TO', u'VB', u'VBN', u'VBN', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'CD', u'.'], u'char_offsets': [[28807, 28813], [28813, 28814], [28815, 28816], [28816, 28822], [28822, 28823], [28824, 28826], [28827, 28830], [28830, 28831], [28831, 28834], [28836, 28843], [28843, 28844], [28845, 28850], [28851, 28856], [28857, 28860], [28861, 28868], [28869, 28871], [28872, 28876], [28877, 28881], [28882, 28891], [28892, 28895], [28896, 28899], [28900, 28905], [28906, 28911], [28912, 28914], [28915, 28919], [28919, 28920]]}) 
answer: set([u'die'])
candidate Sentence: (0.15547725558280945, {u'tokens': [u'It', u'is', u'said', u'he', u'died', u'impoverished', u',', u'at', u'the', u'age', u'of', u'86', u'.'], u'lemmas': [u'it', u'be', u'say', u'he', u'die', u'impoverished', u',', u'at', u'the', u'age', u'of', u'86', u'.'], u'pos': [u'PRP', u'VBZ', u'VBD', u'PRP', u'VBD', u'JJ', u',', u'IN', u'DT', u'NN', u'IN', u'CD', u'.'], u'char_offsets': [[1535, 1537], [1538, 1540], [1541, 1545], [1546, 1548], [1549, 1553], [1554, 1566], [1566, 1567], [1568, 1570], [1571, 1574], [1575, 1578], [1579, 1581], [1582, 1584], [1584, 1585]]}) 
answer: set([u'alone'])
candidate Sentence: (0.14595095813274384, {u'tokens': [u'He', u'did', u'not', u'like', u'posing', u'for', u'portraits', u',', u'doing', u'so', u'only', u'once', u'for', u'princess', u'Vilma', u'Lwoff-Parlaghy', u'.'], u'lemmas': [u'he', u'do', u'not', u'like', u'pose', u'for', u'portrait', u',', u'do', u'so', u'only', u'once', u'for', u'princess', u'Vilma', u'Lwoff-Parlaghy', u'.'], u'pos': [u'PRP', u'VBD', u'RB', u'VB', u'VBG', u'IN', u'NNS', u',', u'VBG', u'RB', u'RB', u'RB', u'IN', u'NN', u'NNP', u'NNP', u'.'], u'char_offsets': [[46695, 46697], [46698, 46701], [46702, 46705], [46706, 46710], [46711, 46717], [46718, 46721], [46722, 46731], [46731, 46732], [46733, 46738], [46739, 46741], [46742, 46746], [46747, 46751], [46752, 46755], [46756, 46764], [46765, 46770], [46771, 46785], [46785, 46786]]}) 
answer: set([u'alone', u'die'])
candidate Sentence: (0.1430395245552063, {u'tokens': [u'*', u'W.C.', u'Wysock', u',', u'J.F.', u'Corum', u',', u'J.M.', u'Hardesty', u'and', u'K.L.', u'Corum', u',', u'Who', u'Was', u'The', u'Real', u'Dr.', u'Nikola', u'Tesla', u'?'], u'lemmas': [u'*', u'W.C.', u'Wysock', u',', u'J.F.', u'Corum', u',', u'J.M.', u'Hardesty', u'and', u'K.L.', u'Corum', u',', u'who', u'be', u'the', u'real', u'Dr.', u'Nikola', u'Tesla', u'?'], u'pos': [u'SYM', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u',', u'WP', u'VBD', u'DT', u'JJ', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[55797, 55798], [55799, 55803], [55804, 55810], [55810, 55811], [55812, 55816], [55817, 55822], [55822, 55823], [55824, 55828], [55829, 55837], [55838, 55841], [55842, 55846], [55847, 55852], [55852, 55853], [55855, 55858], [55859, 55862], [55863, 55866], [55867, 55871], [55872, 55875], [55876, 55882], [55883, 55888], [55888, 55889]]}) 
answer: set([u'alone', u'die'])
candidate Sentence: (0.13964457809925079, {u'tokens': [u'*', u'Nikola', u'Tesla', u'.'], u'lemmas': [u'*', u'Nikola', u'Tesla', u'.'], u'pos': [u'SYM', u'NNP', u'NNP', u'.'], u'char_offsets': [[55117, 55118], [55120, 55126], [55127, 55132], [55132, 55133]]}) 
answer: set([u'alone', u'die'])
candidate Sentence: (0.13268288969993591, {u'tokens': [u'Despite', u'having', u'sold', u'his', u'AC', u'electricity', u'patents', u',', u'Tesla', u'died', u'with', u'significant', u'debts', u'on', u'the', u'books', u'.'], u'lemmas': [u'despite', u'have', u'sell', u'he', u'ac', u'electricity', u'patent', u',', u'Tesla', u'die', u'with', u'significant', u'debt', u'on', u'the', u'book', u'.'], u'pos': [u'IN', u'VBG', u'VBN', u'PRP$', u'NN', u'NN', u'NNS', u',', u'NNP', u'VBD', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[42746, 42753], [42754, 42760], [42761, 42765], [42766, 42769], [42770, 42772], [42773, 42784], [42785, 42792], [42792, 42793], [42794, 42799], [42800, 42804], [42805, 42809], [42810, 42821], [42822, 42827], [42828, 42830], [42831, 42834], [42835, 42840], [42840, 42841]]}) 
answer: set([u'alone'])

Did Nikola Tesla die alone?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Nikola Tesla died alone.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Nikola Tesla died alone.') == True
 +  where 'Nikola Tesla died alone.' = <src.question_processing.Question_parser instance at 0x1114d8488>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param234] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8518>, (<src.tfidf.TF_IDF object at 0x10e16f950>, set(['nikola', 'nikola_tesla', 'tesla'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Nikola Tesla was close friends with Mark Twain.') == True
E                +  where 'Nikola Tesla was close friends with Mark Twain.' = <src.question_processing.Question_parser instance at 0x1114d8518>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.67244809865951538, {u'tokens': [u'Mark', u'Twain', u'in', u'Tesla', u"'s", u'lab', u',', u'spring', u'1894', u'In', u'middle', u'age', u',', u'Tesla', u'became', u'very', u'close', u'friends', u'with', u'Mark', u'Twain', u'.'], u'lemmas': [u'Mark', u'Twain', u'in', u'Tesla', u"'s", u'lab', u',', u'spring', u'1894', u'in', u'middle', u'age', u',', u'Tesla', u'become', u'very', u'close', u'friend', u'with', u'Mark', u'Twain', u'.'], u'pos': [u'NNP', u'NNP', u'IN', u'NNP', u'POS', u'NN', u',', u'NN', u'CD', u'IN', u'JJ', u'NN', u',', u'NNP', u'VBD', u'RB', u'JJ', u'NNS', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[39377, 39381], [39382, 39387], [39388, 39390], [39391, 39396], [39396, 39398], [39399, 39402], [39402, 39403], [39404, 39410], [39411, 39415], [39416, 39418], [39419, 39425], [39426, 39429], [39429, 39430], [39431, 39436], [39437, 39443], [39444, 39448], [39449, 39454], [39455, 39462], [39463, 39467], [39468, 39472], [39473, 39478], [39478, 39479]]}) 
answer: set([])
candidate Sentence: (0.37225052714347839, {u'tokens': [u'Krumme', u',', u'Katherine', u',', u'Mark', u'Twain', u'and', u'Nikola', u'Tesla', u':', u'Thunder', u'and', u'Lightning', u'.'], u'lemmas': [u'Krumme', u',', u'Katherine', u',', u'Mark', u'Twain', u'and', u'Nikola', u'Tesla', u':', u'thunder', u'and', u'lightning', u'.'], u'pos': [u'NNP', u',', u'NNP', u',', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u':', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[17418, 17424], [17424, 17425], [17426, 17435], [17435, 17436], [17438, 17442], [17443, 17448], [17449, 17452], [17453, 17459], [17460, 17465], [17465, 17466], [17467, 17474], [17475, 17478], [17479, 17488], [17488, 17489]]}) 
answer: set([u'close', u'friend'])
candidate Sentence: (0.22968560457229614, {u'tokens': [u'Why', u'the', u'Name', u'``', u'Tesla', u"''", u'?'], u'lemmas': [u'why', u'the', u'name', u'``', u'Tesla', u"''", u'?'], u'pos': [u'WRB', u'DT', u'NN', u'``', u'NNP', u"''", u'.'], u'char_offsets': [[49416, 49419], [49420, 49423], [49424, 49428], [49429, 49430], [49430, 49435], [49435, 49436], [49436, 49437]]}) 
answer: set([u'twain', u'close', u'friend', u'mark'])
candidate Sentence: (0.19178107380867004, {u'tokens': [u'Tesla', u'was', u'good', u'friends', u'with', u'Robert', u'Underwood', u'Johnson', u'.'], u'lemmas': [u'Tesla', u'be', u'good', u'friend', u'with', u'Robert', u'Underwood', u'Johnson', u'.'], u'pos': [u'NNP', u'VBD', u'JJ', u'NNS', u'IN', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[39981, 39986], [39987, 39990], [39991, 39995], [39996, 40003], [40004, 40008], [40009, 40015], [40016, 40025], [40026, 40033], [40033, 40034]]}) 
answer: set([u'twain', u'close', u'mark'])
candidate Sentence: (0.18738089501857758, {u'tokens': [u'16', u'-RRB-', u'His', u'wish', u'was', u'to', u'have', u'a', u'sculpture', u'made', u'by', u'his', u'close', u'friend', u',', u'Croatian', u'sculptor', u'Ivan', u'Me\u0161trovi\u0107', u',', u'who', u'was', u'at', u'that', u'time', u'in', u'United', u'States', u',', u'but', u'he', u'died', u'before', u'getting', u'a', u'chance', u'to', u'see', u'it', u'.'], u'lemmas': [u'16', u'-rrb-', u'he', u'wish', u'be', u'to', u'have', u'a', u'sculpture', u'make', u'by', u'he', u'close', u'friend', u',', u'croatian', u'sculptor', u'Ivan', u'Me\u0161trovi\u0107', u',', u'who', u'be', u'at', u'that', u'time', u'in', u'United', u'States', u',', u'but', u'he', u'die', u'before', u'get', u'a', u'chance', u'to', u'see', u'it', u'.'], u'pos': [u'CD', u'-RRB-', u'PRP$', u'NN', u'VBD', u'TO', u'VB', u'DT', u'NN', u'VBN', u'IN', u'PRP$', u'JJ', u'NN', u',', u'JJ', u'NN', u'NNP', u'NNP', u',', u'WP', u'VBD', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNPS', u',', u'CC', u'PRP', u'VBD', u'IN', u'VBG', u'DT', u'NN', u'TO', u'VB', u'PRP', u'.'], u'char_offsets': [[47133, 47135], [47135, 47136], [47138, 47141], [47142, 47146], [47147, 47150], [47151, 47153], [47154, 47158], [47159, 47160], [47161, 47170], [47171, 47175], [47176, 47178], [47179, 47182], [47183, 47188], [47189, 47195], [47195, 47196], [47197, 47205], [47206, 47214], [47215, 47219], [47220, 47229], [47229, 47230], [47231, 47234], [47235, 47238], [47239, 47241], [47242, 47246], [47247, 47251], [47252, 47254], [47255, 47261], [47262, 47268], [47268, 47269], [47270, 47273], [47274, 47276], [47277, 47281], [47282, 47288], [47289, 47296], [47297, 47298], [47299, 47305], [47306, 47308], [47309, 47312], [47313, 47315], [47315, 47316]]}) 
answer: set([u'twain', u'mark'])
candidate Sentence: (0.17572380602359772, {u'tokens': [u'Did', u'Tesla', u'really', u'invent', u'the', u'loudspeaker', u'?', u"''"], u'lemmas': [u'do', u'Tesla', u'really', u'invent', u'the', u'loudspeaker', u'?', u"''"], u'pos': [u'VBD', u'NNP', u'RB', u'VB', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[7475, 7478], [7479, 7484], [7485, 7491], [7492, 7498], [7499, 7502], [7503, 7514], [7514, 7515], [7515, 7516]]}) 
answer: set([u'twain', u'close', u'friend', u'mark'])
candidate Sentence: (0.1451496034860611, {u'tokens': [u'ISBN', u'*', u'Valentinuzzi', u',', u'M.E.', u',', u'Nikola', u'Tesla', u':', u'why', u'was', u'he', u'so', u'much', u'resisted', u'and', u'forgotten', u'?'], u'lemmas': [u'ISBN', u'*', u'Valentinuzzi', u',', u'M.E.', u',', u'Nikola', u'Tesla', u':', u'why', u'be', u'he', u'so', u'much', u'resist', u'and', u'forget', u'?'], u'pos': [u'NNP', u'SYM', u'NNP', u',', u'NNP', u',', u'NNP', u'NNP', u':', u'WRB', u'VBD', u'PRP', u'RB', u'RB', u'VBN', u'CC', u'VBN', u'.'], u'char_offsets': [[56372, 56376], [56377, 56378], [56379, 56391], [56391, 56392], [56393, 56397], [56397, 56398], [56399, 56405], [56406, 56411], [56411, 56412], [56413, 56416], [56417, 56420], [56421, 56423], [56424, 56426], [56427, 56431], [56432, 56440], [56441, 56444], [56445, 56454], [56454, 56455]]}) 
answer: set([u'twain', u'close', u'friend', u'mark'])
candidate Sentence: (0.14297372102737427, {u'tokens': [u'His', u'friends', u'thought', u'that', u'he', u'had', u'drowned', u'in', u'Mura', u'.'], u'lemmas': [u'he', u'friend', u'think', u'that', u'he', u'have', u'drown', u'in', u'Mura', u'.'], u'pos': [u'PRP$', u'NNS', u'VBD', u'IN', u'PRP', u'VBD', u'VBN', u'IN', u'NNP', u'.'], u'char_offsets': [[5232, 5235], [5236, 5243], [5244, 5251], [5252, 5256], [5257, 5259], [5260, 5263], [5264, 5271], [5272, 5274], [5275, 5279], [5279, 5280]]}) 
answer: set([u'twain', u'close', u'mark'])
candidate Sentence: (0.12193648517131805, {u'tokens': [u'4', u'December', u'2000', u'-LRB-', u'PDF', u'-RRB-', u'Some', u'of', u'Tesla', u"'s", u'closest', u'friends', u'were', u'artists', u'.'], u'lemmas': [u'4', u'December', u'2000', u'-lrb-', u'pdf', u'-rrb-', u'some', u'of', u'Tesla', u"'s", u'closest', u'friend', u'be', u'artist', u'.'], u'pos': [u'CD', u'NNP', u'CD', u'-LRB-', u'NN', u'-RRB-', u'DT', u'IN', u'NNP', u'POS', u'JJS', u'NNS', u'VBD', u'NNS', u'.'], u'char_offsets': [[17490, 17491], [17492, 17500], [17501, 17505], [17506, 17507], [17507, 17510], [17510, 17511], [17512, 17516], [17517, 17519], [17520, 17525], [17525, 17527], [17528, 17535], [17536, 17543], [17544, 17548], [17549, 17556], [17556, 17557]]}) 
answer: set([u'twain', u'close', u'mark'])
candidate Sentence: (0.11693902313709259, {u'tokens': [u'*', u'W.C.', u'Wysock', u',', u'J.F.', u'Corum', u',', u'J.M.', u'Hardesty', u'and', u'K.L.', u'Corum', u',', u'Who', u'Was', u'The', u'Real', u'Dr.', u'Nikola', u'Tesla', u'?'], u'lemmas': [u'*', u'W.C.', u'Wysock', u',', u'J.F.', u'Corum', u',', u'J.M.', u'Hardesty', u'and', u'K.L.', u'Corum', u',', u'who', u'be', u'the', u'real', u'Dr.', u'Nikola', u'Tesla', u'?'], u'pos': [u'SYM', u'NNP', u'NNP', u',', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u',', u'WP', u'VBD', u'DT', u'JJ', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[55797, 55798], [55799, 55803], [55804, 55810], [55810, 55811], [55812, 55816], [55817, 55822], [55822, 55823], [55824, 55828], [55829, 55837], [55838, 55841], [55842, 55846], [55847, 55852], [55852, 55853], [55855, 55858], [55859, 55862], [55863, 55866], [55867, 55871], [55872, 55875], [55876, 55882], [55883, 55888], [55888, 55889]]}) 
answer: set([u'twain', u'close', u'friend', u'mark'])

Was Nikola Tesla close friends with Mark Twain?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Nikola Tesla was close friends with Mark Twain.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Nikola Tesla was close friends with Mark Twain.') == True
 +  where 'Nikola Tesla was close friends with Mark Twain.' = <src.question_processing.Question_parser instance at 0x1114d8518>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param237] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d85f0>, (<src.tfidf.TF_IDF object at 0x10e16f950>, set(['nikola', 'nikola_tesla', 'tesla'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d85f0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.33794176578521729, {u'tokens': [u'Tesla', u'would', u'visualise', u'an', u'invention', u'in', u'his', u'brain', u'with', u'extreme', u'precision', u',', u'including', u'all', u'dimensions', u',', u'before', u'moving', u'to', u'the', u'construction', u'stage', u';', u'a', u'technique', u'sometimes', u'known', u'as', u'picture', u'thinking', u'.'], u'lemmas': [u'Tesla', u'would', u'visualise', u'a', u'invention', u'in', u'he', u'brain', u'with', u'extreme', u'precision', u',', u'include', u'all', u'dimension', u',', u'before', u'move', u'to', u'the', u'construction', u'stage', u';', u'a', u'technique', u'sometimes', u'know', u'as', u'picture', u'thinking', u'.'], u'pos': [u'NNP', u'MD', u'VB', u'DT', u'NN', u'IN', u'PRP$', u'NN', u'IN', u'JJ', u'NN', u',', u'VBG', u'DT', u'NNS', u',', u'IN', u'VBG', u'TO', u'DT', u'NN', u'NN', u':', u'DT', u'NN', u'RB', u'VBN', u'IN', u'NN', u'NN', u'.'], u'char_offsets': [[6339, 6344], [6345, 6350], [6351, 6360], [6361, 6363], [6364, 6373], [6374, 6376], [6377, 6380], [6381, 6386], [6387, 6391], [6392, 6399], [6400, 6409], [6409, 6410], [6411, 6420], [6421, 6424], [6425, 6435], [6435, 6436], [6437, 6443], [6444, 6450], [6451, 6453], [6454, 6457], [6458, 6470], [6471, 6476], [6476, 6477], [6478, 6479], [6480, 6489], [6490, 6499], [6500, 6505], [6506, 6508], [6509, 6516], [6517, 6525], [6525, 6526]]}) 
answer: set([u'use', u'call'])
candidate Sentence: (0.25513803958892822, {u'tokens': [u'Did', u'Tesla', u'really', u'invent', u'the', u'loudspeaker', u'?', u"''"], u'lemmas': [u'do', u'Tesla', u'really', u'invent', u'the', u'loudspeaker', u'?', u"''"], u'pos': [u'VBD', u'NNP', u'RB', u'VB', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[7475, 7478], [7479, 7484], [7485, 7491], [7492, 7498], [7499, 7502], [7503, 7514], [7514, 7515], [7515, 7516]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique', u'call'])
candidate Sentence: (0.21482178568840027, {u'tokens': [u'Why', u'the', u'Name', u'``', u'Tesla', u"''", u'?'], u'lemmas': [u'why', u'the', u'name', u'``', u'Tesla', u"''", u'?'], u'pos': [u'WRB', u'DT', u'NN', u'``', u'NNP', u"''", u'.'], u'char_offsets': [[49416, 49419], [49420, 49423], [49424, 49428], [49429, 49430], [49430, 49435], [49435, 49436], [49436, 49437]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique', u'call'])
candidate Sentence: (0.16537007689476013, {u'tokens': [u'Tesla', u'called', u'his', u'boat', u'a', u'``', u'teleautomaton', u"''", u'.'], u'lemmas': [u'Tesla', u'call', u'he', u'boat', u'a', u'``', u'teleautomaton', u"''", u'.'], u'pos': [u'NNP', u'VBD', u'PRP$', u'NN', u'DT', u'``', u'NN', u"''", u'.'], u'char_offsets': [[21536, 21541], [21542, 21548], [21549, 21552], [21553, 21557], [21558, 21559], [21560, 21561], [21561, 21574], [21574, 21575], [21575, 21576]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique'])
candidate Sentence: (0.13067649304866791, {u'tokens': [u'ISBN', u'*', u'Valentinuzzi', u',', u'M.E.', u',', u'Nikola', u'Tesla', u':', u'why', u'was', u'he', u'so', u'much', u'resisted', u'and', u'forgotten', u'?'], u'lemmas': [u'ISBN', u'*', u'Valentinuzzi', u',', u'M.E.', u',', u'Nikola', u'Tesla', u':', u'why', u'be', u'he', u'so', u'much', u'resist', u'and', u'forget', u'?'], u'pos': [u'NNP', u'SYM', u'NNP', u',', u'NNP', u',', u'NNP', u'NNP', u':', u'WRB', u'VBD', u'PRP', u'RB', u'RB', u'VBN', u'CC', u'VBN', u'.'], u'char_offsets': [[56372, 56376], [56377, 56378], [56379, 56391], [56391, 56392], [56393, 56397], [56397, 56398], [56399, 56405], [56406, 56411], [56411, 56412], [56413, 56416], [56417, 56420], [56421, 56423], [56424, 56426], [56427, 56431], [56432, 56440], [56441, 56444], [56445, 56454], [56454, 56455]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique', u'call'])
candidate Sentence: (0.11780964583158493, {u'tokens': [u'Publicity', u'picture', u'of', u'a', u'participant', u'sitting', u'in', u'his', u'laboratory', u'in', u'Colorado', u'Springs', u'with', u'his', u'``', u'Magnifying', u'Transmitter', u"''", u'generating', u'millions', u'of', u'volts', u'.'], u'lemmas': [u'publicity', u'picture', u'of', u'a', u'participant', u'sit', u'in', u'he', u'laboratory', u'in', u'Colorado', u'Springs', u'with', u'he', u'``', u'magnify', u'transmitter', u"''", u'generate', u'million', u'of', u'volt', u'.'], u'pos': [u'NN', u'NN', u'IN', u'DT', u'NN', u'VBG', u'IN', u'PRP$', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'PRP$', u'``', u'VBG', u'NN', u"''", u'VBG', u'NNS', u'IN', u'NNS', u'.'], u'char_offsets': [[22303, 22312], [22313, 22320], [22321, 22323], [22324, 22325], [22326, 22337], [22338, 22345], [22346, 22348], [22349, 22352], [22353, 22363], [22364, 22366], [22367, 22375], [22376, 22383], [22384, 22388], [22389, 22392], [22393, 22394], [22394, 22404], [22405, 22416], [22416, 22417], [22418, 22428], [22429, 22437], [22438, 22440], [22441, 22446], [22446, 22447]]}) 
answer: set([u'thinking', u'use', u'technique', u'call'])
candidate Sentence: (0.1142103299498558, {u'tokens': [u'The', u'press', u'called', u'it', u'a', u'``', u'peace', u'ray', u"''", u'or', u'death', u'ray', u'.'], u'lemmas': [u'the', u'press', u'call', u'it', u'a', u'``', u'peace', u'ray', u"''", u'or', u'death', u'ray', u'.'], u'pos': [u'DT', u'NN', u'VBD', u'PRP', u'DT', u'``', u'NN', u'NN', u"''", u'CC', u'NN', u'NN', u'.'], u'char_offsets': [[33502, 33505], [33506, 33511], [33512, 33518], [33519, 33521], [33522, 33523], [33524, 33525], [33525, 33530], [33531, 33534], [33534, 33535], [33536, 33538], [33539, 33544], [33545, 33548], [33548, 33549]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique'])
candidate Sentence: (0.11217330396175385, {u'tokens': [u'In', u'April', u'1887', u',', u'Tesla', u'began', u'investigating', u'what', u'would', u'later', u'be', u'called', u'X', u'rays', u'using', u'his', u'own', u'single', u'terminal', u'vacuum', u'tubes', u'-LRB-', u'similar', u'to', u'his', u'patent', u'-RRB-', u'.'], u'lemmas': [u'in', u'April', u'1887', u',', u'Tesla', u'begin', u'investigate', u'what', u'would', u'later', u'be', u'call', u'x', u'ray', u'use', u'he', u'own', u'single', u'terminal', u'vacuum', u'tube', u'-lrb-', u'similar', u'to', u'he', u'patent', u'-rrb-', u'.'], u'pos': [u'IN', u'NNP', u'CD', u',', u'NNP', u'VBD', u'VBG', u'WP', u'MD', u'RB', u'VB', u'VBN', u'NN', u'NNS', u'VBG', u'PRP$', u'JJ', u'JJ', u'JJ', u'NN', u'NNS', u'-LRB-', u'JJ', u'TO', u'PRP$', u'NN', u'-RRB-', u'.'], u'char_offsets': [[11090, 11092], [11093, 11098], [11099, 11103], [11103, 11104], [11105, 11110], [11111, 11116], [11117, 11130], [11131, 11135], [11136, 11141], [11142, 11147], [11148, 11150], [11151, 11157], [11158, 11159], [11160, 11164], [11165, 11170], [11171, 11174], [11175, 11178], [11179, 11185], [11186, 11194], [11195, 11201], [11202, 11207], [11208, 11209], [11209, 11216], [11217, 11219], [11220, 11223], [11224, 11230], [11232, 11233], [11233, 11234]]}) 
answer: set([u'thinking', u'picture', u'technique'])
candidate Sentence: (0.11187008768320084, {u'tokens': [u'Belgrade', u'International', u'Airport', u'is', u'called', u'``', u'Belgrade', u'Nikola', u'Tesla', u'Airport', u"''", u'.'], u'lemmas': [u'Belgrade', u'International', u'Airport', u'be', u'call', u'``', u'Belgrade', u'Nikola', u'Tesla', u'Airport', u"''", u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u'VBZ', u'VBN', u'``', u'NNP', u'NNP', u'NNP', u'NNP', u"''", u'.'], u'char_offsets': [[53268, 53276], [53277, 53290], [53291, 53298], [53299, 53301], [53302, 53308], [53309, 53310], [53310, 53318], [53319, 53325], [53326, 53331], [53332, 53339], [53339, 53340], [53340, 53341]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique'])
candidate Sentence: (0.10742168873548508, {u'tokens': [u'He', u'did', u'not', u'like', u'posing', u'for', u'portraits', u',', u'doing', u'so', u'only', u'once', u'for', u'princess', u'Vilma', u'Lwoff-Parlaghy', u'.'], u'lemmas': [u'he', u'do', u'not', u'like', u'pose', u'for', u'portrait', u',', u'do', u'so', u'only', u'once', u'for', u'princess', u'Vilma', u'Lwoff-Parlaghy', u'.'], u'pos': [u'PRP', u'VBD', u'RB', u'VB', u'VBG', u'IN', u'NNS', u',', u'VBG', u'RB', u'RB', u'RB', u'IN', u'NN', u'NNP', u'NNP', u'.'], u'char_offsets': [[46695, 46697], [46698, 46701], [46702, 46705], [46706, 46710], [46711, 46717], [46718, 46721], [46722, 46731], [46731, 46732], [46733, 46738], [46739, 46741], [46742, 46746], [46747, 46751], [46752, 46755], [46756, 46764], [46765, 46770], [46771, 46785], [46785, 46786]]}) 
answer: set([u'thinking', u'picture', u'use', u'technique', u'call'])

Did Nikola Tesla use a technique called picture thinking?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d85f0>.answer
_____________________________ test_yesno[param251] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d89e0>, (<src.tfidf.TF_IDF object at 0x10a4d4c10>, set(['piano'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114d89e0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.25397381186485291, {u'tokens': [u'The', u'invention', u'of', u'the', u'modern', u'piano', u'is', u'credited', u'to', u'Bartolomeo', u'Cristofori', u'of', u'Padua', u',', u'Italy', u',', u'who', u'was', u'employed', u'by', u'Prince', u'Ferdinand', u'de', u'Medici', u'as', u'the', u'Keeper', u'of', u'the', u'Instruments', u'.'], u'lemmas': [u'the', u'invention', u'of', u'the', u'modern', u'piano', u'be', u'credit', u'to', u'Bartolomeo', u'Cristofori', u'of', u'Padua', u',', u'Italy', u',', u'who', u'be', u'employ', u'by', u'Prince', u'Ferdinand', u'de', u'Medici', u'as', u'the', u'keeper', u'of', u'the', u'Instruments', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'VBN', u'TO', u'NNP', u'NNP', u'IN', u'NNP', u',', u'NNP', u',', u'WP', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u'IN', u'NNP', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNPS', u'.'], u'char_offsets': [[2700, 2703], [2704, 2713], [2714, 2716], [2717, 2720], [2721, 2727], [2728, 2733], [2734, 2736], [2737, 2745], [2746, 2748], [2749, 2759], [2760, 2770], [2771, 2773], [2774, 2779], [2779, 2780], [2781, 2786], [2786, 2787], [2788, 2791], [2792, 2795], [2796, 2804], [2805, 2807], [2808, 2814], [2815, 2824], [2825, 2827], [2828, 2834], [2835, 2837], [2838, 2841], [2842, 2848], [2849, 2851], [2852, 2855], [2856, 2867], [2867, 2868]]}) 
answer: set([u'invent'])
candidate Sentence: (0.18724089860916138, {u'tokens': [u'Silbermann', u"'s", u'pianos', u'were', u'virtually', u'direct', u'copies', u'of', u'Cristofori', u"'s", u',', u'with', u'one', u'important', u'addition', u':', u'Silbermann', u'invented', u'the', u'forerunner', u'of', u'the', u'modern', u'damper', u'pedal', u',', u'which', u'lifts', u'all', u'the', u'dampers', u'from', u'the', u'strings', u'at', u'once', u'.'], u'lemmas': [u'Silbermann', u"'s", u'piano', u'be', u'virtually', u'direct', u'copy', u'of', u'Cristofori', u"'s", u',', u'with', u'one', u'important', u'addition', u':', u'Silbermann', u'invent', u'the', u'forerunner', u'of', u'the', u'modern', u'damper', u'pedal', u',', u'which', u'lift', u'all', u'the', u'damper', u'from', u'the', u'string', u'at', u'once', u'.'], u'pos': [u'NNP', u'POS', u'NNS', u'VBD', u'RB', u'JJ', u'NNS', u'IN', u'NNP', u'POS', u',', u'IN', u'CD', u'JJ', u'NN', u':', u'NNP', u'VBD', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u',', u'WDT', u'VBZ', u'PDT', u'DT', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'RB', u'.'], u'char_offsets': [[4531, 4541], [4541, 4543], [4544, 4550], [4551, 4555], [4556, 4565], [4566, 4572], [4573, 4579], [4580, 4582], [4583, 4593], [4593, 4595], [4595, 4596], [4597, 4601], [4602, 4605], [4606, 4615], [4616, 4624], [4624, 4625], [4626, 4636], [4637, 4645], [4646, 4649], [4650, 4660], [4661, 4663], [4664, 4667], [4668, 4674], [4675, 4681], [4682, 4687], [4687, 4688], [4689, 4694], [4695, 4700], [4701, 4704], [4705, 4708], [4709, 4716], [4717, 4721], [4722, 4725], [4726, 4733], [4734, 4736], [4737, 4741], [4741, 4742]]}) 
answer: set([u'bartolomeo'])
candidate Sentence: (0.14103066921234131, {u'tokens': [u'Earliest', u'French', u'grand', u'piano', u'known', u'to', u'survive', u';', u'includes', u'an', u'inverted', u'wrestplank', u'and', u'action', u'derived', u'from', u'the', u'work', u'of', u'Bartolomeo', u'Cristofiori', u'-LRB-', u'ca.', u'1700', u'-RRB-', u'with', u'ornately', u'decorated', u'soundboard', u'.'], u'lemmas': [u'earliest', u'french', u'grand', u'piano', u'know', u'to', u'survive', u';', u'include', u'a', u'inverted', u'wrestplank', u'and', u'action', u'derive', u'from', u'the', u'work', u'of', u'Bartolomeo', u'Cristofiori', u'-lrb-', u'ca.', u'1700', u'-rrb-', u'with', u'ornately', u'decorate', u'soundboard', u'.'], u'pos': [u'JJS', u'JJ', u'JJ', u'NN', u'VBN', u'TO', u'VB', u':', u'VBZ', u'DT', u'JJ', u'NN', u'CC', u'NN', u'VBN', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'-LRB-', u'FW', u'CD', u'-RRB-', u'IN', u'RB', u'VBN', u'NN', u'.'], u'char_offsets': [[2516, 2524], [2525, 2531], [2532, 2537], [2538, 2543], [2544, 2549], [2550, 2552], [2553, 2560], [2560, 2561], [2562, 2570], [2571, 2573], [2574, 2582], [2583, 2593], [2594, 2597], [2598, 2604], [2605, 2612], [2613, 2617], [2618, 2621], [2622, 2626], [2627, 2629], [2630, 2640], [2641, 2652], [2653, 2654], [2654, 2657], [2658, 2662], [2662, 2663], [2664, 2668], [2669, 2677], [2678, 2687], [2688, 2698], [2698, 2699]]}) 
answer: set([u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.14029444754123688, {u'tokens': [u'The', u'use', u'of', u'aluminum', u'for', u'piano', u'plates', u',', u'however', u',', u'did', u'not', u'become', u'widely', u'accepted', u'and', u'was', u'discontinued', u'.'], u'lemmas': [u'the', u'use', u'of', u'aluminum', u'for', u'piano', u'plate', u',', u'however', u',', u'do', u'not', u'become', u'widely', u'accept', u'and', u'be', u'discontinue', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'IN', u'NN', u'NNS', u',', u'RB', u',', u'VBD', u'RB', u'VB', u'RB', u'VBN', u'CC', u'VBD', u'VBN', u'.'], u'char_offsets': [[27857, 27860], [27861, 27864], [27865, 27867], [27868, 27876], [27877, 27880], [27881, 27886], [27887, 27893], [27893, 27894], [27895, 27902], [27902, 27903], [27904, 27907], [27908, 27911], [27912, 27918], [27919, 27925], [27926, 27934], [27935, 27938], [27939, 27942], [27943, 27955], [27955, 27956]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.12901169061660767, {u'tokens': [u'Since', u'this', u'sympathetic', u'vibration', u'is', u'considered', u'central', u'to', u'piano', u'tone', u',', u'many', u'digital', u'pianos', u'do', u'not', u'sound', u'the', u'same', u'as', u'the', u'best', u'acoustic', u'pianos', u'.'], u'lemmas': [u'since', u'this', u'sympathetic', u'vibration', u'be', u'consider', u'central', u'to', u'piano', u'tone', u',', u'many', u'digital', u'piano', u'do', u'not', u'sound', u'the', u'same', u'as', u'the', u'best', u'acoustic', u'piano', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'VBN', u'JJ', u'TO', u'NN', u'NN', u',', u'JJ', u'JJ', u'NNS', u'VBP', u'RB', u'VB', u'DT', u'JJ', u'IN', u'DT', u'JJS', u'JJ', u'NNS', u'.'], u'char_offsets': [[18929, 18934], [18935, 18939], [18940, 18951], [18952, 18961], [18962, 18964], [18965, 18975], [18976, 18983], [18984, 18986], [18987, 18992], [18993, 18997], [18997, 18998], [19000, 19004], [19005, 19012], [19013, 19019], [19020, 19022], [19023, 19026], [19027, 19032], [19033, 19036], [19037, 19041], [19042, 19044], [19045, 19048], [19049, 19053], [19054, 19062], [19063, 19069], [19069, 19070]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.12266797572374344, {u'tokens': [u'It', u'is', u'not', u'known', u'exactly', u'when', u'Cristofori', u'first', u'built', u'a', u'piano', u'.'], u'lemmas': [u'it', u'be', u'not', u'know', u'exactly', u'when', u'Cristofori', u'first', u'build', u'a', u'piano', u'.'], u'pos': [u'PRP', u'VBZ', u'RB', u'VBN', u'RB', u'WRB', u'NNP', u'RB', u'VBD', u'DT', u'NN', u'.'], u'char_offsets': [[2998, 3000], [3001, 3003], [3004, 3007], [3008, 3013], [3014, 3021], [3022, 3026], [3027, 3037], [3038, 3043], [3044, 3049], [3050, 3051], [3052, 3057], [3057, 3058]]}) 
answer: set([u'bartolomeo', u'modern', u'invent'])
candidate Sentence: (0.11743426322937012, {u'tokens': [u'Irving', u'Berlin', u'played', u'a', u'special', u'piano', u'called', u'the', u'transposing', u'piano', u',', u'which', u'was', u'invented', u'in', u'1801', u'by', u'Edward', u'Ryley', u'.'], u'lemmas': [u'Irving', u'Berlin', u'play', u'a', u'special', u'piano', u'call', u'the', u'transpose', u'piano', u',', u'which', u'be', u'invent', u'in', u'1801', u'by', u'Edward', u'Ryley', u'.'], u'pos': [u'NNP', u'NNP', u'VBD', u'DT', u'JJ', u'NN', u'VBD', u'DT', u'VBG', u'NN', u',', u'WDT', u'VBD', u'VBN', u'IN', u'CD', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[17418, 17424], [17425, 17431], [17432, 17438], [17439, 17440], [17441, 17448], [17449, 17454], [17455, 17461], [17462, 17465], [17466, 17477], [17478, 17483], [17483, 17484], [17485, 17490], [17491, 17494], [17495, 17503], [17504, 17506], [17507, 17511], [17512, 17514], [17515, 17521], [17522, 17527], [17527, 17528]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori'])
candidate Sentence: (0.11363589018583298, {u'tokens': [u'The', u'three', u'Cristofori', u'pianos', u'that', u'survive', u'today', u'date', u'from', u'the', u'1720s', u'.'], u'lemmas': [u'the', u'three', u'Cristofori', u'piano', u'that', u'survive', u'today', u'date', u'from', u'the', u'1720', u'.'], u'pos': [u'DT', u'CD', u'NNP', u'NNS', u'WDT', u'VBP', u'NN', u'NN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[3237, 3240], [3241, 3246], [3247, 3257], [3258, 3264], [3265, 3269], [3270, 3277], [3278, 3283], [3284, 3288], [3289, 3293], [3294, 3297], [3298, 3303], [3303, 3304]]}) 
answer: set([u'bartolomeo', u'modern', u'invent'])
candidate Sentence: (0.1115104928612709, {u'tokens': [u'Bach', u'did', u'approve', u'of', u'a', u'later', u'instrument', u'he', u'saw', u'in', u'1747', u',', u'and', u'even', u'served', u'as', u'an', u'agent', u'in', u'selling', u'Silbermann', u"'s", u'pianos', u'.'], u'lemmas': [u'Bach', u'do', u'approve', u'of', u'a', u'later', u'instrument', u'he', u'see', u'in', u'1747', u',', u'and', u'even', u'serve', u'as', u'a', u'agent', u'in', u'sell', u'Silbermann', u"'s", u'piano', u'.'], u'pos': [u'NNP', u'VBD', u'VB', u'IN', u'DT', u'JJ', u'NN', u'PRP', u'VBD', u'IN', u'CD', u',', u'CC', u'RB', u'VBD', u'IN', u'DT', u'NN', u'IN', u'VBG', u'NNP', u'POS', u'NNS', u'.'], u'char_offsets': [[5035, 5039], [5040, 5043], [5044, 5051], [5052, 5054], [5055, 5056], [5057, 5062], [5063, 5073], [5074, 5076], [5077, 5080], [5081, 5083], [5084, 5088], [5088, 5089], [5090, 5093], [5094, 5098], [5099, 5105], [5106, 5108], [5109, 5111], [5112, 5117], [5118, 5120], [5121, 5128], [5129, 5139], [5139, 5141], [5142, 5148], [5148, 5149]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.11103278398513794, {u'tokens': [u'In', u'1863', u',', u'Henri', u'Fourneaux', u'invented', u'the', u'player', u'piano', u',', u'which', u'``', u'plays', u'itself', u"''", u'from', u'a', u'piano', u'roll', u'without', u'the', u'need', u'for', u'a', u'pianist', u'.'], u'lemmas': [u'in', u'1863', u',', u'Henri', u'Fourneaux', u'invent', u'the', u'player', u'piano', u',', u'which', u'``', u'play', u'itself', u"''", u'from', u'a', u'piano', u'roll', u'without', u'the', u'need', u'for', u'a', u'pianist', u'.'], u'pos': [u'IN', u'CD', u',', u'NNP', u'NNP', u'VBD', u'DT', u'NN', u'NN', u',', u'WDT', u'``', u'VBZ', u'PRP', u"''", u'IN', u'DT', u'NN', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[16861, 16863], [16864, 16868], [16868, 16869], [16870, 16875], [16876, 16885], [16886, 16894], [16895, 16898], [16899, 16905], [16906, 16911], [16911, 16912], [16913, 16918], [16919, 16920], [16920, 16925], [16926, 16932], [16932, 16933], [16934, 16938], [16939, 16940], [16941, 16946], [16947, 16951], [16952, 16959], [16960, 16963], [16964, 16968], [16969, 16972], [16973, 16974], [16975, 16982], [16982, 16983]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori'])

Did Bartolomeo Cristofori invent the modern piano?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114d89e0>.answer
_____________________________ test_yesno[param252] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8a28>, (<src.tfidf.TF_IDF object at 0x10a4d4c10>, set(['piano'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8a28>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.25397381186485291, {u'tokens': [u'The', u'invention', u'of', u'the', u'modern', u'piano', u'is', u'credited', u'to', u'Bartolomeo', u'Cristofori', u'of', u'Padua', u',', u'Italy', u',', u'who', u'was', u'employed', u'by', u'Prince', u'Ferdinand', u'de', u'Medici', u'as', u'the', u'Keeper', u'of', u'the', u'Instruments', u'.'], u'lemmas': [u'the', u'invention', u'of', u'the', u'modern', u'piano', u'be', u'credit', u'to', u'Bartolomeo', u'Cristofori', u'of', u'Padua', u',', u'Italy', u',', u'who', u'be', u'employ', u'by', u'Prince', u'Ferdinand', u'de', u'Medici', u'as', u'the', u'keeper', u'of', u'the', u'Instruments', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'VBN', u'TO', u'NNP', u'NNP', u'IN', u'NNP', u',', u'NNP', u',', u'WP', u'VBD', u'VBN', u'IN', u'NNP', u'NNP', u'IN', u'NNP', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNPS', u'.'], u'char_offsets': [[2700, 2703], [2704, 2713], [2714, 2716], [2717, 2720], [2721, 2727], [2728, 2733], [2734, 2736], [2737, 2745], [2746, 2748], [2749, 2759], [2760, 2770], [2771, 2773], [2774, 2779], [2779, 2780], [2781, 2786], [2786, 2787], [2788, 2791], [2792, 2795], [2796, 2804], [2805, 2807], [2808, 2814], [2815, 2824], [2825, 2827], [2828, 2834], [2835, 2837], [2838, 2841], [2842, 2848], [2849, 2851], [2852, 2855], [2856, 2867], [2867, 2868]]}) 
answer: set([u'invent'])
candidate Sentence: (0.18724089860916138, {u'tokens': [u'Silbermann', u"'s", u'pianos', u'were', u'virtually', u'direct', u'copies', u'of', u'Cristofori', u"'s", u',', u'with', u'one', u'important', u'addition', u':', u'Silbermann', u'invented', u'the', u'forerunner', u'of', u'the', u'modern', u'damper', u'pedal', u',', u'which', u'lifts', u'all', u'the', u'dampers', u'from', u'the', u'strings', u'at', u'once', u'.'], u'lemmas': [u'Silbermann', u"'s", u'piano', u'be', u'virtually', u'direct', u'copy', u'of', u'Cristofori', u"'s", u',', u'with', u'one', u'important', u'addition', u':', u'Silbermann', u'invent', u'the', u'forerunner', u'of', u'the', u'modern', u'damper', u'pedal', u',', u'which', u'lift', u'all', u'the', u'damper', u'from', u'the', u'string', u'at', u'once', u'.'], u'pos': [u'NNP', u'POS', u'NNS', u'VBD', u'RB', u'JJ', u'NNS', u'IN', u'NNP', u'POS', u',', u'IN', u'CD', u'JJ', u'NN', u':', u'NNP', u'VBD', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'NN', u',', u'WDT', u'VBZ', u'PDT', u'DT', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'RB', u'.'], u'char_offsets': [[4531, 4541], [4541, 4543], [4544, 4550], [4551, 4555], [4556, 4565], [4566, 4572], [4573, 4579], [4580, 4582], [4583, 4593], [4593, 4595], [4595, 4596], [4597, 4601], [4602, 4605], [4606, 4615], [4616, 4624], [4624, 4625], [4626, 4636], [4637, 4645], [4646, 4649], [4650, 4660], [4661, 4663], [4664, 4667], [4668, 4674], [4675, 4681], [4682, 4687], [4687, 4688], [4689, 4694], [4695, 4700], [4701, 4704], [4705, 4708], [4709, 4716], [4717, 4721], [4722, 4725], [4726, 4733], [4734, 4736], [4737, 4741], [4741, 4742]]}) 
answer: set([u'bartolomeo'])
candidate Sentence: (0.14103066921234131, {u'tokens': [u'Earliest', u'French', u'grand', u'piano', u'known', u'to', u'survive', u';', u'includes', u'an', u'inverted', u'wrestplank', u'and', u'action', u'derived', u'from', u'the', u'work', u'of', u'Bartolomeo', u'Cristofiori', u'-LRB-', u'ca.', u'1700', u'-RRB-', u'with', u'ornately', u'decorated', u'soundboard', u'.'], u'lemmas': [u'earliest', u'french', u'grand', u'piano', u'know', u'to', u'survive', u';', u'include', u'a', u'inverted', u'wrestplank', u'and', u'action', u'derive', u'from', u'the', u'work', u'of', u'Bartolomeo', u'Cristofiori', u'-lrb-', u'ca.', u'1700', u'-rrb-', u'with', u'ornately', u'decorate', u'soundboard', u'.'], u'pos': [u'JJS', u'JJ', u'JJ', u'NN', u'VBN', u'TO', u'VB', u':', u'VBZ', u'DT', u'JJ', u'NN', u'CC', u'NN', u'VBN', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'-LRB-', u'FW', u'CD', u'-RRB-', u'IN', u'RB', u'VBN', u'NN', u'.'], u'char_offsets': [[2516, 2524], [2525, 2531], [2532, 2537], [2538, 2543], [2544, 2549], [2550, 2552], [2553, 2560], [2560, 2561], [2562, 2570], [2571, 2573], [2574, 2582], [2583, 2593], [2594, 2597], [2598, 2604], [2605, 2612], [2613, 2617], [2618, 2621], [2622, 2626], [2627, 2629], [2630, 2640], [2641, 2652], [2653, 2654], [2654, 2657], [2658, 2662], [2662, 2663], [2664, 2668], [2669, 2677], [2678, 2687], [2688, 2698], [2698, 2699]]}) 
answer: set([u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.14029444754123688, {u'tokens': [u'The', u'use', u'of', u'aluminum', u'for', u'piano', u'plates', u',', u'however', u',', u'did', u'not', u'become', u'widely', u'accepted', u'and', u'was', u'discontinued', u'.'], u'lemmas': [u'the', u'use', u'of', u'aluminum', u'for', u'piano', u'plate', u',', u'however', u',', u'do', u'not', u'become', u'widely', u'accept', u'and', u'be', u'discontinue', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NN', u'IN', u'NN', u'NNS', u',', u'RB', u',', u'VBD', u'RB', u'VB', u'RB', u'VBN', u'CC', u'VBD', u'VBN', u'.'], u'char_offsets': [[27857, 27860], [27861, 27864], [27865, 27867], [27868, 27876], [27877, 27880], [27881, 27886], [27887, 27893], [27893, 27894], [27895, 27902], [27902, 27903], [27904, 27907], [27908, 27911], [27912, 27918], [27919, 27925], [27926, 27934], [27935, 27938], [27939, 27942], [27943, 27955], [27955, 27956]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.12901169061660767, {u'tokens': [u'Since', u'this', u'sympathetic', u'vibration', u'is', u'considered', u'central', u'to', u'piano', u'tone', u',', u'many', u'digital', u'pianos', u'do', u'not', u'sound', u'the', u'same', u'as', u'the', u'best', u'acoustic', u'pianos', u'.'], u'lemmas': [u'since', u'this', u'sympathetic', u'vibration', u'be', u'consider', u'central', u'to', u'piano', u'tone', u',', u'many', u'digital', u'piano', u'do', u'not', u'sound', u'the', u'same', u'as', u'the', u'best', u'acoustic', u'piano', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'VBN', u'JJ', u'TO', u'NN', u'NN', u',', u'JJ', u'JJ', u'NNS', u'VBP', u'RB', u'VB', u'DT', u'JJ', u'IN', u'DT', u'JJS', u'JJ', u'NNS', u'.'], u'char_offsets': [[18929, 18934], [18935, 18939], [18940, 18951], [18952, 18961], [18962, 18964], [18965, 18975], [18976, 18983], [18984, 18986], [18987, 18992], [18993, 18997], [18997, 18998], [19000, 19004], [19005, 19012], [19013, 19019], [19020, 19022], [19023, 19026], [19027, 19032], [19033, 19036], [19037, 19041], [19042, 19044], [19045, 19048], [19049, 19053], [19054, 19062], [19063, 19069], [19069, 19070]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.12266797572374344, {u'tokens': [u'It', u'is', u'not', u'known', u'exactly', u'when', u'Cristofori', u'first', u'built', u'a', u'piano', u'.'], u'lemmas': [u'it', u'be', u'not', u'know', u'exactly', u'when', u'Cristofori', u'first', u'build', u'a', u'piano', u'.'], u'pos': [u'PRP', u'VBZ', u'RB', u'VBN', u'RB', u'WRB', u'NNP', u'RB', u'VBD', u'DT', u'NN', u'.'], u'char_offsets': [[2998, 3000], [3001, 3003], [3004, 3007], [3008, 3013], [3014, 3021], [3022, 3026], [3027, 3037], [3038, 3043], [3044, 3049], [3050, 3051], [3052, 3057], [3057, 3058]]}) 
answer: set([u'bartolomeo', u'modern', u'invent'])
candidate Sentence: (0.11743426322937012, {u'tokens': [u'Irving', u'Berlin', u'played', u'a', u'special', u'piano', u'called', u'the', u'transposing', u'piano', u',', u'which', u'was', u'invented', u'in', u'1801', u'by', u'Edward', u'Ryley', u'.'], u'lemmas': [u'Irving', u'Berlin', u'play', u'a', u'special', u'piano', u'call', u'the', u'transpose', u'piano', u',', u'which', u'be', u'invent', u'in', u'1801', u'by', u'Edward', u'Ryley', u'.'], u'pos': [u'NNP', u'NNP', u'VBD', u'DT', u'JJ', u'NN', u'VBD', u'DT', u'VBG', u'NN', u',', u'WDT', u'VBD', u'VBN', u'IN', u'CD', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[17418, 17424], [17425, 17431], [17432, 17438], [17439, 17440], [17441, 17448], [17449, 17454], [17455, 17461], [17462, 17465], [17466, 17477], [17478, 17483], [17483, 17484], [17485, 17490], [17491, 17494], [17495, 17503], [17504, 17506], [17507, 17511], [17512, 17514], [17515, 17521], [17522, 17527], [17527, 17528]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori'])
candidate Sentence: (0.11363589018583298, {u'tokens': [u'The', u'three', u'Cristofori', u'pianos', u'that', u'survive', u'today', u'date', u'from', u'the', u'1720s', u'.'], u'lemmas': [u'the', u'three', u'Cristofori', u'piano', u'that', u'survive', u'today', u'date', u'from', u'the', u'1720', u'.'], u'pos': [u'DT', u'CD', u'NNP', u'NNS', u'WDT', u'VBP', u'NN', u'NN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[3237, 3240], [3241, 3246], [3247, 3257], [3258, 3264], [3265, 3269], [3270, 3277], [3278, 3283], [3284, 3288], [3289, 3293], [3294, 3297], [3298, 3303], [3303, 3304]]}) 
answer: set([u'bartolomeo', u'modern', u'invent'])
candidate Sentence: (0.1115104928612709, {u'tokens': [u'Bach', u'did', u'approve', u'of', u'a', u'later', u'instrument', u'he', u'saw', u'in', u'1747', u',', u'and', u'even', u'served', u'as', u'an', u'agent', u'in', u'selling', u'Silbermann', u"'s", u'pianos', u'.'], u'lemmas': [u'Bach', u'do', u'approve', u'of', u'a', u'later', u'instrument', u'he', u'see', u'in', u'1747', u',', u'and', u'even', u'serve', u'as', u'a', u'agent', u'in', u'sell', u'Silbermann', u"'s", u'piano', u'.'], u'pos': [u'NNP', u'VBD', u'VB', u'IN', u'DT', u'JJ', u'NN', u'PRP', u'VBD', u'IN', u'CD', u',', u'CC', u'RB', u'VBD', u'IN', u'DT', u'NN', u'IN', u'VBG', u'NNP', u'POS', u'NNS', u'.'], u'char_offsets': [[5035, 5039], [5040, 5043], [5044, 5051], [5052, 5054], [5055, 5056], [5057, 5062], [5063, 5073], [5074, 5076], [5077, 5080], [5081, 5083], [5084, 5088], [5088, 5089], [5090, 5093], [5094, 5098], [5099, 5105], [5106, 5108], [5109, 5111], [5112, 5117], [5118, 5120], [5121, 5128], [5129, 5139], [5139, 5141], [5142, 5148], [5148, 5149]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori', u'invent'])
candidate Sentence: (0.11103278398513794, {u'tokens': [u'In', u'1863', u',', u'Henri', u'Fourneaux', u'invented', u'the', u'player', u'piano', u',', u'which', u'``', u'plays', u'itself', u"''", u'from', u'a', u'piano', u'roll', u'without', u'the', u'need', u'for', u'a', u'pianist', u'.'], u'lemmas': [u'in', u'1863', u',', u'Henri', u'Fourneaux', u'invent', u'the', u'player', u'piano', u',', u'which', u'``', u'play', u'itself', u"''", u'from', u'a', u'piano', u'roll', u'without', u'the', u'need', u'for', u'a', u'pianist', u'.'], u'pos': [u'IN', u'CD', u',', u'NNP', u'NNP', u'VBD', u'DT', u'NN', u'NN', u',', u'WDT', u'``', u'VBZ', u'PRP', u"''", u'IN', u'DT', u'NN', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[16861, 16863], [16864, 16868], [16868, 16869], [16870, 16875], [16876, 16885], [16886, 16894], [16895, 16898], [16899, 16905], [16906, 16911], [16911, 16912], [16913, 16918], [16919, 16920], [16920, 16925], [16926, 16932], [16932, 16933], [16934, 16938], [16939, 16940], [16941, 16946], [16947, 16951], [16952, 16959], [16960, 16963], [16964, 16968], [16969, 16972], [16973, 16974], [16975, 16982], [16982, 16983]]}) 
answer: set([u'bartolomeo', u'modern', u'cristofori'])

Did Bartolomeo Cristofori invent the modern piano?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8a28>.answer
_____________________________ test_yesno[param253] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8a70>, (<src.tfidf.TF_IDF object at 0x10a4d4c10>, set(['piano'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d8a70>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.49156421422958374, {u'tokens': [u'The', u'soft', u'pedal', u'or', u'una', u'corda', u'pedal', u'is', u'placed', u'leftmost', u'in', u'the', u'row', u'of', u'pedals', u'.'], u'lemmas': [u'the', u'soft', u'pedal', u'or', u'una', u'corda', u'pedal', u'be', u'place', u'leftmost', u'in', u'the', u'row', u'of', u'pedal', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'CC', u'FW', u'FW', u'NN', u'VBZ', u'VBN', u'JJS', u'IN', u'DT', u'NN', u'IN', u'NNS', u'.'], u'char_offsets': [[22355, 22358], [22359, 22363], [22364, 22369], [22370, 22372], [22373, 22376], [22377, 22382], [22383, 22388], [22389, 22391], [22392, 22398], [22399, 22407], [22408, 22410], [22411, 22414], [22415, 22418], [22419, 22421], [22422, 22428], [22428, 22429]]}) 
answer: set([u'left-most', u'call', u'grand'])
candidate Sentence: (0.48642778396606445, {u'tokens': [u'Piano', u'pedals', u'from', u'left', u'to', u'right', u':', u'una', u'corda', u',', u'sostenuto', u',', u'and', u'damper', u'.'], u'lemmas': [u'piano', u'pedal', u'from', u'leave', u'to', u'right', u':', u'una', u'corda', u',', u'sostenuto', u',', u'and', u'damper', u'.'], u'pos': [u'NN', u'NNS', u'IN', u'VBN', u'TO', u'NN', u':', u'FW', u'FW', u',', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[21576, 21581], [21582, 21588], [21589, 21593], [21594, 21598], [21599, 21601], [21602, 21607], [21607, 21608], [21609, 21612], [21613, 21618], [21618, 21619], [21620, 21629], [21629, 21630], [21631, 21634], [21635, 21641], [21641, 21642]]}) 
answer: set([u'left-most', u'call', u'grand'])
candidate Sentence: (0.43915429711341858, {u'tokens': [u'Most', u'grand', u'pianos', u'have', u'three', u'pedals', u':', u'soft', u'pedal', u'-LRB-', u'una', u'corda', u'-RRB-', u',', u'sostenuto', u',', u'and', u'sustain', u'pedal', u'-LRB-', u'from', u'left', u'to', u'right', u',', u'respectively', u'-RRB-', u'.'], u'lemmas': [u'most', u'grand', u'piano', u'have', u'three', u'pedal', u':', u'soft', u'pedal', u'-lrb-', u'una', u'corda', u'-rrb-', u',', u'sostenuto', u',', u'and', u'sustain', u'pedal', u'-lrb-', u'from', u'leave', u'to', u'right', u',', u'respectively', u'-rrb-', u'.'], u'pos': [u'JJS', u'JJ', u'NNS', u'VBP', u'CD', u'NNS', u':', u'JJ', u'NN', u'-LRB-', u'FW', u'FW', u'-RRB-', u',', u'NN', u',', u'CC', u'VB', u'NN', u'-LRB-', u'IN', u'VBN', u'TO', u'RB', u',', u'RB', u'-RRB-', u'.'], u'char_offsets': [[21820, 21824], [21825, 21830], [21831, 21837], [21838, 21842], [21843, 21848], [21849, 21855], [21855, 21856], [21857, 21861], [21862, 21867], [21868, 21869], [21869, 21872], [21873, 21878], [21878, 21879], [21879, 21880], [21881, 21890], [21890, 21891], [21892, 21895], [21896, 21903], [21904, 21909], [21910, 21911], [21911, 21915], [21916, 21920], [21921, 21923], [21924, 21929], [21929, 21930], [21931, 21943], [21943, 21944], [21944, 21945]]}) 
answer: set([u'left-most', u'call'])
candidate Sentence: (0.34400025010108948, {u'tokens': [u'On', u'grand', u'pianos', u',', u'the', u'middle', u'pedal', u'is', u'a', u'sostenuto', u'pedal', u'.'], u'lemmas': [u'on', u'grand', u'piano', u',', u'the', u'middle', u'pedal', u'be', u'a', u'sostenuto', u'pedal', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u',', u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[22883, 22885], [22886, 22891], [22892, 22898], [22898, 22899], [22900, 22903], [22904, 22910], [22911, 22916], [22917, 22919], [22920, 22921], [22922, 22931], [22932, 22937], [22937, 22938]]}) 
answer: set([u'left-most', u'corda', u'call', u'una'])
candidate Sentence: (0.27836233377456665, {u'tokens': [u'grand', u'piano', u'.'], u'lemmas': [u'grand', u'piano', u'.'], u'pos': [u'JJ', u'NN', u'.'], u'char_offsets': [[10196, 10201], [10202, 10207], [10207, 10208]]}) 
answer: set([u'left-most', u'corda', u'pedal', u'call', u'una'])
candidate Sentence: (0.27367448806762695, {u'tokens': [u'In', u'grand', u'pianos', u',', u'it', u'shifts', u'the', u'entire', u'action', u',', u'including', u'the', u'keyboard', u',', u'to', u'the', u'right', u',', u'so', u'that', u'the', u'hammers', u'hit', u'only', u'one', u'of', u'the', u'three', u'strings', u'for', u'each', u'note', u'-LRB-', u'hence', u'the', u'name', u'una', u'corda', u',', u'or', u'`', u'one', u'string', u"'", u'-RRB-', u'.'], u'lemmas': [u'in', u'grand', u'piano', u',', u'it', u'shift', u'the', u'entire', u'action', u',', u'include', u'the', u'keyboard', u',', u'to', u'the', u'right', u',', u'so', u'that', u'the', u'hammer', u'hit', u'only', u'one', u'of', u'the', u'three', u'string', u'for', u'each', u'note', u'-lrb-', u'hence', u'the', u'name', u'una', u'corda', u',', u'or', u'`', u'one', u'string', u"'", u'-rrb-', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u',', u'PRP', u'VBZ', u'DT', u'JJ', u'NN', u',', u'VBG', u'DT', u'NN', u',', u'TO', u'DT', u'NN', u',', u'RB', u'IN', u'DT', u'NNS', u'VBD', u'RB', u'CD', u'IN', u'DT', u'CD', u'NNS', u'IN', u'DT', u'NN', u'-LRB-', u'RB', u'DT', u'NN', u'FW', u'FW', u',', u'CC', u'``', u'CD', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[22430, 22432], [22433, 22438], [22439, 22445], [22445, 22446], [22447, 22449], [22450, 22456], [22457, 22460], [22461, 22467], [22468, 22474], [22474, 22475], [22476, 22485], [22486, 22489], [22490, 22498], [22498, 22499], [22500, 22502], [22503, 22506], [22507, 22512], [22512, 22513], [22514, 22516], [22517, 22521], [22522, 22525], [22526, 22533], [22534, 22537], [22538, 22542], [22543, 22546], [22547, 22549], [22550, 22553], [22554, 22559], [22560, 22567], [22568, 22571], [22572, 22576], [22577, 22581], [22582, 22583], [22583, 22588], [22589, 22592], [22593, 22597], [22598, 22601], [22602, 22607], [22607, 22608], [22609, 22611], [22612, 22613], [22613, 22616], [22617, 22623], [22623, 22624], [22624, 22625], [22625, 22626]]}) 
answer: set([u'left-most', u'pedal', u'call'])
candidate Sentence: (0.25456073880195618, {u'tokens': [u'On', u'many', u'upright', u'pianos', u',', u'there', u'is', u'a', u'middle', u'pedal', u'called', u'the', u'`', u'practice', u"'", u'or', u'celeste', u'pedal', u'.'], u'lemmas': [u'on', u'many', u'upright', u'piano', u',', u'there', u'be', u'a', u'middle', u'pedal', u'call', u'the', u'`', u'practice', u"'", u'or', u'celeste', u'pedal', u'.'], u'pos': [u'IN', u'JJ', u'JJ', u'NNS', u',', u'EX', u'VBZ', u'DT', u'JJ', u'NN', u'VBD', u'DT', u'``', u'NN', u"''", u'CC', u'JJ', u'NN', u'.'], u'char_offsets': [[23325, 23327], [23328, 23332], [23333, 23340], [23341, 23347], [23347, 23348], [23349, 23354], [23355, 23357], [23358, 23359], [23360, 23366], [23367, 23372], [23373, 23379], [23380, 23383], [23384, 23385], [23385, 23393], [23393, 23394], [23395, 23397], [23398, 23405], [23406, 23411], [23411, 23412]]}) 
answer: set([u'left-most', u'corda', u'grand', u'una'])
candidate Sentence: (0.23683032393455505, {u'tokens': [u'The', u'sustain', u'pedal', u'-LRB-', u'or', u',', u'damper', u'pedal', u'-RRB-', u'is', u'often', u'simply', u'called', u'``', u'the', u'pedal', u"''", u',', u'since', u'it', u'is', u'the', u'most', u'frequently', u'used', u'.'], u'lemmas': [u'the', u'sustain', u'pedal', u'-lrb-', u'or', u',', u'damper', u'pedal', u'-rrb-', u'be', u'often', u'simply', u'call', u'``', u'the', u'pedal', u"''", u',', u'since', u'it', u'be', u'the', u'most', u'frequently', u'use', u'.'], u'pos': [u'DT', u'VBP', u'NN', u'-LRB-', u'CC', u',', u'NN', u'NN', u'-RRB-', u'VBZ', u'RB', u'RB', u'VBN', u'``', u'DT', u'NN', u"''", u',', u'IN', u'PRP', u'VBZ', u'DT', u'RBS', u'RB', u'VBN', u'.'], u'char_offsets': [[22098, 22101], [22102, 22109], [22110, 22115], [22116, 22117], [22117, 22119], [22119, 22120], [22121, 22127], [22128, 22133], [22133, 22134], [22135, 22137], [22138, 22143], [22144, 22150], [22151, 22157], [22158, 22159], [22159, 22162], [22163, 22168], [22168, 22169], [22169, 22170], [22171, 22176], [22177, 22179], [22180, 22182], [22183, 22186], [22187, 22191], [22192, 22202], [22203, 22207], [22207, 22208]]}) 
answer: set([u'left-most', u'corda', u'una', u'grand'])
candidate Sentence: (0.16957953572273254, {u'tokens': [u'The', u'longer', u'strings', u'on', u'a', u'concert', u'grand', u'can', u'vibrate', u'more', u'freely', u'than', u'the', u'shorter', u',', u'thicker', u'strings', u'on', u'a', u'baby', u'grand', u',', u'which', u'means', u'that', u'a', u'concert', u'grand', u"'s", u'strings', u'will', u'have', u'truer', u'overtones', u'.'], u'lemmas': [u'the', u'longer', u'string', u'on', u'a', u'concert', u'grand', u'can', u'vibrate', u'more', u'freely', u'than', u'the', u'shorter', u',', u'thicker', u'string', u'on', u'a', u'baby', u'grand', u',', u'which', u'mean', u'that', u'a', u'concert', u'grand', u"'s", u'string', u'will', u'have', u'truer', u'overtone', u'.'], u'pos': [u'DT', u'JJR', u'NNS', u'IN', u'DT', u'NN', u'JJ', u'MD', u'VB', u'RBR', u'RB', u'IN', u'DT', u'JJR', u',', u'JJR', u'NNS', u'IN', u'DT', u'NN', u'JJ', u',', u'WDT', u'VBZ', u'IN', u'DT', u'NN', u'JJ', u'POS', u'NNS', u'MD', u'VB', u'JJR', u'NNS', u'.'], u'char_offsets': [[14471, 14474], [14475, 14481], [14482, 14489], [14490, 14492], [14493, 14494], [14495, 14502], [14503, 14508], [14509, 14512], [14513, 14520], [14521, 14525], [14526, 14532], [14533, 14537], [14538, 14541], [14542, 14549], [14549, 14550], [14551, 14558], [14559, 14566], [14567, 14569], [14570, 14571], [14572, 14576], [14577, 14582], [14582, 14583], [14584, 14589], [14590, 14595], [14596, 14600], [14601, 14602], [14603, 14610], [14611, 14616], [14616, 14618], [14619, 14626], [14627, 14631], [14632, 14636], [14637, 14642], [14643, 14652], [14652, 14653]]}) 
answer: set([u'left-most', u'corda', u'pedal', u'call', u'una'])
candidate Sentence: (0.15880560874938965, {u'tokens': [u'Most', u'modern', u'upright', u'pianos', u'have', u'three', u'pedals', u':', u'soft', u'pedal', u',', u'practice', u'pedal', u'and', u'sustain', u'pedal', u',', u'though', u'older', u'or', u'cheaper', u'models', u'may', u'lack', u'the', u'practice', u'pedal', u'.'], u'lemmas': [u'most', u'modern', u'upright', u'piano', u'have', u'three', u'pedal', u':', u'soft', u'pedal', u',', u'practice', u'pedal', u'and', u'sustain', u'pedal', u',', u'though', u'older', u'or', u'cheaper', u'model', u'may', u'lack', u'the', u'practice', u'pedal', u'.'], u'pos': [u'JJS', u'JJ', u'JJ', u'NNS', u'VBP', u'CD', u'NNS', u':', u'JJ', u'NN', u',', u'NN', u'NN', u'CC', u'VB', u'NN', u',', u'IN', u'JJR', u'CC', u'JJR', u'NNS', u'MD', u'VB', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[21946, 21950], [21951, 21957], [21958, 21965], [21966, 21972], [21973, 21977], [21978, 21983], [21984, 21990], [21990, 21991], [21992, 21996], [21997, 22002], [22002, 22003], [22004, 22012], [22013, 22018], [22019, 22022], [22023, 22030], [22031, 22036], [22036, 22037], [22038, 22044], [22045, 22050], [22051, 22053], [22054, 22061], [22062, 22068], [22069, 22072], [22073, 22077], [22078, 22081], [22082, 22090], [22091, 22096], [22096, 22097]]}) 
answer: set([u'left-most', u'corda', u'grand', u'call', u'una'])

Is the left-most pedal on a grand piano called the una corda?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d8a70>.answer
_____________________________ test_yesno[param254] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8ab8>, (<src.tfidf.TF_IDF object at 0x10a4d4c10>, set(['piano'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, the left-most pedal on a grand piano is called the una corda.')
E                +    where 'Yes, the left-most pedal on a grand piano is called the una corda.' = <src.question_processing.Question_parser instance at 0x1114d8ab8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.49156421422958374, {u'tokens': [u'The', u'soft', u'pedal', u'or', u'una', u'corda', u'pedal', u'is', u'placed', u'leftmost', u'in', u'the', u'row', u'of', u'pedals', u'.'], u'lemmas': [u'the', u'soft', u'pedal', u'or', u'una', u'corda', u'pedal', u'be', u'place', u'leftmost', u'in', u'the', u'row', u'of', u'pedal', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'CC', u'FW', u'FW', u'NN', u'VBZ', u'VBN', u'JJS', u'IN', u'DT', u'NN', u'IN', u'NNS', u'.'], u'char_offsets': [[22355, 22358], [22359, 22363], [22364, 22369], [22370, 22372], [22373, 22376], [22377, 22382], [22383, 22388], [22389, 22391], [22392, 22398], [22399, 22407], [22408, 22410], [22411, 22414], [22415, 22418], [22419, 22421], [22422, 22428], [22428, 22429]]}) 
answer: set([u'left-most', u'call', u'grand'])
candidate Sentence: (0.48642778396606445, {u'tokens': [u'Piano', u'pedals', u'from', u'left', u'to', u'right', u':', u'una', u'corda', u',', u'sostenuto', u',', u'and', u'damper', u'.'], u'lemmas': [u'piano', u'pedal', u'from', u'leave', u'to', u'right', u':', u'una', u'corda', u',', u'sostenuto', u',', u'and', u'damper', u'.'], u'pos': [u'NN', u'NNS', u'IN', u'VBN', u'TO', u'NN', u':', u'FW', u'FW', u',', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[21576, 21581], [21582, 21588], [21589, 21593], [21594, 21598], [21599, 21601], [21602, 21607], [21607, 21608], [21609, 21612], [21613, 21618], [21618, 21619], [21620, 21629], [21629, 21630], [21631, 21634], [21635, 21641], [21641, 21642]]}) 
answer: set([u'left-most', u'call', u'grand'])
candidate Sentence: (0.43915429711341858, {u'tokens': [u'Most', u'grand', u'pianos', u'have', u'three', u'pedals', u':', u'soft', u'pedal', u'-LRB-', u'una', u'corda', u'-RRB-', u',', u'sostenuto', u',', u'and', u'sustain', u'pedal', u'-LRB-', u'from', u'left', u'to', u'right', u',', u'respectively', u'-RRB-', u'.'], u'lemmas': [u'most', u'grand', u'piano', u'have', u'three', u'pedal', u':', u'soft', u'pedal', u'-lrb-', u'una', u'corda', u'-rrb-', u',', u'sostenuto', u',', u'and', u'sustain', u'pedal', u'-lrb-', u'from', u'leave', u'to', u'right', u',', u'respectively', u'-rrb-', u'.'], u'pos': [u'JJS', u'JJ', u'NNS', u'VBP', u'CD', u'NNS', u':', u'JJ', u'NN', u'-LRB-', u'FW', u'FW', u'-RRB-', u',', u'NN', u',', u'CC', u'VB', u'NN', u'-LRB-', u'IN', u'VBN', u'TO', u'RB', u',', u'RB', u'-RRB-', u'.'], u'char_offsets': [[21820, 21824], [21825, 21830], [21831, 21837], [21838, 21842], [21843, 21848], [21849, 21855], [21855, 21856], [21857, 21861], [21862, 21867], [21868, 21869], [21869, 21872], [21873, 21878], [21878, 21879], [21879, 21880], [21881, 21890], [21890, 21891], [21892, 21895], [21896, 21903], [21904, 21909], [21910, 21911], [21911, 21915], [21916, 21920], [21921, 21923], [21924, 21929], [21929, 21930], [21931, 21943], [21943, 21944], [21944, 21945]]}) 
answer: set([u'left-most', u'call'])
candidate Sentence: (0.34400025010108948, {u'tokens': [u'On', u'grand', u'pianos', u',', u'the', u'middle', u'pedal', u'is', u'a', u'sostenuto', u'pedal', u'.'], u'lemmas': [u'on', u'grand', u'piano', u',', u'the', u'middle', u'pedal', u'be', u'a', u'sostenuto', u'pedal', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u',', u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[22883, 22885], [22886, 22891], [22892, 22898], [22898, 22899], [22900, 22903], [22904, 22910], [22911, 22916], [22917, 22919], [22920, 22921], [22922, 22931], [22932, 22937], [22937, 22938]]}) 
answer: set([u'left-most', u'corda', u'call', u'una'])
candidate Sentence: (0.27836233377456665, {u'tokens': [u'grand', u'piano', u'.'], u'lemmas': [u'grand', u'piano', u'.'], u'pos': [u'JJ', u'NN', u'.'], u'char_offsets': [[10196, 10201], [10202, 10207], [10207, 10208]]}) 
answer: set([u'left-most', u'corda', u'pedal', u'call', u'una'])
candidate Sentence: (0.27367448806762695, {u'tokens': [u'In', u'grand', u'pianos', u',', u'it', u'shifts', u'the', u'entire', u'action', u',', u'including', u'the', u'keyboard', u',', u'to', u'the', u'right', u',', u'so', u'that', u'the', u'hammers', u'hit', u'only', u'one', u'of', u'the', u'three', u'strings', u'for', u'each', u'note', u'-LRB-', u'hence', u'the', u'name', u'una', u'corda', u',', u'or', u'`', u'one', u'string', u"'", u'-RRB-', u'.'], u'lemmas': [u'in', u'grand', u'piano', u',', u'it', u'shift', u'the', u'entire', u'action', u',', u'include', u'the', u'keyboard', u',', u'to', u'the', u'right', u',', u'so', u'that', u'the', u'hammer', u'hit', u'only', u'one', u'of', u'the', u'three', u'string', u'for', u'each', u'note', u'-lrb-', u'hence', u'the', u'name', u'una', u'corda', u',', u'or', u'`', u'one', u'string', u"'", u'-rrb-', u'.'], u'pos': [u'IN', u'JJ', u'NNS', u',', u'PRP', u'VBZ', u'DT', u'JJ', u'NN', u',', u'VBG', u'DT', u'NN', u',', u'TO', u'DT', u'NN', u',', u'RB', u'IN', u'DT', u'NNS', u'VBD', u'RB', u'CD', u'IN', u'DT', u'CD', u'NNS', u'IN', u'DT', u'NN', u'-LRB-', u'RB', u'DT', u'NN', u'FW', u'FW', u',', u'CC', u'``', u'CD', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[22430, 22432], [22433, 22438], [22439, 22445], [22445, 22446], [22447, 22449], [22450, 22456], [22457, 22460], [22461, 22467], [22468, 22474], [22474, 22475], [22476, 22485], [22486, 22489], [22490, 22498], [22498, 22499], [22500, 22502], [22503, 22506], [22507, 22512], [22512, 22513], [22514, 22516], [22517, 22521], [22522, 22525], [22526, 22533], [22534, 22537], [22538, 22542], [22543, 22546], [22547, 22549], [22550, 22553], [22554, 22559], [22560, 22567], [22568, 22571], [22572, 22576], [22577, 22581], [22582, 22583], [22583, 22588], [22589, 22592], [22593, 22597], [22598, 22601], [22602, 22607], [22607, 22608], [22609, 22611], [22612, 22613], [22613, 22616], [22617, 22623], [22623, 22624], [22624, 22625], [22625, 22626]]}) 
answer: set([u'left-most', u'pedal', u'call'])
candidate Sentence: (0.25456073880195618, {u'tokens': [u'On', u'many', u'upright', u'pianos', u',', u'there', u'is', u'a', u'middle', u'pedal', u'called', u'the', u'`', u'practice', u"'", u'or', u'celeste', u'pedal', u'.'], u'lemmas': [u'on', u'many', u'upright', u'piano', u',', u'there', u'be', u'a', u'middle', u'pedal', u'call', u'the', u'`', u'practice', u"'", u'or', u'celeste', u'pedal', u'.'], u'pos': [u'IN', u'JJ', u'JJ', u'NNS', u',', u'EX', u'VBZ', u'DT', u'JJ', u'NN', u'VBD', u'DT', u'``', u'NN', u"''", u'CC', u'JJ', u'NN', u'.'], u'char_offsets': [[23325, 23327], [23328, 23332], [23333, 23340], [23341, 23347], [23347, 23348], [23349, 23354], [23355, 23357], [23358, 23359], [23360, 23366], [23367, 23372], [23373, 23379], [23380, 23383], [23384, 23385], [23385, 23393], [23393, 23394], [23395, 23397], [23398, 23405], [23406, 23411], [23411, 23412]]}) 
answer: set([u'left-most', u'corda', u'grand', u'una'])
candidate Sentence: (0.23683032393455505, {u'tokens': [u'The', u'sustain', u'pedal', u'-LRB-', u'or', u',', u'damper', u'pedal', u'-RRB-', u'is', u'often', u'simply', u'called', u'``', u'the', u'pedal', u"''", u',', u'since', u'it', u'is', u'the', u'most', u'frequently', u'used', u'.'], u'lemmas': [u'the', u'sustain', u'pedal', u'-lrb-', u'or', u',', u'damper', u'pedal', u'-rrb-', u'be', u'often', u'simply', u'call', u'``', u'the', u'pedal', u"''", u',', u'since', u'it', u'be', u'the', u'most', u'frequently', u'use', u'.'], u'pos': [u'DT', u'VBP', u'NN', u'-LRB-', u'CC', u',', u'NN', u'NN', u'-RRB-', u'VBZ', u'RB', u'RB', u'VBN', u'``', u'DT', u'NN', u"''", u',', u'IN', u'PRP', u'VBZ', u'DT', u'RBS', u'RB', u'VBN', u'.'], u'char_offsets': [[22098, 22101], [22102, 22109], [22110, 22115], [22116, 22117], [22117, 22119], [22119, 22120], [22121, 22127], [22128, 22133], [22133, 22134], [22135, 22137], [22138, 22143], [22144, 22150], [22151, 22157], [22158, 22159], [22159, 22162], [22163, 22168], [22168, 22169], [22169, 22170], [22171, 22176], [22177, 22179], [22180, 22182], [22183, 22186], [22187, 22191], [22192, 22202], [22203, 22207], [22207, 22208]]}) 
answer: set([u'left-most', u'corda', u'una', u'grand'])
candidate Sentence: (0.16957953572273254, {u'tokens': [u'The', u'longer', u'strings', u'on', u'a', u'concert', u'grand', u'can', u'vibrate', u'more', u'freely', u'than', u'the', u'shorter', u',', u'thicker', u'strings', u'on', u'a', u'baby', u'grand', u',', u'which', u'means', u'that', u'a', u'concert', u'grand', u"'s", u'strings', u'will', u'have', u'truer', u'overtones', u'.'], u'lemmas': [u'the', u'longer', u'string', u'on', u'a', u'concert', u'grand', u'can', u'vibrate', u'more', u'freely', u'than', u'the', u'shorter', u',', u'thicker', u'string', u'on', u'a', u'baby', u'grand', u',', u'which', u'mean', u'that', u'a', u'concert', u'grand', u"'s", u'string', u'will', u'have', u'truer', u'overtone', u'.'], u'pos': [u'DT', u'JJR', u'NNS', u'IN', u'DT', u'NN', u'JJ', u'MD', u'VB', u'RBR', u'RB', u'IN', u'DT', u'JJR', u',', u'JJR', u'NNS', u'IN', u'DT', u'NN', u'JJ', u',', u'WDT', u'VBZ', u'IN', u'DT', u'NN', u'JJ', u'POS', u'NNS', u'MD', u'VB', u'JJR', u'NNS', u'.'], u'char_offsets': [[14471, 14474], [14475, 14481], [14482, 14489], [14490, 14492], [14493, 14494], [14495, 14502], [14503, 14508], [14509, 14512], [14513, 14520], [14521, 14525], [14526, 14532], [14533, 14537], [14538, 14541], [14542, 14549], [14549, 14550], [14551, 14558], [14559, 14566], [14567, 14569], [14570, 14571], [14572, 14576], [14577, 14582], [14582, 14583], [14584, 14589], [14590, 14595], [14596, 14600], [14601, 14602], [14603, 14610], [14611, 14616], [14616, 14618], [14619, 14626], [14627, 14631], [14632, 14636], [14637, 14642], [14643, 14652], [14652, 14653]]}) 
answer: set([u'left-most', u'corda', u'pedal', u'call', u'una'])
candidate Sentence: (0.15880560874938965, {u'tokens': [u'Most', u'modern', u'upright', u'pianos', u'have', u'three', u'pedals', u':', u'soft', u'pedal', u',', u'practice', u'pedal', u'and', u'sustain', u'pedal', u',', u'though', u'older', u'or', u'cheaper', u'models', u'may', u'lack', u'the', u'practice', u'pedal', u'.'], u'lemmas': [u'most', u'modern', u'upright', u'piano', u'have', u'three', u'pedal', u':', u'soft', u'pedal', u',', u'practice', u'pedal', u'and', u'sustain', u'pedal', u',', u'though', u'older', u'or', u'cheaper', u'model', u'may', u'lack', u'the', u'practice', u'pedal', u'.'], u'pos': [u'JJS', u'JJ', u'JJ', u'NNS', u'VBP', u'CD', u'NNS', u':', u'JJ', u'NN', u',', u'NN', u'NN', u'CC', u'VB', u'NN', u',', u'IN', u'JJR', u'CC', u'JJR', u'NNS', u'MD', u'VB', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[21946, 21950], [21951, 21957], [21958, 21965], [21966, 21972], [21973, 21977], [21978, 21983], [21984, 21990], [21990, 21991], [21992, 21996], [21997, 22002], [22002, 22003], [22004, 22012], [22013, 22018], [22019, 22022], [22023, 22030], [22031, 22036], [22036, 22037], [22038, 22044], [22045, 22050], [22051, 22053], [22054, 22061], [22062, 22068], [22069, 22072], [22073, 22077], [22078, 22081], [22082, 22090], [22091, 22096], [22096, 22097]]}) 
answer: set([u'left-most', u'corda', u'grand', u'call', u'una'])

Is the left-most pedal on a grand piano called the una corda?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, the left-most pedal on a grand piano is called the una corda.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, the left-most pedal on a grand piano is called the una corda.')
 +    where 'Yes, the left-most pedal on a grand piano is called the una corda.' = <src.question_processing.Question_parser instance at 0x1114d8ab8>.answer
_____________________________ test_yesno[param255] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8b00>, (<src.tfidf.TF_IDF object at 0x10a4d4c10>, set(['piano'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d8b00>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.90349835157394409, {u'tokens': [u'It', u'is', u'advantageous', u'for', u'the', u'plate', u'to', u'be', u'quite', u'massive', u'.'], u'lemmas': [u'it', u'be', u'advantageous', u'for', u'the', u'plate', u'to', u'be', u'quite', u'massive', u'.'], u'pos': [u'PRP', u'VBZ', u'JJ', u'IN', u'DT', u'NN', u'TO', u'VB', u'RB', u'JJ', u'.'], u'char_offsets': [[26946, 26948], [26949, 26951], [26952, 26964], [26965, 26968], [26969, 26972], [26973, 26978], [26979, 26981], [26982, 26984], [26985, 26990], [26991, 26998], [26998, 26999]]}) 
answer: set([u'metal', u'grand'])
candidate Sentence: (0.21564431488513947, {u'tokens': [u'The', u'plate', u',', u'or', u'metal', u'frame', u',', u'of', u'a', u'piano', u'is', u'usually', u'made', u'of', u'cast', u'iron', u'.'], u'lemmas': [u'the', u'plate', u',', u'or', u'metal', u'frame', u',', u'of', u'a', u'piano', u'be', u'usually', u'make', u'of', u'cast', u'iron', u'.'], u'pos': [u'DT', u'NN', u',', u'CC', u'NN', u'NN', u',', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'IN', u'NN', u'NN', u'.'], u'char_offsets': [[26878, 26881], [26882, 26887], [26887, 26888], [26889, 26891], [26892, 26897], [26898, 26903], [26903, 26904], [26905, 26907], [26908, 26909], [26910, 26915], [26916, 26918], [26919, 26926], [26927, 26931], [26932, 26934], [26935, 26939], [26940, 26944], [26944, 26945]]}) 
answer: set([u'quite', u'massive', u'advantageous', u'grand'])
candidate Sentence: (0.18475976586341858, {u'tokens': [u'grand', u'piano', u'.'], u'lemmas': [u'grand', u'piano', u'.'], u'pos': [u'JJ', u'NN', u'.'], u'char_offsets': [[10196, 10201], [10202, 10207], [10207, 10208]]}) 
answer: set([u'plate', u'metal', u'massive', u'advantageous', u'quite'])
candidate Sentence: (0.11836342513561249, {u'tokens': [u'The', u'inclusion', u'in', u'a', u'piano', u'of', u'an', u'extremely', u'large', u'piece', u'of', u'metal', u'is', u'potentially', u'an', u'aesthetic', u'handicap', u',', u'which', u'piano', u'makers', u'overcome', u'by', u'polishing', u',', u'painting', u'and', u'decorating', u'the', u'plate', u'.'], u'lemmas': [u'the', u'inclusion', u'in', u'a', u'piano', u'of', u'a', u'extremely', u'large', u'piece', u'of', u'metal', u'be', u'potentially', u'a', u'aesthetic', u'handicap', u',', u'which', u'piano', u'maker', u'overcome', u'by', u'polish', u',', u'painting', u'and', u'decorate', u'the', u'plate', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'RB', u'JJ', u'NN', u'IN', u'NN', u'VBZ', u'RB', u'DT', u'JJ', u'NN', u',', u'WDT', u'NN', u'NNS', u'VBN', u'IN', u'VBG', u',', u'NN', u'CC', u'VBG', u'DT', u'NN', u'.'], u'char_offsets': [[27434, 27437], [27438, 27447], [27448, 27450], [27451, 27452], [27453, 27458], [27459, 27461], [27462, 27464], [27465, 27474], [27475, 27480], [27481, 27486], [27487, 27489], [27490, 27495], [27496, 27498], [27499, 27510], [27511, 27513], [27514, 27523], [27524, 27532], [27532, 27533], [27534, 27539], [27540, 27545], [27546, 27552], [27553, 27561], [27562, 27564], [27565, 27574], [27574, 27575], [27576, 27584], [27585, 27588], [27589, 27599], [27600, 27603], [27604, 27609], [27609, 27610]]}) 
answer: set([u'quite', u'massive', u'advantageous', u'grand'])
candidate Sentence: (0.10767658054828644, {u'tokens': [u'Plates', u'often', u'include', u'the', u'manufacturer', u"'s", u'ornamental', u'medallion', u'and', u'can', u'be', u'strikingly', u'attractive', u'.'], u'lemmas': [u'plate', u'often', u'include', u'the', u'manufacturer', u"'s", u'ornamental', u'medallion', u'and', u'can', u'be', u'strikingly', u'attractive', u'.'], u'pos': [u'NNS', u'RB', u'VBP', u'DT', u'NN', u'POS', u'JJ', u'NN', u'CC', u'MD', u'VB', u'RB', u'JJ', u'.'], u'char_offsets': [[27611, 27617], [27618, 27623], [27624, 27631], [27632, 27635], [27636, 27648], [27648, 27650], [27651, 27661], [27662, 27671], [27672, 27675], [27676, 27679], [27680, 27682], [27683, 27693], [27694, 27704], [27704, 27705]]}) 
answer: set([u'grand', u'metal', u'massive', u'advantageous', u'quite'])
candidate Sentence: (0.1001773402094841, {u'tokens': [u'The', u'metal', u'rod', u'at', u'lower', u'right', u'is', u'a', u'humidity', u'control', u'device', u'.'], u'lemmas': [u'the', u'metal', u'rod', u'at', u'lower', u'right', u'be', u'a', u'humidity', u'control', u'device', u'.'], u'pos': [u'DT', u'NN', u'NN', u'IN', u'JJR', u'NN', u'VBZ', u'DT', u'NN', u'NN', u'NN', u'.'], u'char_offsets': [[25531, 25534], [25535, 25540], [25541, 25544], [25545, 25547], [25548, 25553], [25554, 25559], [25560, 25562], [25563, 25564], [25565, 25573], [25574, 25581], [25582, 25588], [25588, 25589]]}) 
answer: set([u'plate', u'grand', u'massive', u'advantageous', u'quite'])
candidate Sentence: (0.094274967908859253, {u'tokens': [u'The', u'longer', u'strings', u'on', u'a', u'concert', u'grand', u'can', u'vibrate', u'more', u'freely', u'than', u'the', u'shorter', u',', u'thicker', u'strings', u'on', u'a', u'baby', u'grand', u',', u'which', u'means', u'that', u'a', u'concert', u'grand', u"'s", u'strings', u'will', u'have', u'truer', u'overtones', u'.'], u'lemmas': [u'the', u'longer', u'string', u'on', u'a', u'concert', u'grand', u'can', u'vibrate', u'more', u'freely', u'than', u'the', u'shorter', u',', u'thicker', u'string', u'on', u'a', u'baby', u'grand', u',', u'which', u'mean', u'that', u'a', u'concert', u'grand', u"'s", u'string', u'will', u'have', u'truer', u'overtone', u'.'], u'pos': [u'DT', u'JJR', u'NNS', u'IN', u'DT', u'NN', u'JJ', u'MD', u'VB', u'RBR', u'RB', u'IN', u'DT', u'JJR', u',', u'JJR', u'NNS', u'IN', u'DT', u'NN', u'JJ', u',', u'WDT', u'VBZ', u'IN', u'DT', u'NN', u'JJ', u'POS', u'NNS', u'MD', u'VB', u'JJR', u'NNS', u'.'], u'char_offsets': [[14471, 14474], [14475, 14481], [14482, 14489], [14490, 14492], [14493, 14494], [14495, 14502], [14503, 14508], [14509, 14512], [14513, 14520], [14521, 14525], [14526, 14532], [14533, 14537], [14538, 14541], [14542, 14549], [14549, 14550], [14551, 14558], [14559, 14566], [14567, 14569], [14570, 14571], [14572, 14576], [14577, 14582], [14582, 14583], [14584, 14589], [14590, 14595], [14596, 14600], [14601, 14602], [14603, 14610], [14611, 14616], [14616, 14618], [14619, 14626], [14627, 14631], [14632, 14636], [14637, 14642], [14643, 14652], [14652, 14653]]}) 
answer: set([u'plate', u'metal', u'massive', u'advantageous', u'quite'])
candidate Sentence: (0.094078436493873596, {u'tokens': [u'Since', u'the', u'strings', u'are', u'attached', u'to', u'the', u'plate', u'at', u'one', u'end', u',', u'any', u'vibrations', u'transmitted', u'to', u'the', u'plate', u'will', u'result', u'in', u'loss', u'of', u'energy', u'to', u'the', u'desired', u'-LRB-', u'efficient', u'-RRB-', u'channel', u'of', u'sound', u'transmission', u',', u'namely', u'the', u'bridge', u'and', u'the', u'soundboard', u'.'], u'lemmas': [u'since', u'the', u'string', u'be', u'attach', u'to', u'the', u'plate', u'at', u'one', u'end', u',', u'any', u'vibration', u'transmit', u'to', u'the', u'plate', u'will', u'result', u'in', u'loss', u'of', u'energy', u'to', u'the', u'desire', u'-lrb-', u'efficient', u'-rrb-', u'channel', u'of', u'sound', u'transmission', u',', u'namely', u'the', u'bridge', u'and', u'the', u'soundboard', u'.'], u'pos': [u'IN', u'DT', u'NNS', u'VBP', u'VBN', u'TO', u'DT', u'NN', u'IN', u'CD', u'NN', u',', u'DT', u'NNS', u'VBD', u'TO', u'DT', u'NN', u'MD', u'VB', u'IN', u'NN', u'IN', u'NN', u'TO', u'DT', u'VBN', u'-LRB-', u'JJ', u'-RRB-', u'NN', u'IN', u'JJ', u'NN', u',', u'RB', u'DT', u'NN', u'CC', u'DT', u'NN', u'.'], u'char_offsets': [[27000, 27005], [27006, 27009], [27010, 27017], [27018, 27021], [27022, 27030], [27031, 27033], [27034, 27037], [27038, 27043], [27044, 27046], [27047, 27050], [27051, 27054], [27054, 27055], [27056, 27059], [27060, 27070], [27071, 27082], [27083, 27085], [27086, 27089], [27090, 27095], [27096, 27100], [27101, 27107], [27108, 27110], [27111, 27115], [27116, 27118], [27119, 27125], [27126, 27128], [27129, 27132], [27133, 27140], [27141, 27142], [27142, 27151], [27151, 27152], [27153, 27160], [27161, 27163], [27164, 27169], [27170, 27182], [27182, 27183], [27184, 27190], [27191, 27194], [27195, 27201], [27202, 27205], [27206, 27209], [27210, 27220], [27220, 27221]]}) 
answer: set([u'grand', u'metal', u'massive', u'advantageous', u'quite'])
candidate Sentence: (0.09238298237323761, {u'tokens': [u'Some', u'manufacturers', u'now', u'use', u'cast', u'steel', u'in', u'their', u'plates', u',', u'for', u'greater', u'strength', u'.'], u'lemmas': [u'some', u'manufacturer', u'now', u'use', u'cast', u'steel', u'in', u'they', u'plate', u',', u'for', u'greater', u'strength', u'.'], u'pos': [u'DT', u'NNS', u'RB', u'VBP', u'VBN', u'NN', u'IN', u'PRP$', u'NNS', u',', u'IN', u'JJR', u'NN', u'.'], u'char_offsets': [[27222, 27226], [27227, 27240], [27241, 27244], [27245, 27248], [27249, 27253], [27254, 27259], [27260, 27262], [27263, 27268], [27269, 27275], [27275, 27276], [27277, 27280], [27281, 27288], [27289, 27297], [27297, 27298]]}) 
answer: set([u'grand', u'metal', u'massive', u'advantageous', u'quite'])
candidate Sentence: (0.091342821717262268, {u'tokens': [u'The', u'scores', u'for', u'music', u'for', u'prepared', u'piano', u'often', u'instruct', u'the', u'pianist', u'to', u'insert', u'pieces', u'of', u'rubber', u'or', u'small', u'pieces', u'of', u'metal', u'-LRB-', u'screws', u'or', u'washers', u'-RRB-', u'in', u'between', u'the', u'strings', u'.'], u'lemmas': [u'the', u'score', u'for', u'music', u'for', u'prepared', u'piano', u'often', u'instruct', u'the', u'pianist', u'to', u'insert', u'piece', u'of', u'rubber', u'or', u'small', u'piece', u'of', u'metal', u'-lrb-', u'screw', u'or', u'washer', u'-rrb-', u'in', u'between', u'the', u'string', u'.'], u'pos': [u'DT', u'NNS', u'IN', u'NN', u'IN', u'JJ', u'NN', u'RB', u'VB', u'DT', u'NN', u'TO', u'VB', u'NNS', u'IN', u'NN', u'CC', u'JJ', u'NNS', u'IN', u'NN', u'-LRB-', u'NNS', u'CC', u'NNS', u'-RRB-', u'IN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[18076, 18079], [18080, 18086], [18087, 18090], [18091, 18096], [18097, 18100], [18101, 18109], [18110, 18115], [18116, 18121], [18122, 18130], [18131, 18134], [18135, 18142], [18143, 18145], [18146, 18152], [18153, 18159], [18160, 18162], [18163, 18169], [18170, 18172], [18173, 18178], [18179, 18185], [18186, 18188], [18189, 18194], [18195, 18196], [18196, 18202], [18203, 18205], [18206, 18213], [18213, 18214], [18215, 18217], [18218, 18225], [18226, 18229], [18230, 18237], [18237, 18238]]}) 
answer: set([u'plate', u'grand', u'massive', u'advantageous', u'quite'])

Is it advantageous for a grand piano's metal plate to be quite massive?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114d8b00>.answer
_____________________________ test_yesno[param258] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8bd8>, (<src.tfidf.TF_IDF object at 0x10a4d4c10>, set(['piano'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('The mechanism in upright pianos is perpendicular to the keys.') == True
E                +  where 'The mechanism in upright pianos is perpendicular to the keys.' = <src.question_processing.Question_parser instance at 0x1114d8bd8>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.89109480381011963, {u'tokens': [u'The', u'mechanism', u'in', u'upright', u'pianos', u'is', u'perpendicular', u'to', u'the', u'keys', u'.'], u'lemmas': [u'the', u'mechanism', u'in', u'upright', u'piano', u'be', u'perpendicular', u'to', u'the', u'key', u'.'], u'pos': [u'DT', u'NN', u'IN', u'JJ', u'NNS', u'VBZ', u'JJ', u'TO', u'DT', u'NNS', u'.'], u'char_offsets': [[11768, 11771], [11772, 11781], [11782, 11784], [11785, 11792], [11793, 11799], [11800, 11802], [11803, 11816], [11817, 11819], [11820, 11823], [11824, 11828], [11828, 11829]]}) 
answer: set([])
candidate Sentence: (0.26921898126602173, {u'tokens': [u'A', u'prepared', u'piano', u'is', u'a', u'standard', u'grand', u'piano', u'which', u'has', u'had', u'objects', u'placed', u'inside', u'it', u'before', u'a', u'performance', u'in', u'order', u'to', u'alter', u'its', u'sound', u',', u'or', u'which', u'has', u'had', u'its', u'mechanism', u'changed', u'in', u'some', u'way', u'.'], u'lemmas': [u'a', u'prepared', u'piano', u'be', u'a', u'standard', u'grand', u'piano', u'which', u'have', u'have', u'object', u'place', u'inside', u'it', u'before', u'a', u'performance', u'in', u'order', u'to', u'alter', u'its', u'sound', u',', u'or', u'which', u'have', u'have', u'its', u'mechanism', u'change', u'in', u'some', u'way', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'JJ', u'JJ', u'NN', u'WDT', u'VBZ', u'VBN', u'NNS', u'VBD', u'IN', u'PRP', u'IN', u'DT', u'NN', u'IN', u'NN', u'TO', u'VB', u'PRP$', u'NN', u',', u'CC', u'WDT', u'VBZ', u'VBN', u'PRP$', u'NN', u'VBD', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[17892, 17893], [17894, 17902], [17903, 17908], [17909, 17911], [17912, 17913], [17914, 17922], [17923, 17928], [17929, 17934], [17935, 17940], [17941, 17944], [17945, 17948], [17949, 17956], [17957, 17963], [17964, 17970], [17971, 17973], [17974, 17980], [17981, 17982], [17983, 17994], [17995, 17997], [17998, 18003], [18004, 18006], [18007, 18012], [18013, 18016], [18017, 18022], [18022, 18023], [18024, 18026], [18027, 18032], [18033, 18036], [18037, 18040], [18041, 18044], [18045, 18054], [18055, 18062], [18063, 18065], [18066, 18070], [18071, 18074], [18074, 18075]]}) 
answer: set([u'upright', u'perpendicular', u'key'])
candidate Sentence: (0.16358505189418793, {u'tokens': [u'The', u'extra', u'keys', u'are', u'the', u'same', u'as', u'the', u'other', u'keys', u'in', u'appearance', u'.'], u'lemmas': [u'the', u'extra', u'key', u'be', u'the', u'same', u'as', u'the', u'other', u'key', u'in', u'appearance', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u'VBP', u'DT', u'JJ', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'NN', u'.'], u'char_offsets': [[21053, 21056], [21057, 21062], [21063, 21067], [21068, 21071], [21072, 21075], [21076, 21080], [21081, 21083], [21084, 21087], [21088, 21093], [21094, 21098], [21099, 21101], [21102, 21112], [21112, 21113]]}) 
answer: set([u'upright', u'perpendicular', u'mechanism'])
candidate Sentence: (0.14855265617370605, {u'tokens': [u'The', u'entire', u'action', u'of', u'the', u'piano', u'is', u'thus', u'shifted', u'to', u'allow', u'the', u'pianist', u'to', u'play', u'music', u'written', u'in', u'one', u'key', u'so', u'that', u'it', u'sounds', u'in', u'a', u'different', u'key', u'.'], u'lemmas': [u'the', u'entire', u'action', u'of', u'the', u'piano', u'be', u'thus', u'shift', u'to', u'allow', u'the', u'pianist', u'to', u'play', u'music', u'write', u'in', u'one', u'key', u'so', u'that', u'it', u'sound', u'in', u'a', u'different', u'key', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'TO', u'VB', u'DT', u'NN', u'TO', u'VB', u'NN', u'VBN', u'IN', u'CD', u'NN', u'IN', u'IN', u'PRP', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[24302, 24305], [24306, 24312], [24313, 24319], [24320, 24322], [24323, 24326], [24327, 24332], [24333, 24335], [24336, 24340], [24341, 24348], [24349, 24351], [24352, 24357], [24358, 24361], [24362, 24369], [24370, 24372], [24373, 24377], [24378, 24383], [24384, 24391], [24392, 24394], [24395, 24398], [24399, 24402], [24403, 24405], [24406, 24410], [24411, 24413], [24414, 24420], [24421, 24423], [24424, 24425], [24426, 24435], [24436, 24439], [24439, 24440]]}) 
answer: set([u'upright', u'perpendicular', u'mechanism'])
candidate Sentence: (0.14286276698112488, {u'tokens': [u'Upright', u'pianos', u'with', u'unusually', u'tall', u'frames', u'and', u'long', u'strings', u'are', u'sometimes', u'called', u'``', u'upright', u'grand', u"''", u'pianos', u'.'], u'lemmas': [u'upright', u'piano', u'with', u'unusually', u'tall', u'frame', u'and', u'long', u'string', u'be', u'sometimes', u'call', u'``', u'upright', u'grand', u"''", u'piano', u'.'], u'pos': [u'JJ', u'NNS', u'IN', u'RB', u'JJ', u'NNS', u'CC', u'JJ', u'NNS', u'VBP', u'RB', u'VBN', u'``', u'JJ', u'JJ', u"''", u'NNS', u'.'], u'char_offsets': [[16079, 16086], [16087, 16093], [16094, 16098], [16099, 16108], [16109, 16113], [16114, 16120], [16121, 16124], [16125, 16129], [16130, 16137], [16138, 16141], [16142, 16151], [16152, 16158], [16159, 16160], [16160, 16167], [16168, 16173], [16173, 16174], [16175, 16181], [16181, 16182]]}) 
answer: set([u'perpendicular', u'key', u'mechanism'])
candidate Sentence: (0.14285695552825928, {u'tokens': [u'In', u'1821', u',', u'S\xe9bastien', u'\xc9rard', u'invented', u'the', u'double', u'escapement', u'action', u',', u'which', u'permitted', u'a', u'note', u'to', u'be', u'repeated', u'even', u'if', u'the', u'key', u'had', u'not', u'yet', u'risen', u'to', u'its', u'maximum', u'vertical', u'position', u'.'], u'lemmas': [u'in', u'1821', u',', u'S\xe9bastien', u'\xc9rard', u'invent', u'the', u'double', u'escapement', u'action', u',', u'which', u'permit', u'a', u'note', u'to', u'be', u'repeat', u'even', u'if', u'the', u'key', u'have', u'not', u'yet', u'rise', u'to', u'its', u'maximum', u'vertical', u'position', u'.'], u'pos': [u'IN', u'CD', u',', u'NNP', u'NNP', u'VBD', u'DT', u'JJ', u'NN', u'NN', u',', u'WDT', u'VBD', u'DT', u'NN', u'TO', u'VB', u'VBN', u'RB', u'IN', u'DT', u'NN', u'VBD', u'RB', u'RB', u'VBN', u'TO', u'PRP$', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[7590, 7592], [7593, 7597], [7597, 7598], [7599, 7608], [7609, 7614], [7615, 7623], [7624, 7627], [7628, 7634], [7635, 7645], [7646, 7652], [7652, 7653], [7654, 7659], [7660, 7669], [7670, 7671], [7672, 7676], [7677, 7679], [7680, 7682], [7683, 7691], [7692, 7696], [7697, 7699], [7700, 7703], [7704, 7707], [7708, 7711], [7712, 7715], [7716, 7719], [7720, 7725], [7726, 7728], [7729, 7732], [7733, 7740], [7741, 7749], [7750, 7758], [7758, 7759]]}) 
answer: set([u'upright', u'perpendicular', u'mechanism'])
candidate Sentence: (0.14097769558429718, {u'tokens': [u'From', u'lower', u'left', u'to', u'upper', u'right', u':', u'dampers', u',', u'main', u'sounding', u'length', u'of', u'strings', u',', u'treble', u'bridge', u',', u'duplex', u'string', u'length', u',', u'duplex', u'bridge', u'-LRB-', u'long', u'bar', u'perpendicular', u'to', u'strings', u'-RRB-', u',', u'hitchpins', u'.'], u'lemmas': [u'from', u'lower', u'leave', u'to', u'upper', u'right', u':', u'damper', u',', u'main', u'sound', u'length', u'of', u'string', u',', u'treble', u'bridge', u',', u'duplex', u'string', u'length', u',', u'duplex', u'bridge', u'-lrb-', u'long', u'bar', u'perpendicular', u'to', u'string', u'-rrb-', u',', u'hitchpin', u'.'], u'pos': [u'IN', u'JJR', u'VBD', u'TO', u'JJ', u'NN', u':', u'NNS', u',', u'JJ', u'VBG', u'NN', u'IN', u'NNS', u',', u'JJ', u'NN', u',', u'NN', u'NN', u'NN', u',', u'NN', u'NN', u'-LRB-', u'JJ', u'NN', u'JJ', u'TO', u'NNS', u'-RRB-', u',', u'NNS', u'.'], u'char_offsets': [[10209, 10213], [10214, 10219], [10220, 10224], [10225, 10227], [10228, 10233], [10234, 10239], [10239, 10240], [10241, 10248], [10248, 10249], [10250, 10254], [10255, 10263], [10264, 10270], [10271, 10273], [10274, 10281], [10281, 10282], [10283, 10289], [10290, 10296], [10296, 10297], [10298, 10304], [10305, 10311], [10312, 10318], [10318, 10319], [10320, 10326], [10327, 10333], [10334, 10335], [10335, 10339], [10340, 10343], [10344, 10357], [10358, 10360], [10361, 10368], [10368, 10369], [10369, 10370], [10371, 10380], [10380, 10381]]}) 
answer: set([u'upright', u'mechanism', u'key'])
candidate Sentence: (0.13965897262096405, {u'tokens': [u'Spruce', u'is', u'chosen', u'for', u'its', u'high', u'ratio', u'of', u'strength', u'to', u'weight', u'.'], u'lemmas': [u'spruce', u'be', u'choose', u'for', u'its', u'high', u'ratio', u'of', u'strength', u'to', u'weight', u'.'], u'pos': [u'NN', u'VBZ', u'VBN', u'IN', u'PRP$', u'JJ', u'NN', u'IN', u'NN', u'TO', u'NN', u'.'], u'char_offsets': [[29194, 29200], [29201, 29203], [29204, 29210], [29211, 29214], [29215, 29218], [29219, 29223], [29224, 29229], [29230, 29232], [29233, 29241], [29242, 29244], [29245, 29251], [29251, 29252]]}) 
answer: set([u'upright', u'perpendicular', u'key', u'mechanism'])
candidate Sentence: (0.13123956322669983, {u'tokens': [u'*', u'The', u'Early', u'Pianoforte', u'by', u'Stewart', u'Pollens', u'-LRB-', u'1995', u',', u'Cambridge', u':', u'Cambridge', u'University', u'Press', u'-RRB-', u'is', u'an', u'authoritative', u'work', u'covering', u'the', u'ancestry', u'of', u'the', u'piano', u',', u'its', u'invention', u'by', u'Cristofori', u',', u'and', u'the', u'early', u'stages', u'of', u'its', u'subsequent', u'evolution', u'.'], u'lemmas': [u'*', u'the', u'early', u'pianoforte', u'by', u'Stewart', u'Pollens', u'-lrb-', u'1995', u',', u'Cambridge', u':', u'Cambridge', u'University', u'Press', u'-rrb-', u'be', u'a', u'authoritative', u'work', u'cover', u'the', u'ancestry', u'of', u'the', u'piano', u',', u'its', u'invention', u'by', u'Cristofori', u',', u'and', u'the', u'early', u'stage', u'of', u'its', u'subsequent', u'evolution', u'.'], u'pos': [u'SYM', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'-LRB-', u'CD', u',', u'NNP', u':', u'NNP', u'NNP', u'NNP', u'-RRB-', u'VBZ', u'DT', u'JJ', u'NN', u'VBG', u'DT', u'NN', u'IN', u'DT', u'NN', u',', u'PRP$', u'NN', u'IN', u'NNP', u',', u'CC', u'DT', u'JJ', u'NNS', u'IN', u'PRP$', u'JJ', u'NN', u'.'], u'char_offsets': [[32908, 32909], [32909, 32912], [32913, 32918], [32919, 32929], [32930, 32932], [32933, 32940], [32941, 32948], [32949, 32950], [32950, 32954], [32954, 32955], [32956, 32965], [32965, 32966], [32967, 32976], [32977, 32987], [32988, 32993], [32993, 32994], [32995, 32997], [32998, 33000], [33001, 33014], [33015, 33019], [33020, 33028], [33029, 33032], [33033, 33041], [33042, 33044], [33045, 33048], [33049, 33054], [33054, 33055], [33056, 33059], [33060, 33069], [33070, 33072], [33073, 33083], [33083, 33084], [33085, 33088], [33089, 33092], [33093, 33098], [33099, 33105], [33106, 33108], [33109, 33112], [33113, 33123], [33124, 33133], [33133, 33134]]}) 
answer: set([u'upright', u'perpendicular', u'key', u'mechanism'])
candidate Sentence: (0.1266556978225708, {u'tokens': [u'There', u'are', u'two', u'types', u'of', u'pedal', u'piano', u':', u'the', u'pedal', u'board', u'may', u'be', u'an', u'integral', u'part', u'of', u'the', u'instrument', u',', u'using', u'the', u'same', u'strings', u'and', u'mechanism', u'as', u'the', u'manual', u'keyboard', u',', u'or', u',', u'less', u'frequently', u',', u'it', u'may', u'consist', u'of', u'two', u'independent', u'pianos', u'-LRB-', u'each', u'with', u'its', u'separate', u'mechanics', u'and', u'strings', u'-RRB-', u'which', u'are', u'placed', u'one', u'above', u'the', u'other', u',', u'a', u'regular', u'piano', u'played', u'by', u'the', u'hands', u'and', u'a', u'bass-register', u'piano', u'played', u'by', u'the', u'feet', u'.'], u'lemmas': [u'there', u'be', u'two', u'type', u'of', u'pedal', u'piano', u':', u'the', u'pedal', u'board', u'may', u'be', u'a', u'integral', u'part', u'of', u'the', u'instrument', u',', u'use', u'the', u'same', u'string', u'and', u'mechanism', u'as', u'the', u'manual', u'keyboard', u',', u'or', u',', u'less', u'frequently', u',', u'it', u'may', u'consist', u'of', u'two', u'independent', u'piano', u'-lrb-', u'each', u'with', u'its', u'separate', u'mechanic', u'and', u'string', u'-rrb-', u'which', u'be', u'place', u'one', u'above', u'the', u'other', u',', u'a', u'regular', u'piano', u'play', u'by', u'the', u'hand', u'and', u'a', u'bass-register', u'piano', u'play', u'by', u'the', u'foot', u'.'], u'pos': [u'EX', u'VBP', u'CD', u'NNS', u'IN', u'NN', u'NN', u':', u'DT', u'NN', u'NN', u'MD', u'VB', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u',', u'VBG', u'DT', u'JJ', u'NNS', u'CC', u'NN', u'IN', u'DT', u'JJ', u'NN', u',', u'CC', u',', u'RBR', u'RB', u',', u'PRP', u'MD', u'VB', u'IN', u'CD', u'JJ', u'NNS', u'-LRB-', u'DT', u'IN', u'PRP$', u'JJ', u'NNS', u'CC', u'NNS', u'-RRB-', u'WDT', u'VBP', u'VBN', u'CD', u'IN', u'DT', u'JJ', u',', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'DT', u'NNS', u'CC', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[24615, 24620], [24621, 24624], [24625, 24628], [24629, 24634], [24635, 24637], [24638, 24643], [24644, 24649], [24649, 24650], [24651, 24654], [24655, 24660], [24661, 24666], [24667, 24670], [24671, 24673], [24674, 24676], [24677, 24685], [24686, 24690], [24691, 24693], [24694, 24697], [24698, 24708], [24708, 24709], [24710, 24715], [24716, 24719], [24720, 24724], [24725, 24732], [24733, 24736], [24737, 24746], [24747, 24749], [24750, 24753], [24754, 24760], [24761, 24769], [24769, 24770], [24771, 24773], [24773, 24774], [24775, 24779], [24780, 24790], [24790, 24791], [24792, 24794], [24795, 24798], [24799, 24806], [24807, 24809], [24810, 24813], [24814, 24825], [24826, 24832], [24833, 24834], [24834, 24838], [24839, 24843], [24844, 24847], [24848, 24856], [24857, 24866], [24867, 24870], [24871, 24878], [24878, 24879], [24880, 24885], [24886, 24889], [24890, 24896], [24897, 24900], [24901, 24906], [24907, 24910], [24911, 24916], [24916, 24917], [24918, 24919], [24920, 24927], [24928, 24933], [24934, 24940], [24941, 24943], [24944, 24947], [24948, 24953], [24954, 24957], [24958, 24959], [24960, 24973], [24974, 24979], [24980, 24986], [24987, 24989], [24990, 24993], [24994, 24998], [24998, 24999]]}) 
answer: set([u'upright', u'perpendicular', u'key'])

Is the mechanism in an upright piano perpendicular to its keys?
Validity= False
Question Type = NA
Answer Type = NA
Answer = The mechanism in upright pianos is perpendicular to the keys.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('The mechanism in upright pianos is perpendicular to the keys.') == True
 +  where 'The mechanism in upright pianos is perpendicular to the keys.' = <src.question_processing.Question_parser instance at 0x1114d8bd8>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param261] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8cb0>, (<src.tfidf.TF_IDF object at 0x10a49f2d0>, set(['language', 'portuguese', 'portuguese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8cb0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.2091362476348877, {u'tokens': [u'Arriving', u'in', u'the', u'Iberian', u'Peninsula', u'in', u'216', u'BC', u',', u'the', u'Romans', u'brought', u'with', u'them', u'the', u'Latin', u'language', u',', u'from', u'which', u'all', u'Romance', u'languages', u'descend', u'.'], u'lemmas': [u'arrive', u'in', u'the', u'Iberian', u'Peninsula', u'in', u'216', u'bc', u',', u'the', u'Romans', u'bring', u'with', u'they', u'the', u'latin', u'language', u',', u'from', u'which', u'all', u'romance', u'language', u'descend', u'.'], u'pos': [u'VBG', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'CD', u'NN', u',', u'DT', u'NNPS', u'VBD', u'IN', u'PRP', u'DT', u'JJ', u'NN', u',', u'IN', u'WDT', u'DT', u'NN', u'NNS', u'VBP', u'.'], u'char_offsets': [[12404, 12412], [12413, 12415], [12416, 12419], [12420, 12427], [12428, 12437], [12438, 12440], [12441, 12444], [12445, 12447], [12447, 12448], [12449, 12452], [12453, 12459], [12460, 12467], [12468, 12472], [12473, 12477], [12478, 12481], [12482, 12487], [12488, 12496], [12496, 12497], [12498, 12502], [12503, 12508], [12509, 12512], [12513, 12520], [12521, 12530], [12531, 12538], [12538, 12539]]}) 
answer: set([u'root'])
candidate Sentence: (0.20443069934844971, {u'tokens': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u',', u'CC', u'NNP', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32421, 32422], [32423, 32426], [32427, 32432], [32433, 32434], [32435, 32441], [32442, 32449], [32449, 32450]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.17612333595752716, {u'tokens': [u'The', u'earliest', u'surviving', u'records', u'of', u'a', u'distinctively', u'Portuguese', u'language', u'are', u'administrative', u'documents', u'of', u'the', u'9th', u'century', u',', u'still', u'interspersed', u'with', u'many', u'Latin', u'phrases', u'.'], u'lemmas': [u'the', u'earliest', u'survive', u'record', u'of', u'a', u'distinctively', u'portuguese', u'language', u'be', u'administrative', u'document', u'of', u'the', u'9th', u'century', u',', u'still', u'intersperse', u'with', u'many', u'latin', u'phrase', u'.'], u'pos': [u'DT', u'JJS', u'VBG', u'NNS', u'IN', u'DT', u'RB', u'JJ', u'NN', u'VBP', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'RB', u'VBN', u'IN', u'JJ', u'JJ', u'NNS', u'.'], u'char_offsets': [[13311, 13314], [13315, 13323], [13324, 13333], [13334, 13341], [13342, 13344], [13345, 13346], [13347, 13360], [13361, 13371], [13372, 13380], [13381, 13384], [13385, 13399], [13400, 13409], [13410, 13412], [13413, 13416], [13417, 13420], [13421, 13428], [13428, 13429], [13430, 13435], [13436, 13448], [13449, 13453], [13454, 13458], [13459, 13464], [13465, 13472], [13472, 13473]]}) 
answer: set([u'root'])
candidate Sentence: (0.17510885000228882, {u'tokens': [u'is', u'not', u'*', u'Tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u'be', u'not', u'*', u'tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u'VBZ', u'RB', u'SYM', u'FW', u'FW', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32385, 32387], [32388, 32391], [32392, 32393], [32393, 32396], [32397, 32403], [32404, 32405], [32406, 32412], [32413, 32420], [32420, 32421]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.16205896437168121, {u'tokens': [u'On', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'Have', u'you', u'heard', u'the', u'latest', u'news', u'?', u"''"], u'lemmas': [u'on', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'have', u'you', u'hear', u'the', u'latest', u'news', u'?', u"''"], u'pos': [u'IN', u'DT', u'JJ', u'NN', u',', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'``', u'VBP', u'PRP', u'VBD', u'DT', u'JJS', u'NN', u'.', u"''"], u'char_offsets': [[32292, 32294], [32295, 32298], [32299, 32304], [32305, 32309], [32309, 32310], [32311, 32314], [32315, 32322], [32323, 32334], [32335, 32337], [32338, 32341], [32342, 32350], [32351, 32352], [32352, 32356], [32357, 32360], [32361, 32366], [32367, 32370], [32371, 32377], [32378, 32382], [32382, 32383], [32383, 32384]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.1295616626739502, {u'tokens': [u'Portuguese', u'belongs', u'to', u'the', u'West', u'Iberian', u'branch', u'of', u'the', u'Romance', u'languages', u',', u'and', u'it', u'has', u'special', u'ties', u'with', u'the', u'following', u'members', u'of', u'this', u'group', u':', u'*', u'Galician', u'and', u'Fala', u',', u'its', u'closest', u'relatives', u'.'], u'lemmas': [u'portuguese', u'belong', u'to', u'the', u'West', u'Iberian', u'branch', u'of', u'the', u'romance', u'language', u',', u'and', u'it', u'have', u'special', u'tie', u'with', u'the', u'follow', u'member', u'of', u'this', u'group', u':', u'*', u'galician', u'and', u'Fala', u',', u'its', u'closest', u'relative', u'.'], u'pos': [u'NN', u'VBZ', u'TO', u'DT', u'NNP', u'NNP', u'NN', u'IN', u'DT', u'NN', u'NNS', u',', u'CC', u'PRP', u'VBZ', u'JJ', u'NNS', u'IN', u'DT', u'VBG', u'NNS', u'IN', u'DT', u'NN', u':', u'SYM', u'JJ', u'CC', u'NNP', u',', u'PRP$', u'JJS', u'NNS', u'.'], u'char_offsets': [[20720, 20730], [20731, 20738], [20739, 20741], [20742, 20745], [20746, 20750], [20751, 20758], [20759, 20765], [20766, 20768], [20769, 20772], [20773, 20780], [20781, 20790], [20790, 20791], [20792, 20795], [20796, 20798], [20799, 20802], [20803, 20810], [20811, 20815], [20816, 20820], [20821, 20824], [20825, 20834], [20835, 20842], [20843, 20845], [20846, 20850], [20851, 20856], [20856, 20857], [20858, 20859], [20860, 20868], [20869, 20872], [20873, 20877], [20877, 20878], [20879, 20882], [20883, 20890], [20891, 20900], [20900, 20901]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.12114281952381134, {u'tokens': [u'Its', u'spread', u'was', u'helped', u'by', u'mixed', u'marriages', u'between', u'Portuguese', u'and', u'local', u'people', u',', u'and', u'by', u'its', u'association', u'with', u'Roman', u'Catholic', u'missionary', u'efforts', u',', u'which', u'led', u'to', u'the', u'formation', u'of', u'a', u'creole', u'language', u'called', u'Kristang', u'in', u'many', u'parts', u'of', u'Asia', u'-LRB-', u'from', u'the', u'word', u'crist\xe3o', u',', u'``', u'Christian', u"''", u'-RRB-', u'.'], u'lemmas': [u'its', u'spread', u'be', u'help', u'by', u'mixed', u'marriage', u'between', u'Portuguese', u'and', u'local', u'people', u',', u'and', u'by', u'its', u'association', u'with', u'Roman', u'Catholic', u'missionary', u'effort', u',', u'which', u'lead', u'to', u'the', u'formation', u'of', u'a', u'creole', u'language', u'call', u'Kristang', u'in', u'many', u'part', u'of', u'Asia', u'-lrb-', u'from', u'the', u'word', u'crist\xe3o', u',', u'``', u'Christian', u"''", u'-rrb-', u'.'], u'pos': [u'PRP$', u'NN', u'VBD', u'VBN', u'IN', u'JJ', u'NNS', u'IN', u'NNP', u'CC', u'JJ', u'NNS', u',', u'CC', u'IN', u'PRP$', u'NN', u'IN', u'NNP', u'NNP', u'JJ', u'NNS', u',', u'WDT', u'VBD', u'TO', u'DT', u'NN', u'IN', u'DT', u'NN', u'NN', u'VBN', u'NNP', u'IN', u'JJ', u'NNS', u'IN', u'NNP', u'-LRB-', u'IN', u'DT', u'NN', u'NN', u',', u'``', u'NNP', u"''", u'-RRB-', u'.'], u'char_offsets': [[14718, 14721], [14722, 14728], [14729, 14732], [14733, 14739], [14740, 14742], [14743, 14748], [14749, 14758], [14759, 14766], [14767, 14777], [14778, 14781], [14782, 14787], [14788, 14794], [14794, 14795], [14796, 14799], [14800, 14802], [14803, 14806], [14807, 14818], [14819, 14823], [14824, 14829], [14830, 14838], [14839, 14849], [14850, 14857], [14857, 14858], [14859, 14864], [14865, 14868], [14869, 14871], [14872, 14875], [14876, 14885], [14886, 14888], [14889, 14890], [14891, 14897], [14898, 14906], [14907, 14913], [14914, 14922], [14923, 14925], [14926, 14930], [14931, 14936], [14937, 14939], [14940, 14944], [14945, 14946], [14946, 14950], [14951, 14954], [14955, 14959], [14960, 14967], [14967, 14968], [14969, 14970], [14970, 14979], [14979, 14980], [14980, 14981], [14981, 14982]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.11956603080034256, {u'tokens': [u'#', u'Ga\xfacho', u'--', u'Rio', u'Grande', u'do', u'Sul', u'.'], u'lemmas': [u'#', u'Ga\xfacho', u'--', u'Rio', u'Grande', u'do', u'Sul', u'.'], u'pos': [u'#', u'NNP', u':', u'NNP', u'NNP', u'VBP', u'NNP', u'.'], u'char_offsets': [[9716, 9717], [9718, 9724], [9726, 9727], [9728, 9731], [9732, 9738], [9739, 9741], [9742, 9745], [9745, 9746]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.11939571052789688, {u'tokens': [u'Romulo', u'Alexandre', u'Soares', u',', u'president', u'of', u'the', u'Brazil-Portugal', u'Chamber', u'highlights', u'that', u'the', u'positioning', u'of', u'Brazil', u'in', u'the', u'international', u'arena', u'as', u'one', u'of', u'the', u'emergent', u'powers', u'of', u'the', u'21st', u'century', u',', u'the', u'size', u'of', u'its', u'population', u',', u'and', u'the', u'presence', u'of', u'the', u'language', u'around', u'the', u'world', u'provides', u'legitimacy', u'and', u'justifies', u'a', u'petition', u'to', u'the', u'UN', u'to', u'make', u'the', u'Portuguese', u'language', u'an', u'official', u'language', u'of', u'the', u'UN', u'.'], u'lemmas': [u'Romulo', u'Alexandre', u'Soares', u',', u'president', u'of', u'the', u'Brazil-Portugal', u'Chamber', u'highlight', u'that', u'the', u'positioning', u'of', u'Brazil', u'in', u'the', u'international', u'arena', u'as', u'one', u'of', u'the', u'emergent', u'power', u'of', u'the', u'21st', u'century', u',', u'the', u'size', u'of', u'its', u'population', u',', u'and', u'the', u'presence', u'of', u'the', u'language', u'around', u'the', u'world', u'provide', u'legitimacy', u'and', u'justify', u'a', u'petition', u'to', u'the', u'UN', u'to', u'make', u'the', u'portuguese', u'language', u'a', u'official', u'language', u'of', u'the', u'UN', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u',', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'VBZ', u'IN', u'DT', u'NN', u'IN', u'NNP', u'IN', u'DT', u'JJ', u'NN', u'IN', u'CD', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'DT', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'NN', u'CC', u'VBZ', u'DT', u'NN', u'TO', u'DT', u'NNP', u'TO', u'VB', u'DT', u'JJ', u'NN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NNP', u'.'], u'char_offsets': [[25913, 25919], [25920, 25929], [25930, 25936], [25936, 25937], [25938, 25947], [25948, 25950], [25951, 25954], [25955, 25970], [25971, 25978], [25979, 25989], [25990, 25994], [25995, 25998], [25999, 26010], [26011, 26013], [26014, 26020], [26021, 26023], [26024, 26027], [26028, 26041], [26042, 26047], [26048, 26050], [26051, 26054], [26055, 26057], [26058, 26061], [26062, 26070], [26071, 26077], [26078, 26080], [26081, 26084], [26085, 26089], [26090, 26097], [26097, 26098], [26099, 26102], [26103, 26107], [26108, 26110], [26111, 26114], [26115, 26125], [26125, 26126], [26127, 26130], [26131, 26134], [26135, 26143], [26144, 26146], [26147, 26150], [26151, 26159], [26160, 26166], [26167, 26170], [26171, 26176], [26177, 26185], [26186, 26196], [26197, 26200], [26201, 26210], [26211, 26212], [26213, 26221], [26222, 26224], [26225, 26228], [26229, 26231], [26232, 26234], [26235, 26239], [26240, 26243], [26244, 26254], [26255, 26263], [26264, 26266], [26267, 26275], [26276, 26284], [26285, 26287], [26288, 26291], [26292, 26294], [26294, 26295]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.11222980916500092, {u'tokens': [u'Finally', u'in', u'Asia', u',', u'a', u'continent', u'with', u'several', u'languages', u'that', u'have', u'hundreds', u'of', u'millions', u'of', u'speakers', u',', u'the', u'only', u'sovereign', u'state', u'with', u'Portuguese', u'as', u'an', u'official', u'language', u'is', u'East', u'Timor', u',', u'which', u'has', u'only', u'a', u'million', u'people', u'.'], u'lemmas': [u'finally', u'in', u'Asia', u',', u'a', u'continent', u'with', u'several', u'language', u'that', u'have', u'hundred', u'of', u'million', u'of', u'speaker', u',', u'the', u'only', u'sovereign', u'state', u'with', u'portuguese', u'as', u'a', u'official', u'language', u'be', u'East', u'Timor', u',', u'which', u'have', u'only', u'a', u'million', u'people', u'.'], u'pos': [u'RB', u'IN', u'NNP', u',', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'WDT', u'VBP', u'NNS', u'IN', u'NNS', u'IN', u'NNS', u',', u'DT', u'JJ', u'JJ', u'NN', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'NNP', u'NNP', u',', u'WDT', u'VBZ', u'RB', u'DT', u'CD', u'NNS', u'.'], u'char_offsets': [[28299, 28306], [28307, 28309], [28310, 28314], [28314, 28315], [28316, 28317], [28318, 28327], [28328, 28332], [28333, 28340], [28341, 28350], [28351, 28355], [28356, 28360], [28361, 28369], [28370, 28372], [28373, 28381], [28382, 28384], [28385, 28393], [28393, 28394], [28395, 28398], [28399, 28403], [28404, 28413], [28414, 28419], [28420, 28424], [28425, 28435], [28436, 28438], [28439, 28441], [28442, 28450], [28451, 28459], [28460, 28462], [28463, 28467], [28468, 28473], [28473, 28474], [28475, 28480], [28481, 28484], [28485, 28489], [28490, 28491], [28492, 28499], [28500, 28506], [28506, 28507]]}) 
answer: set([u'latin', u'root'])

Does the Portuguese language have its roots in the Latin language?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8cb0>.answer
_____________________________ test_yesno[param262] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8cf8>, (<src.tfidf.TF_IDF object at 0x10a49f2d0>, set(['language', 'portuguese', 'portuguese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, Portuguese is derived from Latin.')
E                +    where 'Yes, Portuguese is derived from Latin.' = <src.question_processing.Question_parser instance at 0x1114d8cf8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.2091362476348877, {u'tokens': [u'Arriving', u'in', u'the', u'Iberian', u'Peninsula', u'in', u'216', u'BC', u',', u'the', u'Romans', u'brought', u'with', u'them', u'the', u'Latin', u'language', u',', u'from', u'which', u'all', u'Romance', u'languages', u'descend', u'.'], u'lemmas': [u'arrive', u'in', u'the', u'Iberian', u'Peninsula', u'in', u'216', u'bc', u',', u'the', u'Romans', u'bring', u'with', u'they', u'the', u'latin', u'language', u',', u'from', u'which', u'all', u'romance', u'language', u'descend', u'.'], u'pos': [u'VBG', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'CD', u'NN', u',', u'DT', u'NNPS', u'VBD', u'IN', u'PRP', u'DT', u'JJ', u'NN', u',', u'IN', u'WDT', u'DT', u'NN', u'NNS', u'VBP', u'.'], u'char_offsets': [[12404, 12412], [12413, 12415], [12416, 12419], [12420, 12427], [12428, 12437], [12438, 12440], [12441, 12444], [12445, 12447], [12447, 12448], [12449, 12452], [12453, 12459], [12460, 12467], [12468, 12472], [12473, 12477], [12478, 12481], [12482, 12487], [12488, 12496], [12496, 12497], [12498, 12502], [12503, 12508], [12509, 12512], [12513, 12520], [12521, 12530], [12531, 12538], [12538, 12539]]}) 
answer: set([u'root'])
candidate Sentence: (0.20443069934844971, {u'tokens': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u',', u'CC', u'NNP', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32421, 32422], [32423, 32426], [32427, 32432], [32433, 32434], [32435, 32441], [32442, 32449], [32449, 32450]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.17612333595752716, {u'tokens': [u'The', u'earliest', u'surviving', u'records', u'of', u'a', u'distinctively', u'Portuguese', u'language', u'are', u'administrative', u'documents', u'of', u'the', u'9th', u'century', u',', u'still', u'interspersed', u'with', u'many', u'Latin', u'phrases', u'.'], u'lemmas': [u'the', u'earliest', u'survive', u'record', u'of', u'a', u'distinctively', u'portuguese', u'language', u'be', u'administrative', u'document', u'of', u'the', u'9th', u'century', u',', u'still', u'intersperse', u'with', u'many', u'latin', u'phrase', u'.'], u'pos': [u'DT', u'JJS', u'VBG', u'NNS', u'IN', u'DT', u'RB', u'JJ', u'NN', u'VBP', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'RB', u'VBN', u'IN', u'JJ', u'JJ', u'NNS', u'.'], u'char_offsets': [[13311, 13314], [13315, 13323], [13324, 13333], [13334, 13341], [13342, 13344], [13345, 13346], [13347, 13360], [13361, 13371], [13372, 13380], [13381, 13384], [13385, 13399], [13400, 13409], [13410, 13412], [13413, 13416], [13417, 13420], [13421, 13428], [13428, 13429], [13430, 13435], [13436, 13448], [13449, 13453], [13454, 13458], [13459, 13464], [13465, 13472], [13472, 13473]]}) 
answer: set([u'root'])
candidate Sentence: (0.17510885000228882, {u'tokens': [u'is', u'not', u'*', u'Tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u'be', u'not', u'*', u'tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u'VBZ', u'RB', u'SYM', u'FW', u'FW', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32385, 32387], [32388, 32391], [32392, 32393], [32393, 32396], [32397, 32403], [32404, 32405], [32406, 32412], [32413, 32420], [32420, 32421]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.16205896437168121, {u'tokens': [u'On', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'Have', u'you', u'heard', u'the', u'latest', u'news', u'?', u"''"], u'lemmas': [u'on', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'have', u'you', u'hear', u'the', u'latest', u'news', u'?', u"''"], u'pos': [u'IN', u'DT', u'JJ', u'NN', u',', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'``', u'VBP', u'PRP', u'VBD', u'DT', u'JJS', u'NN', u'.', u"''"], u'char_offsets': [[32292, 32294], [32295, 32298], [32299, 32304], [32305, 32309], [32309, 32310], [32311, 32314], [32315, 32322], [32323, 32334], [32335, 32337], [32338, 32341], [32342, 32350], [32351, 32352], [32352, 32356], [32357, 32360], [32361, 32366], [32367, 32370], [32371, 32377], [32378, 32382], [32382, 32383], [32383, 32384]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.1295616626739502, {u'tokens': [u'Portuguese', u'belongs', u'to', u'the', u'West', u'Iberian', u'branch', u'of', u'the', u'Romance', u'languages', u',', u'and', u'it', u'has', u'special', u'ties', u'with', u'the', u'following', u'members', u'of', u'this', u'group', u':', u'*', u'Galician', u'and', u'Fala', u',', u'its', u'closest', u'relatives', u'.'], u'lemmas': [u'portuguese', u'belong', u'to', u'the', u'West', u'Iberian', u'branch', u'of', u'the', u'romance', u'language', u',', u'and', u'it', u'have', u'special', u'tie', u'with', u'the', u'follow', u'member', u'of', u'this', u'group', u':', u'*', u'galician', u'and', u'Fala', u',', u'its', u'closest', u'relative', u'.'], u'pos': [u'NN', u'VBZ', u'TO', u'DT', u'NNP', u'NNP', u'NN', u'IN', u'DT', u'NN', u'NNS', u',', u'CC', u'PRP', u'VBZ', u'JJ', u'NNS', u'IN', u'DT', u'VBG', u'NNS', u'IN', u'DT', u'NN', u':', u'SYM', u'JJ', u'CC', u'NNP', u',', u'PRP$', u'JJS', u'NNS', u'.'], u'char_offsets': [[20720, 20730], [20731, 20738], [20739, 20741], [20742, 20745], [20746, 20750], [20751, 20758], [20759, 20765], [20766, 20768], [20769, 20772], [20773, 20780], [20781, 20790], [20790, 20791], [20792, 20795], [20796, 20798], [20799, 20802], [20803, 20810], [20811, 20815], [20816, 20820], [20821, 20824], [20825, 20834], [20835, 20842], [20843, 20845], [20846, 20850], [20851, 20856], [20856, 20857], [20858, 20859], [20860, 20868], [20869, 20872], [20873, 20877], [20877, 20878], [20879, 20882], [20883, 20890], [20891, 20900], [20900, 20901]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.12114281952381134, {u'tokens': [u'Its', u'spread', u'was', u'helped', u'by', u'mixed', u'marriages', u'between', u'Portuguese', u'and', u'local', u'people', u',', u'and', u'by', u'its', u'association', u'with', u'Roman', u'Catholic', u'missionary', u'efforts', u',', u'which', u'led', u'to', u'the', u'formation', u'of', u'a', u'creole', u'language', u'called', u'Kristang', u'in', u'many', u'parts', u'of', u'Asia', u'-LRB-', u'from', u'the', u'word', u'crist\xe3o', u',', u'``', u'Christian', u"''", u'-RRB-', u'.'], u'lemmas': [u'its', u'spread', u'be', u'help', u'by', u'mixed', u'marriage', u'between', u'Portuguese', u'and', u'local', u'people', u',', u'and', u'by', u'its', u'association', u'with', u'Roman', u'Catholic', u'missionary', u'effort', u',', u'which', u'lead', u'to', u'the', u'formation', u'of', u'a', u'creole', u'language', u'call', u'Kristang', u'in', u'many', u'part', u'of', u'Asia', u'-lrb-', u'from', u'the', u'word', u'crist\xe3o', u',', u'``', u'Christian', u"''", u'-rrb-', u'.'], u'pos': [u'PRP$', u'NN', u'VBD', u'VBN', u'IN', u'JJ', u'NNS', u'IN', u'NNP', u'CC', u'JJ', u'NNS', u',', u'CC', u'IN', u'PRP$', u'NN', u'IN', u'NNP', u'NNP', u'JJ', u'NNS', u',', u'WDT', u'VBD', u'TO', u'DT', u'NN', u'IN', u'DT', u'NN', u'NN', u'VBN', u'NNP', u'IN', u'JJ', u'NNS', u'IN', u'NNP', u'-LRB-', u'IN', u'DT', u'NN', u'NN', u',', u'``', u'NNP', u"''", u'-RRB-', u'.'], u'char_offsets': [[14718, 14721], [14722, 14728], [14729, 14732], [14733, 14739], [14740, 14742], [14743, 14748], [14749, 14758], [14759, 14766], [14767, 14777], [14778, 14781], [14782, 14787], [14788, 14794], [14794, 14795], [14796, 14799], [14800, 14802], [14803, 14806], [14807, 14818], [14819, 14823], [14824, 14829], [14830, 14838], [14839, 14849], [14850, 14857], [14857, 14858], [14859, 14864], [14865, 14868], [14869, 14871], [14872, 14875], [14876, 14885], [14886, 14888], [14889, 14890], [14891, 14897], [14898, 14906], [14907, 14913], [14914, 14922], [14923, 14925], [14926, 14930], [14931, 14936], [14937, 14939], [14940, 14944], [14945, 14946], [14946, 14950], [14951, 14954], [14955, 14959], [14960, 14967], [14967, 14968], [14969, 14970], [14970, 14979], [14979, 14980], [14980, 14981], [14981, 14982]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.11956603080034256, {u'tokens': [u'#', u'Ga\xfacho', u'--', u'Rio', u'Grande', u'do', u'Sul', u'.'], u'lemmas': [u'#', u'Ga\xfacho', u'--', u'Rio', u'Grande', u'do', u'Sul', u'.'], u'pos': [u'#', u'NNP', u':', u'NNP', u'NNP', u'VBP', u'NNP', u'.'], u'char_offsets': [[9716, 9717], [9718, 9724], [9726, 9727], [9728, 9731], [9732, 9738], [9739, 9741], [9742, 9745], [9745, 9746]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.11939571052789688, {u'tokens': [u'Romulo', u'Alexandre', u'Soares', u',', u'president', u'of', u'the', u'Brazil-Portugal', u'Chamber', u'highlights', u'that', u'the', u'positioning', u'of', u'Brazil', u'in', u'the', u'international', u'arena', u'as', u'one', u'of', u'the', u'emergent', u'powers', u'of', u'the', u'21st', u'century', u',', u'the', u'size', u'of', u'its', u'population', u',', u'and', u'the', u'presence', u'of', u'the', u'language', u'around', u'the', u'world', u'provides', u'legitimacy', u'and', u'justifies', u'a', u'petition', u'to', u'the', u'UN', u'to', u'make', u'the', u'Portuguese', u'language', u'an', u'official', u'language', u'of', u'the', u'UN', u'.'], u'lemmas': [u'Romulo', u'Alexandre', u'Soares', u',', u'president', u'of', u'the', u'Brazil-Portugal', u'Chamber', u'highlight', u'that', u'the', u'positioning', u'of', u'Brazil', u'in', u'the', u'international', u'arena', u'as', u'one', u'of', u'the', u'emergent', u'power', u'of', u'the', u'21st', u'century', u',', u'the', u'size', u'of', u'its', u'population', u',', u'and', u'the', u'presence', u'of', u'the', u'language', u'around', u'the', u'world', u'provide', u'legitimacy', u'and', u'justify', u'a', u'petition', u'to', u'the', u'UN', u'to', u'make', u'the', u'portuguese', u'language', u'a', u'official', u'language', u'of', u'the', u'UN', u'.'], u'pos': [u'NNP', u'NNP', u'NNP', u',', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'VBZ', u'IN', u'DT', u'NN', u'IN', u'NNP', u'IN', u'DT', u'JJ', u'NN', u'IN', u'CD', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'DT', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'DT', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'NN', u'CC', u'VBZ', u'DT', u'NN', u'TO', u'DT', u'NNP', u'TO', u'VB', u'DT', u'JJ', u'NN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NNP', u'.'], u'char_offsets': [[25913, 25919], [25920, 25929], [25930, 25936], [25936, 25937], [25938, 25947], [25948, 25950], [25951, 25954], [25955, 25970], [25971, 25978], [25979, 25989], [25990, 25994], [25995, 25998], [25999, 26010], [26011, 26013], [26014, 26020], [26021, 26023], [26024, 26027], [26028, 26041], [26042, 26047], [26048, 26050], [26051, 26054], [26055, 26057], [26058, 26061], [26062, 26070], [26071, 26077], [26078, 26080], [26081, 26084], [26085, 26089], [26090, 26097], [26097, 26098], [26099, 26102], [26103, 26107], [26108, 26110], [26111, 26114], [26115, 26125], [26125, 26126], [26127, 26130], [26131, 26134], [26135, 26143], [26144, 26146], [26147, 26150], [26151, 26159], [26160, 26166], [26167, 26170], [26171, 26176], [26177, 26185], [26186, 26196], [26197, 26200], [26201, 26210], [26211, 26212], [26213, 26221], [26222, 26224], [26225, 26228], [26229, 26231], [26232, 26234], [26235, 26239], [26240, 26243], [26244, 26254], [26255, 26263], [26264, 26266], [26267, 26275], [26276, 26284], [26285, 26287], [26288, 26291], [26292, 26294], [26294, 26295]]}) 
answer: set([u'latin', u'root'])
candidate Sentence: (0.11222980916500092, {u'tokens': [u'Finally', u'in', u'Asia', u',', u'a', u'continent', u'with', u'several', u'languages', u'that', u'have', u'hundreds', u'of', u'millions', u'of', u'speakers', u',', u'the', u'only', u'sovereign', u'state', u'with', u'Portuguese', u'as', u'an', u'official', u'language', u'is', u'East', u'Timor', u',', u'which', u'has', u'only', u'a', u'million', u'people', u'.'], u'lemmas': [u'finally', u'in', u'Asia', u',', u'a', u'continent', u'with', u'several', u'language', u'that', u'have', u'hundred', u'of', u'million', u'of', u'speaker', u',', u'the', u'only', u'sovereign', u'state', u'with', u'portuguese', u'as', u'a', u'official', u'language', u'be', u'East', u'Timor', u',', u'which', u'have', u'only', u'a', u'million', u'people', u'.'], u'pos': [u'RB', u'IN', u'NNP', u',', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'WDT', u'VBP', u'NNS', u'IN', u'NNS', u'IN', u'NNS', u',', u'DT', u'JJ', u'JJ', u'NN', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBZ', u'NNP', u'NNP', u',', u'WDT', u'VBZ', u'RB', u'DT', u'CD', u'NNS', u'.'], u'char_offsets': [[28299, 28306], [28307, 28309], [28310, 28314], [28314, 28315], [28316, 28317], [28318, 28327], [28328, 28332], [28333, 28340], [28341, 28350], [28351, 28355], [28356, 28360], [28361, 28369], [28370, 28372], [28373, 28381], [28382, 28384], [28385, 28393], [28393, 28394], [28395, 28398], [28399, 28403], [28404, 28413], [28414, 28419], [28420, 28424], [28425, 28435], [28436, 28438], [28439, 28441], [28442, 28450], [28451, 28459], [28460, 28462], [28463, 28467], [28468, 28473], [28473, 28474], [28475, 28480], [28481, 28484], [28485, 28489], [28490, 28491], [28492, 28499], [28500, 28506], [28506, 28507]]}) 
answer: set([u'latin', u'root'])

Does the Portuguese language have its roots in the Latin language?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, Portuguese is derived from Latin.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, Portuguese is derived from Latin.')
 +    where 'Yes, Portuguese is derived from Latin.' = <src.question_processing.Question_parser instance at 0x1114d8cf8>.answer
_____________________________ test_yesno[param263] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8d40>, (<src.tfidf.TF_IDF object at 0x10a49f2d0>, set(['language', 'portuguese', 'portuguese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8d40>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.2600092887878418, {u'tokens': [u'Partial', u'preview', u'available', u'on', u'Google', u'Books', u'See', u'also', u'List', u'of', u'English', u'words', u'of', u'Portuguese', u'origin', u',', u'Loan', u'words', u'in', u'Indonesian', u',', u'Japanese', u'words', u'of', u'Portuguese', u'origin', u',', u'Borrowed', u'words', u'in', u'Malay', u',', u'Sinhala', u'words', u'of', u'Portuguese', u'origin', u',', u'Loan', u'words', u'from', u'Portuguese', u'in', u'Sri', u'Lankan', u'Tamil', u'.'], u'lemmas': [u'partial', u'preview', u'available', u'on', u'Google', u'Books', u'see', u'also', u'list', u'of', u'English', u'word', u'of', u'portuguese', u'origin', u',', u'loan', u'word', u'in', u'indonesian', u',', u'japanese', u'word', u'of', u'portuguese', u'origin', u',', u'borrow', u'word', u'in', u'Malay', u',', u'Sinhala', u'word', u'of', u'portuguese', u'origin', u',', u'loan', u'word', u'from', u'Portuguese', u'in', u'Sri', u'Lankan', u'Tamil', u'.'], u'pos': [u'JJ', u'NN', u'JJ', u'IN', u'NNP', u'NNPS', u'VB', u'RB', u'NN', u'IN', u'NNP', u'NNS', u'IN', u'JJ', u'NN', u',', u'NN', u'NNS', u'IN', u'JJ', u',', u'JJ', u'NNS', u'IN', u'JJ', u'NN', u',', u'VBN', u'NNS', u'IN', u'NNP', u',', u'NNP', u'NNS', u'IN', u'JJ', u'NN', u',', u'NN', u'NNS', u'IN', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[24419, 24426], [24427, 24434], [24435, 24444], [24445, 24447], [24448, 24454], [24455, 24460], [24461, 24464], [24465, 24469], [24470, 24474], [24475, 24477], [24478, 24485], [24486, 24491], [24492, 24494], [24495, 24505], [24506, 24512], [24512, 24513], [24514, 24518], [24519, 24524], [24525, 24527], [24528, 24538], [24538, 24539], [24540, 24548], [24549, 24554], [24555, 24557], [24558, 24568], [24569, 24575], [24575, 24576], [24577, 24585], [24586, 24591], [24592, 24594], [24595, 24600], [24600, 24601], [24602, 24609], [24610, 24615], [24616, 24618], [24619, 24629], [24630, 24636], [24636, 24637], [24638, 24642], [24643, 24648], [24649, 24653], [24654, 24664], [24665, 24667], [24668, 24671], [24672, 24678], [24679, 24684], [24684, 24685]]}) 
answer: set([u'arabic', u'does', u'contain'])
candidate Sentence: (0.25397604703903198, {u'tokens': [u'Between', u'the', u'9th', u'and', u'13th', u'centuries', u',', u'Portuguese', u'acquired', u'about', u'800', u'words', u'from', u'Arabic', u'by', u'influence', u'of', u'Moorish', u'Iberia', u'.'], u'lemmas': [u'between', u'the', u'9th', u'and', u'13th', u'century', u',', u'Portuguese', u'acquire', u'about', u'800', u'word', u'from', u'arabic', u'by', u'influence', u'of', u'Moorish', u'Iberia', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'CC', u'JJ', u'NNS', u',', u'NNP', u'VBD', u'IN', u'CD', u'NNS', u'IN', u'JJ', u'IN', u'NN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[18276, 18283], [18284, 18287], [18288, 18291], [18292, 18295], [18296, 18300], [18301, 18310], [18310, 18311], [18312, 18322], [18323, 18331], [18332, 18337], [18338, 18341], [18342, 18347], [18348, 18352], [18353, 18359], [18360, 18362], [18363, 18372], [18373, 18375], [18376, 18383], [18384, 18390], [18390, 18391]]}) 
answer: set([u'does', u'contain'])
candidate Sentence: (0.25238749384880066, {u'tokens': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u',', u'CC', u'NNP', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32421, 32422], [32423, 32426], [32427, 32432], [32433, 32434], [32435, 32441], [32442, 32449], [32449, 32450]]}) 
answer: set([u'arabic', u'does', u'word', u'contain'])
candidate Sentence: (0.24704590439796448, {u'tokens': [u'The', u'word', u'Mozambique', u'itself', u'is', u'from', u'the', u'Arabic', u'name', u'of', u'sultan', u'Mu\xe7a', u'Alebique', u'-LRB-', u'Musa', u'Alibiki', u'-RRB-', u'.'], u'lemmas': [u'the', u'word', u'Mozambique', u'itself', u'be', u'from', u'the', u'arabic', u'name', u'of', u'sultan', u'mu\xe7a', u'alebique', u'-lrb-', u'Musa', u'Alibiki', u'-rrb-', u'.'], u'pos': [u'DT', u'NN', u'NNP', u'PRP', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'NN', u'NN', u'-LRB-', u'NNP', u'NNP', u'-RRB-', u'.'], u'char_offsets': [[18833, 18836], [18837, 18841], [18842, 18852], [18853, 18859], [18860, 18862], [18863, 18867], [18868, 18871], [18872, 18878], [18879, 18883], [18884, 18886], [18887, 18893], [18894, 18898], [18899, 18907], [18908, 18909], [18909, 18913], [18914, 18921], [18921, 18922], [18922, 18923]]}) 
answer: set([u'does', u'contain'])
candidate Sentence: (0.21618713438510895, {u'tokens': [u'is', u'not', u'*', u'Tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u'be', u'not', u'*', u'tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u'VBZ', u'RB', u'SYM', u'FW', u'FW', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32385, 32387], [32388, 32391], [32392, 32393], [32393, 32396], [32397, 32403], [32404, 32405], [32406, 32412], [32413, 32420], [32420, 32421]]}) 
answer: set([u'arabic', u'does', u'word', u'contain'])
candidate Sentence: (0.16338968276977539, {u'tokens': [u'They', u'are', u'often', u'recognizable', u'by', u'the', u'initial', u'Arabic', u'article', u'a', u'-LRB-', u'l', u'-RRB-', u'-', u',', u'and', u'include', u'many', u'common', u'words', u'such', u'as', u'aldeia', u'``', u'village', u"''", u'from', u'\u0627\u0644\u0636\u064a\u0639\u0629', u'aldaya', u',', u'alface', u'``', u'lettuce', u"''", u'from', u'\u0627\u0644\u062e\u0633', u'alkhass', u',', u'armaz\xe9m', u'``', u'warehouse', u"''", u'from', u'\u0627\u0644\u0645\u062e\u0632\u0646', u'almahazan', u',', u'and', u'azeite', u'``', u'olive', u'oil', u"''", u'from', u'\u0627\u0644\u0632\u064a\u062a', u'azzait', u'.'], u'lemmas': [u'they', u'be', u'often', u'recognizable', u'by', u'the', u'initial', u'arabic', u'article', u'a', u'-lrb-', u'l', u'-rrb-', u'-', u',', u'and', u'include', u'many', u'common', u'word', u'such', u'as', u'aldeium', u'``', u'village', u"''", u'from', u'\u0627\u0644\u0636\u064a\u0639\u0629', u'aldaya', u',', u'alface', u'``', u'lettuce', u"''", u'from', u'\u0627\u0644\u062e\u0633', u'alkhass', u',', u'armaz\xe9m', u'``', u'warehouse', u"''", u'from', u'\u0627\u0644\u0645\u062e\u0632\u0646', u'almahazan', u',', u'and', u'azeite', u'``', u'olive', u'oil', u"''", u'from', u'\u0627\u0644\u0632\u064a\u062a', u'azzait', u'.'], u'pos': [u'PRP', u'VBP', u'RB', u'JJ', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'DT', u'-LRB-', u'NN', u'-RRB-', u':', u',', u'CC', u'VBP', u'JJ', u'JJ', u'NNS', u'JJ', u'IN', u'NN', u'``', u'NN', u"''", u'IN', u'CD', u'NN', u',', u'IN', u'``', u'NN', u"''", u'IN', u'CD', u'NN', u',', u'NN', u'``', u'NN', u"''", u'IN', u'CD', u'NN', u',', u'CC', u'NN', u'``', u'JJ', u'NN', u"''", u'IN', u'CD', u'NN', u'.'], u'char_offsets': [[18392, 18396], [18397, 18400], [18401, 18406], [18407, 18419], [18420, 18422], [18423, 18426], [18427, 18434], [18435, 18441], [18442, 18449], [18450, 18451], [18451, 18452], [18452, 18453], [18453, 18454], [18454, 18455], [18455, 18456], [18457, 18460], [18461, 18468], [18469, 18473], [18474, 18480], [18481, 18486], [18487, 18491], [18492, 18494], [18495, 18501], [18502, 18503], [18503, 18510], [18510, 18511], [18512, 18516], [18517, 18523], [18524, 18530], [18530, 18531], [18532, 18538], [18539, 18540], [18540, 18547], [18547, 18548], [18549, 18553], [18554, 18558], [18559, 18566], [18566, 18567], [18568, 18575], [18576, 18577], [18577, 18586], [18586, 18587], [18588, 18592], [18593, 18599], [18600, 18609], [18609, 18610], [18611, 18614], [18615, 18621], [18622, 18623], [18623, 18628], [18629, 18632], [18632, 18633], [18634, 18638], [18639, 18644], [18645, 18651], [18651, 18652]]}) 
answer: set([u'does', u'contain'])
candidate Sentence: (0.16143520176410675, {u'tokens': [u'On', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'Have', u'you', u'heard', u'the', u'latest', u'news', u'?', u"''"], u'lemmas': [u'on', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'have', u'you', u'hear', u'the', u'latest', u'news', u'?', u"''"], u'pos': [u'IN', u'DT', u'JJ', u'NN', u',', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'``', u'VBP', u'PRP', u'VBD', u'DT', u'JJS', u'NN', u'.', u"''"], u'char_offsets': [[32292, 32294], [32295, 32298], [32299, 32304], [32305, 32309], [32309, 32310], [32311, 32314], [32315, 32322], [32323, 32334], [32335, 32337], [32338, 32341], [32342, 32350], [32351, 32352], [32352, 32356], [32357, 32360], [32361, 32366], [32367, 32370], [32371, 32377], [32378, 32382], [32382, 32383], [32383, 32384]]}) 
answer: set([u'arabic', u'does', u'word', u'contain'])
candidate Sentence: (0.13723279535770416, {u'tokens': [u'The', u'influence', u'exerted', u'by', u'Arabic', u'on', u'the', u'Romance', u'dialects', u'spoken', u'in', u'the', u'Christian', u'kingdoms', u'of', u'the', u'north', u'was', u'small', u',', u'affecting', u'mainly', u'their', u'lexicon', u'.'], u'lemmas': [u'the', u'influence', u'exert', u'by', u'arabic', u'on', u'the', u'romance', u'dialect', u'speak', u'in', u'the', u'Christian', u'kingdom', u'of', u'the', u'north', u'be', u'small', u',', u'affect', u'mainly', u'they', u'lexicon', u'.'], u'pos': [u'DT', u'NN', u'VBN', u'IN', u'JJ', u'IN', u'DT', u'NN', u'NNS', u'VBN', u'IN', u'DT', u'NNP', u'NNS', u'IN', u'DT', u'NN', u'VBD', u'JJ', u',', u'VBG', u'RB', u'PRP$', u'NN', u'.'], u'char_offsets': [[13166, 13169], [13170, 13179], [13180, 13187], [13188, 13190], [13191, 13197], [13198, 13200], [13201, 13204], [13205, 13212], [13213, 13221], [13222, 13228], [13229, 13231], [13232, 13235], [13236, 13245], [13246, 13254], [13255, 13257], [13258, 13261], [13262, 13267], [13268, 13271], [13272, 13277], [13277, 13278], [13279, 13288], [13289, 13295], [13296, 13301], [13302, 13309], [13309, 13310]]}) 
answer: set([u'does', u'word', u'contain'])
candidate Sentence: (0.13067291676998138, {u'tokens': [u'After', u'the', u'Moorish', u'invasion', u'of', u'711', u',', u'Arabic', u'became', u'the', u'administrative', u'language', u'in', u'the', u'conquered', u'regions', u',', u'but', u'most', u'of', u'the', u'population', u'continued', u'to', u'speak', u'a', u'form', u'of', u'Romance', u'commonly', u'known', u'as', u'Mozarabic', u'.'], u'lemmas': [u'after', u'the', u'moorish', u'invasion', u'of', u'711', u',', u'arabic', u'become', u'the', u'administrative', u'language', u'in', u'the', u'conquer', u'region', u',', u'but', u'most', u'of', u'the', u'population', u'continue', u'to', u'speak', u'a', u'form', u'of', u'romance', u'commonly', u'know', u'as', u'Mozarabic', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NN', u'IN', u'CD', u',', u'JJ', u'VBD', u'DT', u'JJ', u'NN', u'IN', u'DT', u'VBN', u'NNS', u',', u'CC', u'JJS', u'IN', u'DT', u'NN', u'VBD', u'TO', u'VB', u'DT', u'NN', u'IN', u'NN', u'RB', u'VBN', u'IN', u'NNP', u'.'], u'char_offsets': [[12970, 12975], [12976, 12979], [12980, 12987], [12988, 12996], [12997, 12999], [13000, 13003], [13003, 13004], [13005, 13011], [13012, 13018], [13019, 13022], [13023, 13037], [13038, 13046], [13047, 13049], [13050, 13053], [13054, 13063], [13064, 13071], [13071, 13072], [13073, 13076], [13077, 13081], [13082, 13084], [13085, 13088], [13089, 13099], [13100, 13109], [13110, 13112], [13113, 13118], [13119, 13120], [13121, 13125], [13126, 13128], [13129, 13136], [13137, 13145], [13146, 13151], [13152, 13154], [13155, 13164], [13164, 13165]]}) 
answer: set([u'does', u'word', u'contain'])
candidate Sentence: (0.12287190556526184, {u'tokens': [u'Nasal', u'diphthongs', u'occur', u'mostly', u'at', u'the', u'ends', u'of', u'words', u'.'], u'lemmas': [u'nasal', u'diphthong', u'occur', u'mostly', u'at', u'the', u'end', u'of', u'word', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'RB', u'IN', u'DT', u'NNS', u'IN', u'NNS', u'.'], u'char_offsets': [[30024, 30029], [30030, 30040], [30041, 30046], [30047, 30053], [30054, 30056], [30057, 30060], [30061, 30065], [30066, 30068], [30069, 30074], [30074, 30075]]}) 
answer: set([u'arabic', u'does', u'contain'])

Does Portuguese contain words from the Arabic language?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8d40>.answer
_____________________________ test_yesno[param264] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8d88>, (<src.tfidf.TF_IDF object at 0x10a49f2d0>, set(['language', 'portuguese', 'portuguese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, Portuguese contains words from the Arabic language.')
E                +    where 'Yes, Portuguese contains words from the Arabic language.' = <src.question_processing.Question_parser instance at 0x1114d8d88>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.2600092887878418, {u'tokens': [u'Partial', u'preview', u'available', u'on', u'Google', u'Books', u'See', u'also', u'List', u'of', u'English', u'words', u'of', u'Portuguese', u'origin', u',', u'Loan', u'words', u'in', u'Indonesian', u',', u'Japanese', u'words', u'of', u'Portuguese', u'origin', u',', u'Borrowed', u'words', u'in', u'Malay', u',', u'Sinhala', u'words', u'of', u'Portuguese', u'origin', u',', u'Loan', u'words', u'from', u'Portuguese', u'in', u'Sri', u'Lankan', u'Tamil', u'.'], u'lemmas': [u'partial', u'preview', u'available', u'on', u'Google', u'Books', u'see', u'also', u'list', u'of', u'English', u'word', u'of', u'portuguese', u'origin', u',', u'loan', u'word', u'in', u'indonesian', u',', u'japanese', u'word', u'of', u'portuguese', u'origin', u',', u'borrow', u'word', u'in', u'Malay', u',', u'Sinhala', u'word', u'of', u'portuguese', u'origin', u',', u'loan', u'word', u'from', u'Portuguese', u'in', u'Sri', u'Lankan', u'Tamil', u'.'], u'pos': [u'JJ', u'NN', u'JJ', u'IN', u'NNP', u'NNPS', u'VB', u'RB', u'NN', u'IN', u'NNP', u'NNS', u'IN', u'JJ', u'NN', u',', u'NN', u'NNS', u'IN', u'JJ', u',', u'JJ', u'NNS', u'IN', u'JJ', u'NN', u',', u'VBN', u'NNS', u'IN', u'NNP', u',', u'NNP', u'NNS', u'IN', u'JJ', u'NN', u',', u'NN', u'NNS', u'IN', u'NNP', u'IN', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[24419, 24426], [24427, 24434], [24435, 24444], [24445, 24447], [24448, 24454], [24455, 24460], [24461, 24464], [24465, 24469], [24470, 24474], [24475, 24477], [24478, 24485], [24486, 24491], [24492, 24494], [24495, 24505], [24506, 24512], [24512, 24513], [24514, 24518], [24519, 24524], [24525, 24527], [24528, 24538], [24538, 24539], [24540, 24548], [24549, 24554], [24555, 24557], [24558, 24568], [24569, 24575], [24575, 24576], [24577, 24585], [24586, 24591], [24592, 24594], [24595, 24600], [24600, 24601], [24602, 24609], [24610, 24615], [24616, 24618], [24619, 24629], [24630, 24636], [24636, 24637], [24638, 24642], [24643, 24648], [24649, 24653], [24654, 24664], [24665, 24667], [24668, 24671], [24672, 24678], [24679, 24684], [24684, 24685]]}) 
answer: set([u'arabic', u'does', u'contain'])
candidate Sentence: (0.25397604703903198, {u'tokens': [u'Between', u'the', u'9th', u'and', u'13th', u'centuries', u',', u'Portuguese', u'acquired', u'about', u'800', u'words', u'from', u'Arabic', u'by', u'influence', u'of', u'Moorish', u'Iberia', u'.'], u'lemmas': [u'between', u'the', u'9th', u'and', u'13th', u'century', u',', u'Portuguese', u'acquire', u'about', u'800', u'word', u'from', u'arabic', u'by', u'influence', u'of', u'Moorish', u'Iberia', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'CC', u'JJ', u'NNS', u',', u'NNP', u'VBD', u'IN', u'CD', u'NNS', u'IN', u'JJ', u'IN', u'NN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[18276, 18283], [18284, 18287], [18288, 18291], [18292, 18295], [18296, 18300], [18301, 18310], [18310, 18311], [18312, 18322], [18323, 18331], [18332, 18337], [18338, 18341], [18342, 18347], [18348, 18352], [18353, 18359], [18360, 18362], [18363, 18372], [18373, 18375], [18376, 18383], [18384, 18390], [18390, 18391]]}) 
answer: set([u'does', u'contain'])
candidate Sentence: (0.25238749384880066, {u'tokens': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u',', u'but', u'Ouviu', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u',', u'CC', u'NNP', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32421, 32422], [32423, 32426], [32427, 32432], [32433, 32434], [32435, 32441], [32442, 32449], [32449, 32450]]}) 
answer: set([u'arabic', u'does', u'word', u'contain'])
candidate Sentence: (0.24704590439796448, {u'tokens': [u'The', u'word', u'Mozambique', u'itself', u'is', u'from', u'the', u'Arabic', u'name', u'of', u'sultan', u'Mu\xe7a', u'Alebique', u'-LRB-', u'Musa', u'Alibiki', u'-RRB-', u'.'], u'lemmas': [u'the', u'word', u'Mozambique', u'itself', u'be', u'from', u'the', u'arabic', u'name', u'of', u'sultan', u'mu\xe7a', u'alebique', u'-lrb-', u'Musa', u'Alibiki', u'-rrb-', u'.'], u'pos': [u'DT', u'NN', u'NNP', u'PRP', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'NN', u'NN', u'-LRB-', u'NNP', u'NNP', u'-RRB-', u'.'], u'char_offsets': [[18833, 18836], [18837, 18841], [18842, 18852], [18853, 18859], [18860, 18862], [18863, 18867], [18868, 18871], [18872, 18878], [18879, 18883], [18884, 18886], [18887, 18893], [18894, 18898], [18899, 18907], [18908, 18909], [18909, 18913], [18914, 18921], [18921, 18922], [18922, 18923]]}) 
answer: set([u'does', u'contain'])
candidate Sentence: (0.21618713438510895, {u'tokens': [u'is', u'not', u'*', u'Tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'lemmas': [u'be', u'not', u'*', u'tem', u'ouvido', u'a', u'\xfaltima', u'not\xedcia', u'?'], u'pos': [u'VBZ', u'RB', u'SYM', u'FW', u'FW', u'DT', u'NN', u'NN', u'.'], u'char_offsets': [[32385, 32387], [32388, 32391], [32392, 32393], [32393, 32396], [32397, 32403], [32404, 32405], [32406, 32412], [32413, 32420], [32420, 32421]]}) 
answer: set([u'arabic', u'does', u'word', u'contain'])
candidate Sentence: (0.16338968276977539, {u'tokens': [u'They', u'are', u'often', u'recognizable', u'by', u'the', u'initial', u'Arabic', u'article', u'a', u'-LRB-', u'l', u'-RRB-', u'-', u',', u'and', u'include', u'many', u'common', u'words', u'such', u'as', u'aldeia', u'``', u'village', u"''", u'from', u'\u0627\u0644\u0636\u064a\u0639\u0629', u'aldaya', u',', u'alface', u'``', u'lettuce', u"''", u'from', u'\u0627\u0644\u062e\u0633', u'alkhass', u',', u'armaz\xe9m', u'``', u'warehouse', u"''", u'from', u'\u0627\u0644\u0645\u062e\u0632\u0646', u'almahazan', u',', u'and', u'azeite', u'``', u'olive', u'oil', u"''", u'from', u'\u0627\u0644\u0632\u064a\u062a', u'azzait', u'.'], u'lemmas': [u'they', u'be', u'often', u'recognizable', u'by', u'the', u'initial', u'arabic', u'article', u'a', u'-lrb-', u'l', u'-rrb-', u'-', u',', u'and', u'include', u'many', u'common', u'word', u'such', u'as', u'aldeium', u'``', u'village', u"''", u'from', u'\u0627\u0644\u0636\u064a\u0639\u0629', u'aldaya', u',', u'alface', u'``', u'lettuce', u"''", u'from', u'\u0627\u0644\u062e\u0633', u'alkhass', u',', u'armaz\xe9m', u'``', u'warehouse', u"''", u'from', u'\u0627\u0644\u0645\u062e\u0632\u0646', u'almahazan', u',', u'and', u'azeite', u'``', u'olive', u'oil', u"''", u'from', u'\u0627\u0644\u0632\u064a\u062a', u'azzait', u'.'], u'pos': [u'PRP', u'VBP', u'RB', u'JJ', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'DT', u'-LRB-', u'NN', u'-RRB-', u':', u',', u'CC', u'VBP', u'JJ', u'JJ', u'NNS', u'JJ', u'IN', u'NN', u'``', u'NN', u"''", u'IN', u'CD', u'NN', u',', u'IN', u'``', u'NN', u"''", u'IN', u'CD', u'NN', u',', u'NN', u'``', u'NN', u"''", u'IN', u'CD', u'NN', u',', u'CC', u'NN', u'``', u'JJ', u'NN', u"''", u'IN', u'CD', u'NN', u'.'], u'char_offsets': [[18392, 18396], [18397, 18400], [18401, 18406], [18407, 18419], [18420, 18422], [18423, 18426], [18427, 18434], [18435, 18441], [18442, 18449], [18450, 18451], [18451, 18452], [18452, 18453], [18453, 18454], [18454, 18455], [18455, 18456], [18457, 18460], [18461, 18468], [18469, 18473], [18474, 18480], [18481, 18486], [18487, 18491], [18492, 18494], [18495, 18501], [18502, 18503], [18503, 18510], [18510, 18511], [18512, 18516], [18517, 18523], [18524, 18530], [18530, 18531], [18532, 18538], [18539, 18540], [18540, 18547], [18547, 18548], [18549, 18553], [18554, 18558], [18559, 18566], [18566, 18567], [18568, 18575], [18576, 18577], [18577, 18586], [18586, 18587], [18588, 18592], [18593, 18599], [18600, 18609], [18609, 18610], [18611, 18614], [18615, 18621], [18622, 18623], [18623, 18628], [18629, 18632], [18632, 18633], [18634, 18638], [18639, 18644], [18645, 18651], [18651, 18652]]}) 
answer: set([u'does', u'contain'])
candidate Sentence: (0.16143520176410675, {u'tokens': [u'On', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'Have', u'you', u'heard', u'the', u'latest', u'news', u'?', u"''"], u'lemmas': [u'on', u'the', u'other', u'hand', u',', u'the', u'correct', u'translation', u'of', u'the', u'question', u'``', u'have', u'you', u'hear', u'the', u'latest', u'news', u'?', u"''"], u'pos': [u'IN', u'DT', u'JJ', u'NN', u',', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'``', u'VBP', u'PRP', u'VBD', u'DT', u'JJS', u'NN', u'.', u"''"], u'char_offsets': [[32292, 32294], [32295, 32298], [32299, 32304], [32305, 32309], [32309, 32310], [32311, 32314], [32315, 32322], [32323, 32334], [32335, 32337], [32338, 32341], [32342, 32350], [32351, 32352], [32352, 32356], [32357, 32360], [32361, 32366], [32367, 32370], [32371, 32377], [32378, 32382], [32382, 32383], [32383, 32384]]}) 
answer: set([u'arabic', u'does', u'word', u'contain'])
candidate Sentence: (0.13723279535770416, {u'tokens': [u'The', u'influence', u'exerted', u'by', u'Arabic', u'on', u'the', u'Romance', u'dialects', u'spoken', u'in', u'the', u'Christian', u'kingdoms', u'of', u'the', u'north', u'was', u'small', u',', u'affecting', u'mainly', u'their', u'lexicon', u'.'], u'lemmas': [u'the', u'influence', u'exert', u'by', u'arabic', u'on', u'the', u'romance', u'dialect', u'speak', u'in', u'the', u'Christian', u'kingdom', u'of', u'the', u'north', u'be', u'small', u',', u'affect', u'mainly', u'they', u'lexicon', u'.'], u'pos': [u'DT', u'NN', u'VBN', u'IN', u'JJ', u'IN', u'DT', u'NN', u'NNS', u'VBN', u'IN', u'DT', u'NNP', u'NNS', u'IN', u'DT', u'NN', u'VBD', u'JJ', u',', u'VBG', u'RB', u'PRP$', u'NN', u'.'], u'char_offsets': [[13166, 13169], [13170, 13179], [13180, 13187], [13188, 13190], [13191, 13197], [13198, 13200], [13201, 13204], [13205, 13212], [13213, 13221], [13222, 13228], [13229, 13231], [13232, 13235], [13236, 13245], [13246, 13254], [13255, 13257], [13258, 13261], [13262, 13267], [13268, 13271], [13272, 13277], [13277, 13278], [13279, 13288], [13289, 13295], [13296, 13301], [13302, 13309], [13309, 13310]]}) 
answer: set([u'does', u'word', u'contain'])
candidate Sentence: (0.13067291676998138, {u'tokens': [u'After', u'the', u'Moorish', u'invasion', u'of', u'711', u',', u'Arabic', u'became', u'the', u'administrative', u'language', u'in', u'the', u'conquered', u'regions', u',', u'but', u'most', u'of', u'the', u'population', u'continued', u'to', u'speak', u'a', u'form', u'of', u'Romance', u'commonly', u'known', u'as', u'Mozarabic', u'.'], u'lemmas': [u'after', u'the', u'moorish', u'invasion', u'of', u'711', u',', u'arabic', u'become', u'the', u'administrative', u'language', u'in', u'the', u'conquer', u'region', u',', u'but', u'most', u'of', u'the', u'population', u'continue', u'to', u'speak', u'a', u'form', u'of', u'romance', u'commonly', u'know', u'as', u'Mozarabic', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'NN', u'IN', u'CD', u',', u'JJ', u'VBD', u'DT', u'JJ', u'NN', u'IN', u'DT', u'VBN', u'NNS', u',', u'CC', u'JJS', u'IN', u'DT', u'NN', u'VBD', u'TO', u'VB', u'DT', u'NN', u'IN', u'NN', u'RB', u'VBN', u'IN', u'NNP', u'.'], u'char_offsets': [[12970, 12975], [12976, 12979], [12980, 12987], [12988, 12996], [12997, 12999], [13000, 13003], [13003, 13004], [13005, 13011], [13012, 13018], [13019, 13022], [13023, 13037], [13038, 13046], [13047, 13049], [13050, 13053], [13054, 13063], [13064, 13071], [13071, 13072], [13073, 13076], [13077, 13081], [13082, 13084], [13085, 13088], [13089, 13099], [13100, 13109], [13110, 13112], [13113, 13118], [13119, 13120], [13121, 13125], [13126, 13128], [13129, 13136], [13137, 13145], [13146, 13151], [13152, 13154], [13155, 13164], [13164, 13165]]}) 
answer: set([u'does', u'word', u'contain'])
candidate Sentence: (0.12287190556526184, {u'tokens': [u'Nasal', u'diphthongs', u'occur', u'mostly', u'at', u'the', u'ends', u'of', u'words', u'.'], u'lemmas': [u'nasal', u'diphthong', u'occur', u'mostly', u'at', u'the', u'end', u'of', u'word', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'RB', u'IN', u'DT', u'NNS', u'IN', u'NNS', u'.'], u'char_offsets': [[30024, 30029], [30030, 30040], [30041, 30046], [30047, 30053], [30054, 30056], [30057, 30060], [30061, 30065], [30066, 30068], [30069, 30074], [30074, 30075]]}) 
answer: set([u'arabic', u'does', u'contain'])

Does Portuguese contain words from the Arabic language?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, Portuguese contains words from the Arabic language.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, Portuguese contains words from the Arabic language.')
 +    where 'Yes, Portuguese contains words from the Arabic language.' = <src.question_processing.Question_parser instance at 0x1114d8d88>.answer
_____________________________ test_yesno[param269] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8ef0>, (<src.tfidf.TF_IDF object at 0x10fd76cd0>, set(['francisco', 'san', 'san_francisco'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, San Francisco is characterized by a high standard of living.')
E                +    where 'Yes, San Francisco is characterized by a high standard of living.' = <src.question_processing.Question_parser instance at 0x1114d8ef0>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.79884129762649536, {u'tokens': [u'San', u'Francisco', u'is', u'characterized', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'lemmas': [u'San', u'Francisco', u'be', u'characterize', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[22107, 22110], [22111, 22120], [22121, 22123], [22124, 22137], [22138, 22140], [22141, 22142], [22143, 22147], [22148, 22156], [22157, 22159], [22160, 22166], [22166, 22167]]}) 
answer: set([u'franciscio'])
candidate Sentence: (0.23346078395843506, {u'tokens': [u'Because', u'the', u'cost', u'of', u'living', u'in', u'San', u'Francisco', u'is', u'exceptionally', u'high', u',', u'many', u'middle', u'class', u'families', u'have', u'decided', u'they', u'can', u'no', u'longer', u'afford', u'to', u'live', u'within', u'the', u'city', u'and', u'have', u'left', u'.'], u'lemmas': [u'because', u'the', u'cost', u'of', u'living', u'in', u'San', u'Francisco', u'be', u'exceptionally', u'high', u',', u'many', u'middle', u'class', u'family', u'have', u'decide', u'they', u'can', u'no', u'longer', u'afford', u'to', u'live', u'within', u'the', u'city', u'and', u'have', u'leave', u'.'], u'pos': [u'IN', u'DT', u'NN', u'IN', u'NN', u'IN', u'NNP', u'NNP', u'VBZ', u'RB', u'JJ', u',', u'JJ', u'JJ', u'NN', u'NNS', u'VBP', u'VBN', u'PRP', u'MD', u'RB', u'RB', u'VB', u'TO', u'VB', u'IN', u'DT', u'NN', u'CC', u'VBP', u'VBN', u'.'], u'char_offsets': [[22808, 22815], [22816, 22819], [22820, 22824], [22825, 22827], [22828, 22834], [22835, 22837], [22838, 22841], [22842, 22851], [22852, 22854], [22855, 22868], [22869, 22873], [22873, 22874], [22875, 22879], [22880, 22886], [22887, 22892], [22893, 22901], [22902, 22906], [22907, 22914], [22915, 22919], [22920, 22923], [22924, 22926], [22927, 22933], [22934, 22940], [22941, 22943], [22944, 22948], [22949, 22955], [22956, 22959], [22960, 22964], [22965, 22968], [22969, 22973], [22974, 22978], [22978, 22979]]}) 
answer: set([u'franciscio', u'standard'])
candidate Sentence: (0.19880320131778717, {u'tokens': [u'Its', u'current', u'structure', u',', u'featuring', u'a', u'living', u'roof', u',', u'is', u'an', u'example', u'of', u'sustainable', u'architecture', u'and', u'opened', u'in', u'2008', u'.'], u'lemmas': [u'its', u'current', u'structure', u',', u'feature', u'a', u'living', u'roof', u',', u'be', u'a', u'example', u'of', u'sustainable', u'architecture', u'and', u'open', u'in', u'2008', u'.'], u'pos': [u'PRP$', u'JJ', u'NN', u',', u'VBG', u'DT', u'NN', u'NN', u',', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NN', u'CC', u'VBD', u'IN', u'CD', u'.'], u'char_offsets': [[28220, 28223], [28224, 28231], [28232, 28241], [28241, 28242], [28243, 28252], [28253, 28254], [28255, 28261], [28262, 28266], [28266, 28267], [28268, 28270], [28271, 28273], [28274, 28281], [28282, 28284], [28285, 28296], [28297, 28309], [28310, 28313], [28314, 28320], [28321, 28323], [28324, 28328], [28328, 28329]]}) 
answer: set([u'high', u'franciscio', u'standard'])
candidate Sentence: (0.15127129852771759, {u'tokens': [u'The', u'city', u'has', u'repeatedly', u'upgraded', u'its', u'building', u'codes', u',', u'requiring', u'retrofits', u'for', u'older', u'buildings', u'and', u'higher', u'engineering', u'standards', u'for', u'new', u'construction', u'.'], u'lemmas': [u'the', u'city', u'have', u'repeatedly', u'upgrade', u'its', u'building', u'code', u',', u'require', u'retrofit', u'for', u'older', u'building', u'and', u'higher', u'engineering', u'standard', u'for', u'new', u'construction', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'PRP$', u'NN', u'NNS', u',', u'VBG', u'NNS', u'IN', u'JJR', u'NNS', u'CC', u'JJR', u'NN', u'NNS', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[13347, 13350], [13351, 13355], [13356, 13359], [13360, 13370], [13371, 13379], [13380, 13383], [13384, 13392], [13393, 13398], [13398, 13399], [13400, 13409], [13410, 13419], [13420, 13423], [13424, 13429], [13430, 13439], [13440, 13443], [13444, 13450], [13451, 13462], [13463, 13472], [13473, 13476], [13477, 13480], [13481, 13493], [13493, 13494]]}) 
answer: set([u'high', u'living', u'franciscio'])
candidate Sentence: (0.12330088019371033, {u'tokens': [u'The', u'rainy', u'period', u'of', u'November', u'to', u'April', u'is', u'cool', u'with', u'high', u'temperatures', u'of', u'and', u'lows', u'of', u'.'], u'lemmas': [u'the', u'rainy', u'period', u'of', u'November', u'to', u'April', u'be', u'cool', u'with', u'high', u'temperature', u'of', u'and', u'low', u'of', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNP', u'TO', u'NNP', u'VBZ', u'JJ', u'IN', u'JJ', u'NNS', u'IN', u'CC', u'NNS', u'IN', u'.'], u'char_offsets': [[15123, 15126], [15127, 15132], [15133, 15139], [15140, 15142], [15143, 15151], [15152, 15154], [15155, 15160], [15161, 15163], [15164, 15168], [15169, 15173], [15174, 15178], [15179, 15191], [15192, 15194], [15197, 15200], [15201, 15205], [15206, 15208], [15210, 15211]]}) 
answer: set([u'living', u'standard', u'franciscio'])
candidate Sentence: (0.1124764159321785, {u'tokens': [u'The', u'city-owned', u'system', u'operates', u'both', u'a', u'combined', u'light', u'rail', u'and', u'subway', u'system', u'-LRB-', u'the', u'Muni', u'Metro', u'-RRB-', u'and', u'a', u'bus', u'network', u'that', u'includes', u'trolleybuses', u',', u'standard', u'diesel', u'motorcoaches', u'and', u'diesel', u'hybrid', u'buses', u'.'], u'lemmas': [u'the', u'city-owned', u'system', u'operate', u'both', u'a', u'combined', u'light', u'rail', u'and', u'subway', u'system', u'-lrb-', u'the', u'muni', u'Metro', u'-rrb-', u'and', u'a', u'bus', u'network', u'that', u'include', u'trolleybus', u',', u'standard', u'diesel', u'motorcoach', u'and', u'diesel', u'hybrid', u'bus', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'CC', u'DT', u'JJ', u'JJ', u'NN', u'CC', u'NN', u'NN', u'-LRB-', u'DT', u'JJ', u'NNP', u'-RRB-', u'CC', u'DT', u'NN', u'NN', u'WDT', u'VBZ', u'NNS', u',', u'JJ', u'NN', u'NNS', u'CC', u'NN', u'NN', u'NNS', u'.'], u'char_offsets': [[47991, 47994], [47995, 48005], [48006, 48012], [48013, 48021], [48022, 48026], [48027, 48028], [48029, 48037], [48038, 48043], [48044, 48048], [48049, 48052], [48053, 48059], [48060, 48066], [48067, 48068], [48068, 48071], [48072, 48076], [48077, 48082], [48082, 48083], [48084, 48087], [48088, 48089], [48090, 48093], [48094, 48101], [48102, 48106], [48107, 48115], [48116, 48128], [48128, 48129], [48130, 48138], [48139, 48145], [48146, 48158], [48159, 48162], [48163, 48169], [48170, 48176], [48177, 48182], [48182, 48183]]}) 
answer: set([u'high', u'living', u'franciscio'])
candidate Sentence: (0.10965146124362946, {u'tokens': [u'The', u'dry', u'period', u'of', u'May', u'to', u'October', u'is', u'mild', u'to', u'warm', u',', u'with', u'average', u'high', u'temperatures', u'of', u'and', u'lows', u'of', u'.'], u'lemmas': [u'the', u'dry', u'period', u'of', u'May', u'to', u'October', u'be', u'mild', u'to', u'warm', u',', u'with', u'average', u'high', u'temperature', u'of', u'and', u'low', u'of', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNP', u'TO', u'NNP', u'VBZ', u'JJ', u'TO', u'JJ', u',', u'IN', u'JJ', u'JJ', u'NNS', u'IN', u'CC', u'NNS', u'IN', u'.'], u'char_offsets': [[15022, 15025], [15026, 15029], [15030, 15036], [15037, 15039], [15040, 15043], [15044, 15046], [15047, 15054], [15055, 15057], [15058, 15062], [15063, 15065], [15066, 15070], [15070, 15071], [15072, 15076], [15077, 15084], [15085, 15089], [15090, 15102], [15103, 15105], [15108, 15111], [15112, 15116], [15117, 15119], [15121, 15122]]}) 
answer: set([u'living', u'standard', u'franciscio'])
candidate Sentence: (0.10876637697219849, {u'tokens': [u'The', u'high', u'hills', u'in', u'the', u'geographic', u'center', u'of', u'the', u'city', u'are', u'responsible', u'for', u'a', u'20', u'%', u'variance', u'in', u'annual', u'rainfall', u'between', u'different', u'parts', u'of', u'the', u'city', u'.'], u'lemmas': [u'the', u'high', u'hill', u'in', u'the', u'geographic', u'center', u'of', u'the', u'city', u'be', u'responsible', u'for', u'a', u'20', u'%', u'variance', u'in', u'annual', u'rainfall', u'between', u'different', u'part', u'of', u'the', u'city', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'VBP', u'JJ', u'IN', u'DT', u'CD', u'NN', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[15914, 15917], [15918, 15922], [15923, 15928], [15929, 15931], [15932, 15935], [15936, 15946], [15947, 15953], [15954, 15956], [15957, 15960], [15961, 15965], [15966, 15969], [15970, 15981], [15982, 15985], [15986, 15987], [15988, 15990], [15990, 15991], [15992, 16000], [16001, 16003], [16004, 16010], [16011, 16019], [16020, 16027], [16028, 16037], [16038, 16043], [16044, 16046], [16047, 16050], [16051, 16055], [16055, 16056]]}) 
answer: set([u'living', u'franciscio', u'standard'])
candidate Sentence: (0.10837648808956146, {u'tokens': [u'San', u'Francisco', u"'s", u'tallest', u'hill', u',', u'Mount', u'Davidson', u',', u'is', u'high', u'and', u'is', u'capped', u'with', u'a', u'tall', u'cross', u'built', u'in', u'1934', u'.'], u'lemmas': [u'San', u'Francisco', u"'s", u'tallest', u'hill', u',', u'Mount', u'Davidson', u',', u'be', u'high', u'and', u'be', u'cap', u'with', u'a', u'tall', u'cross', u'build', u'in', u'1934', u'.'], u'pos': [u'NNP', u'NNP', u'POS', u'JJS', u'NN', u',', u'NNP', u'NNP', u',', u'VBZ', u'JJ', u'CC', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'CD', u'.'], u'char_offsets': [[12765, 12768], [12769, 12778], [12778, 12780], [12781, 12788], [12789, 12793], [12793, 12794], [12795, 12800], [12801, 12809], [12809, 12810], [12811, 12813], [12816, 12820], [12821, 12824], [12825, 12827], [12828, 12834], [12835, 12839], [12840, 12841], [12844, 12848], [12849, 12854], [12855, 12860], [12861, 12863], [12864, 12868], [12868, 12869]]}) 
answer: set([u'living', u'franciscio', u'standard'])
candidate Sentence: (0.094395376741886139, {u'tokens': [u'Bayview-Hunters', u'Point', u'in', u'the', u'southeast', u'section', u'of', u'the', u'city', u'is', u'one', u'of', u'the', u'poorest', u'neighborhoods', u'and', u'suffers', u'from', u'a', u'high', u'rate', u'of', u'crime', u',', u'though', u'the', u'area', u'has', u'been', u'the', u'focus', u'of', u'controversial', u'plans', u'for', u'urban', u'renewal', u'.'], u'lemmas': [u'Bayview-Hunters', u'Point', u'in', u'the', u'southeast', u'section', u'of', u'the', u'city', u'be', u'one', u'of', u'the', u'poorest', u'neighborhood', u'and', u'suffer', u'from', u'a', u'high', u'rate', u'of', u'crime', u',', u'though', u'the', u'area', u'have', u'be', u'the', u'focus', u'of', u'controversial', u'plan', u'for', u'urban', u'renewal', u'.'], u'pos': [u'NNP', u'NNP', u'IN', u'DT', u'NN', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'CD', u'IN', u'DT', u'JJS', u'NNS', u'CC', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u',', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[19332, 19347], [19348, 19353], [19354, 19356], [19357, 19360], [19361, 19370], [19371, 19378], [19379, 19381], [19382, 19385], [19386, 19390], [19391, 19393], [19394, 19397], [19398, 19400], [19401, 19404], [19405, 19412], [19413, 19426], [19427, 19430], [19431, 19438], [19439, 19443], [19444, 19445], [19446, 19450], [19451, 19455], [19456, 19458], [19459, 19464], [19464, 19465], [19466, 19472], [19473, 19476], [19477, 19481], [19482, 19485], [19486, 19490], [19491, 19494], [19495, 19500], [19501, 19503], [19504, 19517], [19518, 19523], [19524, 19527], [19528, 19533], [19534, 19541], [19541, 19542]]}) 
answer: set([u'living', u'franciscio', u'standard'])

Is the standard of living in San Franciscio high?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, San Francisco is characterized by a high standard of living.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, San Francisco is characterized by a high standard of living.')
 +    where 'Yes, San Francisco is characterized by a high standard of living.' = <src.question_processing.Question_parser instance at 0x1114d8ef0>.answer
_____________________________ test_yesno[param270] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8f38>, (<src.tfidf.TF_IDF object at 0x10fd76cd0>, set(['francisco', 'san', 'san_francisco'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8f38>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.79884129762649536, {u'tokens': [u'San', u'Francisco', u'is', u'characterized', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'lemmas': [u'San', u'Francisco', u'be', u'characterize', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[22107, 22110], [22111, 22120], [22121, 22123], [22124, 22137], [22138, 22140], [22141, 22142], [22143, 22147], [22148, 22156], [22157, 22159], [22160, 22166], [22166, 22167]]}) 
answer: set([u'franciscio'])
candidate Sentence: (0.23346078395843506, {u'tokens': [u'Because', u'the', u'cost', u'of', u'living', u'in', u'San', u'Francisco', u'is', u'exceptionally', u'high', u',', u'many', u'middle', u'class', u'families', u'have', u'decided', u'they', u'can', u'no', u'longer', u'afford', u'to', u'live', u'within', u'the', u'city', u'and', u'have', u'left', u'.'], u'lemmas': [u'because', u'the', u'cost', u'of', u'living', u'in', u'San', u'Francisco', u'be', u'exceptionally', u'high', u',', u'many', u'middle', u'class', u'family', u'have', u'decide', u'they', u'can', u'no', u'longer', u'afford', u'to', u'live', u'within', u'the', u'city', u'and', u'have', u'leave', u'.'], u'pos': [u'IN', u'DT', u'NN', u'IN', u'NN', u'IN', u'NNP', u'NNP', u'VBZ', u'RB', u'JJ', u',', u'JJ', u'JJ', u'NN', u'NNS', u'VBP', u'VBN', u'PRP', u'MD', u'RB', u'RB', u'VB', u'TO', u'VB', u'IN', u'DT', u'NN', u'CC', u'VBP', u'VBN', u'.'], u'char_offsets': [[22808, 22815], [22816, 22819], [22820, 22824], [22825, 22827], [22828, 22834], [22835, 22837], [22838, 22841], [22842, 22851], [22852, 22854], [22855, 22868], [22869, 22873], [22873, 22874], [22875, 22879], [22880, 22886], [22887, 22892], [22893, 22901], [22902, 22906], [22907, 22914], [22915, 22919], [22920, 22923], [22924, 22926], [22927, 22933], [22934, 22940], [22941, 22943], [22944, 22948], [22949, 22955], [22956, 22959], [22960, 22964], [22965, 22968], [22969, 22973], [22974, 22978], [22978, 22979]]}) 
answer: set([u'franciscio', u'standard'])
candidate Sentence: (0.19880320131778717, {u'tokens': [u'Its', u'current', u'structure', u',', u'featuring', u'a', u'living', u'roof', u',', u'is', u'an', u'example', u'of', u'sustainable', u'architecture', u'and', u'opened', u'in', u'2008', u'.'], u'lemmas': [u'its', u'current', u'structure', u',', u'feature', u'a', u'living', u'roof', u',', u'be', u'a', u'example', u'of', u'sustainable', u'architecture', u'and', u'open', u'in', u'2008', u'.'], u'pos': [u'PRP$', u'JJ', u'NN', u',', u'VBG', u'DT', u'NN', u'NN', u',', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NN', u'CC', u'VBD', u'IN', u'CD', u'.'], u'char_offsets': [[28220, 28223], [28224, 28231], [28232, 28241], [28241, 28242], [28243, 28252], [28253, 28254], [28255, 28261], [28262, 28266], [28266, 28267], [28268, 28270], [28271, 28273], [28274, 28281], [28282, 28284], [28285, 28296], [28297, 28309], [28310, 28313], [28314, 28320], [28321, 28323], [28324, 28328], [28328, 28329]]}) 
answer: set([u'high', u'franciscio', u'standard'])
candidate Sentence: (0.15127129852771759, {u'tokens': [u'The', u'city', u'has', u'repeatedly', u'upgraded', u'its', u'building', u'codes', u',', u'requiring', u'retrofits', u'for', u'older', u'buildings', u'and', u'higher', u'engineering', u'standards', u'for', u'new', u'construction', u'.'], u'lemmas': [u'the', u'city', u'have', u'repeatedly', u'upgrade', u'its', u'building', u'code', u',', u'require', u'retrofit', u'for', u'older', u'building', u'and', u'higher', u'engineering', u'standard', u'for', u'new', u'construction', u'.'], u'pos': [u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'PRP$', u'NN', u'NNS', u',', u'VBG', u'NNS', u'IN', u'JJR', u'NNS', u'CC', u'JJR', u'NN', u'NNS', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[13347, 13350], [13351, 13355], [13356, 13359], [13360, 13370], [13371, 13379], [13380, 13383], [13384, 13392], [13393, 13398], [13398, 13399], [13400, 13409], [13410, 13419], [13420, 13423], [13424, 13429], [13430, 13439], [13440, 13443], [13444, 13450], [13451, 13462], [13463, 13472], [13473, 13476], [13477, 13480], [13481, 13493], [13493, 13494]]}) 
answer: set([u'high', u'living', u'franciscio'])
candidate Sentence: (0.12330088019371033, {u'tokens': [u'The', u'rainy', u'period', u'of', u'November', u'to', u'April', u'is', u'cool', u'with', u'high', u'temperatures', u'of', u'and', u'lows', u'of', u'.'], u'lemmas': [u'the', u'rainy', u'period', u'of', u'November', u'to', u'April', u'be', u'cool', u'with', u'high', u'temperature', u'of', u'and', u'low', u'of', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNP', u'TO', u'NNP', u'VBZ', u'JJ', u'IN', u'JJ', u'NNS', u'IN', u'CC', u'NNS', u'IN', u'.'], u'char_offsets': [[15123, 15126], [15127, 15132], [15133, 15139], [15140, 15142], [15143, 15151], [15152, 15154], [15155, 15160], [15161, 15163], [15164, 15168], [15169, 15173], [15174, 15178], [15179, 15191], [15192, 15194], [15197, 15200], [15201, 15205], [15206, 15208], [15210, 15211]]}) 
answer: set([u'living', u'standard', u'franciscio'])
candidate Sentence: (0.1124764159321785, {u'tokens': [u'The', u'city-owned', u'system', u'operates', u'both', u'a', u'combined', u'light', u'rail', u'and', u'subway', u'system', u'-LRB-', u'the', u'Muni', u'Metro', u'-RRB-', u'and', u'a', u'bus', u'network', u'that', u'includes', u'trolleybuses', u',', u'standard', u'diesel', u'motorcoaches', u'and', u'diesel', u'hybrid', u'buses', u'.'], u'lemmas': [u'the', u'city-owned', u'system', u'operate', u'both', u'a', u'combined', u'light', u'rail', u'and', u'subway', u'system', u'-lrb-', u'the', u'muni', u'Metro', u'-rrb-', u'and', u'a', u'bus', u'network', u'that', u'include', u'trolleybus', u',', u'standard', u'diesel', u'motorcoach', u'and', u'diesel', u'hybrid', u'bus', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'CC', u'DT', u'JJ', u'JJ', u'NN', u'CC', u'NN', u'NN', u'-LRB-', u'DT', u'JJ', u'NNP', u'-RRB-', u'CC', u'DT', u'NN', u'NN', u'WDT', u'VBZ', u'NNS', u',', u'JJ', u'NN', u'NNS', u'CC', u'NN', u'NN', u'NNS', u'.'], u'char_offsets': [[47991, 47994], [47995, 48005], [48006, 48012], [48013, 48021], [48022, 48026], [48027, 48028], [48029, 48037], [48038, 48043], [48044, 48048], [48049, 48052], [48053, 48059], [48060, 48066], [48067, 48068], [48068, 48071], [48072, 48076], [48077, 48082], [48082, 48083], [48084, 48087], [48088, 48089], [48090, 48093], [48094, 48101], [48102, 48106], [48107, 48115], [48116, 48128], [48128, 48129], [48130, 48138], [48139, 48145], [48146, 48158], [48159, 48162], [48163, 48169], [48170, 48176], [48177, 48182], [48182, 48183]]}) 
answer: set([u'high', u'living', u'franciscio'])
candidate Sentence: (0.10965146124362946, {u'tokens': [u'The', u'dry', u'period', u'of', u'May', u'to', u'October', u'is', u'mild', u'to', u'warm', u',', u'with', u'average', u'high', u'temperatures', u'of', u'and', u'lows', u'of', u'.'], u'lemmas': [u'the', u'dry', u'period', u'of', u'May', u'to', u'October', u'be', u'mild', u'to', u'warm', u',', u'with', u'average', u'high', u'temperature', u'of', u'and', u'low', u'of', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNP', u'TO', u'NNP', u'VBZ', u'JJ', u'TO', u'JJ', u',', u'IN', u'JJ', u'JJ', u'NNS', u'IN', u'CC', u'NNS', u'IN', u'.'], u'char_offsets': [[15022, 15025], [15026, 15029], [15030, 15036], [15037, 15039], [15040, 15043], [15044, 15046], [15047, 15054], [15055, 15057], [15058, 15062], [15063, 15065], [15066, 15070], [15070, 15071], [15072, 15076], [15077, 15084], [15085, 15089], [15090, 15102], [15103, 15105], [15108, 15111], [15112, 15116], [15117, 15119], [15121, 15122]]}) 
answer: set([u'living', u'standard', u'franciscio'])
candidate Sentence: (0.10876637697219849, {u'tokens': [u'The', u'high', u'hills', u'in', u'the', u'geographic', u'center', u'of', u'the', u'city', u'are', u'responsible', u'for', u'a', u'20', u'%', u'variance', u'in', u'annual', u'rainfall', u'between', u'different', u'parts', u'of', u'the', u'city', u'.'], u'lemmas': [u'the', u'high', u'hill', u'in', u'the', u'geographic', u'center', u'of', u'the', u'city', u'be', u'responsible', u'for', u'a', u'20', u'%', u'variance', u'in', u'annual', u'rainfall', u'between', u'different', u'part', u'of', u'the', u'city', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'VBP', u'JJ', u'IN', u'DT', u'CD', u'NN', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[15914, 15917], [15918, 15922], [15923, 15928], [15929, 15931], [15932, 15935], [15936, 15946], [15947, 15953], [15954, 15956], [15957, 15960], [15961, 15965], [15966, 15969], [15970, 15981], [15982, 15985], [15986, 15987], [15988, 15990], [15990, 15991], [15992, 16000], [16001, 16003], [16004, 16010], [16011, 16019], [16020, 16027], [16028, 16037], [16038, 16043], [16044, 16046], [16047, 16050], [16051, 16055], [16055, 16056]]}) 
answer: set([u'living', u'franciscio', u'standard'])
candidate Sentence: (0.10837648808956146, {u'tokens': [u'San', u'Francisco', u"'s", u'tallest', u'hill', u',', u'Mount', u'Davidson', u',', u'is', u'high', u'and', u'is', u'capped', u'with', u'a', u'tall', u'cross', u'built', u'in', u'1934', u'.'], u'lemmas': [u'San', u'Francisco', u"'s", u'tallest', u'hill', u',', u'Mount', u'Davidson', u',', u'be', u'high', u'and', u'be', u'cap', u'with', u'a', u'tall', u'cross', u'build', u'in', u'1934', u'.'], u'pos': [u'NNP', u'NNP', u'POS', u'JJS', u'NN', u',', u'NNP', u'NNP', u',', u'VBZ', u'JJ', u'CC', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'CD', u'.'], u'char_offsets': [[12765, 12768], [12769, 12778], [12778, 12780], [12781, 12788], [12789, 12793], [12793, 12794], [12795, 12800], [12801, 12809], [12809, 12810], [12811, 12813], [12816, 12820], [12821, 12824], [12825, 12827], [12828, 12834], [12835, 12839], [12840, 12841], [12844, 12848], [12849, 12854], [12855, 12860], [12861, 12863], [12864, 12868], [12868, 12869]]}) 
answer: set([u'living', u'franciscio', u'standard'])
candidate Sentence: (0.094395376741886139, {u'tokens': [u'Bayview-Hunters', u'Point', u'in', u'the', u'southeast', u'section', u'of', u'the', u'city', u'is', u'one', u'of', u'the', u'poorest', u'neighborhoods', u'and', u'suffers', u'from', u'a', u'high', u'rate', u'of', u'crime', u',', u'though', u'the', u'area', u'has', u'been', u'the', u'focus', u'of', u'controversial', u'plans', u'for', u'urban', u'renewal', u'.'], u'lemmas': [u'Bayview-Hunters', u'Point', u'in', u'the', u'southeast', u'section', u'of', u'the', u'city', u'be', u'one', u'of', u'the', u'poorest', u'neighborhood', u'and', u'suffer', u'from', u'a', u'high', u'rate', u'of', u'crime', u',', u'though', u'the', u'area', u'have', u'be', u'the', u'focus', u'of', u'controversial', u'plan', u'for', u'urban', u'renewal', u'.'], u'pos': [u'NNP', u'NNP', u'IN', u'DT', u'NN', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'CD', u'IN', u'DT', u'JJS', u'NNS', u'CC', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u',', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[19332, 19347], [19348, 19353], [19354, 19356], [19357, 19360], [19361, 19370], [19371, 19378], [19379, 19381], [19382, 19385], [19386, 19390], [19391, 19393], [19394, 19397], [19398, 19400], [19401, 19404], [19405, 19412], [19413, 19426], [19427, 19430], [19431, 19438], [19439, 19443], [19444, 19445], [19446, 19450], [19451, 19455], [19456, 19458], [19459, 19464], [19464, 19465], [19466, 19472], [19473, 19476], [19477, 19481], [19482, 19485], [19486, 19490], [19491, 19494], [19495, 19500], [19501, 19503], [19504, 19517], [19518, 19523], [19524, 19527], [19528, 19533], [19534, 19541], [19541, 19542]]}) 
answer: set([u'living', u'franciscio', u'standard'])

Is the standard of living in San Franciscio high?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8f38>.answer
_____________________________ test_yesno[param271] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8f80>, (<src.tfidf.TF_IDF object at 0x10fd76cd0>, set(['francisco', 'san', 'san_francisco'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.')
E                +    where 'Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.' = <src.question_processing.Question_parser instance at 0x1114d8f80>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.45207801461219788, {u'tokens': [u'According', u'to', u'the', u'2005', u'American', u'Community', u'Survey', u',', u'San', u'Francisco', u'has', u'the', u'highest', u'percentage', u'of', u'gay', u'and', u'lesbian', u'individuals', u'of', u'any', u'of', u'the', u'50', u'largest', u'U.S.', u'cities', u',', u'at', u'15.4', u'%', u'.'], u'lemmas': [u'accord', u'to', u'the', u'2005', u'American', u'Community', u'Survey', u',', u'San', u'Francisco', u'have', u'the', u'highest', u'percentage', u'of', u'gay', u'and', u'lesbian', u'individual', u'of', u'any', u'of', u'the', u'50', u'largest', u'U.S.', u'city', u',', u'at', u'15.4', u'%', u'.'], u'pos': [u'VBG', u'TO', u'DT', u'CD', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'VBZ', u'DT', u'JJS', u'NN', u'IN', u'JJ', u'CC', u'JJ', u'NNS', u'IN', u'DT', u'IN', u'DT', u'CD', u'JJS', u'NNP', u'NNS', u',', u'IN', u'CD', u'NN', u'.'], u'char_offsets': [[40578, 40587], [40588, 40590], [40591, 40594], [40595, 40599], [40600, 40608], [40609, 40618], [40619, 40625], [40625, 40626], [40627, 40630], [40631, 40640], [40641, 40644], [40645, 40648], [40649, 40656], [40657, 40667], [40668, 40670], [40671, 40674], [40675, 40678], [40679, 40686], [40687, 40698], [40699, 40701], [40702, 40705], [40706, 40708], [40709, 40712], [40713, 40715], [40716, 40723], [40724, 40728], [40729, 40735], [40735, 40736], [40737, 40739], [40740, 40744], [40744, 40745], [40745, 40746]]}) 
answer: set([u'high'])
candidate Sentence: (0.1624935120344162, {u'tokens': [u'The', u'current', u'percentage', u'of', u'African', u'Americans', u'in', u'San', u'Francisco', u'is', u'similar', u'to', u'that', u'of', u'the', u'state', u'of', u'California', u';', u'conversely', u',', u'the', u'city', u"'s", u'percentage', u'of', u'Hispanic', u'residents', u'is', u'less', u'than', u'half', u'of', u'that', u'of', u'the', u'state', u'.'], u'lemmas': [u'the', u'current', u'percentage', u'of', u'african', u'Americans', u'in', u'San', u'Francisco', u'be', u'similar', u'to', u'that', u'of', u'the', u'state', u'of', u'California', u';', u'conversely', u',', u'the', u'city', u"'s", u'percentage', u'of', u'hispanic', u'resident', u'be', u'less', u'than', u'half', u'of', u'that', u'of', u'the', u'state', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NNPS', u'IN', u'NNP', u'NNP', u'VBZ', u'JJ', u'TO', u'DT', u'IN', u'DT', u'NN', u'IN', u'NNP', u':', u'RB', u',', u'DT', u'NN', u'POS', u'NN', u'IN', u'JJ', u'NNS', u'VBZ', u'JJR', u'IN', u'NN', u'IN', u'DT', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[40106, 40109], [40110, 40117], [40118, 40128], [40129, 40131], [40132, 40139], [40140, 40149], [40150, 40152], [40153, 40156], [40157, 40166], [40167, 40169], [40170, 40177], [40178, 40180], [40181, 40185], [40186, 40188], [40189, 40192], [40193, 40198], [40199, 40201], [40202, 40212], [40212, 40213], [40215, 40225], [40225, 40226], [40227, 40230], [40231, 40235], [40235, 40237], [40238, 40248], [40249, 40251], [40252, 40260], [40261, 40270], [40271, 40273], [40274, 40278], [40279, 40283], [40284, 40288], [40289, 40291], [40292, 40296], [40297, 40299], [40300, 40303], [40304, 40309], [40309, 40310]]}) 
answer: set([u'high', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.12892843782901764, {u'tokens': [u'San', u'Francisco', u'also', u'has', u'the', u'highest', u'percentage', u'of', u'same-sex', u'households', u'of', u'any', u'American', u'county', u',', u'with', u'the', u'Bay', u'Area', u'having', u'a', u'higher', u'concentration', u'than', u'any', u'other', u'metropolitan', u'area', u'.'], u'lemmas': [u'San', u'Francisco', u'also', u'have', u'the', u'highest', u'percentage', u'of', u'same-sex', u'household', u'of', u'any', u'american', u'county', u',', u'with', u'the', u'Bay', u'Area', u'have', u'a', u'higher', u'concentration', u'than', u'any', u'other', u'metropolitan', u'area', u'.'], u'pos': [u'NNP', u'NNP', u'RB', u'VBZ', u'DT', u'JJS', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'IN', u'DT', u'NNP', u'NNP', u'VBG', u'DT', u'JJR', u'NN', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[40750, 40753], [40754, 40763], [40764, 40768], [40769, 40772], [40773, 40776], [40777, 40784], [40785, 40795], [40796, 40798], [40799, 40807], [40808, 40818], [40819, 40821], [40822, 40825], [40826, 40834], [40835, 40841], [40841, 40842], [40843, 40847], [40848, 40851], [40852, 40855], [40856, 40860], [40861, 40867], [40868, 40869], [40870, 40876], [40877, 40890], [40891, 40895], [40896, 40899], [40900, 40905], [40906, 40918], [40919, 40923], [40923, 40924]]}) 
answer: set([u'high', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.12627848982810974, {u'tokens': [u'Upon', u'the', u'death', u'or', u'resignation', u'of', u'mayor', u',', u'the', u'President', u'of', u'the', u'Board', u'of', u'Supervisors', u'assumes', u'that', u'office', u',', u'as', u'did', u'Dianne', u'Feinstein', u'after', u'the', u'assassination', u'of', u'George', u'Moscone', u'in', u'1978', u'.'], u'lemmas': [u'upon', u'the', u'death', u'or', u'resignation', u'of', u'mayor', u',', u'the', u'President', u'of', u'the', u'Board', u'of', u'Supervisors', u'assume', u'that', u'office', u',', u'as', u'do', u'Dianne', u'Feinstein', u'after', u'the', u'assassination', u'of', u'George', u'Moscone', u'in', u'1978', u'.'], u'pos': [u'IN', u'DT', u'NN', u'CC', u'NN', u'IN', u'NN', u',', u'DT', u'NNP', u'IN', u'DT', u'NNP', u'IN', u'NNPS', u'VBZ', u'IN', u'NN', u',', u'IN', u'VBD', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'CD', u'.'], u'char_offsets': [[37269, 37273], [37274, 37277], [37278, 37283], [37284, 37286], [37287, 37298], [37299, 37301], [37302, 37307], [37307, 37308], [37309, 37312], [37313, 37322], [37323, 37325], [37326, 37329], [37330, 37335], [37336, 37338], [37339, 37350], [37351, 37358], [37359, 37363], [37364, 37370], [37370, 37371], [37372, 37374], [37375, 37378], [37379, 37385], [37386, 37395], [37396, 37401], [37402, 37405], [37406, 37419], [37420, 37422], [37423, 37429], [37430, 37437], [37438, 37440], [37441, 37445], [37445, 37446]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.11960852891206741, {u'tokens': [u'San', u'Francisco', u'is', u'characterized', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'lemmas': [u'San', u'Francisco', u'be', u'characterize', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[22107, 22110], [22111, 22120], [22121, 22123], [22124, 22137], [22138, 22140], [22141, 22142], [22143, 22147], [22148, 22156], [22157, 22159], [22160, 22166], [22166, 22167]]}) 
answer: set([u'percentage', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.1192416250705719, {u'tokens': [u'In', u'the', u'1970s', u',', u'the', u'city', u'became', u'a', u'center', u'of', u'the', u'gay', u'rights', u'movement', u',', u'with', u'the', u'emergence', u'of', u'The', u'Castro', u'as', u'an', u'urban', u'gay', u'village', u',', u'the', u'election', u'of', u'Harvey', u'Milk', u'to', u'the', u'Board', u'of', u'Supervisors', u',', u'and', u'his', u'assassination', u',', u'along', u'with', u'that', u'of', u'Mayor', u'George', u'Moscone', u',', u'in', u'1978', u'.'], u'lemmas': [u'in', u'the', u'1970', u',', u'the', u'city', u'become', u'a', u'center', u'of', u'the', u'gay', u'rights', u'movement', u',', u'with', u'the', u'emergence', u'of', u'the', u'Castro', u'as', u'a', u'urban', u'gay', u'village', u',', u'the', u'election', u'of', u'Harvey', u'milk', u'to', u'the', u'Board', u'of', u'Supervisors', u',', u'and', u'he', u'assassination', u',', u'along', u'with', u'that', u'of', u'Mayor', u'George', u'Moscone', u',', u'in', u'1978', u'.'], u'pos': [u'IN', u'DT', u'NNS', u',', u'DT', u'NN', u'VBD', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NNS', u'NN', u',', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNP', u'IN', u'DT', u'JJ', u'JJ', u'NN', u',', u'DT', u'NN', u'IN', u'NNP', u'NN', u'TO', u'DT', u'NNP', u'IN', u'NNPS', u',', u'CC', u'PRP$', u'NN', u',', u'IN', u'IN', u'DT', u'IN', u'NNP', u'NNP', u'NNP', u',', u'IN', u'CD', u'.'], u'char_offsets': [[10499, 10501], [10502, 10505], [10506, 10511], [10511, 10512], [10513, 10516], [10517, 10521], [10522, 10528], [10529, 10530], [10531, 10537], [10538, 10540], [10541, 10544], [10545, 10548], [10549, 10555], [10556, 10564], [10564, 10565], [10566, 10570], [10571, 10574], [10575, 10584], [10585, 10587], [10588, 10591], [10592, 10598], [10599, 10601], [10602, 10604], [10605, 10610], [10611, 10614], [10615, 10622], [10622, 10623], [10624, 10627], [10628, 10636], [10637, 10639], [10640, 10646], [10647, 10651], [10652, 10654], [10655, 10658], [10659, 10664], [10665, 10667], [10668, 10679], [10679, 10680], [10681, 10684], [10685, 10688], [10689, 10702], [10702, 10703], [10704, 10709], [10710, 10714], [10715, 10719], [10720, 10722], [10723, 10728], [10729, 10735], [10736, 10743], [10743, 10744], [10745, 10747], [10748, 10752], [10752, 10753]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.11247065663337708, {u'tokens': [u'A', u'popular', u'destination', u'for', u'gay', u'tourists', u',', u'the', u'city', u'hosts', u'San', u'Francisco', u'Pride', u',', u'an', u'annual', u'parade', u'and', u'festival', u'.'], u'lemmas': [u'a', u'popular', u'destination', u'for', u'gay', u'tourist', u',', u'the', u'city', u'host', u'San', u'Francisco', u'pride', u',', u'a', u'annual', u'parade', u'and', u'festival', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u',', u'DT', u'NN', u'NNS', u'NNP', u'NNP', u'NN', u',', u'DT', u'JJ', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[25344, 25345], [25346, 25353], [25354, 25365], [25366, 25369], [25370, 25373], [25374, 25382], [25382, 25383], [25384, 25387], [25388, 25392], [25393, 25398], [25399, 25402], [25403, 25412], [25413, 25418], [25418, 25419], [25420, 25422], [25423, 25429], [25430, 25436], [25437, 25440], [25441, 25449], [25449, 25450]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.097809337079524994, {u'tokens': [u'The', u'city', u"'s", u'large', u'gay', u'population', u'has', u'created', u'and', u'sustained', u'a', u'politically', u'and', u'culturally', u'active', u'community', u'over', u'many', u'decades', u',', u'developing', u'a', u'powerful', u'presence', u'in', u'San', u'Francisco', u"'s", u'civic', u'life', u'.'], u'lemmas': [u'the', u'city', u"'s", u'large', u'gay', u'population', u'have', u'create', u'and', u'sustain', u'a', u'politically', u'and', u'culturally', u'active', u'community', u'over', u'many', u'decade', u',', u'develop', u'a', u'powerful', u'presence', u'in', u'San', u'Francisco', u"'s", u'civic', u'life', u'.'], u'pos': [u'DT', u'NN', u'POS', u'JJ', u'JJ', u'NN', u'VBZ', u'VBN', u'CC', u'VBN', u'DT', u'RB', u'CC', u'RB', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u',', u'VBG', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'POS', u'JJ', u'NN', u'.'], u'char_offsets': [[25159, 25162], [25163, 25167], [25167, 25169], [25170, 25175], [25176, 25179], [25180, 25190], [25191, 25194], [25195, 25202], [25203, 25206], [25207, 25216], [25217, 25218], [25219, 25230], [25231, 25234], [25235, 25245], [25246, 25252], [25253, 25262], [25263, 25267], [25268, 25272], [25273, 25280], [25280, 25281], [25282, 25292], [25293, 25294], [25295, 25303], [25304, 25312], [25313, 25315], [25316, 25319], [25320, 25329], [25329, 25331], [25332, 25337], [25338, 25342], [25342, 25343]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.085053525865077972, {u'tokens': [u'Historically', u'known', u'as', u'Eureka', u'Valley', u',', u'the', u'area', u'now', u'popularly', u'called', u'the', u'Castro', u'is', u'the', u'center', u'of', u'gay', u'life', u'in', u'the', u'city', u'.'], u'lemmas': [u'Historically', u'know', u'as', u'Eureka', u'Valley', u',', u'the', u'area', u'now', u'popularly', u'call', u'the', u'Castro', u'be', u'the', u'center', u'of', u'gay', u'life', u'in', u'the', u'city', u'.'], u'pos': [u'NNP', u'VBN', u'IN', u'NNP', u'NNP', u',', u'DT', u'NN', u'RB', u'RB', u'VBN', u'DT', u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[17914, 17926], [17927, 17932], [17933, 17935], [17936, 17942], [17943, 17949], [17949, 17950], [17951, 17954], [17955, 17959], [17960, 17963], [17964, 17973], [17974, 17980], [17981, 17984], [17985, 17991], [17992, 17994], [17995, 17998], [17999, 18005], [18006, 18008], [18009, 18012], [18013, 18017], [18018, 18020], [18021, 18024], [18025, 18029], [18029, 18030]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.083945281803607941, {u'tokens': [u'Native', u'San', u'Franciscans', u'form', u'a', u'relatively', u'small', u'percentage', u'of', u'the', u'city', u"'s", u'population', u':', u'only', u'37.7', u'%', u'of', u'its', u'residents', u'were', u'born', u'in', u'California', u',', u'while', u'25.2', u'%', u'were', u'born', u'in', u'a', u'different', u'U.S.', u'state', u'.'], u'lemmas': [u'native', u'San', u'Franciscans', u'form', u'a', u'relatively', u'small', u'percentage', u'of', u'the', u'city', u"'s", u'population', u':', u'only', u'37.7', u'%', u'of', u'its', u'resident', u'be', u'bear', u'in', u'California', u',', u'while', u'25.2', u'%', u'be', u'bear', u'in', u'a', u'different', u'U.S.', u'state', u'.'], u'pos': [u'JJ', u'NNP', u'NNP', u'VB', u'DT', u'RB', u'JJ', u'NN', u'IN', u'DT', u'NN', u'POS', u'NN', u':', u'RB', u'CD', u'NN', u'IN', u'PRP$', u'NNS', u'VBD', u'VBN', u'IN', u'NNP', u',', u'IN', u'CD', u'NN', u'VBD', u'VBN', u'IN', u'DT', u'JJ', u'NNP', u'NN', u'.'], u'char_offsets': [[40311, 40317], [40318, 40321], [40322, 40333], [40334, 40338], [40339, 40340], [40341, 40351], [40352, 40357], [40358, 40368], [40369, 40371], [40372, 40375], [40376, 40380], [40380, 40382], [40383, 40393], [40393, 40394], [40395, 40399], [40400, 40404], [40404, 40405], [40406, 40408], [40409, 40412], [40413, 40422], [40423, 40427], [40428, 40432], [40433, 40435], [40436, 40446], [40446, 40447], [40448, 40453], [40454, 40458], [40458, 40459], [40460, 40464], [40465, 40469], [40470, 40472], [40473, 40474], [40475, 40484], [40485, 40489], [40490, 40495], [40495, 40496]]}) 
answer: set([u'high', u'individual', u'lesbian', u'gay'])

Does San Francisco have a high percentage of gay and lesbian individuals?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.')
 +    where 'Yes, according to the 2005 American Community Survey, San Francisco has the highest percentage of gay and lesbian individuals of any of the 50 largest U.S. cities, at 15.4%.' = <src.question_processing.Question_parser instance at 0x1114d8f80>.answer
_____________________________ test_yesno[param272] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114d8fc8>, (<src.tfidf.TF_IDF object at 0x10fd76cd0>, set(['francisco', 'san', 'san_francisco'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8fc8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.45207801461219788, {u'tokens': [u'According', u'to', u'the', u'2005', u'American', u'Community', u'Survey', u',', u'San', u'Francisco', u'has', u'the', u'highest', u'percentage', u'of', u'gay', u'and', u'lesbian', u'individuals', u'of', u'any', u'of', u'the', u'50', u'largest', u'U.S.', u'cities', u',', u'at', u'15.4', u'%', u'.'], u'lemmas': [u'accord', u'to', u'the', u'2005', u'American', u'Community', u'Survey', u',', u'San', u'Francisco', u'have', u'the', u'highest', u'percentage', u'of', u'gay', u'and', u'lesbian', u'individual', u'of', u'any', u'of', u'the', u'50', u'largest', u'U.S.', u'city', u',', u'at', u'15.4', u'%', u'.'], u'pos': [u'VBG', u'TO', u'DT', u'CD', u'NNP', u'NNP', u'NNP', u',', u'NNP', u'NNP', u'VBZ', u'DT', u'JJS', u'NN', u'IN', u'JJ', u'CC', u'JJ', u'NNS', u'IN', u'DT', u'IN', u'DT', u'CD', u'JJS', u'NNP', u'NNS', u',', u'IN', u'CD', u'NN', u'.'], u'char_offsets': [[40578, 40587], [40588, 40590], [40591, 40594], [40595, 40599], [40600, 40608], [40609, 40618], [40619, 40625], [40625, 40626], [40627, 40630], [40631, 40640], [40641, 40644], [40645, 40648], [40649, 40656], [40657, 40667], [40668, 40670], [40671, 40674], [40675, 40678], [40679, 40686], [40687, 40698], [40699, 40701], [40702, 40705], [40706, 40708], [40709, 40712], [40713, 40715], [40716, 40723], [40724, 40728], [40729, 40735], [40735, 40736], [40737, 40739], [40740, 40744], [40744, 40745], [40745, 40746]]}) 
answer: set([u'high'])
candidate Sentence: (0.1624935120344162, {u'tokens': [u'The', u'current', u'percentage', u'of', u'African', u'Americans', u'in', u'San', u'Francisco', u'is', u'similar', u'to', u'that', u'of', u'the', u'state', u'of', u'California', u';', u'conversely', u',', u'the', u'city', u"'s", u'percentage', u'of', u'Hispanic', u'residents', u'is', u'less', u'than', u'half', u'of', u'that', u'of', u'the', u'state', u'.'], u'lemmas': [u'the', u'current', u'percentage', u'of', u'african', u'Americans', u'in', u'San', u'Francisco', u'be', u'similar', u'to', u'that', u'of', u'the', u'state', u'of', u'California', u';', u'conversely', u',', u'the', u'city', u"'s", u'percentage', u'of', u'hispanic', u'resident', u'be', u'less', u'than', u'half', u'of', u'that', u'of', u'the', u'state', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NNPS', u'IN', u'NNP', u'NNP', u'VBZ', u'JJ', u'TO', u'DT', u'IN', u'DT', u'NN', u'IN', u'NNP', u':', u'RB', u',', u'DT', u'NN', u'POS', u'NN', u'IN', u'JJ', u'NNS', u'VBZ', u'JJR', u'IN', u'NN', u'IN', u'DT', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[40106, 40109], [40110, 40117], [40118, 40128], [40129, 40131], [40132, 40139], [40140, 40149], [40150, 40152], [40153, 40156], [40157, 40166], [40167, 40169], [40170, 40177], [40178, 40180], [40181, 40185], [40186, 40188], [40189, 40192], [40193, 40198], [40199, 40201], [40202, 40212], [40212, 40213], [40215, 40225], [40225, 40226], [40227, 40230], [40231, 40235], [40235, 40237], [40238, 40248], [40249, 40251], [40252, 40260], [40261, 40270], [40271, 40273], [40274, 40278], [40279, 40283], [40284, 40288], [40289, 40291], [40292, 40296], [40297, 40299], [40300, 40303], [40304, 40309], [40309, 40310]]}) 
answer: set([u'high', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.12892843782901764, {u'tokens': [u'San', u'Francisco', u'also', u'has', u'the', u'highest', u'percentage', u'of', u'same-sex', u'households', u'of', u'any', u'American', u'county', u',', u'with', u'the', u'Bay', u'Area', u'having', u'a', u'higher', u'concentration', u'than', u'any', u'other', u'metropolitan', u'area', u'.'], u'lemmas': [u'San', u'Francisco', u'also', u'have', u'the', u'highest', u'percentage', u'of', u'same-sex', u'household', u'of', u'any', u'american', u'county', u',', u'with', u'the', u'Bay', u'Area', u'have', u'a', u'higher', u'concentration', u'than', u'any', u'other', u'metropolitan', u'area', u'.'], u'pos': [u'NNP', u'NNP', u'RB', u'VBZ', u'DT', u'JJS', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u',', u'IN', u'DT', u'NNP', u'NNP', u'VBG', u'DT', u'JJR', u'NN', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[40750, 40753], [40754, 40763], [40764, 40768], [40769, 40772], [40773, 40776], [40777, 40784], [40785, 40795], [40796, 40798], [40799, 40807], [40808, 40818], [40819, 40821], [40822, 40825], [40826, 40834], [40835, 40841], [40841, 40842], [40843, 40847], [40848, 40851], [40852, 40855], [40856, 40860], [40861, 40867], [40868, 40869], [40870, 40876], [40877, 40890], [40891, 40895], [40896, 40899], [40900, 40905], [40906, 40918], [40919, 40923], [40923, 40924]]}) 
answer: set([u'high', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.12627848982810974, {u'tokens': [u'Upon', u'the', u'death', u'or', u'resignation', u'of', u'mayor', u',', u'the', u'President', u'of', u'the', u'Board', u'of', u'Supervisors', u'assumes', u'that', u'office', u',', u'as', u'did', u'Dianne', u'Feinstein', u'after', u'the', u'assassination', u'of', u'George', u'Moscone', u'in', u'1978', u'.'], u'lemmas': [u'upon', u'the', u'death', u'or', u'resignation', u'of', u'mayor', u',', u'the', u'President', u'of', u'the', u'Board', u'of', u'Supervisors', u'assume', u'that', u'office', u',', u'as', u'do', u'Dianne', u'Feinstein', u'after', u'the', u'assassination', u'of', u'George', u'Moscone', u'in', u'1978', u'.'], u'pos': [u'IN', u'DT', u'NN', u'CC', u'NN', u'IN', u'NN', u',', u'DT', u'NNP', u'IN', u'DT', u'NNP', u'IN', u'NNPS', u'VBZ', u'IN', u'NN', u',', u'IN', u'VBD', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'NNP', u'NNP', u'IN', u'CD', u'.'], u'char_offsets': [[37269, 37273], [37274, 37277], [37278, 37283], [37284, 37286], [37287, 37298], [37299, 37301], [37302, 37307], [37307, 37308], [37309, 37312], [37313, 37322], [37323, 37325], [37326, 37329], [37330, 37335], [37336, 37338], [37339, 37350], [37351, 37358], [37359, 37363], [37364, 37370], [37370, 37371], [37372, 37374], [37375, 37378], [37379, 37385], [37386, 37395], [37396, 37401], [37402, 37405], [37406, 37419], [37420, 37422], [37423, 37429], [37430, 37437], [37438, 37440], [37441, 37445], [37445, 37446]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.11960852891206741, {u'tokens': [u'San', u'Francisco', u'is', u'characterized', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'lemmas': [u'San', u'Francisco', u'be', u'characterize', u'by', u'a', u'high', u'standard', u'of', u'living', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'.'], u'char_offsets': [[22107, 22110], [22111, 22120], [22121, 22123], [22124, 22137], [22138, 22140], [22141, 22142], [22143, 22147], [22148, 22156], [22157, 22159], [22160, 22166], [22166, 22167]]}) 
answer: set([u'percentage', u'individual', u'lesbian', u'gay'])
candidate Sentence: (0.1192416250705719, {u'tokens': [u'In', u'the', u'1970s', u',', u'the', u'city', u'became', u'a', u'center', u'of', u'the', u'gay', u'rights', u'movement', u',', u'with', u'the', u'emergence', u'of', u'The', u'Castro', u'as', u'an', u'urban', u'gay', u'village', u',', u'the', u'election', u'of', u'Harvey', u'Milk', u'to', u'the', u'Board', u'of', u'Supervisors', u',', u'and', u'his', u'assassination', u',', u'along', u'with', u'that', u'of', u'Mayor', u'George', u'Moscone', u',', u'in', u'1978', u'.'], u'lemmas': [u'in', u'the', u'1970', u',', u'the', u'city', u'become', u'a', u'center', u'of', u'the', u'gay', u'rights', u'movement', u',', u'with', u'the', u'emergence', u'of', u'the', u'Castro', u'as', u'a', u'urban', u'gay', u'village', u',', u'the', u'election', u'of', u'Harvey', u'milk', u'to', u'the', u'Board', u'of', u'Supervisors', u',', u'and', u'he', u'assassination', u',', u'along', u'with', u'that', u'of', u'Mayor', u'George', u'Moscone', u',', u'in', u'1978', u'.'], u'pos': [u'IN', u'DT', u'NNS', u',', u'DT', u'NN', u'VBD', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NNS', u'NN', u',', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNP', u'IN', u'DT', u'JJ', u'JJ', u'NN', u',', u'DT', u'NN', u'IN', u'NNP', u'NN', u'TO', u'DT', u'NNP', u'IN', u'NNPS', u',', u'CC', u'PRP$', u'NN', u',', u'IN', u'IN', u'DT', u'IN', u'NNP', u'NNP', u'NNP', u',', u'IN', u'CD', u'.'], u'char_offsets': [[10499, 10501], [10502, 10505], [10506, 10511], [10511, 10512], [10513, 10516], [10517, 10521], [10522, 10528], [10529, 10530], [10531, 10537], [10538, 10540], [10541, 10544], [10545, 10548], [10549, 10555], [10556, 10564], [10564, 10565], [10566, 10570], [10571, 10574], [10575, 10584], [10585, 10587], [10588, 10591], [10592, 10598], [10599, 10601], [10602, 10604], [10605, 10610], [10611, 10614], [10615, 10622], [10622, 10623], [10624, 10627], [10628, 10636], [10637, 10639], [10640, 10646], [10647, 10651], [10652, 10654], [10655, 10658], [10659, 10664], [10665, 10667], [10668, 10679], [10679, 10680], [10681, 10684], [10685, 10688], [10689, 10702], [10702, 10703], [10704, 10709], [10710, 10714], [10715, 10719], [10720, 10722], [10723, 10728], [10729, 10735], [10736, 10743], [10743, 10744], [10745, 10747], [10748, 10752], [10752, 10753]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.11247065663337708, {u'tokens': [u'A', u'popular', u'destination', u'for', u'gay', u'tourists', u',', u'the', u'city', u'hosts', u'San', u'Francisco', u'Pride', u',', u'an', u'annual', u'parade', u'and', u'festival', u'.'], u'lemmas': [u'a', u'popular', u'destination', u'for', u'gay', u'tourist', u',', u'the', u'city', u'host', u'San', u'Francisco', u'pride', u',', u'a', u'annual', u'parade', u'and', u'festival', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u',', u'DT', u'NN', u'NNS', u'NNP', u'NNP', u'NN', u',', u'DT', u'JJ', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[25344, 25345], [25346, 25353], [25354, 25365], [25366, 25369], [25370, 25373], [25374, 25382], [25382, 25383], [25384, 25387], [25388, 25392], [25393, 25398], [25399, 25402], [25403, 25412], [25413, 25418], [25418, 25419], [25420, 25422], [25423, 25429], [25430, 25436], [25437, 25440], [25441, 25449], [25449, 25450]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.097809337079524994, {u'tokens': [u'The', u'city', u"'s", u'large', u'gay', u'population', u'has', u'created', u'and', u'sustained', u'a', u'politically', u'and', u'culturally', u'active', u'community', u'over', u'many', u'decades', u',', u'developing', u'a', u'powerful', u'presence', u'in', u'San', u'Francisco', u"'s", u'civic', u'life', u'.'], u'lemmas': [u'the', u'city', u"'s", u'large', u'gay', u'population', u'have', u'create', u'and', u'sustain', u'a', u'politically', u'and', u'culturally', u'active', u'community', u'over', u'many', u'decade', u',', u'develop', u'a', u'powerful', u'presence', u'in', u'San', u'Francisco', u"'s", u'civic', u'life', u'.'], u'pos': [u'DT', u'NN', u'POS', u'JJ', u'JJ', u'NN', u'VBZ', u'VBN', u'CC', u'VBN', u'DT', u'RB', u'CC', u'RB', u'JJ', u'NN', u'IN', u'JJ', u'NNS', u',', u'VBG', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'NNP', u'POS', u'JJ', u'NN', u'.'], u'char_offsets': [[25159, 25162], [25163, 25167], [25167, 25169], [25170, 25175], [25176, 25179], [25180, 25190], [25191, 25194], [25195, 25202], [25203, 25206], [25207, 25216], [25217, 25218], [25219, 25230], [25231, 25234], [25235, 25245], [25246, 25252], [25253, 25262], [25263, 25267], [25268, 25272], [25273, 25280], [25280, 25281], [25282, 25292], [25293, 25294], [25295, 25303], [25304, 25312], [25313, 25315], [25316, 25319], [25320, 25329], [25329, 25331], [25332, 25337], [25338, 25342], [25342, 25343]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.085053525865077972, {u'tokens': [u'Historically', u'known', u'as', u'Eureka', u'Valley', u',', u'the', u'area', u'now', u'popularly', u'called', u'the', u'Castro', u'is', u'the', u'center', u'of', u'gay', u'life', u'in', u'the', u'city', u'.'], u'lemmas': [u'Historically', u'know', u'as', u'Eureka', u'Valley', u',', u'the', u'area', u'now', u'popularly', u'call', u'the', u'Castro', u'be', u'the', u'center', u'of', u'gay', u'life', u'in', u'the', u'city', u'.'], u'pos': [u'NNP', u'VBN', u'IN', u'NNP', u'NNP', u',', u'DT', u'NN', u'RB', u'RB', u'VBN', u'DT', u'NNP', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[17914, 17926], [17927, 17932], [17933, 17935], [17936, 17942], [17943, 17949], [17949, 17950], [17951, 17954], [17955, 17959], [17960, 17963], [17964, 17973], [17974, 17980], [17981, 17984], [17985, 17991], [17992, 17994], [17995, 17998], [17999, 18005], [18006, 18008], [18009, 18012], [18013, 18017], [18018, 18020], [18021, 18024], [18025, 18029], [18029, 18030]]}) 
answer: set([u'high', u'percentage', u'individual', u'lesbian'])
candidate Sentence: (0.083945281803607941, {u'tokens': [u'Native', u'San', u'Franciscans', u'form', u'a', u'relatively', u'small', u'percentage', u'of', u'the', u'city', u"'s", u'population', u':', u'only', u'37.7', u'%', u'of', u'its', u'residents', u'were', u'born', u'in', u'California', u',', u'while', u'25.2', u'%', u'were', u'born', u'in', u'a', u'different', u'U.S.', u'state', u'.'], u'lemmas': [u'native', u'San', u'Franciscans', u'form', u'a', u'relatively', u'small', u'percentage', u'of', u'the', u'city', u"'s", u'population', u':', u'only', u'37.7', u'%', u'of', u'its', u'resident', u'be', u'bear', u'in', u'California', u',', u'while', u'25.2', u'%', u'be', u'bear', u'in', u'a', u'different', u'U.S.', u'state', u'.'], u'pos': [u'JJ', u'NNP', u'NNP', u'VB', u'DT', u'RB', u'JJ', u'NN', u'IN', u'DT', u'NN', u'POS', u'NN', u':', u'RB', u'CD', u'NN', u'IN', u'PRP$', u'NNS', u'VBD', u'VBN', u'IN', u'NNP', u',', u'IN', u'CD', u'NN', u'VBD', u'VBN', u'IN', u'DT', u'JJ', u'NNP', u'NN', u'.'], u'char_offsets': [[40311, 40317], [40318, 40321], [40322, 40333], [40334, 40338], [40339, 40340], [40341, 40351], [40352, 40357], [40358, 40368], [40369, 40371], [40372, 40375], [40376, 40380], [40380, 40382], [40383, 40393], [40393, 40394], [40395, 40399], [40400, 40404], [40404, 40405], [40406, 40408], [40409, 40412], [40413, 40422], [40423, 40427], [40428, 40432], [40433, 40435], [40436, 40446], [40446, 40447], [40448, 40453], [40454, 40458], [40458, 40459], [40460, 40464], [40465, 40469], [40470, 40472], [40473, 40474], [40475, 40484], [40485, 40489], [40490, 40495], [40495, 40496]]}) 
answer: set([u'high', u'individual', u'lesbian', u'gay'])

Does San Francisco have a high percentage of gay and lesbian individuals?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
INFO:CoreNLP_JavaServer: INPUT: 700 documents, 1415254 characters, 266429 tokens, 2021.8 char/doc, 380.6 tok/doc RATES: 16.431 doc/sec, 6253.9 tok/sec

Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114d8fc8>.answer
_____________________________ test_yesno[param280] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114dd248>, (<src.tfidf.TF_IDF object at 0x10a4ac9d0>, set(['language', 'swahili', 'swahili_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, Swahili has diphthongs. (Typo)')
E                +    where 'Yes, Swahili has diphthongs. (Typo)' = <src.question_processing.Question_parser instance at 0x1114dd248>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39984771609306335, {u'tokens': [u'Education', u'for', u'all', u'--', u'in', u'whose', u'language', u'?'], u'lemmas': [u'education', u'for', u'all', u'--', u'in', u'whose', u'language', u'?'], u'pos': [u'NN', u'IN', u'DT', u':', u'IN', u'WP$', u'NN', u'.'], u'char_offsets': [[29579, 29588], [29589, 29592], [29593, 29596], [29597, 29598], [29599, 29601], [29602, 29607], [29608, 29616], [29616, 29617]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.17273348569869995, {u'tokens': [u'However', u',', u'elsewhere', u'this', u'does', u"n't", u'happen', u':', u'ndizi', u'``', u'banana', u"''", u'has', u'two', u'syllables', u',', u',', u'as', u'does', u'nenda', u'-LRB-', u'not', u'-RRB-', u'``', u'go', u"''", u'.'], u'lemmas': [u'however', u',', u'elsewhere', u'this', u'do', u'not', u'happen', u':', u'ndizus', u'``', u'banana', u"''", u'have', u'two', u'syllable', u',', u',', u'as', u'do', u'nenda', u'-lrb-', u'not', u'-rrb-', u'``', u'go', u"''", u'.'], u'pos': [u'RB', u',', u'RB', u'DT', u'VBZ', u'RB', u'VB', u':', u'NNS', u'``', u'NN', u"''", u'VBZ', u'CD', u'NNS', u',', u',', u'IN', u'VBZ', u'NN', u'-LRB-', u'RB', u'-RRB-', u'``', u'VB', u"''", u'.'], u'char_offsets': [[6447, 6454], [6454, 6455], [6456, 6465], [6466, 6470], [6471, 6475], [6475, 6478], [6479, 6485], [6485, 6486], [6487, 6492], [6493, 6494], [6494, 6500], [6500, 6501], [6502, 6505], [6506, 6509], [6510, 6519], [6519, 6520], [6522, 6523], [6524, 6526], [6527, 6531], [6532, 6537], [6540, 6541], [6541, 6544], [6546, 6547], [6548, 6549], [6549, 6551], [6551, 6552], [6552, 6553]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.16239820420742035, {u'tokens': [u'When', u'the', u'noun', u'itself', u'does', u'not', u'make', u'clear', u'which', u'class', u'it', u'belongs', u'to', u',', u'its', u'concords', u'do', u'.'], u'lemmas': [u'when', u'the', u'noun', u'itself', u'do', u'not', u'make', u'clear', u'which', u'class', u'it', u'belong', u'to', u',', u'its', u'concord', u'do', u'.'], u'pos': [u'WRB', u'DT', u'NN', u'PRP', u'VBZ', u'RB', u'VB', u'JJ', u'WDT', u'NN', u'PRP', u'VBZ', u'TO', u',', u'PRP$', u'NNS', u'VBP', u'.'], u'char_offsets': [[8926, 8930], [8931, 8934], [8935, 8939], [8940, 8946], [8947, 8951], [8952, 8955], [8956, 8960], [8961, 8966], [8967, 8972], [8973, 8978], [8979, 8981], [8982, 8989], [8990, 8992], [8992, 8993], [8994, 8997], [8998, 9006], [9007, 9009], [9009, 9010]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.14764557778835297, {u'tokens': [u'The', u'British', u'did', u'not', u'do', u'so', u'in', u'neighbouring', u'Kenya', u',', u'even', u'though', u'they', u'made', u'moves', u'in', u'that', u'direction', u'.'], u'lemmas': [u'the', u'British', u'do', u'not', u'do', u'so', u'in', u'neighbour', u'Kenya', u',', u'even', u'though', u'they', u'make', u'move', u'in', u'that', u'direction', u'.'], u'pos': [u'DT', u'NNP', u'VBD', u'RB', u'VB', u'RB', u'IN', u'VBG', u'NNP', u',', u'RB', u'IN', u'PRP', u'VBD', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[26399, 26402], [26403, 26410], [26411, 26414], [26415, 26418], [26419, 26421], [26422, 26424], [26425, 26427], [26428, 26440], [26441, 26446], [26446, 26447], [26448, 26452], [26453, 26459], [26460, 26464], [26465, 26469], [26470, 26475], [26476, 26478], [26479, 26483], [26484, 26493], [26493, 26494]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.1305890679359436, {u'tokens': [u'Standard', u'Swahili', u'has', u'five', u'vowel', u'phonemes', u':', u',', u',', u',', u',', u'and', u'.'], u'lemmas': [u'Standard', u'Swahili', u'have', u'five', u'vowel', u'phoneme', u':', u',', u',', u',', u',', u'and', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'CD', u'NN', u'NNS', u':', u',', u',', u',', u',', u'CC', u'.'], u'char_offsets': [[5496, 5504], [5505, 5512], [5513, 5516], [5517, 5521], [5522, 5527], [5528, 5536], [5536, 5537], [5539, 5540], [5542, 5543], [5545, 5546], [5548, 5549], [5550, 5553], [5555, 5556]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.12832434475421906, {u'tokens': [u'This', u'is', u'often', u'called', u'the', u'`', u'tree', u"'", u'class', u',', u'because', u'mti', u',', u'miti', u'``', u'tree', u'-LRB-', u's', u'-RRB-', u"''", u'is', u'the', u'prototypical', u'example', u',', u'but', u'that', u'does', u"n't", u'do', u'it', u'justice', u'.'], u'lemmas': [u'this', u'be', u'often', u'call', u'the', u'`', u'tree', u"'", u'class', u',', u'because', u'mtus', u',', u'mitus', u'``', u'tree', u'-lrb-', u's', u'-rrb-', u"''", u'be', u'the', u'prototypical', u'example', u',', u'but', u'that', u'do', u'not', u'do', u'it', u'justice', u'.'], u'pos': [u'DT', u'VBZ', u'RB', u'VBN', u'DT', u'``', u'NN', u"''", u'NN', u',', u'IN', u'NNS', u',', u'NNS', u'``', u'NN', u'-LRB-', u'NNS', u'-RRB-', u"''", u'VBZ', u'DT', u'JJ', u'NN', u',', u'CC', u'IN', u'VBZ', u'RB', u'VB', u'PRP', u'NN', u'.'], u'char_offsets': [[12097, 12101], [12102, 12104], [12105, 12110], [12111, 12117], [12118, 12121], [12122, 12123], [12123, 12127], [12127, 12128], [12129, 12134], [12134, 12135], [12136, 12143], [12144, 12147], [12147, 12148], [12149, 12153], [12154, 12155], [12155, 12159], [12159, 12160], [12160, 12161], [12161, 12162], [12162, 12163], [12164, 12166], [12167, 12170], [12171, 12183], [12184, 12191], [12191, 12192], [12193, 12196], [12197, 12201], [12202, 12206], [12206, 12209], [12210, 12212], [12213, 12215], [12216, 12223], [12223, 12224]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.093678288161754608, {u'tokens': [u'*', u'Swahili', u'orthography', u'does', u'not', u'distinguish', u'aspirate', u'from', u'tenuis', u'consonants', u'.'], u'lemmas': [u'*', u'swahilus', u'orthography', u'do', u'not', u'distinguish', u'aspirate', u'from', u'tenuis', u'consonant', u'.'], u'pos': [u'SYM', u'NNS', u'NN', u'VBZ', u'RB', u'VB', u'VB', u'IN', u'FW', u'NNS', u'.'], u'char_offsets': [[6683, 6684], [6685, 6692], [6693, 6704], [6705, 6709], [6710, 6713], [6714, 6725], [6726, 6734], [6735, 6739], [6740, 6746], [6747, 6757], [6757, 6758]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.092853188514709473, {u'tokens': [u'For', u'the', u'most', u'part', u',', u'this', u'process', u'did', u'not', u'lead', u'to', u'genuine', u'colonization', u'.'], u'lemmas': [u'for', u'the', u'most', u'part', u',', u'this', u'process', u'do', u'not', u'lead', u'to', u'genuine', u'colonization', u'.'], u'pos': [u'IN', u'DT', u'JJS', u'NN', u',', u'DT', u'NN', u'VBD', u'RB', u'VB', u'TO', u'JJ', u'NN', u'.'], u'char_offsets': [[25913, 25916], [25917, 25920], [25921, 25925], [25926, 25930], [25930, 25931], [25932, 25936], [25937, 25944], [25945, 25948], [25949, 25952], [25953, 25957], [25958, 25960], [25961, 25968], [25969, 25981], [25981, 25982]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.083252690732479095, {u'tokens': [u'Swahili', u'has', u'no', u'diphthongs', u';', u'in', u'vowel', u'combinations', u',', u'each', u'letter', u'is', u'pronounced', u'separately', u'.'], u'lemmas': [u'Swahili', u'have', u'no', u'diphthong', u';', u'in', u'vowel', u'combination', u',', u'each', u'letter', u'be', u'pronounced', u'separately', u'.'], u'pos': [u'NNP', u'VBZ', u'DT', u'NNS', u':', u'IN', u'NN', u'NNS', u',', u'DT', u'NN', u'VBZ', u'JJ', u'RB', u'.'], u'char_offsets': [[6036, 6043], [6044, 6047], [6048, 6050], [6051, 6061], [6061, 6062], [6063, 6065], [6066, 6071], [6072, 6084], [6084, 6085], [6086, 6090], [6091, 6097], [6098, 6100], [6101, 6111], [6112, 6122], [6122, 6123]]}) 
answer: set([u'dipthong'])
candidate Sentence: (0.081113152205944061, {u'tokens': [u'Many', u'of', u'the', u'world', u"'s", u'institutions', u'have', u'responded', u'to', u'Swahili', u"'s", u'growing', u'prominence', u'.'], u'lemmas': [u'many', u'of', u'the', u'world', u"'s", u'institution', u'have', u'respond', u'to', u'Swahili', u"'s", u'grow', u'prominence', u'.'], u'pos': [u'JJ', u'IN', u'DT', u'NN', u'POS', u'NNS', u'VBP', u'VBN', u'TO', u'NNP', u'POS', u'VBG', u'NN', u'.'], u'char_offsets': [[29117, 29121], [29122, 29124], [29125, 29128], [29129, 29134], [29134, 29136], [29137, 29149], [29150, 29154], [29155, 29164], [29165, 29167], [29168, 29175], [29175, 29177], [29178, 29185], [29186, 29196], [29196, 29197]]}) 
answer: set([u'dipthong'])

Does Swahili have dipthongs?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, Swahili has diphthongs. (Typo)
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, Swahili has diphthongs. (Typo)')
 +    where 'Yes, Swahili has diphthongs. (Typo)' = <src.question_processing.Question_parser instance at 0x1114dd248>.answer
_____________________________ test_yesno[param283] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114dd320>, (<src.tfidf.TF_IDF object at 0x10a4ac9d0>, set(['language', 'swahili', 'swahili_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, Uganda made Swahili a required subject in primary schools.')
E                +    where 'Yes, Uganda made Swahili a required subject in primary schools.' = <src.question_processing.Question_parser instance at 0x1114dd320>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39814144372940063, {u'tokens': [u'The', u'neighboring', u'nation', u'of', u'Uganda', u'made', u'Swahili', u'a', u'required', u'subject', u'in', u'primary', u'schools', u'in', u'1992', u'--', u'although', u'this', u'mandate', u'has', u'not', u'been', u'well', u'implemented', u'--', u'and', u'declared', u'it', u'an', u'official', u'language', u'in', u'2005', u'in', u'preparation', u'for', u'the', u'East', u'African', u'Federation', u'.'], u'lemmas': [u'the', u'neighboring', u'nation', u'of', u'Uganda', u'make', u'Swahili', u'a', u'require', u'subject', u'in', u'primary', u'school', u'in', u'1992', u'--', u'although', u'this', u'mandate', u'have', u'not', u'be', u'well', u'implement', u'--', u'and', u'declare', u'it', u'a', u'official', u'language', u'in', u'2005', u'in', u'preparation', u'for', u'the', u'east', u'african', u'Federation', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNP', u'VBD', u'NNP', u'DT', u'VBN', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'CD', u':', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'RB', u'VBN', u':', u'CC', u'VBD', u'PRP', u'DT', u'JJ', u'NN', u'IN', u'CD', u'IN', u'NN', u'IN', u'DT', u'JJ', u'JJ', u'NNP', u'.'], u'char_offsets': [[1240, 1243], [1244, 1255], [1256, 1262], [1263, 1265], [1266, 1272], [1273, 1277], [1278, 1285], [1286, 1287], [1288, 1296], [1297, 1304], [1305, 1307], [1308, 1315], [1316, 1323], [1324, 1326], [1327, 1331], [1331, 1332], [1332, 1340], [1341, 1345], [1346, 1353], [1354, 1357], [1358, 1361], [1362, 1366], [1367, 1371], [1372, 1383], [1383, 1384], [1384, 1387], [1388, 1396], [1397, 1399], [1400, 1402], [1403, 1411], [1412, 1420], [1421, 1423], [1424, 1428], [1429, 1431], [1432, 1443], [1444, 1447], [1448, 1451], [1452, 1456], [1457, 1464], [1465, 1475], [1475, 1476]]}) 
answer: set([u'swahilus'])
candidate Sentence: (0.22213453054428101, {u'tokens': [u'Education', u'for', u'all', u'--', u'in', u'whose', u'language', u'?'], u'lemmas': [u'education', u'for', u'all', u'--', u'in', u'whose', u'language', u'?'], u'pos': [u'NN', u'IN', u'DT', u':', u'IN', u'WP$', u'NN', u'.'], u'char_offsets': [[29579, 29588], [29589, 29592], [29593, 29596], [29597, 29598], [29599, 29601], [29602, 29607], [29608, 29616], [29616, 29617]]}) 
answer: set([u'school', u'require', u'primary', u'uganda', u'subject', u'swahilus', u'make'])
candidate Sentence: (0.19435977935791016, {u'tokens': [u'In', u'Uganda', u',', u'the', u'Baganda', u'generally', u'do', u"n't", u'speak', u'Swahili', u',', u'but', u'it', u'is', u'in', u'common', u'use', u'among', u'the', u'25', u'million', u'people', u'elsewhere', u'in', u'the', u'country', u',', u'and', u'is', u'currently', u'being', u'implemented', u'in', u'schools', u'nationwide', u'in', u'preparation', u'for', u'the', u'East', u'African', u'Community', u'.'], u'lemmas': [u'in', u'Uganda', u',', u'the', u'Baganda', u'generally', u'do', u'not', u'speak', u'Swahili', u',', u'but', u'it', u'be', u'in', u'common', u'use', u'among', u'the', u'25', u'million', u'people', u'elsewhere', u'in', u'the', u'country', u',', u'and', u'be', u'currently', u'be', u'implement', u'in', u'school', u'nationwide', u'in', u'preparation', u'for', u'the', u'east', u'African', u'Community', u'.'], u'pos': [u'IN', u'NNP', u',', u'DT', u'NNP', u'RB', u'VBP', u'RB', u'VB', u'NNP', u',', u'CC', u'PRP', u'VBZ', u'IN', u'JJ', u'NN', u'IN', u'DT', u'CD', u'CD', u'NNS', u'RB', u'IN', u'DT', u'NN', u',', u'CC', u'VBZ', u'RB', u'VBG', u'VBN', u'IN', u'NNS', u'JJ', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NNP', u'NNP', u'.'], u'char_offsets': [[28442, 28444], [28445, 28451], [28451, 28452], [28453, 28456], [28457, 28464], [28465, 28474], [28475, 28477], [28477, 28480], [28481, 28486], [28487, 28494], [28494, 28495], [28496, 28499], [28500, 28502], [28503, 28505], [28506, 28508], [28509, 28515], [28516, 28519], [28520, 28525], [28526, 28529], [28530, 28532], [28533, 28540], [28541, 28547], [28548, 28557], [28558, 28560], [28561, 28564], [28565, 28572], [28572, 28573], [28574, 28577], [28578, 28580], [28581, 28590], [28591, 28596], [28597, 28608], [28609, 28611], [28612, 28619], [28620, 28630], [28631, 28633], [28634, 28645], [28646, 28649], [28650, 28653], [28654, 28658], [28659, 28666], [28667, 28676], [28676, 28677]]}) 
answer: set([u'make', u'swahilus', u'subject', u'require', u'primary'])
candidate Sentence: (0.16400471329689026, {u'tokens': [u'When', u'the', u'noun', u'itself', u'does', u'not', u'make', u'clear', u'which', u'class', u'it', u'belongs', u'to', u',', u'its', u'concords', u'do', u'.'], u'lemmas': [u'when', u'the', u'noun', u'itself', u'do', u'not', u'make', u'clear', u'which', u'class', u'it', u'belong', u'to', u',', u'its', u'concord', u'do', u'.'], u'pos': [u'WRB', u'DT', u'NN', u'PRP', u'VBZ', u'RB', u'VB', u'JJ', u'WDT', u'NN', u'PRP', u'VBZ', u'TO', u',', u'PRP$', u'NNS', u'VBP', u'.'], u'char_offsets': [[8926, 8930], [8931, 8934], [8935, 8939], [8940, 8946], [8947, 8951], [8952, 8955], [8956, 8960], [8961, 8966], [8967, 8972], [8973, 8978], [8979, 8981], [8982, 8989], [8990, 8992], [8992, 8993], [8994, 8997], [8998, 9006], [9007, 9009], [9009, 9010]]}) 
answer: set([u'school', u'swahilus', u'primary', u'uganda', u'require', u'subject'])
candidate Sentence: (0.16231720149517059, {u'tokens': [u'Most', u'educated', u'Kenyans', u'are', u'able', u'to', u'communicate', u'fluently', u'in', u'Swahili', u',', u'since', u'it', u'is', u'a', u'compulsory', u'subject', u'in', u'school', u'from', u'grade', u'one', u'.'], u'lemmas': [u'most', u'educate', u'kenyan', u'be', u'able', u'to', u'communicate', u'fluently', u'in', u'Swahili', u',', u'since', u'it', u'be', u'a', u'compulsory', u'subject', u'in', u'school', u'from', u'grade', u'one', u'.'], u'pos': [u'JJS', u'VBN', u'NNS', u'VBP', u'JJ', u'TO', u'VB', u'RB', u'IN', u'NNP', u',', u'IN', u'PRP', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'NN', u'IN', u'NN', u'CD', u'.'], u'char_offsets': [[28049, 28053], [28054, 28062], [28063, 28070], [28071, 28074], [28075, 28079], [28080, 28082], [28083, 28094], [28096, 28104], [28105, 28107], [28108, 28115], [28115, 28116], [28117, 28122], [28123, 28125], [28126, 28128], [28129, 28130], [28131, 28141], [28142, 28149], [28150, 28152], [28153, 28159], [28160, 28164], [28165, 28170], [28171, 28174], [28174, 28175]]}) 
answer: set([u'swahilus', u'make', u'require', u'uganda', u'primary'])
candidate Sentence: (0.15981066226959229, {u'tokens': [u'The', u'British', u'did', u'not', u'do', u'so', u'in', u'neighbouring', u'Kenya', u',', u'even', u'though', u'they', u'made', u'moves', u'in', u'that', u'direction', u'.'], u'lemmas': [u'the', u'British', u'do', u'not', u'do', u'so', u'in', u'neighbour', u'Kenya', u',', u'even', u'though', u'they', u'make', u'move', u'in', u'that', u'direction', u'.'], u'pos': [u'DT', u'NNP', u'VBD', u'RB', u'VB', u'RB', u'IN', u'VBG', u'NNP', u',', u'RB', u'IN', u'PRP', u'VBD', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[26399, 26402], [26403, 26410], [26411, 26414], [26415, 26418], [26419, 26421], [26422, 26424], [26425, 26427], [26428, 26440], [26441, 26446], [26446, 26447], [26448, 26452], [26453, 26459], [26460, 26464], [26465, 26469], [26470, 26475], [26476, 26478], [26479, 26483], [26484, 26493], [26493, 26494]]}) 
answer: set([u'school', u'require', u'primary', u'uganda', u'swahilus', u'subject'])
candidate Sentence: (0.15490207076072693, {u'tokens': [u'The', u'end', u'result', u'is', u'a', u'semantic', u'net', u'that', u'made', u'sense', u'at', u'the', u'time', u',', u'and', u'often', u'still', u'does', u'make', u'sense', u',', u'but', u'which', u'can', u'be', u'confusing', u'to', u'a', u'non-speaker', u'.'], u'lemmas': [u'the', u'end', u'result', u'be', u'a', u'semantic', u'net', u'that', u'make', u'sense', u'at', u'the', u'time', u',', u'and', u'often', u'still', u'do', u'make', u'sense', u',', u'but', u'which', u'can', u'be', u'confuse', u'to', u'a', u'non-speaker', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBZ', u'DT', u'JJ', u'NN', u'WDT', u'VBD', u'NN', u'IN', u'DT', u'NN', u',', u'CC', u'RB', u'RB', u'VBZ', u'VB', u'NN', u',', u'CC', u'WDT', u'MD', u'VB', u'VBG', u'TO', u'DT', u'JJ', u'.'], u'char_offsets': [[10027, 10030], [10031, 10034], [10035, 10041], [10042, 10044], [10045, 10046], [10047, 10055], [10056, 10059], [10060, 10064], [10065, 10069], [10070, 10075], [10076, 10078], [10079, 10082], [10083, 10087], [10087, 10088], [10089, 10092], [10093, 10098], [10099, 10104], [10105, 10109], [10110, 10114], [10115, 10120], [10120, 10121], [10122, 10125], [10126, 10131], [10132, 10135], [10136, 10138], [10139, 10148], [10149, 10151], [10152, 10153], [10154, 10165], [10165, 10166]]}) 
answer: set([u'school', u'swahilus', u'primary', u'uganda', u'require', u'subject'])
candidate Sentence: (0.13706952333450317, {u'tokens': [u'The', u'British', u'authorities', u',', u'with', u'the', u'collaboration', u'of', u'British', u'Christian', u'missionary', u'institutions', u'active', u'in', u'these', u'colonies', u',', u'increased', u'their', u'resolve', u'to', u'institute', u'Swahili', u'as', u'a', u'common', u'language', u'for', u'primary', u'education', u'and', u'low', u'level', u'governance', u'throughout', u'their', u'East', u'African', u'colonies', u'-LRB-', u'Uganda', u',', u'Tanganyika', u',', u'Zanzibar', u',', u'and', u'Kenya', u'-RRB-', u'.'], u'lemmas': [u'the', u'british', u'authority', u',', u'with', u'the', u'collaboration', u'of', u'british', u'christian', u'missionary', u'institution', u'active', u'in', u'these', u'colony', u',', u'increase', u'they', u'resolve', u'to', u'institute', u'Swahili', u'as', u'a', u'common', u'language', u'for', u'primary', u'education', u'and', u'low', u'level', u'governance', u'throughout', u'they', u'east', u'african', u'colony', u'-lrb-', u'Uganda', u',', u'Tanganyika', u',', u'Zanzibar', u',', u'and', u'Kenya', u'-rrb-', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u',', u'IN', u'DT', u'NN', u'IN', u'JJ', u'JJ', u'JJ', u'NNS', u'JJ', u'IN', u'DT', u'NNS', u',', u'VBD', u'PRP$', u'NN', u'TO', u'VB', u'NNP', u'IN', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NN', u'CC', u'JJ', u'NN', u'NN', u'IN', u'PRP$', u'JJ', u'JJ', u'NNS', u'-LRB-', u'NNP', u',', u'NNP', u',', u'NNP', u',', u'CC', u'NNP', u'-RRB-', u'.'], u'char_offsets': [[26897, 26900], [26901, 26908], [26909, 26920], [26920, 26921], [26922, 26926], [26927, 26930], [26931, 26944], [26945, 26947], [26948, 26955], [26956, 26965], [26966, 26976], [26977, 26989], [26990, 26996], [26997, 26999], [27000, 27005], [27006, 27014], [27014, 27015], [27016, 27025], [27026, 27031], [27032, 27039], [27040, 27042], [27043, 27052], [27053, 27060], [27061, 27063], [27064, 27065], [27066, 27072], [27073, 27081], [27082, 27085], [27086, 27093], [27094, 27103], [27104, 27107], [27108, 27111], [27112, 27117], [27118, 27128], [27129, 27139], [27140, 27145], [27146, 27150], [27151, 27158], [27159, 27167], [27168, 27169], [27169, 27175], [27175, 27176], [27177, 27187], [27187, 27188], [27189, 27197], [27197, 27198], [27199, 27202], [27203, 27208], [27208, 27209], [27209, 27210]]}) 
answer: set([u'swahilus', u'subject', u'require', u'school', u'make'])
candidate Sentence: (0.11414574086666107, {u'tokens': [u'Swahili', u'verbs', u'consist', u'of', u'a', u'root', u'and', u'a', u'number', u'of', u'affixes', u'-LRB-', u'mostly', u'prefixes', u'-RRB-', u'which', u'can', u'be', u'attached', u'to', u'express', u'grammatical', u'persons', u',', u'tense', u',', u'and', u'subordinate', u'clauses', u',', u'which', u'require', u'a', u'conjunction', u'in', u'languages', u'such', u'as', u'English', u'.'], u'lemmas': [u'swahili', u'verb', u'consist', u'of', u'a', u'root', u'and', u'a', u'number', u'of', u'affix', u'-lrb-', u'mostly', u'prefix', u'-rrb-', u'which', u'can', u'be', u'attach', u'to', u'express', u'grammatical', u'person', u',', u'tense', u',', u'and', u'subordinate', u'clause', u',', u'which', u'require', u'a', u'conjunction', u'in', u'language', u'such', u'as', u'English', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'IN', u'DT', u'NN', u'CC', u'DT', u'NN', u'IN', u'NNS', u'-LRB-', u'RB', u'NNS', u'-RRB-', u'WDT', u'MD', u'VB', u'VBN', u'TO', u'VB', u'JJ', u'NNS', u',', u'JJ', u',', u'CC', u'JJ', u'NNS', u',', u'WDT', u'VBP', u'DT', u'NN', u'IN', u'NNS', u'JJ', u'IN', u'NNP', u'.'], u'char_offsets': [[17818, 17825], [17826, 17831], [17832, 17839], [17840, 17842], [17843, 17844], [17845, 17849], [17850, 17853], [17854, 17855], [17856, 17862], [17863, 17865], [17866, 17873], [17874, 17875], [17875, 17881], [17882, 17890], [17890, 17891], [17892, 17897], [17898, 17901], [17902, 17904], [17905, 17913], [17914, 17916], [17917, 17924], [17925, 17936], [17937, 17944], [17944, 17945], [17946, 17951], [17951, 17952], [17953, 17956], [17957, 17968], [17969, 17976], [17976, 17977], [17978, 17983], [17984, 17991], [17992, 17993], [17994, 18005], [18006, 18008], [18009, 18018], [18019, 18023], [18024, 18026], [18027, 18034], [18034, 18035]]}) 
answer: set([u'school', u'swahilus', u'primary', u'uganda', u'make', u'subject'])
candidate Sentence: (0.10530249774456024, {u'tokens': [u'In', u'Standard', u'Swahili', u',', u'human', u'subjects', u'and', u'objects', u'of', u'whatever', u'class', u'trigger', u'animacy', u'concord', u'in', u'a', u'-', u',', u'wa', u'-', u'and', u'm', u'-', u',', u'wa', u'-', u',', u'while', u'non-human', u'subjects', u'and', u'objects', u'trigger', u'a', u'variety', u'of', u'gender-concord', u'prefixes', u'.'], u'lemmas': [u'in', u'Standard', u'Swahili', u',', u'human', u'subject', u'and', u'object', u'of', u'whatever', u'class', u'trigger', u'animacy', u'concord', u'in', u'a', u'-', u',', u'wa', u'-', u'and', u'm', u'-', u',', u'wa', u'-', u',', u'while', u'non-human', u'subject', u'and', u'object', u'trigger', u'a', u'variety', u'of', u'gender-concord', u'prefix', u'.'], u'pos': [u'IN', u'NNP', u'NNP', u',', u'JJ', u'NNS', u'CC', u'NNS', u'IN', u'WDT', u'NN', u'NN', u'NN', u'NN', u'IN', u'DT', u':', u',', u'SYM', u':', u'CC', u'NN', u':', u',', u'SYM', u':', u',', u'IN', u'JJ', u'NNS', u'CC', u'NNS', u'VBP', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[20723, 20725], [20726, 20734], [20735, 20742], [20742, 20743], [20744, 20749], [20750, 20758], [20759, 20762], [20763, 20770], [20771, 20773], [20774, 20782], [20783, 20788], [20789, 20796], [20797, 20804], [20805, 20812], [20813, 20815], [20816, 20817], [20817, 20818], [20818, 20819], [20820, 20822], [20822, 20823], [20824, 20827], [20828, 20829], [20829, 20830], [20830, 20831], [20832, 20834], [20834, 20835], [20835, 20836], [20837, 20842], [20843, 20852], [20853, 20861], [20862, 20865], [20866, 20873], [20874, 20881], [20882, 20883], [20884, 20891], [20892, 20894], [20895, 20909], [20910, 20918], [20918, 20919]]}) 
answer: set([u'school', u'swahilus', u'require', u'primary', u'uganda', u'make'])

Did Uganda make Swahili a required subject in primary schools?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, Uganda made Swahili a required subject in primary schools.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, Uganda made Swahili a required subject in primary schools.')
 +    where 'Yes, Uganda made Swahili a required subject in primary schools.' = <src.question_processing.Question_parser instance at 0x1114dd320>.answer
_____________________________ test_yesno[param284] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114dd368>, (<src.tfidf.TF_IDF object at 0x10a4ac9d0>, set(['language', 'swahili', 'swahili_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114dd368>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.39814144372940063, {u'tokens': [u'The', u'neighboring', u'nation', u'of', u'Uganda', u'made', u'Swahili', u'a', u'required', u'subject', u'in', u'primary', u'schools', u'in', u'1992', u'--', u'although', u'this', u'mandate', u'has', u'not', u'been', u'well', u'implemented', u'--', u'and', u'declared', u'it', u'an', u'official', u'language', u'in', u'2005', u'in', u'preparation', u'for', u'the', u'East', u'African', u'Federation', u'.'], u'lemmas': [u'the', u'neighboring', u'nation', u'of', u'Uganda', u'make', u'Swahili', u'a', u'require', u'subject', u'in', u'primary', u'school', u'in', u'1992', u'--', u'although', u'this', u'mandate', u'have', u'not', u'be', u'well', u'implement', u'--', u'and', u'declare', u'it', u'a', u'official', u'language', u'in', u'2005', u'in', u'preparation', u'for', u'the', u'east', u'african', u'Federation', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'NNP', u'VBD', u'NNP', u'DT', u'VBN', u'NN', u'IN', u'JJ', u'NNS', u'IN', u'CD', u':', u'IN', u'DT', u'NN', u'VBZ', u'RB', u'VBN', u'RB', u'VBN', u':', u'CC', u'VBD', u'PRP', u'DT', u'JJ', u'NN', u'IN', u'CD', u'IN', u'NN', u'IN', u'DT', u'JJ', u'JJ', u'NNP', u'.'], u'char_offsets': [[1240, 1243], [1244, 1255], [1256, 1262], [1263, 1265], [1266, 1272], [1273, 1277], [1278, 1285], [1286, 1287], [1288, 1296], [1297, 1304], [1305, 1307], [1308, 1315], [1316, 1323], [1324, 1326], [1327, 1331], [1331, 1332], [1332, 1340], [1341, 1345], [1346, 1353], [1354, 1357], [1358, 1361], [1362, 1366], [1367, 1371], [1372, 1383], [1383, 1384], [1384, 1387], [1388, 1396], [1397, 1399], [1400, 1402], [1403, 1411], [1412, 1420], [1421, 1423], [1424, 1428], [1429, 1431], [1432, 1443], [1444, 1447], [1448, 1451], [1452, 1456], [1457, 1464], [1465, 1475], [1475, 1476]]}) 
answer: set([u'swahilus'])
candidate Sentence: (0.22213453054428101, {u'tokens': [u'Education', u'for', u'all', u'--', u'in', u'whose', u'language', u'?'], u'lemmas': [u'education', u'for', u'all', u'--', u'in', u'whose', u'language', u'?'], u'pos': [u'NN', u'IN', u'DT', u':', u'IN', u'WP$', u'NN', u'.'], u'char_offsets': [[29579, 29588], [29589, 29592], [29593, 29596], [29597, 29598], [29599, 29601], [29602, 29607], [29608, 29616], [29616, 29617]]}) 
answer: set([u'school', u'require', u'primary', u'uganda', u'subject', u'swahilus', u'make'])
candidate Sentence: (0.19435977935791016, {u'tokens': [u'In', u'Uganda', u',', u'the', u'Baganda', u'generally', u'do', u"n't", u'speak', u'Swahili', u',', u'but', u'it', u'is', u'in', u'common', u'use', u'among', u'the', u'25', u'million', u'people', u'elsewhere', u'in', u'the', u'country', u',', u'and', u'is', u'currently', u'being', u'implemented', u'in', u'schools', u'nationwide', u'in', u'preparation', u'for', u'the', u'East', u'African', u'Community', u'.'], u'lemmas': [u'in', u'Uganda', u',', u'the', u'Baganda', u'generally', u'do', u'not', u'speak', u'Swahili', u',', u'but', u'it', u'be', u'in', u'common', u'use', u'among', u'the', u'25', u'million', u'people', u'elsewhere', u'in', u'the', u'country', u',', u'and', u'be', u'currently', u'be', u'implement', u'in', u'school', u'nationwide', u'in', u'preparation', u'for', u'the', u'east', u'African', u'Community', u'.'], u'pos': [u'IN', u'NNP', u',', u'DT', u'NNP', u'RB', u'VBP', u'RB', u'VB', u'NNP', u',', u'CC', u'PRP', u'VBZ', u'IN', u'JJ', u'NN', u'IN', u'DT', u'CD', u'CD', u'NNS', u'RB', u'IN', u'DT', u'NN', u',', u'CC', u'VBZ', u'RB', u'VBG', u'VBN', u'IN', u'NNS', u'JJ', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NNP', u'NNP', u'.'], u'char_offsets': [[28442, 28444], [28445, 28451], [28451, 28452], [28453, 28456], [28457, 28464], [28465, 28474], [28475, 28477], [28477, 28480], [28481, 28486], [28487, 28494], [28494, 28495], [28496, 28499], [28500, 28502], [28503, 28505], [28506, 28508], [28509, 28515], [28516, 28519], [28520, 28525], [28526, 28529], [28530, 28532], [28533, 28540], [28541, 28547], [28548, 28557], [28558, 28560], [28561, 28564], [28565, 28572], [28572, 28573], [28574, 28577], [28578, 28580], [28581, 28590], [28591, 28596], [28597, 28608], [28609, 28611], [28612, 28619], [28620, 28630], [28631, 28633], [28634, 28645], [28646, 28649], [28650, 28653], [28654, 28658], [28659, 28666], [28667, 28676], [28676, 28677]]}) 
answer: set([u'make', u'swahilus', u'subject', u'require', u'primary'])
candidate Sentence: (0.16400471329689026, {u'tokens': [u'When', u'the', u'noun', u'itself', u'does', u'not', u'make', u'clear', u'which', u'class', u'it', u'belongs', u'to', u',', u'its', u'concords', u'do', u'.'], u'lemmas': [u'when', u'the', u'noun', u'itself', u'do', u'not', u'make', u'clear', u'which', u'class', u'it', u'belong', u'to', u',', u'its', u'concord', u'do', u'.'], u'pos': [u'WRB', u'DT', u'NN', u'PRP', u'VBZ', u'RB', u'VB', u'JJ', u'WDT', u'NN', u'PRP', u'VBZ', u'TO', u',', u'PRP$', u'NNS', u'VBP', u'.'], u'char_offsets': [[8926, 8930], [8931, 8934], [8935, 8939], [8940, 8946], [8947, 8951], [8952, 8955], [8956, 8960], [8961, 8966], [8967, 8972], [8973, 8978], [8979, 8981], [8982, 8989], [8990, 8992], [8992, 8993], [8994, 8997], [8998, 9006], [9007, 9009], [9009, 9010]]}) 
answer: set([u'school', u'swahilus', u'primary', u'uganda', u'require', u'subject'])
candidate Sentence: (0.16231720149517059, {u'tokens': [u'Most', u'educated', u'Kenyans', u'are', u'able', u'to', u'communicate', u'fluently', u'in', u'Swahili', u',', u'since', u'it', u'is', u'a', u'compulsory', u'subject', u'in', u'school', u'from', u'grade', u'one', u'.'], u'lemmas': [u'most', u'educate', u'kenyan', u'be', u'able', u'to', u'communicate', u'fluently', u'in', u'Swahili', u',', u'since', u'it', u'be', u'a', u'compulsory', u'subject', u'in', u'school', u'from', u'grade', u'one', u'.'], u'pos': [u'JJS', u'VBN', u'NNS', u'VBP', u'JJ', u'TO', u'VB', u'RB', u'IN', u'NNP', u',', u'IN', u'PRP', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'NN', u'IN', u'NN', u'CD', u'.'], u'char_offsets': [[28049, 28053], [28054, 28062], [28063, 28070], [28071, 28074], [28075, 28079], [28080, 28082], [28083, 28094], [28096, 28104], [28105, 28107], [28108, 28115], [28115, 28116], [28117, 28122], [28123, 28125], [28126, 28128], [28129, 28130], [28131, 28141], [28142, 28149], [28150, 28152], [28153, 28159], [28160, 28164], [28165, 28170], [28171, 28174], [28174, 28175]]}) 
answer: set([u'swahilus', u'make', u'require', u'uganda', u'primary'])
candidate Sentence: (0.15981066226959229, {u'tokens': [u'The', u'British', u'did', u'not', u'do', u'so', u'in', u'neighbouring', u'Kenya', u',', u'even', u'though', u'they', u'made', u'moves', u'in', u'that', u'direction', u'.'], u'lemmas': [u'the', u'British', u'do', u'not', u'do', u'so', u'in', u'neighbour', u'Kenya', u',', u'even', u'though', u'they', u'make', u'move', u'in', u'that', u'direction', u'.'], u'pos': [u'DT', u'NNP', u'VBD', u'RB', u'VB', u'RB', u'IN', u'VBG', u'NNP', u',', u'RB', u'IN', u'PRP', u'VBD', u'NNS', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[26399, 26402], [26403, 26410], [26411, 26414], [26415, 26418], [26419, 26421], [26422, 26424], [26425, 26427], [26428, 26440], [26441, 26446], [26446, 26447], [26448, 26452], [26453, 26459], [26460, 26464], [26465, 26469], [26470, 26475], [26476, 26478], [26479, 26483], [26484, 26493], [26493, 26494]]}) 
answer: set([u'school', u'require', u'primary', u'uganda', u'swahilus', u'subject'])
candidate Sentence: (0.15490207076072693, {u'tokens': [u'The', u'end', u'result', u'is', u'a', u'semantic', u'net', u'that', u'made', u'sense', u'at', u'the', u'time', u',', u'and', u'often', u'still', u'does', u'make', u'sense', u',', u'but', u'which', u'can', u'be', u'confusing', u'to', u'a', u'non-speaker', u'.'], u'lemmas': [u'the', u'end', u'result', u'be', u'a', u'semantic', u'net', u'that', u'make', u'sense', u'at', u'the', u'time', u',', u'and', u'often', u'still', u'do', u'make', u'sense', u',', u'but', u'which', u'can', u'be', u'confuse', u'to', u'a', u'non-speaker', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBZ', u'DT', u'JJ', u'NN', u'WDT', u'VBD', u'NN', u'IN', u'DT', u'NN', u',', u'CC', u'RB', u'RB', u'VBZ', u'VB', u'NN', u',', u'CC', u'WDT', u'MD', u'VB', u'VBG', u'TO', u'DT', u'JJ', u'.'], u'char_offsets': [[10027, 10030], [10031, 10034], [10035, 10041], [10042, 10044], [10045, 10046], [10047, 10055], [10056, 10059], [10060, 10064], [10065, 10069], [10070, 10075], [10076, 10078], [10079, 10082], [10083, 10087], [10087, 10088], [10089, 10092], [10093, 10098], [10099, 10104], [10105, 10109], [10110, 10114], [10115, 10120], [10120, 10121], [10122, 10125], [10126, 10131], [10132, 10135], [10136, 10138], [10139, 10148], [10149, 10151], [10152, 10153], [10154, 10165], [10165, 10166]]}) 
answer: set([u'school', u'swahilus', u'primary', u'uganda', u'require', u'subject'])
candidate Sentence: (0.13706952333450317, {u'tokens': [u'The', u'British', u'authorities', u',', u'with', u'the', u'collaboration', u'of', u'British', u'Christian', u'missionary', u'institutions', u'active', u'in', u'these', u'colonies', u',', u'increased', u'their', u'resolve', u'to', u'institute', u'Swahili', u'as', u'a', u'common', u'language', u'for', u'primary', u'education', u'and', u'low', u'level', u'governance', u'throughout', u'their', u'East', u'African', u'colonies', u'-LRB-', u'Uganda', u',', u'Tanganyika', u',', u'Zanzibar', u',', u'and', u'Kenya', u'-RRB-', u'.'], u'lemmas': [u'the', u'british', u'authority', u',', u'with', u'the', u'collaboration', u'of', u'british', u'christian', u'missionary', u'institution', u'active', u'in', u'these', u'colony', u',', u'increase', u'they', u'resolve', u'to', u'institute', u'Swahili', u'as', u'a', u'common', u'language', u'for', u'primary', u'education', u'and', u'low', u'level', u'governance', u'throughout', u'they', u'east', u'african', u'colony', u'-lrb-', u'Uganda', u',', u'Tanganyika', u',', u'Zanzibar', u',', u'and', u'Kenya', u'-rrb-', u'.'], u'pos': [u'DT', u'JJ', u'NNS', u',', u'IN', u'DT', u'NN', u'IN', u'JJ', u'JJ', u'JJ', u'NNS', u'JJ', u'IN', u'DT', u'NNS', u',', u'VBD', u'PRP$', u'NN', u'TO', u'VB', u'NNP', u'IN', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'NN', u'CC', u'JJ', u'NN', u'NN', u'IN', u'PRP$', u'JJ', u'JJ', u'NNS', u'-LRB-', u'NNP', u',', u'NNP', u',', u'NNP', u',', u'CC', u'NNP', u'-RRB-', u'.'], u'char_offsets': [[26897, 26900], [26901, 26908], [26909, 26920], [26920, 26921], [26922, 26926], [26927, 26930], [26931, 26944], [26945, 26947], [26948, 26955], [26956, 26965], [26966, 26976], [26977, 26989], [26990, 26996], [26997, 26999], [27000, 27005], [27006, 27014], [27014, 27015], [27016, 27025], [27026, 27031], [27032, 27039], [27040, 27042], [27043, 27052], [27053, 27060], [27061, 27063], [27064, 27065], [27066, 27072], [27073, 27081], [27082, 27085], [27086, 27093], [27094, 27103], [27104, 27107], [27108, 27111], [27112, 27117], [27118, 27128], [27129, 27139], [27140, 27145], [27146, 27150], [27151, 27158], [27159, 27167], [27168, 27169], [27169, 27175], [27175, 27176], [27177, 27187], [27187, 27188], [27189, 27197], [27197, 27198], [27199, 27202], [27203, 27208], [27208, 27209], [27209, 27210]]}) 
answer: set([u'swahilus', u'subject', u'require', u'school', u'make'])
candidate Sentence: (0.11414574086666107, {u'tokens': [u'Swahili', u'verbs', u'consist', u'of', u'a', u'root', u'and', u'a', u'number', u'of', u'affixes', u'-LRB-', u'mostly', u'prefixes', u'-RRB-', u'which', u'can', u'be', u'attached', u'to', u'express', u'grammatical', u'persons', u',', u'tense', u',', u'and', u'subordinate', u'clauses', u',', u'which', u'require', u'a', u'conjunction', u'in', u'languages', u'such', u'as', u'English', u'.'], u'lemmas': [u'swahili', u'verb', u'consist', u'of', u'a', u'root', u'and', u'a', u'number', u'of', u'affix', u'-lrb-', u'mostly', u'prefix', u'-rrb-', u'which', u'can', u'be', u'attach', u'to', u'express', u'grammatical', u'person', u',', u'tense', u',', u'and', u'subordinate', u'clause', u',', u'which', u'require', u'a', u'conjunction', u'in', u'language', u'such', u'as', u'English', u'.'], u'pos': [u'JJ', u'NNS', u'VBP', u'IN', u'DT', u'NN', u'CC', u'DT', u'NN', u'IN', u'NNS', u'-LRB-', u'RB', u'NNS', u'-RRB-', u'WDT', u'MD', u'VB', u'VBN', u'TO', u'VB', u'JJ', u'NNS', u',', u'JJ', u',', u'CC', u'JJ', u'NNS', u',', u'WDT', u'VBP', u'DT', u'NN', u'IN', u'NNS', u'JJ', u'IN', u'NNP', u'.'], u'char_offsets': [[17818, 17825], [17826, 17831], [17832, 17839], [17840, 17842], [17843, 17844], [17845, 17849], [17850, 17853], [17854, 17855], [17856, 17862], [17863, 17865], [17866, 17873], [17874, 17875], [17875, 17881], [17882, 17890], [17890, 17891], [17892, 17897], [17898, 17901], [17902, 17904], [17905, 17913], [17914, 17916], [17917, 17924], [17925, 17936], [17937, 17944], [17944, 17945], [17946, 17951], [17951, 17952], [17953, 17956], [17957, 17968], [17969, 17976], [17976, 17977], [17978, 17983], [17984, 17991], [17992, 17993], [17994, 18005], [18006, 18008], [18009, 18018], [18019, 18023], [18024, 18026], [18027, 18034], [18034, 18035]]}) 
answer: set([u'school', u'swahilus', u'primary', u'uganda', u'make', u'subject'])
candidate Sentence: (0.10530249774456024, {u'tokens': [u'In', u'Standard', u'Swahili', u',', u'human', u'subjects', u'and', u'objects', u'of', u'whatever', u'class', u'trigger', u'animacy', u'concord', u'in', u'a', u'-', u',', u'wa', u'-', u'and', u'm', u'-', u',', u'wa', u'-', u',', u'while', u'non-human', u'subjects', u'and', u'objects', u'trigger', u'a', u'variety', u'of', u'gender-concord', u'prefixes', u'.'], u'lemmas': [u'in', u'Standard', u'Swahili', u',', u'human', u'subject', u'and', u'object', u'of', u'whatever', u'class', u'trigger', u'animacy', u'concord', u'in', u'a', u'-', u',', u'wa', u'-', u'and', u'm', u'-', u',', u'wa', u'-', u',', u'while', u'non-human', u'subject', u'and', u'object', u'trigger', u'a', u'variety', u'of', u'gender-concord', u'prefix', u'.'], u'pos': [u'IN', u'NNP', u'NNP', u',', u'JJ', u'NNS', u'CC', u'NNS', u'IN', u'WDT', u'NN', u'NN', u'NN', u'NN', u'IN', u'DT', u':', u',', u'SYM', u':', u'CC', u'NN', u':', u',', u'SYM', u':', u',', u'IN', u'JJ', u'NNS', u'CC', u'NNS', u'VBP', u'DT', u'NN', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[20723, 20725], [20726, 20734], [20735, 20742], [20742, 20743], [20744, 20749], [20750, 20758], [20759, 20762], [20763, 20770], [20771, 20773], [20774, 20782], [20783, 20788], [20789, 20796], [20797, 20804], [20805, 20812], [20813, 20815], [20816, 20817], [20817, 20818], [20818, 20819], [20820, 20822], [20822, 20823], [20824, 20827], [20828, 20829], [20829, 20830], [20830, 20831], [20832, 20834], [20834, 20835], [20835, 20836], [20837, 20842], [20843, 20852], [20853, 20861], [20862, 20865], [20866, 20873], [20874, 20881], [20882, 20883], [20884, 20891], [20892, 20894], [20895, 20909], [20910, 20918], [20918, 20919]]}) 
answer: set([u'school', u'swahilus', u'require', u'primary', u'uganda', u'make'])

Did Uganda make Swahili a required subject in primary schools?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114dd368>.answer
_____________________________ test_yesno[param289] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114dd4d0>, (<src.tfidf.TF_IDF object at 0x10a4d4f90>, set(['taipei'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('Taipei is in the valleys of the Keelung and Xindian Rivers') == True
E                +  where 'Taipei is in the valleys of the Keelung and Xindian Rivers' = <src.question_processing.Question_parser instance at 0x1114dd4d0>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.19104708731174469, {u'tokens': [u'Taipei', u'lies', u'in', u'the', u'two', u'relatively', u'narrow', u'valleys', u'of', u'the', u'Keelung', u'-LRB-', u'\u57fa\u9686\u6cb3', u'-RRB-', u'and', u'Xindian', u'-LRB-', u'\u65b0\u5e97\u6eaa', u'-RRB-', u'Rivers', u',', u'which', u'join', u'to', u'form', u'the', u'Danshui', u'River', u'along', u'the', u'city', u"'s", u'western', u'border', u'.'], u'lemmas': [u'Taipei', u'lie', u'in', u'the', u'two', u'relatively', u'narrow', u'valley', u'of', u'the', u'Keelung', u'-lrb-', u'\u57fa\u9686\u6cb3', u'-rrb-', u'and', u'xindian', u'-lrb-', u'\u65b0\u5e97\u6eaa', u'-rrb-', u'Rivers', u',', u'which', u'join', u'to', u'form', u'the', u'Danshui', u'River', u'along', u'the', u'city', u"'s", u'western', u'border', u'.'], u'pos': [u'NNP', u'VBZ', u'IN', u'DT', u'CD', u'RB', u'JJ', u'NNS', u'IN', u'DT', u'NNP', u'-LRB-', u'CD', u'-RRB-', u'CC', u'NN', u'-LRB-', u'CD', u'-RRB-', u'NNP', u',', u'WDT', u'VBP', u'TO', u'VB', u'DT', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'POS', u'JJ', u'NN', u'.'], u'char_offsets': [[471, 477], [478, 482], [483, 485], [486, 489], [490, 493], [494, 504], [505, 511], [512, 519], [520, 522], [523, 526], [527, 534], [535, 536], [536, 539], [539, 540], [541, 544], [545, 552], [553, 554], [554, 557], [557, 558], [559, 565], [565, 566], [567, 572], [573, 577], [578, 580], [581, 585], [586, 589], [590, 597], [598, 603], [604, 609], [610, 613], [614, 618], [618, 620], [621, 628], [629, 635], [635, 636]]}) 
answer: set([])
candidate Sentence: (0.079398036003112793, {u'tokens': [u'*', u'Te-sheng', u'Wei', u"'s", u'Cape', u'No.', u'7', u'-LRB-', u'drama/comedy', u'-RRB-', u'*', u'Yun', u'Fu', u"'s", u'Take', u'Me', u'From', u'Behind', u'-LRB-', u'music', u'video', u'-RRB-', u'*', u'Jack', u'Yu', u"'s", u'Lollipop', u'Love', u'-LRB-', u'music', u'video', u'-RRB-', u'*', u'Edward', u'Yang', u"'s", u'A', u'Brighter', u'Summer', u'Day', u'-LRB-', u'drama', u'-RRB-', u'*', u'Lee', u'Kang-sheng', u"'s", u'Help', u'Me', u'Eros', u'-LRB-', u'drama', u'-RRB-', u'*', u'Tsai', u'Ming-liang', u"'s", u'Vive', u"L'Amour", u'-LRB-', u'drama', u'-RRB-', u'*', u'Tsai', u'Ming-liang', u"'s", u'What', u'Time', u'Is', u'It', u'There', u'?'], u'lemmas': [u'*', u'te-sheng', u'Wei', u"'s", u'Cape', u'no.', u'7', u'-lrb-', u'drama/comedy', u'-rrb-', u'*', u'Yun', u'Fu', u"'s", u'take', u'I', u'from', u'behind', u'-lrb-', u'music', u'video', u'-rrb-', u'*', u'Jack', u'Yu', u"'s", u'Lollipop', u'Love', u'-lrb-', u'music', u'video', u'-rrb-', u'*', u'Edward', u'Yang', u"'s", u'a', u'brighter', u'summer', u'day', u'-lrb-', u'drama', u'-rrb-', u'*', u'Lee', u'Kang-sheng', u"'s", u'help', u'I', u'Eros', u'-lrb-', u'drama', u'-rrb-', u'*', u'Tsai', u'Ming-liang', u"'s", u'Vive', u"L'Amour", u'-lrb-', u'drama', u'-rrb-', u'*', u'Tsai', u'Ming-liang', u"'s", u'what', u'Time', u'be', u'it', u'there', u'?'], u'pos': [u'SYM', u'NN', u'NNP', u'POS', u'NNP', u'NN', u'CD', u'-LRB-', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'POS', u'VB', u'PRP', u'IN', u'IN', u'-LRB-', u'NN', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'POS', u'NNP', u'NNP', u'-LRB-', u'NN', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'POS', u'DT', u'JJR', u'NN', u'NN', u'-LRB-', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'POS', u'NN', u'PRP', u'NNPS', u'-LRB-', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'POS', u'NNP', u'NNP', u'-LRB-', u'NN', u'-RRB-', u'SYM', u'NNP', u'NNP', u'POS', u'WDT', u'NNP', u'VBZ', u'PRP', u'EX', u'.'], u'char_offsets': [[11684, 11685], [11685, 11693], [11694, 11697], [11697, 11699], [11700, 11704], [11705, 11708], [11709, 11710], [11711, 11712], [11712, 11724], [11724, 11725], [11726, 11727], [11727, 11730], [11731, 11733], [11733, 11735], [11736, 11740], [11741, 11743], [11744, 11748], [11749, 11755], [11756, 11757], [11757, 11762], [11763, 11768], [11768, 11769], [11770, 11771], [11771, 11775], [11776, 11778], [11778, 11780], [11781, 11789], [11790, 11794], [11795, 11796], [11796, 11801], [11802, 11807], [11807, 11808], [11809, 11810], [11810, 11816], [11817, 11821], [11821, 11823], [11824, 11825], [11826, 11834], [11835, 11841], [11842, 11845], [11846, 11847], [11847, 11852], [11852, 11853], [11854, 11855], [11855, 11858], [11859, 11869], [11869, 11871], [11872, 11876], [11877, 11879], [11880, 11884], [11885, 11886], [11886, 11891], [11891, 11892], [11893, 11894], [11894, 11898], [11899, 11909], [11909, 11911], [11912, 11916], [11917, 11924], [11925, 11926], [11926, 11931], [11931, 11932], [11933, 11934], [11934, 11938], [11939, 11949], [11949, 11951], [11952, 11956], [11957, 11961], [11962, 11964], [11965, 11967], [11968, 11973], [11973, 11974]]}) 
answer: set([u'valley'])
candidate Sentence: (0.047226514667272568, {u'tokens': [u'Taipei', u'City', u'is', u'located', u'in', u'the', u'Taipei', u'Basin', u'in', u'northern', u'Taiwan', u'.'], u'lemmas': [u'Taipei', u'City', u'be', u'located', u'in', u'the', u'Taipei', u'Basin', u'in', u'northern', u'Taiwan', u'.'], u'pos': [u'NNP', u'NNP', u'VBZ', u'JJ', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'JJ', u'NNP', u'.'], u'char_offsets': [[13231, 13237], [13238, 13242], [13243, 13245], [13246, 13253], [13254, 13256], [13257, 13260], [13261, 13267], [13268, 13273], [13274, 13276], [13277, 13285], [13286, 13292], [13292, 13293]]}) 
answer: set([u'valley'])
candidate Sentence: (0.040846370160579681, {u'tokens': [u'The', u'mayor', u'of', u'Taipei', u'City', u'had', u'been', u'an', u'appointed', u'position', u'since', u'Taipei', u"'s", u'conversion', u'to', u'a', u'centrally-administered', u'municipality', u'in', u'1967', u'until', u'the', u'first', u'public', u'election', u'was', u'held', u'in', u'1994', u'.'], u'lemmas': [u'the', u'mayor', u'of', u'Taipei', u'City', u'have', u'be', u'a', u'appoint', u'position', u'since', u'Taipei', u"'s", u'conversion', u'to', u'a', u'centrally-administered', u'municipality', u'in', u'1967', u'until', u'the', u'first', u'public', u'election', u'be', u'hold', u'in', u'1994', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NNP', u'NNP', u'VBD', u'VBN', u'DT', u'VBN', u'NN', u'IN', u'NNP', u'POS', u'NN', u'TO', u'DT', u'JJ', u'NN', u'IN', u'CD', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'VBD', u'VBN', u'IN', u'CD', u'.'], u'char_offsets': [[22377, 22380], [22381, 22386], [22387, 22389], [22390, 22396], [22397, 22401], [22402, 22405], [22406, 22410], [22411, 22413], [22414, 22423], [22424, 22432], [22433, 22438], [22439, 22445], [22445, 22447], [22448, 22458], [22459, 22461], [22462, 22463], [22464, 22486], [22487, 22499], [22500, 22502], [22503, 22507], [22508, 22513], [22514, 22517], [22518, 22523], [22524, 22530], [22531, 22539], [22540, 22543], [22544, 22548], [22549, 22551], [22552, 22556], [22556, 22557]]}) 
answer: set([u'valley'])
candidate Sentence: (0.038070954382419586, {u'tokens': [u'It', u'is', u'a', u'public', u'university', u'with', u'campuses', u'in', u'both', u'Taipei', u'and', u'Hsinchu', u'.'], u'lemmas': [u'it', u'be', u'a', u'public', u'university', u'with', u'campus', u'in', u'both', u'Taipei', u'and', u'Hsinchu', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'NNS', u'IN', u'DT', u'NNP', u'CC', u'NNP', u'.'], u'char_offsets': [[26241, 26243], [26244, 26246], [26247, 26248], [26249, 26255], [26256, 26266], [26267, 26271], [26272, 26280], [26281, 26283], [26284, 26288], [26289, 26295], [26296, 26299], [26300, 26307], [26307, 26308]]}) 
answer: set([u'valley'])
candidate Sentence: (0.037459775805473328, {u'tokens': [u'Taipei', u'is', u'part', u'of', u'a', u'major', u'industrial', u'area', u'.'], u'lemmas': [u'Taipei', u'be', u'part', u'of', u'a', u'major', u'industrial', u'area', u'.'], u'pos': [u'NNP', u'VBZ', u'NN', u'IN', u'DT', u'JJ', u'JJ', u'NN', u'.'], u'char_offsets': [[969, 975], [976, 978], [979, 983], [984, 986], [987, 988], [989, 994], [995, 1005], [1006, 1010], [1010, 1011]]}) 
answer: set([u'valley'])
candidate Sentence: (0.033871188759803772, {u'tokens': [u'It', u'was', u'designed', u'by', u'Archasia', u',', u'an', u'architectural', u'firm', u'established', u'in', u'Taipei', u'.'], u'lemmas': [u'it', u'be', u'design', u'by', u'Archasia', u',', u'a', u'architectural', u'firm', u'establish', u'in', u'Taipei', u'.'], u'pos': [u'PRP', u'VBD', u'VBN', u'IN', u'NNP', u',', u'DT', u'JJ', u'NN', u'VBN', u'IN', u'NNP', u'.'], u'char_offsets': [[28724, 28726], [28727, 28730], [28731, 28739], [28740, 28742], [28743, 28751], [28751, 28752], [28753, 28755], [28756, 28769], [28770, 28774], [28775, 28786], [28787, 28789], [28790, 28796], [28796, 28797]]}) 
answer: set([u'valley'])
candidate Sentence: (0.031249720603227615, {u'tokens': [u'In', u'1886', u',', u'when', u'Taiwan', u'was', u'proclaimed', u'a', u'province', u'of', u'China', u',', u'Taipei', u'city', u'was', u'made', u'the', u'provincial', u'capital', u'.'], u'lemmas': [u'in', u'1886', u',', u'when', u'Taiwan', u'be', u'proclaim', u'a', u'province', u'of', u'China', u',', u'Taipei', u'city', u'be', u'make', u'the', u'provincial', u'capital', u'.'], u'pos': [u'IN', u'CD', u',', u'WRB', u'NNP', u'VBD', u'VBN', u'DT', u'NN', u'IN', u'NNP', u',', u'NNP', u'NN', u'VBD', u'VBN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[17132, 17134], [17135, 17139], [17139, 17140], [17141, 17145], [17146, 17152], [17153, 17156], [17157, 17167], [17168, 17169], [17170, 17178], [17179, 17181], [17182, 17187], [17187, 17188], [17189, 17195], [17196, 17200], [17201, 17204], [17205, 17209], [17210, 17213], [17214, 17224], [17225, 17232], [17232, 17233]]}) 
answer: set([u'valley'])
candidate Sentence: (0.031138071790337563, {u'tokens': [u'In', u'2001', u',', u'Museum', u'of', u'Contemporary', u'Art', u'Taipei', u'-LRB-', u'\u53f0\u5317\u7576\u4ee3\u85dd\u8853\u9928', u';', u'MOCA', u'Taipei', u'-RRB-', u'was', u'established', u'in', u'the', u'Taipei', u'City', u'government', u'old', u'building', u'.'], u'lemmas': [u'in', u'2001', u',', u'museum', u'of', u'Contemporary', u'Art', u'Taipei', u'-lrb-', u'\u53f0\u5317\u7576\u4ee3\u85dd\u8853\u9928', u';', u'MOCA', u'Taipei', u'-rrb-', u'be', u'establish', u'in', u'the', u'Taipei', u'City', u'government', u'old', u'building', u'.'], u'pos': [u'IN', u'CD', u',', u'NN', u'IN', u'NNP', u'NNP', u'NNP', u'-LRB-', u'CD', u':', u'NNP', u'NNP', u'-RRB-', u'VBD', u'VBN', u'IN', u'DT', u'NNP', u'NNP', u'NN', u'JJ', u'NN', u'.'], u'char_offsets': [[4571, 4573], [4574, 4578], [4578, 4579], [4580, 4586], [4587, 4589], [4590, 4602], [4603, 4606], [4607, 4613], [4614, 4615], [4615, 4622], [4622, 4623], [4623, 4627], [4628, 4634], [4634, 4635], [4636, 4639], [4640, 4651], [4652, 4654], [4655, 4658], [4659, 4665], [4666, 4670], [4671, 4681], [4682, 4685], [4686, 4694], [4694, 4695]]}) 
answer: set([u'valley'])
candidate Sentence: (0.030810713768005371, {u'tokens': [u'The', u'same', u'design', u'process', u'is', u'also', u'in', u'place', u'for', u'a', u'new', u'Taipei', u'Center', u'for', u'Popular', u'Music', u'and', u'Taipei', u'City', u'Museum', u'.'], u'lemmas': [u'the', u'same', u'design', u'process', u'be', u'also', u'in', u'place', u'for', u'a', u'new', u'Taipei', u'Center', u'for', u'Popular', u'Music', u'and', u'Taipei', u'City', u'Museum', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'VBZ', u'RB', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NNP', u'NNP', u'IN', u'NNP', u'NNP', u'CC', u'NNP', u'NNP', u'NNP', u'.'], u'char_offsets': [[7419, 7422], [7423, 7427], [7428, 7434], [7435, 7442], [7443, 7445], [7446, 7450], [7451, 7453], [7454, 7459], [7460, 7463], [7464, 7465], [7466, 7469], [7470, 7476], [7477, 7483], [7484, 7487], [7488, 7495], [7496, 7501], [7502, 7505], [7506, 7512], [7513, 7517], [7518, 7524], [7524, 7525]]}) 
answer: set([u'valley'])

Is Taipei in a valley?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Taipei is in the valleys of the Keelung and Xindian Rivers
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('Taipei is in the valleys of the Keelung and Xindian Rivers') == True
 +  where 'Taipei is in the valleys of the Keelung and Xindian Rivers' = <src.question_processing.Question_parser instance at 0x1114dd4d0>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param308] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ddf38>, (<src.tfidf.TF_IDF object at 0x10a4ac550>, set(['language', 'turkish', 'turkish_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('No.') == True
E                +  where 'No.' = <src.question_processing.Question_parser instance at 0x1114ddf38>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.37835401296615601, {u'tokens': [u'\u0130ml\xe2', u'Kilavuzu', u'There', u'is', u'no', u'definite', u'article', u'in', u'Turkish', u',', u'but', u'definiteness', u'of', u'the', u'object', u'is', u'implied', u'when', u'the', u'accusative', u'ending', u'is', u'used', u'-LRB-', u'see', u'below', u'-RRB-', u'.'], u'lemmas': [u'\u0130ml\xe2', u'Kilavuzu', u'there', u'be', u'no', u'definite', u'article', u'in', u'turkish', u',', u'but', u'definiteness', u'of', u'the', u'object', u'be', u'imply', u'when', u'the', u'accusative', u'ending', u'be', u'use', u'-lrb-', u'see', u'below', u'-rrb-', u'.'], u'pos': [u'NNP', u'NNP', u'EX', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'JJ', u',', u'CC', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'WRB', u'DT', u'JJ', u'NN', u'VBZ', u'VBN', u'-LRB-', u'VB', u'IN', u'-RRB-', u'.'], u'char_offsets': [[19960, 19964], [19965, 19973], [19974, 19979], [19980, 19982], [19983, 19985], [19986, 19994], [19995, 20002], [20003, 20005], [20006, 20013], [20013, 20014], [20015, 20018], [20019, 20031], [20032, 20034], [20035, 20038], [20039, 20045], [20046, 20048], [20049, 20056], [20057, 20061], [20062, 20065], [20066, 20076], [20077, 20083], [20084, 20086], [20087, 20091], [20092, 20093], [20093, 20096], [20097, 20102], [20102, 20103], [20103, 20104]]}) 
answer: set([])
candidate Sentence: (0.25493136048316956, {u'tokens': [u'-LSB-', u'is', u'it', u'a', u'-RSB-', u'tree', u'?', u"''"], u'lemmas': [u'-lsb-', u'be', u'it', u'a', u'-rsb-', u'tree', u'?', u"''"], u'pos': [u'-LRB-', u'VBZ', u'PRP', u'DT', u'-RRB-', u'NN', u'.', u"''"], u'char_offsets': [[21439, 21440], [21440, 21442], [21443, 21445], [21446, 21447], [21447, 21448], [21449, 21453], [21453, 21454], [21454, 21455]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.23411878943443298, {u'tokens': [u',', u'a\u011fa\xe7', u'm\u0131', u'?', u"''"], u'lemmas': [u',', u'a\u011fa\xe7', u'm\u0131', u'?', u"''"], u'pos': [u',', u'NN', u'NN', u'.', u"''"], u'char_offsets': [[21427, 21428], [21429, 21433], [21434, 21436], [21436, 21437], [21438, 21439]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.20974752306938171, {u'tokens': [u'-LSB-', u'going', u'-RSB-', u'to', u'the', u'village', u'?', u"''"], u'lemmas': [u'-lsb-', u'go', u'-rsb-', u'to', u'the', u'village', u'?', u"''"], u'pos': [u'-LRB-', u'VBG', u'-RRB-', u'TO', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[21403, 21404], [21404, 21409], [21409, 21410], [21411, 21413], [21414, 21417], [21418, 21425], [21425, 21426], [21426, 21427]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.13151182234287262, {u'tokens': [u'There', u'are', u'some', u'exceptions', u'to', u'the', u'rules', u'of', u'vowel', u'harmony', u'.'], u'lemmas': [u'there', u'be', u'some', u'exception', u'to', u'the', u'rule', u'of', u'vowel', u'harmony', u'.'], u'pos': [u'EX', u'VBP', u'DT', u'NNS', u'TO', u'DT', u'NNS', u'IN', u'NN', u'NN', u'.'], u'char_offsets': [[16197, 16202], [16203, 16206], [16207, 16211], [16212, 16222], [16223, 16225], [16226, 16229], [16230, 16235], [16236, 16238], [16239, 16244], [16245, 16252], [16252, 16253]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.11230453103780746, {u'tokens': [u'The', u'interrogative', u'particle', u'mi', u'4', u'immediately', u'follows', u'the', u'word', u'being', u'questioned', u':', u'k\xf6ye', u'mi', u'?', u"''"], u'lemmas': [u'the', u'interrogative', u'particle', u'mi', u'4', u'immediately', u'follow', u'the', u'word', u'be', u'question', u':', u'k\xf6ye', u'mi', u'?', u"''"], u'pos': [u'DT', u'JJ', u'NN', u'FW', u'CD', u'RB', u'VBZ', u'DT', u'NN', u'VBG', u'VBN', u':', u'JJ', u'NNS', u'.', u"''"], u'char_offsets': [[21313, 21316], [21317, 21330], [21331, 21339], [21340, 21342], [21343, 21344], [21346, 21357], [21358, 21365], [21366, 21369], [21370, 21374], [21375, 21380], [21381, 21391], [21391, 21392], [21393, 21397], [21398, 21400], [21400, 21401], [21402, 21403]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.1093580573797226, {u'tokens': [u'For', u'the', u'third', u'see', u'There', u'is', u'also', u'a', u'political', u'dimension', u'to', u'the', u'language', u'debate', u',', u'with', u'conservative', u'groups', u'tending', u'to', u'use', u'more', u'archaic', u'words', u'in', u'the', u'press', u'or', u'everyday', u'language', u'.'], u'lemmas': [u'for', u'the', u'third', u'see', u'there', u'be', u'also', u'a', u'political', u'dimension', u'to', u'the', u'language', u'debate', u',', u'with', u'conservative', u'group', u'tend', u'to', u'use', u'more', u'archaic', u'word', u'in', u'the', u'press', u'or', u'everyday', u'language', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'VBP', u'EX', u'VBZ', u'RB', u'DT', u'JJ', u'NN', u'TO', u'DT', u'NN', u'NN', u',', u'IN', u'JJ', u'NNS', u'VBG', u'TO', u'VB', u'JJR', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'CC', u'JJ', u'NN', u'.'], u'char_offsets': [[6215, 6218], [6219, 6222], [6223, 6228], [6229, 6232], [6238, 6243], [6244, 6246], [6247, 6251], [6252, 6253], [6254, 6263], [6264, 6273], [6274, 6276], [6277, 6280], [6281, 6289], [6290, 6296], [6296, 6297], [6298, 6302], [6303, 6315], [6316, 6322], [6323, 6330], [6331, 6333], [6334, 6337], [6338, 6342], [6343, 6350], [6351, 6356], [6357, 6359], [6360, 6363], [6364, 6369], [6370, 6372], [6373, 6381], [6382, 6390], [6390, 6391]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.10719111561775208, {u'tokens': [u'Here', u'the', u'first', u'noun', u'has', u'no', u'ending', u';', u'but', u'the', u'second', u'noun', u'has', u'the', u'ending', u'-', u'-LRB-', u's', u'-RRB-', u'i', u'4', u'--', u'the', u'same', u'as', u'in', u'definite', u'compounds', u'.'], u'lemmas': [u'here', u'the', u'first', u'noun', u'have', u'no', u'end', u';', u'but', u'the', u'second', u'noun', u'have', u'the', u'end', u'-', u'-lrb-', u's', u'-rrb-', u'i', u'4', u'--', u'the', u'same', u'as', u'in', u'definite', u'compound', u'.'], u'pos': [u'RB', u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'VBG', u':', u'CC', u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'VBG', u':', u'-LRB-', u'NNS', u'-RRB-', u'FW', u'CD', u':', u'DT', u'JJ', u'IN', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[22553, 22557], [22558, 22561], [22562, 22567], [22568, 22572], [22573, 22576], [22577, 22579], [22580, 22586], [22586, 22587], [22588, 22591], [22592, 22595], [22596, 22602], [22603, 22607], [22608, 22611], [22612, 22615], [22616, 22622], [22623, 22624], [22624, 22625], [22625, 22626], [22626, 22627], [22627, 22628], [22629, 22630], [22631, 22632], [22632, 22635], [22636, 22640], [22641, 22643], [22644, 22646], [22647, 22655], [22656, 22665], [22665, 22666]]}) 
answer: set([u'article'])
candidate Sentence: (0.10423383116722107, {u'tokens': [u'Two', u'nouns', u',', u'or', u'groups', u'of', u'nouns', u',', u'may', u'be', u'joined', u'in', u'either', u'of', u'two', u'ways', u':', u'*', u'definite', u'-LRB-', u'possessive', u'-RRB-', u'compound', u'-LRB-', u'belirtili', u'tamlama', u'-RRB-', u'.'], u'lemmas': [u'two', u'noun', u',', u'or', u'group', u'of', u'noun', u',', u'may', u'be', u'join', u'in', u'either', u'of', u'two', u'way', u':', u'*', u'definite', u'-lrb-', u'possessive', u'-rrb-', u'compound', u'-lrb-', u'belirtilus', u'tamlama', u'-rrb-', u'.'], u'pos': [u'CD', u'NNS', u',', u'CC', u'NNS', u'IN', u'NNS', u',', u'MD', u'VB', u'VBN', u'IN', u'DT', u'IN', u'CD', u'NNS', u':', u'SYM', u'JJ', u'-LRB-', u'JJ', u'-RRB-', u'NN', u'-LRB-', u'NN', u'NN', u'-RRB-', u'.'], u'char_offsets': [[21835, 21838], [21839, 21844], [21844, 21845], [21846, 21848], [21849, 21855], [21856, 21858], [21859, 21864], [21864, 21865], [21866, 21869], [21870, 21872], [21873, 21879], [21880, 21882], [21883, 21889], [21890, 21892], [21893, 21896], [21897, 21901], [21901, 21902], [21903, 21904], [21905, 21913], [21914, 21915], [21915, 21925], [21925, 21926], [21927, 21935], [21936, 21937], [21937, 21946], [21947, 21954], [21954, 21955], [21955, 21956]]}) 
answer: set([u'article'])
candidate Sentence: (0.10023322701454163, {u'tokens': [u'There', u'are', u'also', u'a', u'few', u'native', u'Turkish', u'words', u'that', u'do', u'not', u'follow', u'the', u'rule', u',', u'such', u'as', u'anne', u'-LRB-', u'``', u'mother', u"''", u'-RRB-', u'.'], u'lemmas': [u'there', u'be', u'also', u'a', u'few', u'native', u'turkish', u'word', u'that', u'do', u'not', u'follow', u'the', u'rule', u',', u'such', u'as', u'anne', u'-lrb-', u'``', u'mother', u"''", u'-rrb-', u'.'], u'pos': [u'EX', u'VBP', u'RB', u'DT', u'JJ', u'JJ', u'JJ', u'NNS', u'WDT', u'VBP', u'RB', u'VB', u'DT', u'NN', u',', u'JJ', u'IN', u'NN', u'-LRB-', u'``', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[16970, 16975], [16976, 16979], [16980, 16984], [16985, 16986], [16987, 16990], [16991, 16997], [16998, 17005], [17006, 17011], [17012, 17016], [17017, 17019], [17020, 17023], [17024, 17030], [17031, 17034], [17035, 17039], [17039, 17040], [17041, 17045], [17046, 17048], [17049, 17053], [17054, 17055], [17055, 17056], [17056, 17062], [17062, 17063], [17063, 17064], [17064, 17065]]}) 
answer: set([u'article', u'definite'])

Is there a definite article in Turkish language?
Validity= False
Question Type = NA
Answer Type = NA
Answer = No.
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('No.') == True
 +  where 'No.' = <src.question_processing.Question_parser instance at 0x1114ddf38>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param309] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114ddfc8>, (<src.tfidf.TF_IDF object at 0x10a4ac550>, set(['language', 'turkish', 'turkish_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert str2bool('No') == True
E                +  where 'No' = <src.question_processing.Question_parser instance at 0x1114ddfc8>.answer
E                +  and   True = str2bool('Yes')

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.37835401296615601, {u'tokens': [u'\u0130ml\xe2', u'Kilavuzu', u'There', u'is', u'no', u'definite', u'article', u'in', u'Turkish', u',', u'but', u'definiteness', u'of', u'the', u'object', u'is', u'implied', u'when', u'the', u'accusative', u'ending', u'is', u'used', u'-LRB-', u'see', u'below', u'-RRB-', u'.'], u'lemmas': [u'\u0130ml\xe2', u'Kilavuzu', u'there', u'be', u'no', u'definite', u'article', u'in', u'turkish', u',', u'but', u'definiteness', u'of', u'the', u'object', u'be', u'imply', u'when', u'the', u'accusative', u'ending', u'be', u'use', u'-lrb-', u'see', u'below', u'-rrb-', u'.'], u'pos': [u'NNP', u'NNP', u'EX', u'VBZ', u'DT', u'JJ', u'NN', u'IN', u'JJ', u',', u'CC', u'NN', u'IN', u'DT', u'NN', u'VBZ', u'VBN', u'WRB', u'DT', u'JJ', u'NN', u'VBZ', u'VBN', u'-LRB-', u'VB', u'IN', u'-RRB-', u'.'], u'char_offsets': [[19960, 19964], [19965, 19973], [19974, 19979], [19980, 19982], [19983, 19985], [19986, 19994], [19995, 20002], [20003, 20005], [20006, 20013], [20013, 20014], [20015, 20018], [20019, 20031], [20032, 20034], [20035, 20038], [20039, 20045], [20046, 20048], [20049, 20056], [20057, 20061], [20062, 20065], [20066, 20076], [20077, 20083], [20084, 20086], [20087, 20091], [20092, 20093], [20093, 20096], [20097, 20102], [20102, 20103], [20103, 20104]]}) 
answer: set([])
candidate Sentence: (0.25493136048316956, {u'tokens': [u'-LSB-', u'is', u'it', u'a', u'-RSB-', u'tree', u'?', u"''"], u'lemmas': [u'-lsb-', u'be', u'it', u'a', u'-rsb-', u'tree', u'?', u"''"], u'pos': [u'-LRB-', u'VBZ', u'PRP', u'DT', u'-RRB-', u'NN', u'.', u"''"], u'char_offsets': [[21439, 21440], [21440, 21442], [21443, 21445], [21446, 21447], [21447, 21448], [21449, 21453], [21453, 21454], [21454, 21455]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.23411878943443298, {u'tokens': [u',', u'a\u011fa\xe7', u'm\u0131', u'?', u"''"], u'lemmas': [u',', u'a\u011fa\xe7', u'm\u0131', u'?', u"''"], u'pos': [u',', u'NN', u'NN', u'.', u"''"], u'char_offsets': [[21427, 21428], [21429, 21433], [21434, 21436], [21436, 21437], [21438, 21439]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.20974752306938171, {u'tokens': [u'-LSB-', u'going', u'-RSB-', u'to', u'the', u'village', u'?', u"''"], u'lemmas': [u'-lsb-', u'go', u'-rsb-', u'to', u'the', u'village', u'?', u"''"], u'pos': [u'-LRB-', u'VBG', u'-RRB-', u'TO', u'DT', u'NN', u'.', u"''"], u'char_offsets': [[21403, 21404], [21404, 21409], [21409, 21410], [21411, 21413], [21414, 21417], [21418, 21425], [21425, 21426], [21426, 21427]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.13151182234287262, {u'tokens': [u'There', u'are', u'some', u'exceptions', u'to', u'the', u'rules', u'of', u'vowel', u'harmony', u'.'], u'lemmas': [u'there', u'be', u'some', u'exception', u'to', u'the', u'rule', u'of', u'vowel', u'harmony', u'.'], u'pos': [u'EX', u'VBP', u'DT', u'NNS', u'TO', u'DT', u'NNS', u'IN', u'NN', u'NN', u'.'], u'char_offsets': [[16197, 16202], [16203, 16206], [16207, 16211], [16212, 16222], [16223, 16225], [16226, 16229], [16230, 16235], [16236, 16238], [16239, 16244], [16245, 16252], [16252, 16253]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.11230453103780746, {u'tokens': [u'The', u'interrogative', u'particle', u'mi', u'4', u'immediately', u'follows', u'the', u'word', u'being', u'questioned', u':', u'k\xf6ye', u'mi', u'?', u"''"], u'lemmas': [u'the', u'interrogative', u'particle', u'mi', u'4', u'immediately', u'follow', u'the', u'word', u'be', u'question', u':', u'k\xf6ye', u'mi', u'?', u"''"], u'pos': [u'DT', u'JJ', u'NN', u'FW', u'CD', u'RB', u'VBZ', u'DT', u'NN', u'VBG', u'VBN', u':', u'JJ', u'NNS', u'.', u"''"], u'char_offsets': [[21313, 21316], [21317, 21330], [21331, 21339], [21340, 21342], [21343, 21344], [21346, 21357], [21358, 21365], [21366, 21369], [21370, 21374], [21375, 21380], [21381, 21391], [21391, 21392], [21393, 21397], [21398, 21400], [21400, 21401], [21402, 21403]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.1093580573797226, {u'tokens': [u'For', u'the', u'third', u'see', u'There', u'is', u'also', u'a', u'political', u'dimension', u'to', u'the', u'language', u'debate', u',', u'with', u'conservative', u'groups', u'tending', u'to', u'use', u'more', u'archaic', u'words', u'in', u'the', u'press', u'or', u'everyday', u'language', u'.'], u'lemmas': [u'for', u'the', u'third', u'see', u'there', u'be', u'also', u'a', u'political', u'dimension', u'to', u'the', u'language', u'debate', u',', u'with', u'conservative', u'group', u'tend', u'to', u'use', u'more', u'archaic', u'word', u'in', u'the', u'press', u'or', u'everyday', u'language', u'.'], u'pos': [u'IN', u'DT', u'JJ', u'VBP', u'EX', u'VBZ', u'RB', u'DT', u'JJ', u'NN', u'TO', u'DT', u'NN', u'NN', u',', u'IN', u'JJ', u'NNS', u'VBG', u'TO', u'VB', u'JJR', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'CC', u'JJ', u'NN', u'.'], u'char_offsets': [[6215, 6218], [6219, 6222], [6223, 6228], [6229, 6232], [6238, 6243], [6244, 6246], [6247, 6251], [6252, 6253], [6254, 6263], [6264, 6273], [6274, 6276], [6277, 6280], [6281, 6289], [6290, 6296], [6296, 6297], [6298, 6302], [6303, 6315], [6316, 6322], [6323, 6330], [6331, 6333], [6334, 6337], [6338, 6342], [6343, 6350], [6351, 6356], [6357, 6359], [6360, 6363], [6364, 6369], [6370, 6372], [6373, 6381], [6382, 6390], [6390, 6391]]}) 
answer: set([u'article', u'definite'])
candidate Sentence: (0.10719111561775208, {u'tokens': [u'Here', u'the', u'first', u'noun', u'has', u'no', u'ending', u';', u'but', u'the', u'second', u'noun', u'has', u'the', u'ending', u'-', u'-LRB-', u's', u'-RRB-', u'i', u'4', u'--', u'the', u'same', u'as', u'in', u'definite', u'compounds', u'.'], u'lemmas': [u'here', u'the', u'first', u'noun', u'have', u'no', u'end', u';', u'but', u'the', u'second', u'noun', u'have', u'the', u'end', u'-', u'-lrb-', u's', u'-rrb-', u'i', u'4', u'--', u'the', u'same', u'as', u'in', u'definite', u'compound', u'.'], u'pos': [u'RB', u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'VBG', u':', u'CC', u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'VBG', u':', u'-LRB-', u'NNS', u'-RRB-', u'FW', u'CD', u':', u'DT', u'JJ', u'IN', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[22553, 22557], [22558, 22561], [22562, 22567], [22568, 22572], [22573, 22576], [22577, 22579], [22580, 22586], [22586, 22587], [22588, 22591], [22592, 22595], [22596, 22602], [22603, 22607], [22608, 22611], [22612, 22615], [22616, 22622], [22623, 22624], [22624, 22625], [22625, 22626], [22626, 22627], [22627, 22628], [22629, 22630], [22631, 22632], [22632, 22635], [22636, 22640], [22641, 22643], [22644, 22646], [22647, 22655], [22656, 22665], [22665, 22666]]}) 
answer: set([u'article'])
candidate Sentence: (0.10423383116722107, {u'tokens': [u'Two', u'nouns', u',', u'or', u'groups', u'of', u'nouns', u',', u'may', u'be', u'joined', u'in', u'either', u'of', u'two', u'ways', u':', u'*', u'definite', u'-LRB-', u'possessive', u'-RRB-', u'compound', u'-LRB-', u'belirtili', u'tamlama', u'-RRB-', u'.'], u'lemmas': [u'two', u'noun', u',', u'or', u'group', u'of', u'noun', u',', u'may', u'be', u'join', u'in', u'either', u'of', u'two', u'way', u':', u'*', u'definite', u'-lrb-', u'possessive', u'-rrb-', u'compound', u'-lrb-', u'belirtilus', u'tamlama', u'-rrb-', u'.'], u'pos': [u'CD', u'NNS', u',', u'CC', u'NNS', u'IN', u'NNS', u',', u'MD', u'VB', u'VBN', u'IN', u'DT', u'IN', u'CD', u'NNS', u':', u'SYM', u'JJ', u'-LRB-', u'JJ', u'-RRB-', u'NN', u'-LRB-', u'NN', u'NN', u'-RRB-', u'.'], u'char_offsets': [[21835, 21838], [21839, 21844], [21844, 21845], [21846, 21848], [21849, 21855], [21856, 21858], [21859, 21864], [21864, 21865], [21866, 21869], [21870, 21872], [21873, 21879], [21880, 21882], [21883, 21889], [21890, 21892], [21893, 21896], [21897, 21901], [21901, 21902], [21903, 21904], [21905, 21913], [21914, 21915], [21915, 21925], [21925, 21926], [21927, 21935], [21936, 21937], [21937, 21946], [21947, 21954], [21954, 21955], [21955, 21956]]}) 
answer: set([u'article'])
candidate Sentence: (0.10023322701454163, {u'tokens': [u'There', u'are', u'also', u'a', u'few', u'native', u'Turkish', u'words', u'that', u'do', u'not', u'follow', u'the', u'rule', u',', u'such', u'as', u'anne', u'-LRB-', u'``', u'mother', u"''", u'-RRB-', u'.'], u'lemmas': [u'there', u'be', u'also', u'a', u'few', u'native', u'turkish', u'word', u'that', u'do', u'not', u'follow', u'the', u'rule', u',', u'such', u'as', u'anne', u'-lrb-', u'``', u'mother', u"''", u'-rrb-', u'.'], u'pos': [u'EX', u'VBP', u'RB', u'DT', u'JJ', u'JJ', u'JJ', u'NNS', u'WDT', u'VBP', u'RB', u'VB', u'DT', u'NN', u',', u'JJ', u'IN', u'NN', u'-LRB-', u'``', u'NN', u"''", u'-RRB-', u'.'], u'char_offsets': [[16970, 16975], [16976, 16979], [16980, 16984], [16985, 16986], [16987, 16990], [16991, 16997], [16998, 17005], [17006, 17011], [17012, 17016], [17017, 17019], [17020, 17023], [17024, 17030], [17031, 17034], [17035, 17039], [17039, 17040], [17041, 17045], [17046, 17048], [17049, 17053], [17054, 17055], [17055, 17056], [17056, 17062], [17062, 17063], [17063, 17064], [17064, 17065]]}) 
answer: set([u'article', u'definite'])

Is there a definite article in Turkish language?
Validity= False
Question Type = NA
Answer Type = NA
Answer = No
Difficulty = easy

Yes
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert str2bool('No') == True
 +  where 'No' = <src.question_processing.Question_parser instance at 0x1114ddfc8>.answer
 +  and   True = str2bool('Yes')
_____________________________ test_yesno[param318] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e1518>, (<src.tfidf.TF_IDF object at 0x10e16f290>, set(['language', 'vietnamese', 'vietnamese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114e1518>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.36892408132553101, {u'tokens': [u'While', u'spoken', u'by', u'the', u'Vietnamese', u'people', u'for', u'millennia', u',', u'written', u'Vietnamese', u'did', u'not', u'become', u'the', u'official', u'administrative', u'language', u'of', u'Vietnam', u'until', u'the', u'20th', u'century', u'.'], u'lemmas': [u'while', u'speak', u'by', u'the', u'vietnamese', u'people', u'for', u'millennium', u',', u'write', u'vietnamese', u'do', u'not', u'become', u'the', u'official', u'administrative', u'language', u'of', u'Vietnam', u'until', u'the', u'20th', u'century', u'.'], u'pos': [u'IN', u'VBN', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'NNS', u',', u'VBN', u'NNS', u'VBD', u'RB', u'VB', u'DT', u'JJ', u'JJ', u'NN', u'IN', u'NNP', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[3092, 3097], [3098, 3104], [3105, 3107], [3108, 3111], [3112, 3122], [3123, 3129], [3130, 3133], [3134, 3143], [3143, 3144], [3145, 3152], [3153, 3163], [3164, 3167], [3168, 3171], [3172, 3178], [3179, 3182], [3183, 3191], [3192, 3206], [3207, 3215], [3216, 3218], [3219, 3226], [3227, 3232], [3233, 3236], [3237, 3241], [3242, 3249], [3249, 3250]]}) 
answer: set([])
candidate Sentence: (0.29361721873283386, {u'tokens': [u'``', u'What', u"'s", u'so', u'Chinese', u'about', u'Vietnamese', u'?', u"''"], u'lemmas': [u'``', u'what', u'be', u'so', u'chinese', u'about', u'vietnamese', u'?', u"''"], u'pos': [u'``', u'WP', u'VBZ', u'RB', u'JJ', u'IN', u'NNS', u'.', u"''"], u'char_offsets': [[30347, 30348], [30348, 30352], [30352, 30354], [30355, 30357], [30358, 30365], [30366, 30371], [30372, 30382], [30382, 30383], [30383, 30384]]}) 
answer: set([u'official', u'administrative', u'vietnam'])
candidate Sentence: (0.22242213785648346, {u'tokens': [u'It', u'is', u'the', u'language', u'of', u'instruction', u'in', u'schools', u'and', u'universities', u'and', u'is', u'the', u'language', u'for', u'official', u'business', u'.'], u'lemmas': [u'it', u'be', u'the', u'language', u'of', u'instruction', u'in', u'school', u'and', u'university', u'and', u'be', u'the', u'language', u'for', u'official', u'business', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'NN', u'IN', u'NN', u'IN', u'NNS', u'CC', u'NNS', u'CC', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[3688, 3690], [3691, 3693], [3694, 3697], [3698, 3706], [3707, 3709], [3710, 3721], [3722, 3724], [3725, 3732], [3733, 3736], [3737, 3749], [3750, 3753], [3754, 3756], [3757, 3760], [3761, 3769], [3770, 3773], [3774, 3782], [3783, 3791], [3791, 3792]]}) 
answer: set([u'vietnam', u'administrative'])
candidate Sentence: (0.21178781986236572, {u'tokens': [u',', u'formerly', u'known', u'under', u'French', u'colonization', u'as', u'Annamese', u'-LRB-', u'see', u'Annam', u'-RRB-', u',', u'is', u'the', u'national', u'and', u'official', u'language', u'of', u'Vietnam', u'.'], u'lemmas': [u',', u'formerly', u'know', u'under', u'french', u'colonization', u'as', u'annamese', u'-lrb-', u'see', u'Annam', u'-rrb-', u',', u'be', u'the', u'national', u'and', u'official', u'language', u'of', u'Vietnam', u'.'], u'pos': [u',', u'RB', u'VBN', u'IN', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'VB', u'NNP', u'-RRB-', u',', u'VBZ', u'DT', u'JJ', u'CC', u'JJ', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[305, 306], [307, 315], [316, 321], [322, 327], [328, 334], [335, 347], [348, 350], [351, 359], [360, 361], [361, 364], [365, 370], [370, 371], [371, 372], [373, 375], [376, 379], [380, 388], [389, 392], [393, 401], [402, 410], [411, 413], [414, 421], [421, 422]]}) 
answer: set([u'administrative'])
candidate Sentence: (0.1791614443063736, {u'tokens': [u'It', u'was', u'also', u'used', u'for', u'administrative', u'purposes', u'during', u'the', u'brief', u'Ho', u'and', u'Tay', u'Son', u'Dynasties', u'.'], u'lemmas': [u'it', u'be', u'also', u'use', u'for', u'administrative', u'purpose', u'during', u'the', u'brief', u'Ho', u'and', u'Tay', u'Son', u'Dynasties', u'.'], u'pos': [u'PRP', u'VBD', u'RB', u'VBN', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NNP', u'CC', u'NNP', u'NNP', u'NNPS', u'.'], u'char_offsets': [[3449, 3451], [3452, 3455], [3456, 3460], [3461, 3465], [3466, 3469], [3470, 3484], [3485, 3493], [3494, 3500], [3501, 3504], [3505, 3510], [3511, 3513], [3514, 3517], [3518, 3521], [3522, 3525], [3526, 3535], [3535, 3536]]}) 
answer: set([u'official', u'vietnam'])
candidate Sentence: (0.17770062386989594, {u'tokens': [u'When', u'France', u'invaded', u'Vietnam', u'in', u'the', u'late', u'19th', u'century', u',', u'French', u'gradually', u'replaced', u'Chinese', u'as', u'the', u'official', u'language', u'in', u'education', u'and', u'government', u'.'], u'lemmas': [u'when', u'France', u'invade', u'Vietnam', u'in', u'the', u'late', u'19th', u'century', u',', u'french', u'gradually', u'replace', u'chinese', u'as', u'the', u'official', u'language', u'in', u'education', u'and', u'government', u'.'], u'pos': [u'WRB', u'NNP', u'VBD', u'NNP', u'IN', u'DT', u'JJ', u'JJ', u'NN', u',', u'JJ', u'RB', u'VBN', u'JJ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[6607, 6611], [6612, 6618], [6619, 6626], [6627, 6634], [6635, 6637], [6638, 6641], [6642, 6646], [6647, 6651], [6652, 6659], [6659, 6660], [6661, 6667], [6668, 6677], [6678, 6686], [6687, 6694], [6695, 6697], [6698, 6701], [6702, 6710], [6711, 6719], [6720, 6722], [6723, 6732], [6733, 6736], [6737, 6747], [6747, 6748]]}) 
answer: set([u'administrative'])
candidate Sentence: (0.13574406504631042, {u'tokens': [u'The', u'ancestor', u'of', u'the', u'Vietnamese', u'language', u'was', u'originally', u'based', u'in', u'the', u'area', u'of', u'the', u'Red', u'River', u'in', u'what', u'is', u'now', u'northern', u'Vietnam', u',', u'and', u'during', u'the', u'subsequent', u'expansion', u'of', u'the', u'Vietnamese', u'language', u'and', u'people', u'into', u'what', u'is', u'now', u'central', u'and', u'southern', u'Vietnam', u'-LRB-', u'through', u'conquest', u'of', u'the', u'ancient', u'nation', u'of', u'Champa', u'and', u'the', u'Khmer', u'people', u'of', u'the', u'Mekong', u'Delta', u'in', u'the', u'vicinity', u'of', u'present-day', u'Ho', u'Chi', u'Minh', u'City', u'-LRB-', u'Saigon', u'-RRB-', u',', u'characteristic', u'tonal', u'variations', u'have', u'emerged', u'.'], u'lemmas': [u'the', u'ancestor', u'of', u'the', u'vietnamese', u'language', u'be', u'originally', u'base', u'in', u'the', u'area', u'of', u'the', u'Red', u'River', u'in', u'what', u'be', u'now', u'northern', u'Vietnam', u',', u'and', u'during', u'the', u'subsequent', u'expansion', u'of', u'the', u'vietnamese', u'language', u'and', u'people', u'into', u'what', u'be', u'now', u'central', u'and', u'southern', u'Vietnam', u'-lrb-', u'through', u'conquest', u'of', u'the', u'ancient', u'nation', u'of', u'Champa', u'and', u'the', u'Khmer', u'people', u'of', u'the', u'Mekong', u'Delta', u'in', u'the', u'vicinity', u'of', u'present-day', u'Ho', u'Chi', u'Minh', u'City', u'-lrb-', u'Saigon', u'-rrb-', u',', u'characteristic', u'tonal', u'variation', u'have', u'emerge', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBD', u'RB', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'WP', u'VBZ', u'RB', u'JJ', u'NNP', u',', u'CC', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'JJ', u'NN', u'CC', u'NNS', u'IN', u'WP', u'VBZ', u'RB', u'JJ', u'CC', u'JJ', u'NNP', u'-LRB-', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'CC', u'DT', u'NNP', u'NNS', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'JJ', u'NNP', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u',', u'JJ', u'JJ', u'NNS', u'VBP', u'VBN', u'.'], u'char_offsets': [[4835, 4838], [4839, 4847], [4848, 4850], [4851, 4854], [4855, 4865], [4866, 4874], [4875, 4878], [4879, 4889], [4890, 4895], [4896, 4898], [4899, 4902], [4903, 4907], [4908, 4910], [4911, 4914], [4915, 4918], [4919, 4924], [4925, 4927], [4928, 4932], [4933, 4935], [4936, 4939], [4940, 4948], [4949, 4956], [4956, 4957], [4958, 4961], [4962, 4968], [4969, 4972], [4973, 4983], [4984, 4993], [4994, 4996], [4997, 5000], [5001, 5011], [5012, 5020], [5021, 5024], [5025, 5031], [5032, 5036], [5037, 5041], [5042, 5044], [5045, 5048], [5049, 5056], [5057, 5060], [5061, 5069], [5070, 5077], [5078, 5079], [5079, 5086], [5087, 5095], [5096, 5098], [5099, 5102], [5103, 5110], [5111, 5117], [5118, 5120], [5121, 5127], [5128, 5131], [5132, 5135], [5136, 5141], [5142, 5148], [5149, 5151], [5152, 5155], [5156, 5162], [5163, 5168], [5169, 5171], [5172, 5175], [5176, 5184], [5185, 5187], [5188, 5199], [5200, 5202], [5203, 5206], [5207, 5211], [5212, 5216], [5217, 5218], [5218, 5224], [5224, 5225], [5225, 5226], [5227, 5241], [5242, 5247], [5248, 5258], [5259, 5263], [5264, 5271], [5271, 5272]]}) 
answer: set([u'official', u'administrative'])
candidate Sentence: (0.12883502244949341, {u'tokens': [u'It', u'is', u'also', u'spoken', u'as', u'a', u'second', u'language', u'by', u'many', u'ethnic', u'minorities', u'of', u'Vietnam', u'.'], u'lemmas': [u'it', u'be', u'also', u'speak', u'as', u'a', u'second', u'language', u'by', u'many', u'ethnic', u'minority', u'of', u'Vietnam', u'.'], u'pos': [u'PRP', u'VBZ', u'RB', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'JJ', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[592, 594], [595, 597], [598, 602], [603, 609], [610, 612], [613, 614], [615, 621], [622, 630], [631, 633], [634, 638], [639, 645], [646, 656], [657, 659], [660, 667], [667, 668]]}) 
answer: set([u'official', u'administrative'])
candidate Sentence: (0.11571545153856277, {u'tokens': [u'A', u'study', u'of', u'Middle', u'Vietnamese', u'phonology', u'.'], u'lemmas': [u'a', u'study', u'of', u'Middle', u'Vietnamese', u'phonology', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NNP', u'NNP', u'NN', u'.'], u'char_offsets': [[30730, 30731], [30732, 30737], [30738, 30740], [30741, 30747], [30748, 30758], [30759, 30768], [30768, 30769]]}) 
answer: set([u'official', u'administrative', u'vietnam'])
candidate Sentence: (0.10960178077220917, {u'tokens': [u'Below', u'is', u'a', u'vowel', u'diagram', u'of', u'Hanoi', u'Vietnamese', u'.'], u'lemmas': [u'Below', u'be', u'a', u'vowel', u'diagram', u'of', u'Hanoi', u'Vietnamese', u'.'], u'pos': [u'NNP', u'VBZ', u'DT', u'NN', u'NN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[8439, 8444], [8445, 8447], [8448, 8449], [8450, 8455], [8456, 8463], [8464, 8466], [8467, 8472], [8473, 8483], [8483, 8484]]}) 
answer: set([u'official', u'administrative', u'vietnam'])

Is Vietnamese the official administrative language of Vietnam?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114e1518>.answer
_____________________________ test_yesno[param319] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e15a8>, (<src.tfidf.TF_IDF object at 0x10e16f290>, set(['language', 'vietnamese', 'vietnamese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114e15a8>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.36892408132553101, {u'tokens': [u'While', u'spoken', u'by', u'the', u'Vietnamese', u'people', u'for', u'millennia', u',', u'written', u'Vietnamese', u'did', u'not', u'become', u'the', u'official', u'administrative', u'language', u'of', u'Vietnam', u'until', u'the', u'20th', u'century', u'.'], u'lemmas': [u'while', u'speak', u'by', u'the', u'vietnamese', u'people', u'for', u'millennium', u',', u'write', u'vietnamese', u'do', u'not', u'become', u'the', u'official', u'administrative', u'language', u'of', u'Vietnam', u'until', u'the', u'20th', u'century', u'.'], u'pos': [u'IN', u'VBN', u'IN', u'DT', u'JJ', u'NNS', u'IN', u'NNS', u',', u'VBN', u'NNS', u'VBD', u'RB', u'VB', u'DT', u'JJ', u'JJ', u'NN', u'IN', u'NNP', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[3092, 3097], [3098, 3104], [3105, 3107], [3108, 3111], [3112, 3122], [3123, 3129], [3130, 3133], [3134, 3143], [3143, 3144], [3145, 3152], [3153, 3163], [3164, 3167], [3168, 3171], [3172, 3178], [3179, 3182], [3183, 3191], [3192, 3206], [3207, 3215], [3216, 3218], [3219, 3226], [3227, 3232], [3233, 3236], [3237, 3241], [3242, 3249], [3249, 3250]]}) 
answer: set([])
candidate Sentence: (0.29361721873283386, {u'tokens': [u'``', u'What', u"'s", u'so', u'Chinese', u'about', u'Vietnamese', u'?', u"''"], u'lemmas': [u'``', u'what', u'be', u'so', u'chinese', u'about', u'vietnamese', u'?', u"''"], u'pos': [u'``', u'WP', u'VBZ', u'RB', u'JJ', u'IN', u'NNS', u'.', u"''"], u'char_offsets': [[30347, 30348], [30348, 30352], [30352, 30354], [30355, 30357], [30358, 30365], [30366, 30371], [30372, 30382], [30382, 30383], [30383, 30384]]}) 
answer: set([u'official', u'administrative', u'vietnam'])
candidate Sentence: (0.22242213785648346, {u'tokens': [u'It', u'is', u'the', u'language', u'of', u'instruction', u'in', u'schools', u'and', u'universities', u'and', u'is', u'the', u'language', u'for', u'official', u'business', u'.'], u'lemmas': [u'it', u'be', u'the', u'language', u'of', u'instruction', u'in', u'school', u'and', u'university', u'and', u'be', u'the', u'language', u'for', u'official', u'business', u'.'], u'pos': [u'PRP', u'VBZ', u'DT', u'NN', u'IN', u'NN', u'IN', u'NNS', u'CC', u'NNS', u'CC', u'VBZ', u'DT', u'NN', u'IN', u'JJ', u'NN', u'.'], u'char_offsets': [[3688, 3690], [3691, 3693], [3694, 3697], [3698, 3706], [3707, 3709], [3710, 3721], [3722, 3724], [3725, 3732], [3733, 3736], [3737, 3749], [3750, 3753], [3754, 3756], [3757, 3760], [3761, 3769], [3770, 3773], [3774, 3782], [3783, 3791], [3791, 3792]]}) 
answer: set([u'vietnam', u'administrative'])
candidate Sentence: (0.21178781986236572, {u'tokens': [u',', u'formerly', u'known', u'under', u'French', u'colonization', u'as', u'Annamese', u'-LRB-', u'see', u'Annam', u'-RRB-', u',', u'is', u'the', u'national', u'and', u'official', u'language', u'of', u'Vietnam', u'.'], u'lemmas': [u',', u'formerly', u'know', u'under', u'french', u'colonization', u'as', u'annamese', u'-lrb-', u'see', u'Annam', u'-rrb-', u',', u'be', u'the', u'national', u'and', u'official', u'language', u'of', u'Vietnam', u'.'], u'pos': [u',', u'RB', u'VBN', u'IN', u'JJ', u'NN', u'IN', u'NN', u'-LRB-', u'VB', u'NNP', u'-RRB-', u',', u'VBZ', u'DT', u'JJ', u'CC', u'JJ', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[305, 306], [307, 315], [316, 321], [322, 327], [328, 334], [335, 347], [348, 350], [351, 359], [360, 361], [361, 364], [365, 370], [370, 371], [371, 372], [373, 375], [376, 379], [380, 388], [389, 392], [393, 401], [402, 410], [411, 413], [414, 421], [421, 422]]}) 
answer: set([u'administrative'])
candidate Sentence: (0.1791614443063736, {u'tokens': [u'It', u'was', u'also', u'used', u'for', u'administrative', u'purposes', u'during', u'the', u'brief', u'Ho', u'and', u'Tay', u'Son', u'Dynasties', u'.'], u'lemmas': [u'it', u'be', u'also', u'use', u'for', u'administrative', u'purpose', u'during', u'the', u'brief', u'Ho', u'and', u'Tay', u'Son', u'Dynasties', u'.'], u'pos': [u'PRP', u'VBD', u'RB', u'VBN', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NNP', u'CC', u'NNP', u'NNP', u'NNPS', u'.'], u'char_offsets': [[3449, 3451], [3452, 3455], [3456, 3460], [3461, 3465], [3466, 3469], [3470, 3484], [3485, 3493], [3494, 3500], [3501, 3504], [3505, 3510], [3511, 3513], [3514, 3517], [3518, 3521], [3522, 3525], [3526, 3535], [3535, 3536]]}) 
answer: set([u'official', u'vietnam'])
candidate Sentence: (0.17770062386989594, {u'tokens': [u'When', u'France', u'invaded', u'Vietnam', u'in', u'the', u'late', u'19th', u'century', u',', u'French', u'gradually', u'replaced', u'Chinese', u'as', u'the', u'official', u'language', u'in', u'education', u'and', u'government', u'.'], u'lemmas': [u'when', u'France', u'invade', u'Vietnam', u'in', u'the', u'late', u'19th', u'century', u',', u'french', u'gradually', u'replace', u'chinese', u'as', u'the', u'official', u'language', u'in', u'education', u'and', u'government', u'.'], u'pos': [u'WRB', u'NNP', u'VBD', u'NNP', u'IN', u'DT', u'JJ', u'JJ', u'NN', u',', u'JJ', u'RB', u'VBN', u'JJ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[6607, 6611], [6612, 6618], [6619, 6626], [6627, 6634], [6635, 6637], [6638, 6641], [6642, 6646], [6647, 6651], [6652, 6659], [6659, 6660], [6661, 6667], [6668, 6677], [6678, 6686], [6687, 6694], [6695, 6697], [6698, 6701], [6702, 6710], [6711, 6719], [6720, 6722], [6723, 6732], [6733, 6736], [6737, 6747], [6747, 6748]]}) 
answer: set([u'administrative'])
candidate Sentence: (0.13574406504631042, {u'tokens': [u'The', u'ancestor', u'of', u'the', u'Vietnamese', u'language', u'was', u'originally', u'based', u'in', u'the', u'area', u'of', u'the', u'Red', u'River', u'in', u'what', u'is', u'now', u'northern', u'Vietnam', u',', u'and', u'during', u'the', u'subsequent', u'expansion', u'of', u'the', u'Vietnamese', u'language', u'and', u'people', u'into', u'what', u'is', u'now', u'central', u'and', u'southern', u'Vietnam', u'-LRB-', u'through', u'conquest', u'of', u'the', u'ancient', u'nation', u'of', u'Champa', u'and', u'the', u'Khmer', u'people', u'of', u'the', u'Mekong', u'Delta', u'in', u'the', u'vicinity', u'of', u'present-day', u'Ho', u'Chi', u'Minh', u'City', u'-LRB-', u'Saigon', u'-RRB-', u',', u'characteristic', u'tonal', u'variations', u'have', u'emerged', u'.'], u'lemmas': [u'the', u'ancestor', u'of', u'the', u'vietnamese', u'language', u'be', u'originally', u'base', u'in', u'the', u'area', u'of', u'the', u'Red', u'River', u'in', u'what', u'be', u'now', u'northern', u'Vietnam', u',', u'and', u'during', u'the', u'subsequent', u'expansion', u'of', u'the', u'vietnamese', u'language', u'and', u'people', u'into', u'what', u'be', u'now', u'central', u'and', u'southern', u'Vietnam', u'-lrb-', u'through', u'conquest', u'of', u'the', u'ancient', u'nation', u'of', u'Champa', u'and', u'the', u'Khmer', u'people', u'of', u'the', u'Mekong', u'Delta', u'in', u'the', u'vicinity', u'of', u'present-day', u'Ho', u'Chi', u'Minh', u'City', u'-lrb-', u'Saigon', u'-rrb-', u',', u'characteristic', u'tonal', u'variation', u'have', u'emerge', u'.'], u'pos': [u'DT', u'NN', u'IN', u'DT', u'JJ', u'NN', u'VBD', u'RB', u'VBN', u'IN', u'DT', u'NN', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'WP', u'VBZ', u'RB', u'JJ', u'NNP', u',', u'CC', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'JJ', u'NN', u'CC', u'NNS', u'IN', u'WP', u'VBZ', u'RB', u'JJ', u'CC', u'JJ', u'NNP', u'-LRB-', u'IN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'CC', u'DT', u'NNP', u'NNS', u'IN', u'DT', u'NNP', u'NNP', u'IN', u'DT', u'NN', u'IN', u'JJ', u'NNP', u'NNP', u'NNP', u'NNP', u'-LRB-', u'NNP', u'-RRB-', u',', u'JJ', u'JJ', u'NNS', u'VBP', u'VBN', u'.'], u'char_offsets': [[4835, 4838], [4839, 4847], [4848, 4850], [4851, 4854], [4855, 4865], [4866, 4874], [4875, 4878], [4879, 4889], [4890, 4895], [4896, 4898], [4899, 4902], [4903, 4907], [4908, 4910], [4911, 4914], [4915, 4918], [4919, 4924], [4925, 4927], [4928, 4932], [4933, 4935], [4936, 4939], [4940, 4948], [4949, 4956], [4956, 4957], [4958, 4961], [4962, 4968], [4969, 4972], [4973, 4983], [4984, 4993], [4994, 4996], [4997, 5000], [5001, 5011], [5012, 5020], [5021, 5024], [5025, 5031], [5032, 5036], [5037, 5041], [5042, 5044], [5045, 5048], [5049, 5056], [5057, 5060], [5061, 5069], [5070, 5077], [5078, 5079], [5079, 5086], [5087, 5095], [5096, 5098], [5099, 5102], [5103, 5110], [5111, 5117], [5118, 5120], [5121, 5127], [5128, 5131], [5132, 5135], [5136, 5141], [5142, 5148], [5149, 5151], [5152, 5155], [5156, 5162], [5163, 5168], [5169, 5171], [5172, 5175], [5176, 5184], [5185, 5187], [5188, 5199], [5200, 5202], [5203, 5206], [5207, 5211], [5212, 5216], [5217, 5218], [5218, 5224], [5224, 5225], [5225, 5226], [5227, 5241], [5242, 5247], [5248, 5258], [5259, 5263], [5264, 5271], [5271, 5272]]}) 
answer: set([u'official', u'administrative'])
candidate Sentence: (0.12883502244949341, {u'tokens': [u'It', u'is', u'also', u'spoken', u'as', u'a', u'second', u'language', u'by', u'many', u'ethnic', u'minorities', u'of', u'Vietnam', u'.'], u'lemmas': [u'it', u'be', u'also', u'speak', u'as', u'a', u'second', u'language', u'by', u'many', u'ethnic', u'minority', u'of', u'Vietnam', u'.'], u'pos': [u'PRP', u'VBZ', u'RB', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'JJ', u'JJ', u'NNS', u'IN', u'NNP', u'.'], u'char_offsets': [[592, 594], [595, 597], [598, 602], [603, 609], [610, 612], [613, 614], [615, 621], [622, 630], [631, 633], [634, 638], [639, 645], [646, 656], [657, 659], [660, 667], [667, 668]]}) 
answer: set([u'official', u'administrative'])
candidate Sentence: (0.11571545153856277, {u'tokens': [u'A', u'study', u'of', u'Middle', u'Vietnamese', u'phonology', u'.'], u'lemmas': [u'a', u'study', u'of', u'Middle', u'Vietnamese', u'phonology', u'.'], u'pos': [u'DT', u'NN', u'IN', u'NNP', u'NNP', u'NN', u'.'], u'char_offsets': [[30730, 30731], [30732, 30737], [30738, 30740], [30741, 30747], [30748, 30758], [30759, 30768], [30768, 30769]]}) 
answer: set([u'official', u'administrative', u'vietnam'])
candidate Sentence: (0.10960178077220917, {u'tokens': [u'Below', u'is', u'a', u'vowel', u'diagram', u'of', u'Hanoi', u'Vietnamese', u'.'], u'lemmas': [u'Below', u'be', u'a', u'vowel', u'diagram', u'of', u'Hanoi', u'Vietnamese', u'.'], u'pos': [u'NNP', u'VBZ', u'DT', u'NN', u'NN', u'IN', u'NNP', u'NNP', u'.'], u'char_offsets': [[8439, 8444], [8445, 8447], [8448, 8449], [8450, 8455], [8456, 8463], [8464, 8466], [8467, 8472], [8473, 8483], [8483, 8484]]}) 
answer: set([u'official', u'administrative', u'vietnam'])

Is Vietnamese the official administrative language of Vietnam?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114e15a8>.answer
_____________________________ test_yesno[param320] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e1638>, (<src.tfidf.TF_IDF object at 0x10e16f290>, set(['language', 'vietnamese', 'vietnamese_language'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes, Vietnamese was *formerly* written using the Chinese writing system.')
E                +    where 'Yes, Vietnamese was *formerly* written using the Chinese writing system.' = <src.question_processing.Question_parser instance at 0x1114e1638>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.41661214828491211, {u'tokens': [u'``', u'What', u"'s", u'so', u'Chinese', u'about', u'Vietnamese', u'?', u"''"], u'lemmas': [u'``', u'what', u'be', u'so', u'chinese', u'about', u'vietnamese', u'?', u"''"], u'pos': [u'``', u'WP', u'VBZ', u'RB', u'JJ', u'IN', u'NNS', u'.', u"''"], u'char_offsets': [[30347, 30348], [30348, 30352], [30352, 30354], [30355, 30357], [30358, 30365], [30366, 30371], [30372, 30382], [30382, 30383], [30383, 30384]]}) 
answer: set([u'write', u'use', u'formally', u'system', u'writing'])
candidate Sentence: (0.30014523863792419, {u'tokens': [u'Qu\u1ed1c-ng\u1eef', u':', u'The', u'modern', u'writing', u'system', u'in', u'Vietnam', u'.'], u'lemmas': [u'qu\u1ed1c-ng\u1eef', u':', u'the', u'modern', u'writing', u'system', u'in', u'Vietnam', u'.'], u'pos': [u'NN', u':', u'DT', u'JJ', u'NN', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[31374, 31382], [31382, 31383], [31384, 31387], [31388, 31394], [31395, 31402], [31403, 31409], [31410, 31412], [31413, 31420], [31420, 31421]]}) 
answer: set([u'write', u'use', u'formally', u'chinese'])
candidate Sentence: (0.27482596039772034, {u'tokens': [u'Much', u'vocabulary', u'has', u'been', u'borrowed', u'from', u'Chinese', u',', u'especially', u'words', u'that', u'denote', u'abstract', u'ideas', u'in', u'the', u'same', u'way', u'European', u'languages', u'borrow', u'from', u'Latin', u'and', u'Greek', u',', u'and', u'it', u'was', u'formerly', u'written', u'using', u'the', u'Chinese', u'writing', u'system', u',', u'albeit', u'in', u'a', u'modified', u'format', u'and', u'was', u'given', u'vernacular', u'pronunciation', u'.'], u'lemmas': [u'much', u'vocabulary', u'have', u'be', u'borrow', u'from', u'chinese', u',', u'especially', u'word', u'that', u'denote', u'abstract', u'idea', u'in', u'the', u'same', u'way', u'european', u'language', u'borrow', u'from', u'Latin', u'and', u'greek', u',', u'and', u'it', u'be', u'formerly', u'write', u'use', u'the', u'chinese', u'writing', u'system', u',', u'albeit', u'in', u'a', u'modify', u'format', u'and', u'be', u'give', u'vernacular', u'pronunciation', u'.'], u'pos': [u'JJ', u'NN', u'VBZ', u'VBN', u'VBN', u'IN', u'JJ', u',', u'RB', u'NNS', u'WDT', u'VBP', u'JJ', u'NNS', u'IN', u'DT', u'JJ', u'NN', u'JJ', u'NNS', u'VB', u'IN', u'NNP', u'CC', u'JJ', u',', u'CC', u'PRP', u'VBD', u'RB', u'VBN', u'VBG', u'DT', u'JJ', u'NN', u'NN', u',', u'IN', u'IN', u'DT', u'VBN', u'NN', u'CC', u'VBD', u'VBN', u'JJ', u'NN', u'.'], u'char_offsets': [[852, 856], [857, 867], [868, 871], [872, 876], [877, 885], [886, 890], [891, 898], [898, 899], [900, 910], [911, 916], [917, 921], [922, 928], [929, 937], [938, 943], [944, 946], [947, 950], [951, 955], [956, 959], [960, 968], [969, 978], [979, 985], [986, 990], [991, 996], [997, 1000], [1001, 1006], [1006, 1007], [1008, 1011], [1012, 1014], [1015, 1018], [1019, 1027], [1028, 1035], [1036, 1041], [1042, 1045], [1046, 1053], [1054, 1061], [1062, 1068], [1068, 1069], [1070, 1076], [1077, 1079], [1080, 1081], [1082, 1090], [1091, 1097], [1098, 1101], [1102, 1105], [1106, 1111], [1112, 1122], [1123, 1136], [1136, 1137]]}) 
answer: set([u'formally'])
candidate Sentence: (0.25652617216110229, {u'tokens': [u'Before', u'French', u'rule', u',', u'the', u'first', u'two', u'Vietnamese', u'writing', u'systems', u'were', u'based', u'on', u'Chinese', u'script', u':', u'*', u'the', u'standard', u'Chinese', u'character', u'set', u'called', u'ch\u1eef', u'nho', u'-LRB-', u'scholar', u"'s", u'characters', u',', u'\u5112', u'-RRB-', u':', u'used', u'to', u'write', u'Literary', u'Chinese', u'*', u'a', u'complicated', u'variant', u'form', u'known', u'as', u'ch\u1eef', u'n\xf4m', u'-LRB-', u'southern/vernacular', u'characters', u',', u'\u5583', u'-RRB-', u'with', u'characters', u'not', u'found', u'in', u'the', u'Chinese', u'character', u'set', u';', u'this', u'system', u'was', u'better', u'adapted', u'to', u'the', u'unique', u'phonetic', u'aspects', u'of', u'Vietnamese', u'which', u'differed', u'from', u'Chinese', u'The', u'authentic', u'Chinese', u'writing', u',', u'ch\u1eef', u'nho', u',', u'was', u'in', u'more', u'common', u'usage', u',', u'whereas', u'ch\u1eef', u'n\xf4m', u'was', u'used', u'by', u'members', u'of', u'the', u'educated', u'elite', u'-LRB-', u'one', u'needs', u'to', u'be', u'able', u'to', u'read', u'ch\u1eef', u'nho', u'in', u'order', u'to', u'read', u'ch\u1eef', u'n\xf4m', u'-RRB-', u'.'], u'lemmas': [u'before', u'french', u'rule', u',', u'the', u'first', u'two', u'vietnamese', u'write', u'system', u'be', u'base', u'on', u'chinese', u'script', u':', u'*', u'the', u'standard', u'chinese', u'character', u'set', u'call', u'ch\u1eef', u'nho', u'-lrb-', u'scholar', u"'s", u'character', u',', u'\u5112', u'-rrb-', u':', u'use', u'to', u'write', u'Literary', u'Chinese', u'*', u'a', u'complicated', u'variant', u'form', u'know', u'as', u'ch\u1eef', u'n\xf4m', u'-lrb-', u'southern/vernacular', u'character', u',', u'\u5583', u'-rrb-', u'with', u'character', u'not', u'find', u'in', u'the', u'chinese', u'character', u'set', u';', u'this', u'system', u'be', u'better', u'adapt', u'to', u'the', u'unique', u'phonetic', u'aspect', u'of', u'vietnamese', u'which', u'differ', u'from', u'chinese', u'the', u'authentic', u'chinese', u'writing', u',', u'ch\u1eef', u'nho', u',', u'be', u'in', u'more', u'common', u'usage', u',', u'whereas', u'ch\u1eef', u'n\xf4m', u'be', u'use', u'by', u'member', u'of', u'the', u'educate', u'elite', u'-lrb-', u'one', u'need', u'to', u'be', u'able', u'to', u'read', u'ch\u1eef', u'nho', u'in', u'order', u'to', u'read', u'ch\u1eef', u'n\xf4m', u'-rrb-', u'.'], u'pos': [u'IN', u'JJ', u'NN', u',', u'DT', u'JJ', u'CD', u'JJ', u'VBG', u'NNS', u'VBD', u'VBN', u'IN', u'JJ', u'NN', u':', u'SYM', u'DT', u'JJ', u'JJ', u'NN', u'NN', u'VBN', u'NN', u'NN', u'-LRB-', u'NN', u'POS', u'NNS', u',', u'NN', u'-RRB-', u':', u'VBN', u'TO', u'VB', u'NNP', u'NNP', u'SYM', u'DT', u'JJ', u'JJ', u'NN', u'VBN', u'IN', u'NN', u'NN', u'-LRB-', u'JJ', u'NNS', u',', u'NN', u'-RRB-', u'IN', u'NNS', u'RB', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'NN', u':', u'DT', u'NN', u'VBD', u'RBR', u'VBN', u'TO', u'DT', u'JJ', u'JJ', u'NNS', u'IN', u'NNS', u'WDT', u'VBD', u'IN', u'JJ', u'DT', u'JJ', u'JJ', u'NN', u',', u'NN', u'NN', u',', u'VBD', u'IN', u'RBR', u'JJ', u'NN', u',', u'IN', u'NN', u'NN', u'VBD', u'VBN', u'IN', u'NNS', u'IN', u'DT', u'VBN', u'NN', u'-LRB-', u'CD', u'VBZ', u'TO', u'VB', u'JJ', u'TO', u'VB', u'NN', u'NN', u'IN', u'NN', u'TO', u'VB', u'NN', u'NN', u'-RRB-', u'.'], u'char_offsets': [[22130, 22136], [22137, 22143], [22144, 22148], [22148, 22149], [22150, 22153], [22154, 22159], [22160, 22163], [22164, 22174], [22175, 22182], [22183, 22190], [22191, 22195], [22196, 22201], [22202, 22204], [22205, 22212], [22213, 22219], [22219, 22220], [22221, 22222], [22223, 22226], [22227, 22235], [22236, 22243], [22244, 22253], [22254, 22257], [22258, 22264], [22265, 22268], [22269, 22272], [22273, 22274], [22274, 22281], [22281, 22283], [22284, 22294], [22294, 22295], [22299, 22300], [22300, 22301], [22301, 22302], [22303, 22307], [22308, 22310], [22311, 22316], [22317, 22325], [22326, 22333], [22334, 22335], [22336, 22337], [22338, 22349], [22350, 22357], [22358, 22362], [22363, 22368], [22369, 22371], [22372, 22375], [22376, 22379], [22380, 22381], [22381, 22400], [22401, 22411], [22411, 22412], [22416, 22417], [22417, 22418], [22419, 22423], [22424, 22434], [22435, 22438], [22439, 22444], [22445, 22447], [22448, 22451], [22452, 22459], [22460, 22469], [22470, 22473], [22473, 22474], [22475, 22479], [22480, 22486], [22487, 22490], [22491, 22497], [22498, 22505], [22506, 22508], [22509, 22512], [22513, 22519], [22520, 22528], [22529, 22536], [22537, 22539], [22540, 22550], [22551, 22556], [22557, 22565], [22566, 22570], [22571, 22578], [22579, 22582], [22583, 22592], [22593, 22600], [22601, 22608], [22608, 22609], [22610, 22613], [22614, 22617], [22617, 22618], [22619, 22622], [22623, 22625], [22626, 22630], [22631, 22637], [22638, 22643], [22643, 22644], [22645, 22652], [22653, 22656], [22657, 22660], [22661, 22664], [22665, 22669], [22670, 22672], [22673, 22680], [22681, 22683], [22684, 22687], [22688, 22696], [22697, 22702], [22703, 22704], [22704, 22707], [22708, 22713], [22714, 22716], [22717, 22719], [22720, 22724], [22725, 22727], [22728, 22732], [22733, 22736], [22737, 22740], [22741, 22743], [22744, 22749], [22750, 22752], [22753, 22757], [22758, 22761], [22762, 22765], [22765, 22766], [22766, 22767]]}) 
answer: set([u'formally'])
candidate Sentence: (0.24839325249195099, {u'tokens': [u'The', u'Vietnamese', u'writing', u'system', u'in', u'use', u'today', u'is', u'an', u'adapted', u'version', u'of', u'the', u'Latin', u'alphabet', u',', u'with', u'additional', u'diacritics', u'for', u'tones', u'and', u'certain', u'letters', u'.'], u'lemmas': [u'the', u'vietnamese', u'writing', u'system', u'in', u'use', u'today', u'be', u'a', u'adapt', u'version', u'of', u'the', u'Latin', u'alphabet', u',', u'with', u'additional', u'diacritic', u'for', u'tone', u'and', u'certain', u'letter', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'NN', u'IN', u'NN', u'NN', u'VBZ', u'DT', u'VBN', u'NN', u'IN', u'DT', u'NNP', u'NN', u',', u'IN', u'JJ', u'NNS', u'IN', u'NNS', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[1138, 1141], [1142, 1152], [1153, 1160], [1161, 1167], [1168, 1170], [1171, 1174], [1175, 1180], [1181, 1183], [1184, 1186], [1187, 1194], [1195, 1202], [1203, 1205], [1206, 1209], [1210, 1215], [1216, 1224], [1224, 1225], [1226, 1230], [1231, 1241], [1242, 1252], [1253, 1256], [1257, 1262], [1263, 1266], [1267, 1274], [1275, 1282], [1282, 1283]]}) 
answer: set([u'write', u'formally', u'chinese'])
candidate Sentence: (0.24397403001785278, {u'tokens': [u'For', u'most', u'of', u'its', u'history', u',', u'the', u'entity', u'now', u'known', u'as', u'Vietnam', u'used', u'written', u'classical', u'Chinese', u'for', u'governing', u'purposes', u',', u'whereas', u'written', u'Vietnamese', u'in', u'the', u'form', u'of', u'Ch\u1eef', u'n\xf4m', u'was', u'used', u'for', u'poetry', u'and', u'literature', u'.'], u'lemmas': [u'for', u'most', u'of', u'its', u'history', u',', u'the', u'entity', u'now', u'know', u'as', u'Vietnam', u'use', u'write', u'classical', u'chinese', u'for', u'govern', u'purpose', u',', u'whereas', u'write', u'vietnamese', u'in', u'the', u'form', u'of', u'ch\u1eef', u'n\xf4m', u'be', u'use', u'for', u'poetry', u'and', u'literature', u'.'], u'pos': [u'IN', u'JJS', u'IN', u'PRP$', u'NN', u',', u'DT', u'NN', u'RB', u'VBN', u'IN', u'NNP', u'VBD', u'VBN', u'JJ', u'JJ', u'IN', u'VBG', u'NNS', u',', u'IN', u'VBN', u'NNS', u'IN', u'DT', u'NN', u'IN', u'NN', u'NN', u'VBD', u'VBN', u'IN', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[3251, 3254], [3255, 3259], [3260, 3262], [3263, 3266], [3267, 3274], [3274, 3275], [3276, 3279], [3280, 3286], [3287, 3290], [3291, 3296], [3297, 3299], [3300, 3307], [3308, 3312], [3313, 3320], [3321, 3330], [3331, 3338], [3339, 3342], [3343, 3352], [3353, 3361], [3361, 3362], [3363, 3370], [3371, 3378], [3379, 3389], [3390, 3392], [3393, 3396], [3397, 3401], [3402, 3404], [3405, 3408], [3409, 3412], [3413, 3416], [3417, 3421], [3422, 3425], [3426, 3432], [3433, 3436], [3437, 3447], [3447, 3448]]}) 
answer: set([u'formally', u'system', u'writing'])
candidate Sentence: (0.23686611652374268, {u'tokens': [u'In', u'fact', u',', u'as', u'the', u'vernacular', u'language', u'of', u'Vietnam', u'gradually', u'grew', u'in', u'prestige', u'toward', u'the', u'beginning', u'of', u'the', u'second', u'millennium', u',', u'the', u'Vietnamese', u'language', u'was', u'written', u'using', u'Chinese', u'characters', u'-LRB-', u'using', u'both', u'the', u'original', u'Chinese', u'characters', u',', u'called', u'H\xe1n', u't\u1ef1', u',', u'as', u'well', u'as', u'a', u'system', u'of', u'newly', u'created', u'and', u'modified', u'characters', u'called', u'Ch\u1eef', u'n\xf4m', u'-RRB-', u'adapted', u'to', u'write', u'Vietnamese', u',', u'in', u'a', u'similar', u'pattern', u'as', u'used', u'in', u'Japan', u'-LRB-', u'kanji', u'-RRB-', u',', u'Korea', u'-LRB-', u'hanja', u'-RRB-', u',', u'and', u'other', u'countries', u'in', u'the', u'Sinosphere', u'.'], u'lemmas': [u'in', u'fact', u',', u'as', u'the', u'vernacular', u'language', u'of', u'Vietnam', u'gradually', u'grow', u'in', u'prestige', u'toward', u'the', u'beginning', u'of', u'the', u'second', u'millennium', u',', u'the', u'vietnamese', u'language', u'be', u'write', u'use', u'chinese', u'character', u'-lrb-', u'use', u'both', u'the', u'original', u'chinese', u'character', u',', u'call', u'H\xe1n', u't\u1ef1', u',', u'as', u'well', u'as', u'a', u'system', u'of', u'newly', u'create', u'and', u'modify', u'character', u'call', u'Ch\u1eef', u'n\xf4m', u'-rrb-', u'adapt', u'to', u'write', u'vietnamese', u',', u'in', u'a', u'similar', u'pattern', u'as', u'use', u'in', u'Japan', u'-lrb-', u'kanji', u'-rrb-', u',', u'Korea', u'-lrb-', u'hanja', u'-rrb-', u',', u'and', u'other', u'country', u'in', u'the', u'Sinosphere', u'.'], u'pos': [u'IN', u'NN', u',', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NNP', u'RB', u'VBD', u'IN', u'NN', u'IN', u'DT', u'NN', u'IN', u'DT', u'JJ', u'NNP', u',', u'DT', u'JJ', u'NN', u'VBD', u'VBN', u'VBG', u'JJ', u'NNS', u'-LRB-', u'VBG', u'CC', u'DT', u'JJ', u'JJ', u'NNS', u',', u'VBN', u'NNP', u'NN', u',', u'RB', u'RB', u'IN', u'DT', u'NN', u'IN', u'RB', u'VBN', u'CC', u'VBN', u'NNS', u'VBD', u'NNP', u'NN', u'-RRB-', u'VBD', u'TO', u'VB', u'JJ', u',', u'IN', u'DT', u'JJ', u'NN', u'IN', u'VBN', u'IN', u'NNP', u'-LRB-', u'FW', u'-RRB-', u',', u'NNP', u'-LRB-', u'NN', u'-RRB-', u',', u'CC', u'JJ', u'NNS', u'IN', u'DT', u'NNP', u'.'], u'char_offsets': [[5766, 5768], [5769, 5773], [5773, 5774], [5775, 5777], [5778, 5781], [5782, 5792], [5793, 5801], [5802, 5804], [5805, 5812], [5813, 5822], [5823, 5827], [5828, 5830], [5831, 5839], [5840, 5846], [5847, 5850], [5851, 5860], [5861, 5863], [5864, 5867], [5868, 5874], [5875, 5885], [5885, 5886], [5887, 5890], [5891, 5901], [5902, 5910], [5911, 5914], [5915, 5922], [5923, 5928], [5929, 5936], [5937, 5947], [5948, 5949], [5949, 5954], [5955, 5959], [5960, 5963], [5964, 5972], [5973, 5980], [5981, 5991], [5991, 5992], [5993, 5999], [6000, 6003], [6004, 6006], [6006, 6007], [6008, 6010], [6011, 6015], [6016, 6018], [6019, 6020], [6021, 6027], [6028, 6030], [6031, 6036], [6037, 6044], [6045, 6048], [6049, 6057], [6058, 6068], [6069, 6075], [6076, 6079], [6080, 6083], [6083, 6084], [6085, 6092], [6093, 6095], [6096, 6101], [6102, 6112], [6112, 6113], [6114, 6116], [6117, 6118], [6119, 6126], [6127, 6134], [6135, 6137], [6138, 6142], [6143, 6145], [6146, 6151], [6152, 6153], [6153, 6158], [6158, 6159], [6159, 6160], [6161, 6166], [6167, 6168], [6168, 6173], [6173, 6174], [6174, 6175], [6176, 6179], [6180, 6185], [6186, 6195], [6196, 6198], [6199, 6202], [6203, 6213], [6213, 6214]]}) 
answer: set([u'formally', u'writing'])
candidate Sentence: (0.20272468030452728, {u'tokens': [u',', u'The', u'world', u"'s", u'writing', u'systems', u',', u'-LRB-', u'pp.', u'691-699', u'-RRB-', u'.'], u'lemmas': [u',', u'the', u'world', u"'s", u'write', u'system', u',', u'-lrb-', u'pp.', u'691-699', u'-rrb-', u'.'], u'pos': [u',', u'DT', u'NN', u'POS', u'VBG', u'NNS', u',', u'-LRB-', u'FW', u'CD', u'-RRB-', u'.'], u'char_offsets': [[31718, 31719], [31720, 31723], [31724, 31729], [31729, 31731], [31732, 31739], [31740, 31747], [31747, 31748], [31749, 31750], [31750, 31753], [31754, 31761], [31761, 31762], [31762, 31763]]}) 
answer: set([u'use', u'formally', u'chinese', u'writing'])
candidate Sentence: (0.14999784529209137, {u'tokens': [u'As', u'contact', u'with', u'the', u'West', u'grew', u',', u'the', u'Qu\u1ed1c', u'Ng\u1eef', u'system', u'of', u'Romanized', u'writing', u'was', u'developed', u'in', u'the', u'17th', u'century', u'by', u'Portuguese', u'and', u'other', u'Europeans', u'involved', u'in', u'proselytizing', u'and', u'trade', u'in', u'Vietnam', u'.'], u'lemmas': [u'as', u'contact', u'with', u'the', u'West', u'grow', u',', u'the', u'Qu\u1ed1c', u'ng\u1eef', u'system', u'of', u'romanized', u'writing', u'be', u'develop', u'in', u'the', u'17th', u'century', u'by', u'portuguese', u'and', u'other', u'european', u'involve', u'in', u'proselytize', u'and', u'trade', u'in', u'Vietnam', u'.'], u'pos': [u'IN', u'NN', u'IN', u'DT', u'NNP', u'VBD', u',', u'DT', u'NNP', u'NN', u'NN', u'IN', u'JJ', u'NN', u'VBD', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'IN', u'NN', u'CC', u'JJ', u'NNS', u'VBN', u'IN', u'VBG', u'CC', u'NN', u'IN', u'NNP', u'.'], u'char_offsets': [[6419, 6421], [6422, 6429], [6430, 6434], [6435, 6438], [6439, 6443], [6444, 6448], [6448, 6449], [6450, 6453], [6454, 6458], [6459, 6462], [6463, 6469], [6470, 6472], [6473, 6482], [6483, 6490], [6491, 6494], [6495, 6504], [6505, 6507], [6508, 6511], [6512, 6516], [6517, 6524], [6525, 6527], [6528, 6538], [6539, 6542], [6543, 6548], [6549, 6558], [6559, 6567], [6568, 6570], [6571, 6584], [6585, 6588], [6589, 6594], [6595, 6597], [6598, 6605], [6605, 6606]]}) 
answer: set([u'write', u'use', u'formally', u'chinese'])
candidate Sentence: (0.14655514061450958, {u'tokens': [u'Vietnamese', u'.'], u'lemmas': [u'vietnamese', u'.'], u'pos': [u'NNS', u'.'], u'char_offsets': [[31670, 31680], [31680, 31681]]}) 
answer: set([u'use', u'formally', u'chinese', u'system', u'writing', u'write'])

Was Vietnamese formally written using the Chinese writing system?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes, Vietnamese was *formerly* written using the Chinese writing system.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes, Vietnamese was *formerly* written using the Chinese writing system.')
 +    where 'Yes, Vietnamese was *formerly* written using the Chinese writing system.' = <src.question_processing.Question_parser instance at 0x1114e1638>.answer
_____________________________ test_yesno[param326] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e1998>, (<src.tfidf.TF_IDF object at 0x10a4b01d0>, set(['violin'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114e1998>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.3285260796546936, {u'tokens': [u'A', u'distinctive', u'feature', u'of', u'a', u'violin', u'body', u'is', u'its', u'``', u'hourglass', u"''", u'shape', u'and', u'the', u'arching', u'of', u'its', u'top', u'and', u'back', u'.'], u'lemmas': [u'a', u'distinctive', u'feature', u'of', u'a', u'violin', u'body', u'be', u'its', u'``', u'hourglass', u"''", u'shape', u'and', u'the', u'arching', u'of', u'its', u'top', u'and', u'back', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'NN', u'VBZ', u'PRP$', u'``', u'NN', u"''", u'NN', u'CC', u'DT', u'NN', u'IN', u'PRP$', u'JJ', u'CC', u'RB', u'.'], u'char_offsets': [[5550, 5551], [5552, 5563], [5564, 5571], [5572, 5574], [5575, 5576], [5577, 5583], [5584, 5588], [5589, 5591], [5592, 5595], [5596, 5597], [5597, 5606], [5606, 5607], [5608, 5613], [5614, 5617], [5618, 5621], [5622, 5629], [5630, 5632], [5633, 5636], [5637, 5640], [5641, 5644], [5645, 5649], [5649, 5650]]}) 
answer: set([u'like'])
candidate Sentence: (0.32379016280174255, {u'tokens': [u'*', u'Why', u'is', u'the', u'violin', u'so', u'hard', u'to', u'play', u'?'], u'lemmas': [u'*', u'why', u'be', u'the', u'violin', u'so', u'hard', u'to', u'play', u'?'], u'pos': [u'SYM', u'WRB', u'VBZ', u'DT', u'NN', u'RB', u'JJ', u'TO', u'VB', u'.'], u'char_offsets': [[44832, 44833], [44835, 44838], [44839, 44841], [44842, 44845], [44846, 44852], [44853, 44855], [44856, 44860], [44861, 44863], [44864, 44868], [44868, 44869]]}) 
answer: set([u'shape', u'like', u'hourglass'])
candidate Sentence: (0.20850390195846558, {u'tokens': [u'The', u'hourglass', u'shape', u'comprises', u'two', u'upper', u'bouts', u',', u'two', u'lower', u'bouts', u',', u'and', u'two', u'concave', u'C-bouts', u'at', u'the', u'``', u'waist', u',', u"''", u'providing', u'clearance', u'for', u'the', u'bow', u'.'], u'lemmas': [u'the', u'hourglass', u'shape', u'comprise', u'two', u'upper', u'bout', u',', u'two', u'lower', u'bout', u',', u'and', u'two', u'concave', u'c-bout', u'at', u'the', u'``', u'waist', u',', u"''", u'provide', u'clearance', u'for', u'the', u'bow', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBZ', u'CD', u'JJ', u'NNS', u',', u'CD', u'JJR', u'NNS', u',', u'CC', u'CD', u'JJ', u'NNS', u'IN', u'DT', u'``', u'NN', u',', u"''", u'VBG', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[5651, 5654], [5655, 5664], [5665, 5670], [5671, 5680], [5681, 5684], [5685, 5690], [5691, 5696], [5696, 5697], [5698, 5701], [5702, 5707], [5708, 5713], [5713, 5714], [5715, 5718], [5719, 5722], [5723, 5730], [5731, 5738], [5739, 5741], [5742, 5745], [5746, 5747], [5747, 5752], [5752, 5753], [5753, 5754], [5755, 5764], [5765, 5774], [5775, 5778], [5779, 5782], [5783, 5786], [5786, 5787]]}) 
answer: set([u'like'])
candidate Sentence: (0.15763877332210541, {u'tokens': [u'The', u'arched', u'shape', u',', u'the', u'thickness', u'of', u'the', u'wood', u',', u'and', u'its', u'physical', u'qualities', u'govern', u'the', u'sound', u'of', u'a', u'violin', u'.'], u'lemmas': [u'the', u'arched', u'shape', u',', u'the', u'thickness', u'of', u'the', u'wood', u',', u'and', u'its', u'physical', u'quality', u'govern', u'the', u'sound', u'of', u'a', u'violin', u'.'], u'pos': [u'DT', u'JJ', u'NN', u',', u'DT', u'NN', u'IN', u'DT', u'NN', u',', u'CC', u'PRP$', u'JJ', u'NNS', u'VBP', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[10174, 10177], [10178, 10184], [10185, 10190], [10190, 10191], [10192, 10195], [10196, 10205], [10206, 10208], [10209, 10212], [10213, 10217], [10217, 10218], [10219, 10222], [10223, 10226], [10227, 10235], [10236, 10245], [10246, 10252], [10253, 10256], [10257, 10262], [10263, 10265], [10266, 10267], [10268, 10274], [10274, 10275]]}) 
answer: set([u'like', u'hourglass'])
candidate Sentence: (0.12673331797122955, {u'tokens': [u'The', u'electric', u'violin', u'has', u'even', u'been', u'used', u'by', u'bands', u'like', u'The', u'Cr\xfcxshadows', u'within', u'the', u'context', u'of', u'keyboard', u'based', u'music', u'.'], u'lemmas': [u'the', u'electric', u'violin', u'have', u'even', u'be', u'use', u'by', u'band', u'like', u'the', u'cr\xfcxshadows', u'within', u'the', u'context', u'of', u'keyboard', u'base', u'music', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'RB', u'VBN', u'VBN', u'IN', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'DT', u'NN', u'IN', u'NN', u'VBN', u'NN', u'.'], u'char_offsets': [[37837, 37840], [37841, 37849], [37850, 37856], [37857, 37860], [37861, 37865], [37866, 37870], [37871, 37875], [37876, 37878], [37879, 37884], [37885, 37889], [37890, 37893], [37894, 37905], [37906, 37912], [37913, 37916], [37917, 37924], [37925, 37927], [37928, 37936], [37937, 37942], [37943, 37948], [37948, 37949]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.11969494819641113, {u'tokens': [u'The', u'oldest', u'documented', u'violin', u'to', u'have', u'four', u'strings', u',', u'like', u'the', u'modern', u'violin', u',', u'is', u'supposed', u'to', u'have', u'been', u'constructed', u'in', u'1555', u'by', u'Andrea', u'Amati', u',', u'but', u'the', u'date', u'is', u'doubtuful', u'.'], u'lemmas': [u'the', u'oldest', u'document', u'violin', u'to', u'have', u'four', u'string', u',', u'like', u'the', u'modern', u'violin', u',', u'be', u'suppose', u'to', u'have', u'be', u'construct', u'in', u'1555', u'by', u'Andrea', u'Amati', u',', u'but', u'the', u'date', u'be', u'doubtuful', u'.'], u'pos': [u'DT', u'JJS', u'VBN', u'NN', u'TO', u'VB', u'CD', u'NNS', u',', u'IN', u'DT', u'JJ', u'NN', u',', u'VBZ', u'VBN', u'TO', u'VB', u'VBN', u'VBN', u'IN', u'CD', u'IN', u'NNP', u'NNP', u',', u'CC', u'DT', u'NN', u'VBZ', u'JJ', u'.'], u'char_offsets': [[3275, 3278], [3279, 3285], [3286, 3296], [3297, 3303], [3304, 3306], [3307, 3311], [3312, 3316], [3317, 3324], [3324, 3325], [3326, 3330], [3331, 3334], [3335, 3341], [3342, 3348], [3348, 3349], [3350, 3352], [3353, 3361], [3362, 3364], [3365, 3369], [3370, 3374], [3375, 3386], [3387, 3389], [3390, 3394], [3395, 3397], [3398, 3404], [3405, 3410], [3410, 3411], [3412, 3415], [3416, 3419], [3420, 3424], [3425, 3427], [3428, 3437], [3437, 3438]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.10749715566635132, {u'tokens': [u'The', u'``', u'voice', u"''", u'of', u'a', u'violin', u'depends', u'on', u'its', u'shape', u',', u'the', u'wood', u'it', u'is', u'made', u'from', u',', u'the', u'graduation', u'-LRB-', u'the', u'thickness', u'profile', u'-RRB-', u'of', u'both', u'the', u'top', u'and', u'back', u',', u'and', u'the', u'varnish', u'which', u'coats', u'its', u'outside', u'surface', u'.'], u'lemmas': [u'the', u'``', u'voice', u"''", u'of', u'a', u'violin', u'depend', u'on', u'its', u'shape', u',', u'the', u'wood', u'it', u'be', u'make', u'from', u',', u'the', u'graduation', u'-lrb-', u'the', u'thickness', u'profile', u'-rrb-', u'of', u'both', u'the', u'top', u'and', u'back', u',', u'and', u'the', u'varnish', u'which', u'coat', u'its', u'outside', u'surface', u'.'], u'pos': [u'DT', u'``', u'NN', u"''", u'IN', u'DT', u'NN', u'VBZ', u'IN', u'PRP$', u'NN', u',', u'DT', u'NN', u'PRP', u'VBZ', u'VBN', u'IN', u',', u'DT', u'NN', u'-LRB-', u'DT', u'NN', u'NN', u'-RRB-', u'IN', u'CC', u'DT', u'JJ', u'CC', u'RB', u',', u'CC', u'DT', u'NN', u'WDT', u'NNS', u'PRP$', u'JJ', u'NN', u'.'], u'char_offsets': [[5788, 5791], [5792, 5793], [5793, 5798], [5798, 5799], [5800, 5802], [5803, 5804], [5805, 5811], [5812, 5819], [5820, 5822], [5823, 5826], [5827, 5832], [5832, 5833], [5834, 5837], [5838, 5842], [5843, 5845], [5846, 5848], [5849, 5853], [5854, 5858], [5858, 5859], [5860, 5863], [5864, 5874], [5875, 5876], [5876, 5879], [5880, 5889], [5890, 5897], [5897, 5898], [5899, 5901], [5902, 5906], [5907, 5910], [5911, 5914], [5915, 5918], [5919, 5923], [5923, 5924], [5925, 5928], [5929, 5932], [5933, 5940], [5941, 5946], [5947, 5952], [5953, 5956], [5957, 5964], [5965, 5972], [5972, 5973]]}) 
answer: set([u'like', u'hourglass'])
candidate Sentence: (0.10012640058994293, {u'tokens': [u'Hins-Anders', u'painted', u'by', u'Anders', u'Zorn', u',', u'1904', u'Like', u'many', u'other', u'instruments', u'used', u'in', u'classical', u'music', u',', u'the', u'violin', u'descends', u'from', u'remote', u'ancestors', u'that', u'were', u'used', u'for', u'folk', u'music', u'.'], u'lemmas': [u'Hins-Anders', u'paint', u'by', u'Anders', u'Zorn', u',', u'1904', u'like', u'many', u'other', u'instrument', u'use', u'in', u'classical', u'music', u',', u'the', u'violin', u'descend', u'from', u'remote', u'ancestor', u'that', u'be', u'use', u'for', u'folk', u'music', u'.'], u'pos': [u'NNP', u'VBN', u'IN', u'NNP', u'NNP', u',', u'CD', u'IN', u'JJ', u'JJ', u'NNS', u'VBN', u'IN', u'JJ', u'NN', u',', u'DT', u'NN', u'VBZ', u'IN', u'JJ', u'NNS', u'WDT', u'VBD', u'VBN', u'IN', u'NN', u'NN', u'.'], u'char_offsets': [[38506, 38517], [38518, 38525], [38526, 38528], [38529, 38535], [38536, 38540], [38540, 38541], [38542, 38546], [38547, 38551], [38552, 38556], [38557, 38562], [38563, 38574], [38575, 38579], [38580, 38582], [38583, 38592], [38593, 38598], [38598, 38599], [38600, 38603], [38604, 38610], [38611, 38619], [38620, 38624], [38625, 38631], [38632, 38641], [38642, 38646], [38647, 38651], [38652, 38656], [38657, 38660], [38661, 38665], [38666, 38671], [38671, 38672]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.082919992506504059, {u'tokens': [u'An', u'electric', u'violin', u'is', u'a', u'violin', u'equipped', u'with', u'an', u'electric', u'signal', u'output', u'of', u'its', u'sound', u',', u'and', u'is', u'generally', u'considered', u'to', u'be', u'a', u'specially', u'constructed', u'instrument', u'which', u'can', u'either', u'be', u':', u'*', u'an', u'electro-acoustic', u'violin', u'capable', u'of', u'producing', u'both', u'acoustic', u'sound', u'and', u'electric', u'signal', u'*', u'an', u'electric', u'violin', u'capable', u'of', u'producing', u'only', u'electric', u'signal', u'To', u'be', u'effective', u'as', u'an', u'acoustic', u'violin', u',', u'electro-acoustic', u'violins', u'retain', u'much', u'of', u'the', u'resonating', u'body', u'of', u'the', u'violin', u',', u'often', u'looking', u'very', u'much', u'like', u',', u'sometimes', u'even', u'identical', u'to', u',', u'an', u'acoustic', u'violin', u'or', u'fiddle', u'.'], u'lemmas': [u'a', u'electric', u'violin', u'be', u'a', u'violin', u'equip', u'with', u'a', u'electric', u'signal', u'output', u'of', u'its', u'sound', u',', u'and', u'be', u'generally', u'consider', u'to', u'be', u'a', u'specially', u'construct', u'instrument', u'which', u'can', u'either', u'be', u':', u'*', u'a', u'electro-acoustic', u'violin', u'capable', u'of', u'produce', u'both', u'acoustic', u'sound', u'and', u'electric', u'signal', u'*', u'a', u'electric', u'violin', u'capable', u'of', u'produce', u'only', u'electric', u'signal', u'to', u'be', u'effective', u'as', u'a', u'acoustic', u'violin', u',', u'electro-acoustic', u'violin', u'retain', u'much', u'of', u'the', u'resonate', u'body', u'of', u'the', u'violin', u',', u'often', u'look', u'very', u'much', u'like', u',', u'sometimes', u'even', u'identical', u'to', u',', u'a', u'acoustic', u'violin', u'or', u'fiddle', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'NN', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'VBZ', u'RB', u'VBN', u'TO', u'VB', u'DT', u'RB', u'VBN', u'NN', u'WDT', u'MD', u'RB', u'VB', u':', u'SYM', u'DT', u'JJ', u'NN', u'JJ', u'IN', u'VBG', u'CC', u'JJ', u'NN', u'CC', u'JJ', u'NN', u'SYM', u'DT', u'JJ', u'NN', u'JJ', u'IN', u'VBG', u'RB', u'JJ', u'NN', u'TO', u'VB', u'JJ', u'IN', u'DT', u'JJ', u'NN', u',', u'JJ', u'NNS', u'VBP', u'RB', u'IN', u'DT', u'VBG', u'NN', u'IN', u'DT', u'NN', u',', u'RB', u'VBG', u'RB', u'RB', u'IN', u',', u'RB', u'RB', u'JJ', u'TO', u',', u'DT', u'JJ', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[40040, 40042], [40043, 40051], [40052, 40058], [40059, 40061], [40062, 40063], [40064, 40070], [40071, 40079], [40080, 40084], [40085, 40087], [40088, 40096], [40097, 40103], [40104, 40110], [40111, 40113], [40114, 40117], [40118, 40123], [40123, 40124], [40125, 40128], [40129, 40131], [40132, 40141], [40142, 40152], [40153, 40155], [40156, 40158], [40159, 40160], [40161, 40170], [40171, 40182], [40183, 40193], [40194, 40199], [40200, 40203], [40204, 40210], [40211, 40213], [40213, 40214], [40215, 40216], [40217, 40219], [40220, 40236], [40237, 40243], [40244, 40251], [40252, 40254], [40255, 40264], [40265, 40269], [40270, 40278], [40279, 40284], [40285, 40288], [40289, 40297], [40298, 40304], [40305, 40306], [40307, 40309], [40310, 40318], [40319, 40325], [40326, 40333], [40334, 40336], [40337, 40346], [40347, 40351], [40352, 40360], [40361, 40367], [40368, 40370], [40371, 40373], [40374, 40383], [40384, 40386], [40387, 40389], [40390, 40398], [40399, 40405], [40405, 40406], [40407, 40423], [40424, 40431], [40432, 40438], [40439, 40443], [40444, 40446], [40447, 40450], [40451, 40461], [40462, 40466], [40467, 40469], [40470, 40473], [40474, 40480], [40480, 40481], [40482, 40487], [40488, 40495], [40496, 40500], [40501, 40505], [40506, 40510], [40510, 40511], [40512, 40521], [40522, 40526], [40527, 40536], [40537, 40539], [40539, 40540], [40541, 40543], [40544, 40552], [40553, 40559], [40560, 40562], [40563, 40569], [40569, 40570]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.079056888818740845, {u'tokens': [u'The', u'tailpiece', u'anchors', u'the', u'strings', u'to', u'the', u'lower', u'bout', u'of', u'the', u'violin', u'by', u'means', u'of', u'the', u'tailgut', u',', u'which', u'loops', u'around', u'an', u'ebony', u'button', u'called', u'the', u'tailpin', u'-LRB-', u'sometimes', u'confusingly', u'called', u'``', u'endpin', u"''", u'like', u'the', u'cello', u"'s", u'spike', u'-RRB-', u',', u'which', u'fits', u'into', u'a', u'tapered', u'hole', u'in', u'the', u'bottom', u'block', u'.'], u'lemmas': [u'the', u'tailpiece', u'anchor', u'the', u'string', u'to', u'the', u'lower', u'bout', u'of', u'the', u'violin', u'by', u'means', u'of', u'the', u'tailgut', u',', u'which', u'loop', u'around', u'a', u'ebony', u'button', u'call', u'the', u'tailpin', u'-lrb-', u'sometimes', u'confusingly', u'call', u'``', u'endpin', u"''", u'like', u'the', u'cello', u"'s", u'spike', u'-rrb-', u',', u'which', u'fit', u'into', u'a', u'tapered', u'hole', u'in', u'the', u'bottom', u'block', u'.'], u'pos': [u'DT', u'NN', u'NNS', u'DT', u'NNS', u'TO', u'DT', u'JJR', u'NN', u'IN', u'DT', u'NN', u'IN', u'NNS', u'IN', u'DT', u'NN', u',', u'WDT', u'NNS', u'IN', u'DT', u'NN', u'NN', u'VBD', u'DT', u'NN', u'-LRB-', u'RB', u'RB', u'VBN', u'``', u'NN', u"''", u'IN', u'DT', u'NN', u'POS', u'NN', u'-RRB-', u',', u'WDT', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[8430, 8433], [8434, 8443], [8444, 8451], [8452, 8455], [8456, 8463], [8464, 8466], [8467, 8470], [8471, 8476], [8477, 8481], [8482, 8484], [8485, 8488], [8489, 8495], [8496, 8498], [8499, 8504], [8505, 8507], [8508, 8511], [8512, 8519], [8519, 8520], [8521, 8526], [8527, 8532], [8533, 8539], [8540, 8542], [8543, 8548], [8549, 8555], [8556, 8562], [8563, 8566], [8567, 8574], [8575, 8576], [8576, 8585], [8586, 8597], [8598, 8604], [8605, 8606], [8606, 8612], [8612, 8613], [8614, 8618], [8619, 8622], [8623, 8628], [8628, 8630], [8631, 8636], [8636, 8637], [8637, 8638], [8639, 8644], [8645, 8649], [8650, 8654], [8655, 8656], [8657, 8664], [8665, 8669], [8670, 8672], [8673, 8676], [8677, 8683], [8684, 8689], [8689, 8690]]}) 
answer: set([u'shape', u'hourglass'])

Is the violin shaped like an hourglass?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114e1998>.answer
_____________________________ test_yesno[param327] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e1a28>, (<src.tfidf.TF_IDF object at 0x10a4b01d0>, set(['violin'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes.')
E                +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114e1a28>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.3285260796546936, {u'tokens': [u'A', u'distinctive', u'feature', u'of', u'a', u'violin', u'body', u'is', u'its', u'``', u'hourglass', u"''", u'shape', u'and', u'the', u'arching', u'of', u'its', u'top', u'and', u'back', u'.'], u'lemmas': [u'a', u'distinctive', u'feature', u'of', u'a', u'violin', u'body', u'be', u'its', u'``', u'hourglass', u"''", u'shape', u'and', u'the', u'arching', u'of', u'its', u'top', u'and', u'back', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'IN', u'DT', u'NN', u'NN', u'VBZ', u'PRP$', u'``', u'NN', u"''", u'NN', u'CC', u'DT', u'NN', u'IN', u'PRP$', u'JJ', u'CC', u'RB', u'.'], u'char_offsets': [[5550, 5551], [5552, 5563], [5564, 5571], [5572, 5574], [5575, 5576], [5577, 5583], [5584, 5588], [5589, 5591], [5592, 5595], [5596, 5597], [5597, 5606], [5606, 5607], [5608, 5613], [5614, 5617], [5618, 5621], [5622, 5629], [5630, 5632], [5633, 5636], [5637, 5640], [5641, 5644], [5645, 5649], [5649, 5650]]}) 
answer: set([u'like'])
candidate Sentence: (0.32379016280174255, {u'tokens': [u'*', u'Why', u'is', u'the', u'violin', u'so', u'hard', u'to', u'play', u'?'], u'lemmas': [u'*', u'why', u'be', u'the', u'violin', u'so', u'hard', u'to', u'play', u'?'], u'pos': [u'SYM', u'WRB', u'VBZ', u'DT', u'NN', u'RB', u'JJ', u'TO', u'VB', u'.'], u'char_offsets': [[44832, 44833], [44835, 44838], [44839, 44841], [44842, 44845], [44846, 44852], [44853, 44855], [44856, 44860], [44861, 44863], [44864, 44868], [44868, 44869]]}) 
answer: set([u'shape', u'like', u'hourglass'])
candidate Sentence: (0.20850390195846558, {u'tokens': [u'The', u'hourglass', u'shape', u'comprises', u'two', u'upper', u'bouts', u',', u'two', u'lower', u'bouts', u',', u'and', u'two', u'concave', u'C-bouts', u'at', u'the', u'``', u'waist', u',', u"''", u'providing', u'clearance', u'for', u'the', u'bow', u'.'], u'lemmas': [u'the', u'hourglass', u'shape', u'comprise', u'two', u'upper', u'bout', u',', u'two', u'lower', u'bout', u',', u'and', u'two', u'concave', u'c-bout', u'at', u'the', u'``', u'waist', u',', u"''", u'provide', u'clearance', u'for', u'the', u'bow', u'.'], u'pos': [u'DT', u'NN', u'NN', u'VBZ', u'CD', u'JJ', u'NNS', u',', u'CD', u'JJR', u'NNS', u',', u'CC', u'CD', u'JJ', u'NNS', u'IN', u'DT', u'``', u'NN', u',', u"''", u'VBG', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[5651, 5654], [5655, 5664], [5665, 5670], [5671, 5680], [5681, 5684], [5685, 5690], [5691, 5696], [5696, 5697], [5698, 5701], [5702, 5707], [5708, 5713], [5713, 5714], [5715, 5718], [5719, 5722], [5723, 5730], [5731, 5738], [5739, 5741], [5742, 5745], [5746, 5747], [5747, 5752], [5752, 5753], [5753, 5754], [5755, 5764], [5765, 5774], [5775, 5778], [5779, 5782], [5783, 5786], [5786, 5787]]}) 
answer: set([u'like'])
candidate Sentence: (0.15763877332210541, {u'tokens': [u'The', u'arched', u'shape', u',', u'the', u'thickness', u'of', u'the', u'wood', u',', u'and', u'its', u'physical', u'qualities', u'govern', u'the', u'sound', u'of', u'a', u'violin', u'.'], u'lemmas': [u'the', u'arched', u'shape', u',', u'the', u'thickness', u'of', u'the', u'wood', u',', u'and', u'its', u'physical', u'quality', u'govern', u'the', u'sound', u'of', u'a', u'violin', u'.'], u'pos': [u'DT', u'JJ', u'NN', u',', u'DT', u'NN', u'IN', u'DT', u'NN', u',', u'CC', u'PRP$', u'JJ', u'NNS', u'VBP', u'DT', u'NN', u'IN', u'DT', u'NN', u'.'], u'char_offsets': [[10174, 10177], [10178, 10184], [10185, 10190], [10190, 10191], [10192, 10195], [10196, 10205], [10206, 10208], [10209, 10212], [10213, 10217], [10217, 10218], [10219, 10222], [10223, 10226], [10227, 10235], [10236, 10245], [10246, 10252], [10253, 10256], [10257, 10262], [10263, 10265], [10266, 10267], [10268, 10274], [10274, 10275]]}) 
answer: set([u'like', u'hourglass'])
candidate Sentence: (0.12673331797122955, {u'tokens': [u'The', u'electric', u'violin', u'has', u'even', u'been', u'used', u'by', u'bands', u'like', u'The', u'Cr\xfcxshadows', u'within', u'the', u'context', u'of', u'keyboard', u'based', u'music', u'.'], u'lemmas': [u'the', u'electric', u'violin', u'have', u'even', u'be', u'use', u'by', u'band', u'like', u'the', u'cr\xfcxshadows', u'within', u'the', u'context', u'of', u'keyboard', u'base', u'music', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'RB', u'VBN', u'VBN', u'IN', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'DT', u'NN', u'IN', u'NN', u'VBN', u'NN', u'.'], u'char_offsets': [[37837, 37840], [37841, 37849], [37850, 37856], [37857, 37860], [37861, 37865], [37866, 37870], [37871, 37875], [37876, 37878], [37879, 37884], [37885, 37889], [37890, 37893], [37894, 37905], [37906, 37912], [37913, 37916], [37917, 37924], [37925, 37927], [37928, 37936], [37937, 37942], [37943, 37948], [37948, 37949]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.11969494819641113, {u'tokens': [u'The', u'oldest', u'documented', u'violin', u'to', u'have', u'four', u'strings', u',', u'like', u'the', u'modern', u'violin', u',', u'is', u'supposed', u'to', u'have', u'been', u'constructed', u'in', u'1555', u'by', u'Andrea', u'Amati', u',', u'but', u'the', u'date', u'is', u'doubtuful', u'.'], u'lemmas': [u'the', u'oldest', u'document', u'violin', u'to', u'have', u'four', u'string', u',', u'like', u'the', u'modern', u'violin', u',', u'be', u'suppose', u'to', u'have', u'be', u'construct', u'in', u'1555', u'by', u'Andrea', u'Amati', u',', u'but', u'the', u'date', u'be', u'doubtuful', u'.'], u'pos': [u'DT', u'JJS', u'VBN', u'NN', u'TO', u'VB', u'CD', u'NNS', u',', u'IN', u'DT', u'JJ', u'NN', u',', u'VBZ', u'VBN', u'TO', u'VB', u'VBN', u'VBN', u'IN', u'CD', u'IN', u'NNP', u'NNP', u',', u'CC', u'DT', u'NN', u'VBZ', u'JJ', u'.'], u'char_offsets': [[3275, 3278], [3279, 3285], [3286, 3296], [3297, 3303], [3304, 3306], [3307, 3311], [3312, 3316], [3317, 3324], [3324, 3325], [3326, 3330], [3331, 3334], [3335, 3341], [3342, 3348], [3348, 3349], [3350, 3352], [3353, 3361], [3362, 3364], [3365, 3369], [3370, 3374], [3375, 3386], [3387, 3389], [3390, 3394], [3395, 3397], [3398, 3404], [3405, 3410], [3410, 3411], [3412, 3415], [3416, 3419], [3420, 3424], [3425, 3427], [3428, 3437], [3437, 3438]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.10749715566635132, {u'tokens': [u'The', u'``', u'voice', u"''", u'of', u'a', u'violin', u'depends', u'on', u'its', u'shape', u',', u'the', u'wood', u'it', u'is', u'made', u'from', u',', u'the', u'graduation', u'-LRB-', u'the', u'thickness', u'profile', u'-RRB-', u'of', u'both', u'the', u'top', u'and', u'back', u',', u'and', u'the', u'varnish', u'which', u'coats', u'its', u'outside', u'surface', u'.'], u'lemmas': [u'the', u'``', u'voice', u"''", u'of', u'a', u'violin', u'depend', u'on', u'its', u'shape', u',', u'the', u'wood', u'it', u'be', u'make', u'from', u',', u'the', u'graduation', u'-lrb-', u'the', u'thickness', u'profile', u'-rrb-', u'of', u'both', u'the', u'top', u'and', u'back', u',', u'and', u'the', u'varnish', u'which', u'coat', u'its', u'outside', u'surface', u'.'], u'pos': [u'DT', u'``', u'NN', u"''", u'IN', u'DT', u'NN', u'VBZ', u'IN', u'PRP$', u'NN', u',', u'DT', u'NN', u'PRP', u'VBZ', u'VBN', u'IN', u',', u'DT', u'NN', u'-LRB-', u'DT', u'NN', u'NN', u'-RRB-', u'IN', u'CC', u'DT', u'JJ', u'CC', u'RB', u',', u'CC', u'DT', u'NN', u'WDT', u'NNS', u'PRP$', u'JJ', u'NN', u'.'], u'char_offsets': [[5788, 5791], [5792, 5793], [5793, 5798], [5798, 5799], [5800, 5802], [5803, 5804], [5805, 5811], [5812, 5819], [5820, 5822], [5823, 5826], [5827, 5832], [5832, 5833], [5834, 5837], [5838, 5842], [5843, 5845], [5846, 5848], [5849, 5853], [5854, 5858], [5858, 5859], [5860, 5863], [5864, 5874], [5875, 5876], [5876, 5879], [5880, 5889], [5890, 5897], [5897, 5898], [5899, 5901], [5902, 5906], [5907, 5910], [5911, 5914], [5915, 5918], [5919, 5923], [5923, 5924], [5925, 5928], [5929, 5932], [5933, 5940], [5941, 5946], [5947, 5952], [5953, 5956], [5957, 5964], [5965, 5972], [5972, 5973]]}) 
answer: set([u'like', u'hourglass'])
candidate Sentence: (0.10012640058994293, {u'tokens': [u'Hins-Anders', u'painted', u'by', u'Anders', u'Zorn', u',', u'1904', u'Like', u'many', u'other', u'instruments', u'used', u'in', u'classical', u'music', u',', u'the', u'violin', u'descends', u'from', u'remote', u'ancestors', u'that', u'were', u'used', u'for', u'folk', u'music', u'.'], u'lemmas': [u'Hins-Anders', u'paint', u'by', u'Anders', u'Zorn', u',', u'1904', u'like', u'many', u'other', u'instrument', u'use', u'in', u'classical', u'music', u',', u'the', u'violin', u'descend', u'from', u'remote', u'ancestor', u'that', u'be', u'use', u'for', u'folk', u'music', u'.'], u'pos': [u'NNP', u'VBN', u'IN', u'NNP', u'NNP', u',', u'CD', u'IN', u'JJ', u'JJ', u'NNS', u'VBN', u'IN', u'JJ', u'NN', u',', u'DT', u'NN', u'VBZ', u'IN', u'JJ', u'NNS', u'WDT', u'VBD', u'VBN', u'IN', u'NN', u'NN', u'.'], u'char_offsets': [[38506, 38517], [38518, 38525], [38526, 38528], [38529, 38535], [38536, 38540], [38540, 38541], [38542, 38546], [38547, 38551], [38552, 38556], [38557, 38562], [38563, 38574], [38575, 38579], [38580, 38582], [38583, 38592], [38593, 38598], [38598, 38599], [38600, 38603], [38604, 38610], [38611, 38619], [38620, 38624], [38625, 38631], [38632, 38641], [38642, 38646], [38647, 38651], [38652, 38656], [38657, 38660], [38661, 38665], [38666, 38671], [38671, 38672]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.082919992506504059, {u'tokens': [u'An', u'electric', u'violin', u'is', u'a', u'violin', u'equipped', u'with', u'an', u'electric', u'signal', u'output', u'of', u'its', u'sound', u',', u'and', u'is', u'generally', u'considered', u'to', u'be', u'a', u'specially', u'constructed', u'instrument', u'which', u'can', u'either', u'be', u':', u'*', u'an', u'electro-acoustic', u'violin', u'capable', u'of', u'producing', u'both', u'acoustic', u'sound', u'and', u'electric', u'signal', u'*', u'an', u'electric', u'violin', u'capable', u'of', u'producing', u'only', u'electric', u'signal', u'To', u'be', u'effective', u'as', u'an', u'acoustic', u'violin', u',', u'electro-acoustic', u'violins', u'retain', u'much', u'of', u'the', u'resonating', u'body', u'of', u'the', u'violin', u',', u'often', u'looking', u'very', u'much', u'like', u',', u'sometimes', u'even', u'identical', u'to', u',', u'an', u'acoustic', u'violin', u'or', u'fiddle', u'.'], u'lemmas': [u'a', u'electric', u'violin', u'be', u'a', u'violin', u'equip', u'with', u'a', u'electric', u'signal', u'output', u'of', u'its', u'sound', u',', u'and', u'be', u'generally', u'consider', u'to', u'be', u'a', u'specially', u'construct', u'instrument', u'which', u'can', u'either', u'be', u':', u'*', u'a', u'electro-acoustic', u'violin', u'capable', u'of', u'produce', u'both', u'acoustic', u'sound', u'and', u'electric', u'signal', u'*', u'a', u'electric', u'violin', u'capable', u'of', u'produce', u'only', u'electric', u'signal', u'to', u'be', u'effective', u'as', u'a', u'acoustic', u'violin', u',', u'electro-acoustic', u'violin', u'retain', u'much', u'of', u'the', u'resonate', u'body', u'of', u'the', u'violin', u',', u'often', u'look', u'very', u'much', u'like', u',', u'sometimes', u'even', u'identical', u'to', u',', u'a', u'acoustic', u'violin', u'or', u'fiddle', u'.'], u'pos': [u'DT', u'JJ', u'NN', u'VBZ', u'DT', u'NN', u'VBN', u'IN', u'DT', u'JJ', u'NN', u'NN', u'IN', u'PRP$', u'NN', u',', u'CC', u'VBZ', u'RB', u'VBN', u'TO', u'VB', u'DT', u'RB', u'VBN', u'NN', u'WDT', u'MD', u'RB', u'VB', u':', u'SYM', u'DT', u'JJ', u'NN', u'JJ', u'IN', u'VBG', u'CC', u'JJ', u'NN', u'CC', u'JJ', u'NN', u'SYM', u'DT', u'JJ', u'NN', u'JJ', u'IN', u'VBG', u'RB', u'JJ', u'NN', u'TO', u'VB', u'JJ', u'IN', u'DT', u'JJ', u'NN', u',', u'JJ', u'NNS', u'VBP', u'RB', u'IN', u'DT', u'VBG', u'NN', u'IN', u'DT', u'NN', u',', u'RB', u'VBG', u'RB', u'RB', u'IN', u',', u'RB', u'RB', u'JJ', u'TO', u',', u'DT', u'JJ', u'NN', u'CC', u'NN', u'.'], u'char_offsets': [[40040, 40042], [40043, 40051], [40052, 40058], [40059, 40061], [40062, 40063], [40064, 40070], [40071, 40079], [40080, 40084], [40085, 40087], [40088, 40096], [40097, 40103], [40104, 40110], [40111, 40113], [40114, 40117], [40118, 40123], [40123, 40124], [40125, 40128], [40129, 40131], [40132, 40141], [40142, 40152], [40153, 40155], [40156, 40158], [40159, 40160], [40161, 40170], [40171, 40182], [40183, 40193], [40194, 40199], [40200, 40203], [40204, 40210], [40211, 40213], [40213, 40214], [40215, 40216], [40217, 40219], [40220, 40236], [40237, 40243], [40244, 40251], [40252, 40254], [40255, 40264], [40265, 40269], [40270, 40278], [40279, 40284], [40285, 40288], [40289, 40297], [40298, 40304], [40305, 40306], [40307, 40309], [40310, 40318], [40319, 40325], [40326, 40333], [40334, 40336], [40337, 40346], [40347, 40351], [40352, 40360], [40361, 40367], [40368, 40370], [40371, 40373], [40374, 40383], [40384, 40386], [40387, 40389], [40390, 40398], [40399, 40405], [40405, 40406], [40407, 40423], [40424, 40431], [40432, 40438], [40439, 40443], [40444, 40446], [40447, 40450], [40451, 40461], [40462, 40466], [40467, 40469], [40470, 40473], [40474, 40480], [40480, 40481], [40482, 40487], [40488, 40495], [40496, 40500], [40501, 40505], [40506, 40510], [40510, 40511], [40512, 40521], [40522, 40526], [40527, 40536], [40537, 40539], [40539, 40540], [40541, 40543], [40544, 40552], [40553, 40559], [40560, 40562], [40563, 40569], [40569, 40570]]}) 
answer: set([u'shape', u'hourglass'])
candidate Sentence: (0.079056888818740845, {u'tokens': [u'The', u'tailpiece', u'anchors', u'the', u'strings', u'to', u'the', u'lower', u'bout', u'of', u'the', u'violin', u'by', u'means', u'of', u'the', u'tailgut', u',', u'which', u'loops', u'around', u'an', u'ebony', u'button', u'called', u'the', u'tailpin', u'-LRB-', u'sometimes', u'confusingly', u'called', u'``', u'endpin', u"''", u'like', u'the', u'cello', u"'s", u'spike', u'-RRB-', u',', u'which', u'fits', u'into', u'a', u'tapered', u'hole', u'in', u'the', u'bottom', u'block', u'.'], u'lemmas': [u'the', u'tailpiece', u'anchor', u'the', u'string', u'to', u'the', u'lower', u'bout', u'of', u'the', u'violin', u'by', u'means', u'of', u'the', u'tailgut', u',', u'which', u'loop', u'around', u'a', u'ebony', u'button', u'call', u'the', u'tailpin', u'-lrb-', u'sometimes', u'confusingly', u'call', u'``', u'endpin', u"''", u'like', u'the', u'cello', u"'s", u'spike', u'-rrb-', u',', u'which', u'fit', u'into', u'a', u'tapered', u'hole', u'in', u'the', u'bottom', u'block', u'.'], u'pos': [u'DT', u'NN', u'NNS', u'DT', u'NNS', u'TO', u'DT', u'JJR', u'NN', u'IN', u'DT', u'NN', u'IN', u'NNS', u'IN', u'DT', u'NN', u',', u'WDT', u'NNS', u'IN', u'DT', u'NN', u'NN', u'VBD', u'DT', u'NN', u'-LRB-', u'RB', u'RB', u'VBN', u'``', u'NN', u"''", u'IN', u'DT', u'NN', u'POS', u'NN', u'-RRB-', u',', u'WDT', u'VBZ', u'IN', u'DT', u'JJ', u'NN', u'IN', u'DT', u'JJ', u'NN', u'.'], u'char_offsets': [[8430, 8433], [8434, 8443], [8444, 8451], [8452, 8455], [8456, 8463], [8464, 8466], [8467, 8470], [8471, 8476], [8477, 8481], [8482, 8484], [8485, 8488], [8489, 8495], [8496, 8498], [8499, 8504], [8505, 8507], [8508, 8511], [8512, 8519], [8519, 8520], [8521, 8526], [8527, 8532], [8533, 8539], [8540, 8542], [8543, 8548], [8549, 8555], [8556, 8562], [8563, 8566], [8567, 8574], [8575, 8576], [8576, 8585], [8586, 8597], [8598, 8604], [8605, 8606], [8606, 8612], [8612, 8613], [8614, 8618], [8619, 8622], [8623, 8628], [8628, 8630], [8631, 8636], [8636, 8637], [8637, 8638], [8639, 8644], [8645, 8649], [8650, 8654], [8655, 8656], [8657, 8664], [8665, 8669], [8670, 8672], [8673, 8676], [8677, 8683], [8684, 8689], [8689, 8690]]}) 
answer: set([u'shape', u'hourglass'])

Is the violin shaped like an hourglass?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes.
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes.')
 +    where 'Yes.' = <src.question_processing.Question_parser instance at 0x1114e1a28>.answer
_____________________________ test_yesno[param338] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e4098>, (<src.tfidf.TF_IDF object at 0x10a4b0f10>, set(['zebra'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('yes')
E                +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114e4098>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.31900358200073242, {u'tokens': [u'In', u'captivity', u',', u'Plains', u'Zebras', u'have', u'been', u'crossed', u'with', u'Mountain', u'zebras', u'.'], u'lemmas': [u'in', u'captivity', u',', u'Plains', u'Zebras', u'have', u'be', u'cross', u'with', u'Mountain', u'zebra', u'.'], u'pos': [u'IN', u'NN', u',', u'NNP', u'NNPS', u'VBP', u'VBN', u'VBN', u'IN', u'NNP', u'NNS', u'.'], u'char_offsets': [[4534, 4536], [4537, 4546], [4546, 4547], [4548, 4554], [4555, 4561], [4562, 4566], [4567, 4571], [4572, 4579], [4580, 4584], [4585, 4593], [4594, 4600], [4600, 4601]]}) 
answer: set([u'plain'])
candidate Sentence: (0.24329592287540436, {u'tokens': [u'Mountain', u'zebras', u'and', u'Plains', u'zebras', u'live', u'in', u'groups', u',', u'known', u'as', u'`', u'harems', u"'", u',', u'consisting', u'of', u'one', u'stallion', u'with', u'up', u'to', u'six', u'mares', u'and', u'their', u'foals', u'.'], u'lemmas': [u'Mountain', u'zebra', u'and', u'plain', u'zebra', u'live', u'in', u'group', u',', u'know', u'as', u'`', u'harem', u"'", u',', u'consist', u'of', u'one', u'stallion', u'with', u'up', u'to', u'six', u'mare', u'and', u'they', u'foal', u'.'], u'pos': [u'NNP', u'NNS', u'CC', u'NNS', u'NNS', u'VBP', u'IN', u'NNS', u',', u'VBN', u'IN', u'``', u'NNS', u"''", u',', u'VBG', u'IN', u'CD', u'NN', u'IN', u'RB', u'TO', u'CD', u'NNS', u'CC', u'PRP$', u'NNS', u'.'], u'char_offsets': [[8331, 8339], [8340, 8346], [8347, 8350], [8351, 8357], [8358, 8364], [8365, 8369], [8370, 8372], [8373, 8379], [8379, 8380], [8381, 8386], [8387, 8389], [8390, 8391], [8391, 8397], [8397, 8398], [8398, 8399], [8400, 8410], [8411, 8413], [8414, 8417], [8418, 8426], [8427, 8431], [8432, 8434], [8435, 8437], [8438, 8441], [8442, 8447], [8448, 8451], [8452, 8457], [8458, 8463], [8463, 8464]]}) 
answer: set([u'cross'])
candidate Sentence: (0.20122319459915161, {u'tokens': [u'The', u'Cape', u'mountain', u'zebra', u'was', u'hunted', u'to', u'near', u'extinction', u'with', u'less', u'than', u'100', u'individuals', u'by', u'the', u'1930s', u'.'], u'lemmas': [u'the', u'Cape', u'mountain', u'zebra', u'be', u'hunt', u'to', u'near', u'extinction', u'with', u'less', u'than', u'100', u'individual', u'by', u'the', u'1930', u'.'], u'pos': [u'DT', u'NNP', u'NN', u'NN', u'VBD', u'VBN', u'TO', u'IN', u'NN', u'IN', u'JJR', u'IN', u'CD', u'NNS', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[12351, 12354], [12355, 12359], [12360, 12368], [12369, 12374], [12375, 12378], [12379, 12385], [12386, 12388], [12389, 12393], [12394, 12404], [12405, 12409], [12410, 12414], [12415, 12419], [12420, 12423], [12424, 12435], [12436, 12438], [12439, 12442], [12443, 12448], [12448, 12449]]}) 
answer: set([u'plain', u'cross'])
candidate Sentence: (0.18909837305545807, {u'tokens': [u'The', u'``', u'zebra', u'crossing', u"''", u'is', u'named', u'after', u'the', u'zebra', u"'s", u'black', u'and', u'white', u'stripes', u'.'], u'lemmas': [u'the', u'``', u'zebra', u'cross', u"''", u'be', u'name', u'after', u'the', u'zebra', u"'s", u'black', u'and', u'white', u'stripe', u'.'], u'pos': [u'DT', u'``', u'NN', u'VBG', u"''", u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'POS', u'JJ', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[5449, 5452], [5453, 5454], [5454, 5459], [5460, 5468], [5468, 5469], [5470, 5472], [5473, 5478], [5479, 5484], [5485, 5488], [5489, 5494], [5494, 5496], [5497, 5502], [5503, 5506], [5507, 5512], [5513, 5520], [5520, 5521]]}) 
answer: set([u'mountain', u'plain'])
candidate Sentence: (0.13734087347984314, {u'tokens': [u'They', u'can', u'be', u'found', u'in', u'a', u'variety', u'of', u'habitats', u',', u'such', u'as', u'grasslands', u',', u'savannas', u',', u'woodlands', u',', u'thorny', u'scrublands', u',', u'mountains', u'and', u'coastal', u'hills', u'.'], u'lemmas': [u'they', u'can', u'be', u'find', u'in', u'a', u'variety', u'of', u'habitat', u',', u'such', u'as', u'grassland', u',', u'savanna', u',', u'woodland', u',', u'thorny', u'scrubland', u',', u'mountain', u'and', u'coastal', u'hill', u'.'], u'pos': [u'PRP', u'MD', u'VB', u'VBN', u'IN', u'DT', u'NN', u'IN', u'NNS', u',', u'JJ', u'IN', u'NNS', u',', u'NNS', u',', u'NNS', u',', u'JJ', u'NNS', u',', u'NNS', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[1023, 1027], [1028, 1031], [1032, 1034], [1035, 1040], [1041, 1043], [1044, 1045], [1046, 1053], [1054, 1056], [1057, 1065], [1065, 1066], [1067, 1071], [1072, 1074], [1075, 1085], [1085, 1086], [1087, 1095], [1095, 1096], [1097, 1106], [1106, 1107], [1108, 1114], [1115, 1125], [1125, 1126], [1127, 1136], [1137, 1140], [1141, 1148], [1149, 1154], [1154, 1155]]}) 
answer: set([u'plain', u'cross'])
candidate Sentence: (0.10976560413837433, {u'tokens': [u'In', u'captivity', u',', u'crosses', u'between', u'zebras', u'and', u'other', u'-LRB-', u'non-zebra', u'-RRB-', u'equines', u'have', u'produced', u'several', u'distinct', u'hybrids', u',', u'including', u'the', u'zebroid', u',', u'zeedonk', u',', u'zony', u',', u'and', u'zorse', u'.'], u'lemmas': [u'in', u'captivity', u',', u'cross', u'between', u'zebra', u'and', u'other', u'-lrb-', u'non-zebra', u'-rrb-', u'equine', u'have', u'produce', u'several', u'distinct', u'hybrid', u',', u'include', u'the', u'zebroid', u',', u'zeedonk', u',', u'zony', u',', u'and', u'zorse', u'.'], u'pos': [u'IN', u'NN', u',', u'VBZ', u'IN', u'NNS', u'CC', u'JJ', u'-LRB-', u'JJ', u'-RRB-', u'NNS', u'VBP', u'VBN', u'JJ', u'JJ', u'NNS', u',', u'VBG', u'DT', u'NN', u',', u'NN', u',', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[4834, 4836], [4837, 4846], [4846, 4847], [4848, 4855], [4856, 4863], [4864, 4870], [4871, 4874], [4875, 4880], [4881, 4882], [4882, 4891], [4891, 4892], [4893, 4900], [4901, 4905], [4906, 4914], [4915, 4922], [4923, 4931], [4932, 4939], [4939, 4940], [4941, 4950], [4951, 4954], [4955, 4962], [4962, 4963], [4964, 4971], [4971, 4972], [4973, 4977], [4977, 4978], [4979, 4982], [4983, 4988], [4988, 4989]]}) 
answer: set([u'plain', u'mountain'])
candidate Sentence: (0.10469187051057816, {u'tokens': [u'For', u'this', u'reason', u',', u'zebra-mules', u'or', u'zebroids', u'-LRB-', u'crosses', u'between', u'any', u'species', u'of', u'zebra', u'and', u'a', u'horse', u',', u'pony', u',', u'donkey', u'or', u'ass', u'-RRB-', u'are', u'preferred', u'over', u'pure-bred', u'zebras', u'.'], u'lemmas': [u'for', u'this', u'reason', u',', u'zebra-mule', u'or', u'zebroid', u'-lrb-', u'cross', u'between', u'any', u'species', u'of', u'zebra', u'and', u'a', u'horse', u',', u'pony', u',', u'donkey', u'or', u'ass', u'-rrb-', u'be', u'prefer', u'over', u'pure-bred', u'zebra', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'NNS', u'CC', u'NNS', u'-LRB-', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'NN', u'CC', u'DT', u'NN', u',', u'NN', u',', u'NN', u'CC', u'NN', u'-RRB-', u'VBP', u'VBN', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[11061, 11064], [11065, 11069], [11070, 11076], [11076, 11077], [11078, 11089], [11090, 11092], [11093, 11101], [11102, 11103], [11103, 11110], [11111, 11118], [11119, 11122], [11123, 11130], [11131, 11133], [11134, 11139], [11140, 11143], [11144, 11145], [11146, 11151], [11151, 11152], [11153, 11157], [11157, 11158], [11159, 11165], [11166, 11168], [11169, 11172], [11172, 11173], [11174, 11177], [11178, 11187], [11188, 11192], [11193, 11202], [11203, 11209], [11209, 11210]]}) 
answer: set([u'mountain', u'plain'])
candidate Sentence: (0.086976878345012665, {u'tokens': [u'A', u'zebra', u'feeding', u'on', u'grass', u'Zebras', u'communicate', u'with', u'each', u'other', u'with', u'high', u'pitched', u'barks', u'and', u'whinnying', u'.'], u'lemmas': [u'a', u'zebra', u'feeding', u'on', u'grass', u'zebra', u'communicate', u'with', u'each', u'other', u'with', u'high', u'pitched', u'bark', u'and', u'whinnying', u'.'], u'pos': [u'DT', u'NN', u'NN', u'IN', u'NN', u'NNS', u'VBP', u'IN', u'DT', u'JJ', u'IN', u'JJ', u'JJ', u'NNS', u'CC', u'JJ', u'.'], u'char_offsets': [[9165, 9166], [9167, 9172], [9173, 9180], [9181, 9183], [9184, 9189], [9190, 9196], [9197, 9208], [9209, 9213], [9214, 9218], [9219, 9224], [9225, 9229], [9230, 9234], [9235, 9242], [9243, 9248], [9249, 9252], [9253, 9262], [9262, 9263]]}) 
answer: set([u'mountain', u'cross', u'plain'])
candidate Sentence: (0.082824468612670898, {u'tokens': [u'It', u'was', u'previously', u'believed', u'that', u'zebras', u'were', u'white', u'animals', u'with', u'black', u'stripes', u'since', u'some', u'zebras', u'have', u'white', u'underbellies', u'.'], u'lemmas': [u'it', u'be', u'previously', u'believe', u'that', u'zebra', u'be', u'white', u'animal', u'with', u'black', u'stripe', u'since', u'some', u'zebra', u'have', u'white', u'underbelly', u'.'], u'pos': [u'PRP', u'VBD', u'RB', u'VBN', u'IN', u'NNS', u'VBD', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NNS', u'VBP', u'JJ', u'NNS', u'.'], u'char_offsets': [[4990, 4992], [4993, 4996], [4997, 5007], [5008, 5016], [5017, 5021], [5022, 5028], [5029, 5033], [5034, 5039], [5040, 5047], [5048, 5052], [5053, 5058], [5059, 5066], [5067, 5072], [5073, 5077], [5078, 5084], [5085, 5089], [5090, 5095], [5096, 5108], [5108, 5109]]}) 
answer: set([u'mountain', u'cross', u'plain'])
candidate Sentence: (0.060698788613080978, {u'tokens': [u'Grevy', u"'s", u'zebra', u'is', u'believed', u'to', u'have', u'been', u'the', u'first', u'zebra', u'species', u'to', u'emerge', u'.'], u'lemmas': [u'Grevy', u"'s", u'zebra', u'be', u'believe', u'to', u'have', u'be', u'the', u'first', u'zebra', u'species', u'to', u'emerge', u'.'], u'pos': [u'NNP', u'POS', u'NN', u'VBZ', u'VBN', u'TO', u'VB', u'VBN', u'DT', u'JJ', u'NN', u'NNS', u'TO', u'VB', u'.'], u'char_offsets': [[1738, 1743], [1743, 1745], [1746, 1751], [1752, 1754], [1755, 1763], [1764, 1766], [1767, 1771], [1772, 1776], [1777, 1780], [1781, 1786], [1787, 1792], [1793, 1800], [1801, 1803], [1804, 1810], [1810, 1811]]}) 
answer: set([u'mountain', u'cross', u'plain'])

Have plains zebras been crossed with mountain zebras?
Validity= False
Question Type = NA
Answer Type = NA
Answer = yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('yes')
 +    where 'yes' = <src.question_processing.Question_parser instance at 0x1114e4098>.answer
_____________________________ test_yesno[param339] _____________________________

param = (<src.question_processing.Question_parser instance at 0x1114e4128>, (<src.tfidf.TF_IDF object at 0x10a4b0f10>, set(['zebra'])))

    def test_yesno(param):
        qpobj = param[0]
        stopLemmasSet = getStopLemmas()
        objTfidf,titleLemmasSet = param[1]
        questionProcess = Question_parser(qpobj.question)
        # if questionProcess.qtype != "BOOLEAN" or questionProcess.difficulty =="NA" or qpobj.difficulty == "NA" or questionProcess.answer_type== "NA":
        #     return
        if questionProcess.valid: #questionProcess.difficulty == "easy" :
            try:
                interestingText = objTfidf.getInterestingText(qpobj.question)
                ans = answerYesNo(qpobj.question, interestingText, questionProcess, titleLemmasSet,stopLemmasSet)
                # assert True == str2bool(qpobj.answer)
                assert str2bool(qpobj.answer)== str2bool(ans)
                # assert False == True
            except Exception, e:
                traceback.print_exc()
                print qpobj
                print ans
>               raise e
E               assert True == str2bool('No')
E                +  where True = str2bool('Yes')
E                +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114e4128>.answer

test_compute.py:40: AssertionError
----------------------------- Captured stdout call -----------------------------
candidate Sentence: (0.31900358200073242, {u'tokens': [u'In', u'captivity', u',', u'Plains', u'Zebras', u'have', u'been', u'crossed', u'with', u'Mountain', u'zebras', u'.'], u'lemmas': [u'in', u'captivity', u',', u'Plains', u'Zebras', u'have', u'be', u'cross', u'with', u'Mountain', u'zebra', u'.'], u'pos': [u'IN', u'NN', u',', u'NNP', u'NNPS', u'VBP', u'VBN', u'VBN', u'IN', u'NNP', u'NNS', u'.'], u'char_offsets': [[4534, 4536], [4537, 4546], [4546, 4547], [4548, 4554], [4555, 4561], [4562, 4566], [4567, 4571], [4572, 4579], [4580, 4584], [4585, 4593], [4594, 4600], [4600, 4601]]}) 
answer: set([u'plain'])
candidate Sentence: (0.24329592287540436, {u'tokens': [u'Mountain', u'zebras', u'and', u'Plains', u'zebras', u'live', u'in', u'groups', u',', u'known', u'as', u'`', u'harems', u"'", u',', u'consisting', u'of', u'one', u'stallion', u'with', u'up', u'to', u'six', u'mares', u'and', u'their', u'foals', u'.'], u'lemmas': [u'Mountain', u'zebra', u'and', u'plain', u'zebra', u'live', u'in', u'group', u',', u'know', u'as', u'`', u'harem', u"'", u',', u'consist', u'of', u'one', u'stallion', u'with', u'up', u'to', u'six', u'mare', u'and', u'they', u'foal', u'.'], u'pos': [u'NNP', u'NNS', u'CC', u'NNS', u'NNS', u'VBP', u'IN', u'NNS', u',', u'VBN', u'IN', u'``', u'NNS', u"''", u',', u'VBG', u'IN', u'CD', u'NN', u'IN', u'RB', u'TO', u'CD', u'NNS', u'CC', u'PRP$', u'NNS', u'.'], u'char_offsets': [[8331, 8339], [8340, 8346], [8347, 8350], [8351, 8357], [8358, 8364], [8365, 8369], [8370, 8372], [8373, 8379], [8379, 8380], [8381, 8386], [8387, 8389], [8390, 8391], [8391, 8397], [8397, 8398], [8398, 8399], [8400, 8410], [8411, 8413], [8414, 8417], [8418, 8426], [8427, 8431], [8432, 8434], [8435, 8437], [8438, 8441], [8442, 8447], [8448, 8451], [8452, 8457], [8458, 8463], [8463, 8464]]}) 
answer: set([u'cross'])
candidate Sentence: (0.20122319459915161, {u'tokens': [u'The', u'Cape', u'mountain', u'zebra', u'was', u'hunted', u'to', u'near', u'extinction', u'with', u'less', u'than', u'100', u'individuals', u'by', u'the', u'1930s', u'.'], u'lemmas': [u'the', u'Cape', u'mountain', u'zebra', u'be', u'hunt', u'to', u'near', u'extinction', u'with', u'less', u'than', u'100', u'individual', u'by', u'the', u'1930', u'.'], u'pos': [u'DT', u'NNP', u'NN', u'NN', u'VBD', u'VBN', u'TO', u'IN', u'NN', u'IN', u'JJR', u'IN', u'CD', u'NNS', u'IN', u'DT', u'NNS', u'.'], u'char_offsets': [[12351, 12354], [12355, 12359], [12360, 12368], [12369, 12374], [12375, 12378], [12379, 12385], [12386, 12388], [12389, 12393], [12394, 12404], [12405, 12409], [12410, 12414], [12415, 12419], [12420, 12423], [12424, 12435], [12436, 12438], [12439, 12442], [12443, 12448], [12448, 12449]]}) 
answer: set([u'plain', u'cross'])
candidate Sentence: (0.18909837305545807, {u'tokens': [u'The', u'``', u'zebra', u'crossing', u"''", u'is', u'named', u'after', u'the', u'zebra', u"'s", u'black', u'and', u'white', u'stripes', u'.'], u'lemmas': [u'the', u'``', u'zebra', u'cross', u"''", u'be', u'name', u'after', u'the', u'zebra', u"'s", u'black', u'and', u'white', u'stripe', u'.'], u'pos': [u'DT', u'``', u'NN', u'VBG', u"''", u'VBZ', u'VBN', u'IN', u'DT', u'NN', u'POS', u'JJ', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[5449, 5452], [5453, 5454], [5454, 5459], [5460, 5468], [5468, 5469], [5470, 5472], [5473, 5478], [5479, 5484], [5485, 5488], [5489, 5494], [5494, 5496], [5497, 5502], [5503, 5506], [5507, 5512], [5513, 5520], [5520, 5521]]}) 
answer: set([u'mountain', u'plain'])
candidate Sentence: (0.13734087347984314, {u'tokens': [u'They', u'can', u'be', u'found', u'in', u'a', u'variety', u'of', u'habitats', u',', u'such', u'as', u'grasslands', u',', u'savannas', u',', u'woodlands', u',', u'thorny', u'scrublands', u',', u'mountains', u'and', u'coastal', u'hills', u'.'], u'lemmas': [u'they', u'can', u'be', u'find', u'in', u'a', u'variety', u'of', u'habitat', u',', u'such', u'as', u'grassland', u',', u'savanna', u',', u'woodland', u',', u'thorny', u'scrubland', u',', u'mountain', u'and', u'coastal', u'hill', u'.'], u'pos': [u'PRP', u'MD', u'VB', u'VBN', u'IN', u'DT', u'NN', u'IN', u'NNS', u',', u'JJ', u'IN', u'NNS', u',', u'NNS', u',', u'NNS', u',', u'JJ', u'NNS', u',', u'NNS', u'CC', u'JJ', u'NNS', u'.'], u'char_offsets': [[1023, 1027], [1028, 1031], [1032, 1034], [1035, 1040], [1041, 1043], [1044, 1045], [1046, 1053], [1054, 1056], [1057, 1065], [1065, 1066], [1067, 1071], [1072, 1074], [1075, 1085], [1085, 1086], [1087, 1095], [1095, 1096], [1097, 1106], [1106, 1107], [1108, 1114], [1115, 1125], [1125, 1126], [1127, 1136], [1137, 1140], [1141, 1148], [1149, 1154], [1154, 1155]]}) 
answer: set([u'plain', u'cross'])
candidate Sentence: (0.10976560413837433, {u'tokens': [u'In', u'captivity', u',', u'crosses', u'between', u'zebras', u'and', u'other', u'-LRB-', u'non-zebra', u'-RRB-', u'equines', u'have', u'produced', u'several', u'distinct', u'hybrids', u',', u'including', u'the', u'zebroid', u',', u'zeedonk', u',', u'zony', u',', u'and', u'zorse', u'.'], u'lemmas': [u'in', u'captivity', u',', u'cross', u'between', u'zebra', u'and', u'other', u'-lrb-', u'non-zebra', u'-rrb-', u'equine', u'have', u'produce', u'several', u'distinct', u'hybrid', u',', u'include', u'the', u'zebroid', u',', u'zeedonk', u',', u'zony', u',', u'and', u'zorse', u'.'], u'pos': [u'IN', u'NN', u',', u'VBZ', u'IN', u'NNS', u'CC', u'JJ', u'-LRB-', u'JJ', u'-RRB-', u'NNS', u'VBP', u'VBN', u'JJ', u'JJ', u'NNS', u',', u'VBG', u'DT', u'NN', u',', u'NN', u',', u'NN', u',', u'CC', u'NN', u'.'], u'char_offsets': [[4834, 4836], [4837, 4846], [4846, 4847], [4848, 4855], [4856, 4863], [4864, 4870], [4871, 4874], [4875, 4880], [4881, 4882], [4882, 4891], [4891, 4892], [4893, 4900], [4901, 4905], [4906, 4914], [4915, 4922], [4923, 4931], [4932, 4939], [4939, 4940], [4941, 4950], [4951, 4954], [4955, 4962], [4962, 4963], [4964, 4971], [4971, 4972], [4973, 4977], [4977, 4978], [4979, 4982], [4983, 4988], [4988, 4989]]}) 
answer: set([u'plain', u'mountain'])
candidate Sentence: (0.10469187051057816, {u'tokens': [u'For', u'this', u'reason', u',', u'zebra-mules', u'or', u'zebroids', u'-LRB-', u'crosses', u'between', u'any', u'species', u'of', u'zebra', u'and', u'a', u'horse', u',', u'pony', u',', u'donkey', u'or', u'ass', u'-RRB-', u'are', u'preferred', u'over', u'pure-bred', u'zebras', u'.'], u'lemmas': [u'for', u'this', u'reason', u',', u'zebra-mule', u'or', u'zebroid', u'-lrb-', u'cross', u'between', u'any', u'species', u'of', u'zebra', u'and', u'a', u'horse', u',', u'pony', u',', u'donkey', u'or', u'ass', u'-rrb-', u'be', u'prefer', u'over', u'pure-bred', u'zebra', u'.'], u'pos': [u'IN', u'DT', u'NN', u',', u'NNS', u'CC', u'NNS', u'-LRB-', u'NNS', u'IN', u'DT', u'NNS', u'IN', u'NN', u'CC', u'DT', u'NN', u',', u'NN', u',', u'NN', u'CC', u'NN', u'-RRB-', u'VBP', u'VBN', u'IN', u'JJ', u'NNS', u'.'], u'char_offsets': [[11061, 11064], [11065, 11069], [11070, 11076], [11076, 11077], [11078, 11089], [11090, 11092], [11093, 11101], [11102, 11103], [11103, 11110], [11111, 11118], [11119, 11122], [11123, 11130], [11131, 11133], [11134, 11139], [11140, 11143], [11144, 11145], [11146, 11151], [11151, 11152], [11153, 11157], [11157, 11158], [11159, 11165], [11166, 11168], [11169, 11172], [11172, 11173], [11174, 11177], [11178, 11187], [11188, 11192], [11193, 11202], [11203, 11209], [11209, 11210]]}) 
answer: set([u'mountain', u'plain'])
candidate Sentence: (0.086976878345012665, {u'tokens': [u'A', u'zebra', u'feeding', u'on', u'grass', u'Zebras', u'communicate', u'with', u'each', u'other', u'with', u'high', u'pitched', u'barks', u'and', u'whinnying', u'.'], u'lemmas': [u'a', u'zebra', u'feeding', u'on', u'grass', u'zebra', u'communicate', u'with', u'each', u'other', u'with', u'high', u'pitched', u'bark', u'and', u'whinnying', u'.'], u'pos': [u'DT', u'NN', u'NN', u'IN', u'NN', u'NNS', u'VBP', u'IN', u'DT', u'JJ', u'IN', u'JJ', u'JJ', u'NNS', u'CC', u'JJ', u'.'], u'char_offsets': [[9165, 9166], [9167, 9172], [9173, 9180], [9181, 9183], [9184, 9189], [9190, 9196], [9197, 9208], [9209, 9213], [9214, 9218], [9219, 9224], [9225, 9229], [9230, 9234], [9235, 9242], [9243, 9248], [9249, 9252], [9253, 9262], [9262, 9263]]}) 
answer: set([u'mountain', u'cross', u'plain'])
candidate Sentence: (0.082824468612670898, {u'tokens': [u'It', u'was', u'previously', u'believed', u'that', u'zebras', u'were', u'white', u'animals', u'with', u'black', u'stripes', u'since', u'some', u'zebras', u'have', u'white', u'underbellies', u'.'], u'lemmas': [u'it', u'be', u'previously', u'believe', u'that', u'zebra', u'be', u'white', u'animal', u'with', u'black', u'stripe', u'since', u'some', u'zebra', u'have', u'white', u'underbelly', u'.'], u'pos': [u'PRP', u'VBD', u'RB', u'VBN', u'IN', u'NNS', u'VBD', u'JJ', u'NNS', u'IN', u'JJ', u'NNS', u'IN', u'DT', u'NNS', u'VBP', u'JJ', u'NNS', u'.'], u'char_offsets': [[4990, 4992], [4993, 4996], [4997, 5007], [5008, 5016], [5017, 5021], [5022, 5028], [5029, 5033], [5034, 5039], [5040, 5047], [5048, 5052], [5053, 5058], [5059, 5066], [5067, 5072], [5073, 5077], [5078, 5084], [5085, 5089], [5090, 5095], [5096, 5108], [5108, 5109]]}) 
answer: set([u'mountain', u'cross', u'plain'])
candidate Sentence: (0.060698788613080978, {u'tokens': [u'Grevy', u"'s", u'zebra', u'is', u'believed', u'to', u'have', u'been', u'the', u'first', u'zebra', u'species', u'to', u'emerge', u'.'], u'lemmas': [u'Grevy', u"'s", u'zebra', u'be', u'believe', u'to', u'have', u'be', u'the', u'first', u'zebra', u'species', u'to', u'emerge', u'.'], u'pos': [u'NNP', u'POS', u'NN', u'VBZ', u'VBN', u'TO', u'VB', u'VBN', u'DT', u'JJ', u'NN', u'NNS', u'TO', u'VB', u'.'], u'char_offsets': [[1738, 1743], [1743, 1745], [1746, 1751], [1752, 1754], [1755, 1763], [1764, 1766], [1767, 1771], [1772, 1776], [1777, 1780], [1781, 1786], [1787, 1792], [1793, 1800], [1801, 1803], [1804, 1810], [1810, 1811]]}) 
answer: set([u'mountain', u'cross', u'plain'])

Have plains zebras been crossed with mountain zebras?
Validity= False
Question Type = NA
Answer Type = NA
Answer = Yes
Difficulty = easy

No
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dhruv/Documents/Acads/sem2/nlp/NLP-project/tests/test_compute.py", line 34, in test_yesno
    assert str2bool(qpobj.answer)== str2bool(ans)
AssertionError: assert True == str2bool('No')
 +  where True = str2bool('Yes')
 +    where 'Yes' = <src.question_processing.Question_parser instance at 0x1114e4128>.answer
=============== 71 failed, 269 passed, 1 error in 47.79 seconds ================
